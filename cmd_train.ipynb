{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1660605939985,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"dymDs0Po0aES","outputId":"63a0df44-dcb4-42dc-c73b-3371a3644a55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Aug 15 23:23:23 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1181,"status":"ok","timestamp":1660605941153,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"EfCxDoEXuzgg","outputId":"21a4bc91-9935-44e8-e288-bba5a39b4408"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","source":["!python -m pip install bert-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bOeGCnRF9Cs","executionInfo":{"status":"ok","timestamp":1660605952113,"user_tz":-540,"elapsed":10965,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"46408f12-ce58-43c1-9e45-e5d8ca08ef53"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bert-score\n","  Downloading bert_score-0.3.11-py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert-score) (3.2.2)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.12.1+cu113)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.3.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert-score) (2.23.0)\n","Collecting transformers>=3.0.0numpy\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (4.64.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert-score) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert-score) (3.0.9)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert-score) (4.1.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 58.7 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 88.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (3.8.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert-score) (3.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (0.11.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, bert-score\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed bert-score-0.3.11 huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":454813,"status":"ok","timestamp":1660606406914,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"mshVPsrku0kd","outputId":"d4846a78-1486-4d61-f40f-3d60cf61da3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 12 kB/s \n","\u001b[?25hCollecting transformers==3.0.0\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[K     |████████████████████████████████| 754 kB 73.6 MB/s \n","\u001b[?25hCollecting torch_scatter==2.0.4\n","  Downloading torch_scatter-2.0.4.tar.gz (20 kB)\n","Collecting dgl==0.5.3\n","  Downloading dgl-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 24.4 MB/s \n","\u001b[?25hCollecting hydra==2.4\n","  Downloading Hydra-2.4.tar.gz (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 10.3 MB/s \n","\u001b[?25hCollecting omegaconf==2.2.2\n","  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 74.8 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 49.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2.23.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 66.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (4.64.0)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (2.6.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (1.7.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.2.2->-r requirements.txt (line 7)) (6.0)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 70.6 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.1.0)\n","Building wheels for collected packages: torch-scatter, hydra, antlr4-python3-runtime, sacremoses\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-scatter: filename=torch_scatter-2.0.4-cp37-cp37m-linux_x86_64.whl size=14800807 sha256=a0dcf4426e4a519052ff72cc63d97b24b2c3e261fd5fb16410fa3b23e2244cae\n","  Stored in directory: /root/.cache/pip/wheels/4a/3d/01/e408ecc11389070cbacee91b70c978bf3557130e9aaa18a95b\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.4-cp37-cp37m-linux_x86_64.whl size=219229 sha256=a8a35949c6c4e97162c9d9279dcea08203a3ae7cf6f4fb2cc5aba6e652d86504\n","  Stored in directory: /root/.cache/pip/wheels/f5/65/98/3603b340344bd22dfe1c809365013fc4d425d83d89c3e2cd17\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=d54239df8917376b51b3596003db065356d440c3b3e01be6c9497548236596b0\n","  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=0b3ccfb78d64b1767f0896c4cc0331572360108e4b0fdeb7ec0a692c071946d8\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built torch-scatter hydra antlr4-python3-runtime sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, antlr4-python3-runtime, transformers, torch-scatter, torch, omegaconf, hydra, dgl\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.21.1\n","    Uninstalling transformers-4.21.1:\n","      Successfully uninstalled transformers-4.21.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed antlr4-python3-runtime-4.9.3 dgl-0.5.3 hydra-2.4 omegaconf-2.2.2 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.0rc4 torch-1.8.0 torch-scatter-2.0.4 transformers-3.0.0\n"]}],"source":["!python -m pip install -r requirements.txt"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164927,"status":"ok","timestamp":1660606571818,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"G8LmQt_jcvSZ","outputId":"720e732b-c459-4097-89d2-bd70d5f6518f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 1.6 MB/s eta 0:12:17tcmalloc: large alloc 1147494400 bytes == 0x39568000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████▌               | 1055.7 MB 65.8 MB/s eta 0:00:15tcmalloc: large alloc 1434370048 bytes == 0x7dbbe000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.7 MB/s eta 0:06:57tcmalloc: large alloc 1792966656 bytes == 0x29f0000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 2.2 MB/s eta 0:02:40tcmalloc: large alloc 2241208320 bytes == 0x6d7d8000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf313a000 @  0x7f247bed71e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2551685120 bytes == 0x1e10a8000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 2041.3 MB 7.2 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 1.2 MB/s \n","\u001b[?25hCollecting torchaudio===0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.8.0\n","    Uninstalling torch-1.8.0:\n","      Successfully uninstalled torch-1.8.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}],"source":["!python -m pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":567,"status":"ok","timestamp":1660606572363,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"JJqgY88ou7Qp","outputId":"b395ab72-6a7a-45c9-bb30-b7aab8ff9fe1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch-scatter 2.0.4\n","Uninstalling torch-scatter-2.0.4:\n","  Successfully uninstalled torch-scatter-2.0.4\n"]}],"source":["!python -m pip uninstall torch-scatter -y"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6155,"status":"ok","timestamp":1660606578513,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"7c7V5B7yc9Cc","outputId":"a9318985-21c4-48c9-ffb6-d427430cf38b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 4.0 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.9\n"]}],"source":["!python -m pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":586,"status":"ok","timestamp":1660606579087,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"l2wm30u-c-i0","outputId":"5824397c-a614-4e58-8428-3ebd7c852bab"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.9\n"]}],"source":["!python -c \"import torch_scatter; print(torch_scatter.__version__)\""]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3259,"status":"ok","timestamp":1660606582334,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"GgPMOQSL4HVZ","outputId":"e7850895-c35f-448e-ff7e-b39c20934720"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.9.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.2.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core) (21.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core) (3.0.9)\n","Installing collected packages: hydra-core\n","Successfully installed hydra-core-1.2.0\n"]}],"source":["!pip install hydra-core --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1660203016899,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"FT5vluqcNpey","outputId":"fb6b583e-b039-4cef-cbf9-2bf97cee58d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZROa2w4NUfm"},"outputs":[],"source":["!python preprocess.py --dataset FB15kET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDB7erFzN4St"},"outputs":[],"source":["!python preprocess.py --dataset YAGO43kET"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1660634723701,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"hsnRA4_pUSzk","outputId":"7087e881-62a9-4249-f384-7a3b5bf641f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"586hjT34u-VB","outputId":"28c2c56c-209d-4270-8143-e6677ae911dd","executionInfo":{"status":"ok","timestamp":1660637599956,"user_tz":-540,"elapsed":2876265,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","run.py:18: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-16 07:23:13,537][HYDRA] Hydra 1.2.0\n","[2022-08-16 07:23:13,537][HYDRA] ===========\n","[2022-08-16 07:23:13,537][HYDRA] Installed Hydra Plugins\n","[2022-08-16 07:23:13,537][HYDRA] ***********************\n","[2022-08-16 07:23:13,537][HYDRA] \tConfigSource:\n","[2022-08-16 07:23:13,537][HYDRA] \t-------------\n","[2022-08-16 07:23:13,537][HYDRA] \t\tFileConfigSource\n","[2022-08-16 07:23:13,537][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-16 07:23:13,537][HYDRA] \t\tStructuredConfigSource\n","[2022-08-16 07:23:13,537][HYDRA] \tCompletionPlugin:\n","[2022-08-16 07:23:13,537][HYDRA] \t-----------------\n","[2022-08-16 07:23:13,538][HYDRA] \t\tBashCompletion\n","[2022-08-16 07:23:13,538][HYDRA] \t\tFishCompletion\n","[2022-08-16 07:23:13,538][HYDRA] \t\tZshCompletion\n","[2022-08-16 07:23:13,538][HYDRA] \tLauncher:\n","[2022-08-16 07:23:13,538][HYDRA] \t---------\n","[2022-08-16 07:23:13,538][HYDRA] \t\tBasicLauncher\n","[2022-08-16 07:23:13,538][HYDRA] \tSweeper:\n","[2022-08-16 07:23:13,538][HYDRA] \t--------\n","[2022-08-16 07:23:13,538][HYDRA] \t\tBasicSweeper\n","[2022-08-16 07:23:13,538][HYDRA] \n","[2022-08-16 07:23:13,538][HYDRA] Config search path\n","[2022-08-16 07:23:13,538][HYDRA] ******************\n","[2022-08-16 07:23:13,664][HYDRA] | Provider | Search path                                                           |\n","[2022-08-16 07:23:13,664][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-16 07:23:13,664][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-16 07:23:13,665][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-16 07:23:13,665][HYDRA] | schema   | structured://                                                         |\n","[2022-08-16 07:23:13,665][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-16 07:23:13,734][HYDRA] \n","[2022-08-16 07:23:13,734][HYDRA] Defaults Tree\n","[2022-08-16 07:23:13,734][HYDRA] *************\n","[2022-08-16 07:23:13,734][HYDRA] <root>:\n","[2022-08-16 07:23:13,734][HYDRA]   hydra/config:\n","[2022-08-16 07:23:13,734][HYDRA]     hydra/output: default\n","[2022-08-16 07:23:13,734][HYDRA]     hydra/launcher: basic\n","[2022-08-16 07:23:13,734][HYDRA]     hydra/sweeper: basic\n","[2022-08-16 07:23:13,734][HYDRA]     hydra/help: default\n","[2022-08-16 07:23:13,734][HYDRA]     hydra/hydra_help: default\n","[2022-08-16 07:23:13,734][HYDRA]     hydra/hydra_logging: default\n","[2022-08-16 07:23:13,734][HYDRA]     hydra/job_logging: default\n","[2022-08-16 07:23:13,735][HYDRA]     hydra/callbacks: null\n","[2022-08-16 07:23:13,735][HYDRA]     hydra/env: default\n","[2022-08-16 07:23:13,735][HYDRA]     _self_\n","[2022-08-16 07:23:13,735][HYDRA]   config:\n","[2022-08-16 07:23:13,735][HYDRA]     data/FB15kET\n","[2022-08-16 07:23:13,735][HYDRA]     model/Bart\n","[2022-08-16 07:23:13,735][HYDRA]     _self_\n","[2022-08-16 07:23:13,803][HYDRA] \n","[2022-08-16 07:23:13,804][HYDRA] Defaults List\n","[2022-08-16 07:23:13,804][HYDRA] *************\n","[2022-08-16 07:23:13,804][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-16 07:23:13,804][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-16 07:23:13,804][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-16 07:23:13,804][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-16 07:23:13,804][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-16 07:23:13,804][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-16 07:23:13,804][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-16 07:23:13,804][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-16 07:23:13,804][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-16 07:23:13,804][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-16 07:23:13,804][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-16 07:23:13,804][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-08-16 07:23:13,804][HYDRA] | model/Bart                  | model               | False  | config       |\n","[2022-08-16 07:23:13,804][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-16 07:23:13,804][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-16 07:23:13,922][HYDRA] Config\n","[2022-08-16 07:23:13,922][HYDRA] ******\n","[2022-08-16 07:23:13,926][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: false\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: Bart\n","  train_dataset: ET_train.txt\n","  pretrained_model: facebook/bart-base\n","  append_another_bos: false\n","  append_sep_token: true\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 256\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 256\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_test.txt\n","    save_outputs: true\n","    max_output_length: 128\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: save/FB15kET/ET_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-16 07:23:13,987][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 07:23:14,754][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-16 07:23:14,757][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 07:23:15,516][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-16 07:23:15,518][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-16 07:23:15,518][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-16 07:23:31,277][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 07:23:32,049][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 0\n","[2022-08-16 07:23:32,050][filelock][DEBUG] - Attempting to acquire lock 139633667103760 on /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb.lock\n","[2022-08-16 07:23:32,051][filelock][DEBUG] - Lock 139633667103760 acquired on /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb.lock\n","[2022-08-16 07:23:32,051][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpntjfpnkc\n","[2022-08-16 07:23:32,053][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 07:23:32,844][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 1553\n","Downloading: 100% 1.55k/1.55k [00:00<00:00, 1.39MB/s]\n","[2022-08-16 07:23:32,847][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json in cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","[2022-08-16 07:23:32,847][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","[2022-08-16 07:23:32,848][filelock][DEBUG] - Attempting to release lock 139633667103760 on /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb.lock\n","[2022-08-16 07:23:32,848][filelock][DEBUG] - Lock 139633667103760 released on /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb.lock\n","[2022-08-16 07:23:32,848][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","[2022-08-16 07:23:32,849][transformers.configuration_utils][INFO] - Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\",\n","    \"BartForConditionalGeneration\",\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-16 07:23:32,850][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-16 07:23:33,735][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-16 07:23:33,737][filelock][DEBUG] - Attempting to acquire lock 139633667114832 on /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c.lock\n","[2022-08-16 07:23:33,737][filelock][DEBUG] - Lock 139633667114832 acquired on /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c.lock\n","[2022-08-16 07:23:33,737][transformers.file_utils][INFO] - https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp8xmq134n\n","[2022-08-16 07:23:33,739][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-16 07:23:34,145][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"GET /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 557941479\n","Downloading: 100% 558M/558M [00:29<00:00, 18.9MB/s]\n","[2022-08-16 07:24:03,644][transformers.file_utils][INFO] - storing https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin in cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","[2022-08-16 07:24:03,644][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","[2022-08-16 07:24:03,645][filelock][DEBUG] - Attempting to release lock 139633667114832 on /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c.lock\n","[2022-08-16 07:24:03,645][filelock][DEBUG] - Lock 139633667114832 released on /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c.lock\n","[2022-08-16 07:24:03,645][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","[2022-08-16 07:24:06,715][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","[2022-08-16 07:24:06,715][transformers.modeling_utils][INFO] - All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","[2022-08-16 07:24:11,720][__main__][DEBUG] - Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","[2022-08-16 07:24:11,721][__main__][DEBUG] - Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-16 07:24:11,721][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,721][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,721][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,721][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,722][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,722][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,722][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,722][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,722][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,722][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,722][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,722][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,723][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,723][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,723][__main__][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,723][__main__][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,723][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,723][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,723][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,723][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,723][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,724][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,724][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,724][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,724][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,724][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,724][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,724][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,724][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,724][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,725][__main__][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,725][__main__][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,725][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,725][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,725][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,725][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,725][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,725][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,726][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,726][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,726][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,726][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,726][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,726][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,726][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,726][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,727][__main__][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,727][__main__][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,727][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,727][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,727][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,727][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,727][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,727][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,727][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,728][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,728][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,728][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,728][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,728][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,728][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,728][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,728][__main__][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,729][__main__][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,729][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,729][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,729][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,729][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,729][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,729][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,729][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,729][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,730][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,730][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,730][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,730][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,730][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,730][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,730][__main__][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,730][__main__][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,731][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,731][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,731][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,731][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,731][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,731][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,731][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,731][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,731][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,732][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,732][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,732][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,732][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,732][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,732][__main__][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,732][__main__][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,732][__main__][DEBUG] - Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,732][__main__][DEBUG] - Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,733][__main__][DEBUG] - Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-16 07:24:11,733][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,733][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,733][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,733][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,733][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,733][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,733][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,734][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,734][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,734][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,734][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,734][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,734][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,734][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,734][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,734][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,735][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,735][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,735][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,735][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,735][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,735][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,755][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,755][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,755][__main__][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,755][__main__][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,755][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,755][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,756][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,756][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,756][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,756][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,756][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,756][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,757][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,757][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,757][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,757][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,757][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,757][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,758][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,758][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,758][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,758][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,758][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,758][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,759][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,759][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,759][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,759][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,759][__main__][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,760][__main__][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,760][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,760][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,760][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,760][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,760][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,760][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,761][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,761][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,761][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,761][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,761][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,761][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,762][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,762][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,762][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,762][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,762][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,762][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,763][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,763][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,763][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,763][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,763][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,763][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,763][__main__][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,763][__main__][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,763][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,764][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,764][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,764][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,764][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,764][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,764][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,764][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,764][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,765][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,765][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,765][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,765][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,765][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,765][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,765][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,765][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,765][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,766][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,766][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,766][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,766][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,766][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,766][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,766][__main__][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,766][__main__][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,767][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,768][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,768][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,768][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,768][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,768][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,768][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,768][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,768][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,769][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,769][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,769][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,769][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,769][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,769][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,769][__main__][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,769][__main__][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,770][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,770][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,770][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,770][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,770][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,770][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,770][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,770][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,770][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,771][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,771][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,771][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,771][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,771][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,771][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,771][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,771][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 07:24:11,771][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,772][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,772][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,772][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 07:24:11,772][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 07:24:11,772][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 07:24:11,772][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,858][__main__][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,858][__main__][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,859][__main__][DEBUG] - Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 07:24:11,859][__main__][DEBUG] - Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","Epoch:   0% 0/100 [00:00<?, ?it/s][2022-08-16 07:24:11,861][__main__][DEBUG] - Starting training!\n","\n","Iteration:   0% 0/1851 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-16 07:24:12,829][__main__][DEBUG] - batch 0: tensor([[    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        ...,\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ...,     1,     1,     1],\n","        [    0,   646, 44143,  ..., 29015,   742,     2]], device='cuda:0') \n","[2022-08-16 07:24:12,831][__main__][DEBUG] - batch 1: tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') \n","[2022-08-16 07:24:12,833][__main__][DEBUG] - batch 2: tensor([[    0,  1589,  1584,  ...,     1,     1,     1],\n","        [    0,  1589, 11070,  ...,     1,     1,     1],\n","        [    0,  1589, 12105,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  1589, 17247,  ...,     1,     1,     1],\n","        [    0,  1589, 11070,  ...,     1,     1,     1],\n","        [    0,  1589, 11070,  ...,     1,     1,     1]], device='cuda:0') \n","[2022-08-16 07:24:12,835][__main__][DEBUG] - batch 3: tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0') \n","\n","Iteration:   0% 1/1851 [00:01<48:57,  1.59s/it]\u001b[A\n","Iteration:   0% 2/1851 [00:02<30:17,  1.02it/s]\u001b[A\n","Iteration:   0% 3/1851 [00:02<24:24,  1.26it/s]\u001b[A\n","Iteration:   0% 4/1851 [00:03<21:35,  1.43it/s]\u001b[A\n","Iteration:   0% 5/1851 [00:03<20:05,  1.53it/s]\u001b[A\n","Iteration:   0% 6/1851 [00:04<19:09,  1.60it/s]\u001b[A\n","Iteration:   0% 7/1851 [00:04<18:33,  1.66it/s]\u001b[A\n","Iteration:   0% 8/1851 [00:05<18:08,  1.69it/s]\u001b[A\n","Iteration:   0% 9/1851 [00:06<17:54,  1.71it/s]\u001b[A\n","Iteration:   1% 10/1851 [00:06<17:43,  1.73it/s]\u001b[A\n","Iteration:   1% 11/1851 [00:07<17:37,  1.74it/s]\u001b[A\n","Iteration:   1% 12/1851 [00:07<17:33,  1.75it/s]\u001b[A\n","Iteration:   1% 13/1851 [00:08<17:32,  1.75it/s]\u001b[A\n","Iteration:   1% 14/1851 [00:08<17:31,  1.75it/s]\u001b[A\n","Iteration:   1% 15/1851 [00:09<17:28,  1.75it/s]\u001b[A\n","Iteration:   1% 16/1851 [00:10<17:28,  1.75it/s]\u001b[A\n","Iteration:   1% 17/1851 [00:10<17:27,  1.75it/s]\u001b[A\n","Iteration:   1% 18/1851 [00:11<17:27,  1.75it/s]\u001b[A\n","Iteration:   1% 19/1851 [00:11<17:27,  1.75it/s]\u001b[A\n","Iteration:   1% 20/1851 [00:12<17:26,  1.75it/s]\u001b[A\n","Iteration:   1% 21/1851 [00:12<17:28,  1.75it/s]\u001b[A\n","Iteration:   1% 22/1851 [00:13<17:27,  1.75it/s]\u001b[A\n","Iteration:   1% 23/1851 [00:14<17:27,  1.75it/s]\u001b[A\n","Iteration:   1% 24/1851 [00:14<17:28,  1.74it/s]\u001b[A\n","Iteration:   1% 25/1851 [00:15<17:26,  1.74it/s]\u001b[A\n","Iteration:   1% 26/1851 [00:15<17:27,  1.74it/s]\u001b[A\n","Iteration:   1% 27/1851 [00:16<17:27,  1.74it/s]\u001b[A\n","Iteration:   2% 28/1851 [00:16<17:29,  1.74it/s]\u001b[A\n","Iteration:   2% 29/1851 [00:17<17:32,  1.73it/s]\u001b[A\n","Iteration:   2% 30/1851 [00:18<17:32,  1.73it/s]\u001b[A\n","Iteration:   2% 31/1851 [00:18<17:30,  1.73it/s]\u001b[A\n","Iteration:   2% 32/1851 [00:19<17:34,  1.73it/s]\u001b[A\n","Iteration:   2% 33/1851 [00:19<17:31,  1.73it/s]\u001b[A\n","Iteration:   2% 34/1851 [00:20<17:33,  1.73it/s]\u001b[A\n","Iteration:   2% 35/1851 [00:21<17:31,  1.73it/s]\u001b[A\n","Iteration:   2% 36/1851 [00:21<17:31,  1.73it/s]\u001b[A\n","Iteration:   2% 37/1851 [00:22<17:32,  1.72it/s]\u001b[A\n","Iteration:   2% 38/1851 [00:22<17:36,  1.72it/s]\u001b[A\n","Iteration:   2% 39/1851 [00:23<17:35,  1.72it/s]\u001b[A\n","Iteration:   2% 40/1851 [00:23<17:36,  1.71it/s]\u001b[A\n","Iteration:   2% 41/1851 [00:24<17:34,  1.72it/s]\u001b[A\n","Iteration:   2% 42/1851 [00:25<17:38,  1.71it/s]\u001b[A\n","Iteration:   2% 43/1851 [00:25<17:36,  1.71it/s]\u001b[A\n","Iteration:   2% 44/1851 [00:26<17:40,  1.70it/s]\u001b[A\n","Iteration:   2% 45/1851 [00:26<17:35,  1.71it/s]\u001b[A\n","Iteration:   2% 46/1851 [00:27<17:36,  1.71it/s]\u001b[A\n","Iteration:   3% 47/1851 [00:28<17:36,  1.71it/s]\u001b[A\n","Iteration:   3% 48/1851 [00:28<17:36,  1.71it/s]\u001b[A\n","Iteration:   3% 49/1851 [00:29<17:37,  1.70it/s]\u001b[A\n","Iteration:   3% 50/1851 [00:29<17:37,  1.70it/s]\u001b[A\n","Iteration:   3% 51/1851 [00:30<17:38,  1.70it/s]\u001b[A\n","Iteration:   3% 52/1851 [00:30<17:38,  1.70it/s]\u001b[A\n","Iteration:   3% 53/1851 [00:31<17:37,  1.70it/s]\u001b[A\n","Iteration:   3% 54/1851 [00:32<17:38,  1.70it/s]\u001b[A\n","Iteration:   3% 55/1851 [00:32<17:37,  1.70it/s]\u001b[A\n","Iteration:   3% 56/1851 [00:33<17:40,  1.69it/s]\u001b[A\n","Iteration:   3% 57/1851 [00:33<17:40,  1.69it/s]\u001b[A\n","Iteration:   3% 58/1851 [00:34<17:42,  1.69it/s]\u001b[A\n","Iteration:   3% 59/1851 [00:35<17:40,  1.69it/s]\u001b[A\n","Iteration:   3% 60/1851 [00:35<17:43,  1.68it/s]\u001b[A\n","Iteration:   3% 61/1851 [00:36<17:42,  1.68it/s]\u001b[A\n","Iteration:   3% 62/1851 [00:36<17:45,  1.68it/s]\u001b[A\n","Iteration:   3% 63/1851 [00:37<17:42,  1.68it/s]\u001b[A\n","Iteration:   3% 64/1851 [00:38<17:44,  1.68it/s]\u001b[A\n","Iteration:   4% 65/1851 [00:38<17:43,  1.68it/s]\u001b[A\n","Iteration:   4% 66/1851 [00:39<17:43,  1.68it/s]\u001b[A\n","Iteration:   4% 67/1851 [00:39<17:42,  1.68it/s]\u001b[A\n","Iteration:   4% 68/1851 [00:40<17:44,  1.68it/s]\u001b[A\n","Iteration:   4% 69/1851 [00:41<17:47,  1.67it/s]\u001b[A\n","Iteration:   4% 70/1851 [00:41<17:46,  1.67it/s]\u001b[A\n","Iteration:   4% 71/1851 [00:42<17:44,  1.67it/s]\u001b[A\n","Iteration:   4% 72/1851 [00:42<17:48,  1.66it/s]\u001b[A\n","Iteration:   4% 73/1851 [00:43<17:48,  1.66it/s]\u001b[A\n","Iteration:   4% 74/1851 [00:44<17:50,  1.66it/s]\u001b[A\n","Iteration:   4% 75/1851 [00:44<17:47,  1.66it/s]\u001b[A\n","Iteration:   4% 76/1851 [00:45<17:51,  1.66it/s]\u001b[A\n","Iteration:   4% 77/1851 [00:45<17:48,  1.66it/s]\u001b[A\n","Iteration:   4% 78/1851 [00:46<17:51,  1.65it/s]\u001b[A\n","Iteration:   4% 79/1851 [00:47<17:48,  1.66it/s]\u001b[A\n","Iteration:   4% 80/1851 [00:47<17:49,  1.66it/s]\u001b[A\n","Iteration:   4% 81/1851 [00:48<17:50,  1.65it/s]\u001b[A\n","Iteration:   4% 82/1851 [00:48<17:54,  1.65it/s]\u001b[A\n","Iteration:   4% 83/1851 [00:49<17:56,  1.64it/s]\u001b[A\n","Iteration:   5% 84/1851 [00:50<17:55,  1.64it/s]\u001b[A\n","Iteration:   5% 85/1851 [00:50<17:54,  1.64it/s]\u001b[A\n","Iteration:   5% 86/1851 [00:51<17:54,  1.64it/s]\u001b[A\n","Iteration:   5% 87/1851 [00:52<17:56,  1.64it/s]\u001b[A\n","Iteration:   5% 88/1851 [00:52<17:56,  1.64it/s]\u001b[A\n","Iteration:   5% 89/1851 [00:53<17:56,  1.64it/s]\u001b[A\n","Iteration:   5% 90/1851 [00:53<18:00,  1.63it/s]\u001b[A\n","Iteration:   5% 91/1851 [00:54<18:00,  1.63it/s]\u001b[A\n","Iteration:   5% 92/1851 [00:55<17:58,  1.63it/s]\u001b[A\n","Iteration:   5% 93/1851 [00:55<18:00,  1.63it/s]\u001b[A\n","Iteration:   5% 94/1851 [00:56<17:59,  1.63it/s]\u001b[A\n","Iteration:   5% 95/1851 [00:56<17:59,  1.63it/s]\u001b[A\n","Iteration:   5% 96/1851 [00:57<17:58,  1.63it/s]\u001b[A\n","Iteration:   5% 97/1851 [00:58<18:00,  1.62it/s]\u001b[A\n","Iteration:   5% 98/1851 [00:58<17:56,  1.63it/s]\u001b[A\n","Iteration:   5% 99/1851 [00:59<18:00,  1.62it/s]\u001b[A\n","Iteration:   5% 100/1851 [01:00<17:58,  1.62it/s]\u001b[A\n","Iteration:   5% 101/1851 [01:00<17:57,  1.62it/s]\u001b[A\n","Iteration:   6% 102/1851 [01:01<18:01,  1.62it/s]\u001b[A\n","Iteration:   6% 103/1851 [01:01<17:57,  1.62it/s]\u001b[A\n","Iteration:   6% 104/1851 [01:02<18:01,  1.61it/s]\u001b[A\n","Iteration:   6% 105/1851 [01:03<17:58,  1.62it/s]\u001b[A\n","Iteration:   6% 106/1851 [01:03<17:59,  1.62it/s]\u001b[A\n","Iteration:   6% 107/1851 [01:04<17:59,  1.62it/s]\u001b[A\n","Iteration:   6% 108/1851 [01:04<17:58,  1.62it/s]\u001b[A\n","Iteration:   6% 109/1851 [01:05<17:59,  1.61it/s]\u001b[A\n","Iteration:   6% 110/1851 [01:06<17:59,  1.61it/s]\u001b[A\n","Iteration:   6% 111/1851 [01:06<18:04,  1.60it/s]\u001b[A\n","Iteration:   6% 112/1851 [01:07<18:04,  1.60it/s]\u001b[A\n","Iteration:   6% 113/1851 [01:08<18:04,  1.60it/s]\u001b[A\n","Iteration:   6% 114/1851 [01:08<18:03,  1.60it/s]\u001b[A\n","Iteration:   6% 115/1851 [01:09<18:06,  1.60it/s]\u001b[A\n","Iteration:   6% 116/1851 [01:09<18:07,  1.60it/s]\u001b[A\n","Iteration:   6% 117/1851 [01:10<18:07,  1.59it/s]\u001b[A\n","Iteration:   6% 118/1851 [01:11<18:08,  1.59it/s]\u001b[A\n","Iteration:   6% 119/1851 [01:11<18:09,  1.59it/s]\u001b[A\n","Iteration:   6% 120/1851 [01:12<18:10,  1.59it/s]\u001b[A\n","Iteration:   7% 121/1851 [01:13<18:10,  1.59it/s]\u001b[A\n","Iteration:   7% 122/1851 [01:13<18:11,  1.58it/s]\u001b[A\n","Iteration:   7% 123/1851 [01:14<18:13,  1.58it/s]\u001b[A\n","Iteration:   7% 124/1851 [01:15<18:13,  1.58it/s]\u001b[A\n","Iteration:   7% 125/1851 [01:15<18:15,  1.58it/s]\u001b[A\n","Iteration:   7% 126/1851 [01:16<18:15,  1.57it/s]\u001b[A\n","Iteration:   7% 127/1851 [01:16<18:16,  1.57it/s]\u001b[A\n","Iteration:   7% 128/1851 [01:17<18:14,  1.57it/s]\u001b[A\n","Iteration:   7% 129/1851 [01:18<18:15,  1.57it/s]\u001b[A\n","Iteration:   7% 130/1851 [01:18<18:19,  1.57it/s]\u001b[A\n","Iteration:   7% 131/1851 [01:19<18:19,  1.56it/s]\u001b[A\n","Iteration:   7% 132/1851 [01:20<18:18,  1.56it/s]\u001b[A\n","Iteration:   7% 133/1851 [01:20<18:16,  1.57it/s]\u001b[A\n","Iteration:   7% 134/1851 [01:21<18:21,  1.56it/s]\u001b[A\n","Iteration:   7% 135/1851 [01:22<18:21,  1.56it/s]\u001b[A\n","Iteration:   7% 136/1851 [01:22<18:22,  1.56it/s]\u001b[A\n","Iteration:   7% 137/1851 [01:23<18:25,  1.55it/s]\u001b[A\n","Iteration:   7% 138/1851 [01:23<18:28,  1.55it/s]\u001b[A\n","Iteration:   8% 139/1851 [01:24<18:29,  1.54it/s]\u001b[A\n","Iteration:   8% 140/1851 [01:25<18:32,  1.54it/s]\u001b[A\n","Iteration:   8% 141/1851 [01:25<18:33,  1.54it/s]\u001b[A\n","Iteration:   8% 142/1851 [01:26<18:36,  1.53it/s]\u001b[A\n","Iteration:   8% 143/1851 [01:27<18:36,  1.53it/s]\u001b[A\n","Iteration:   8% 144/1851 [01:27<18:38,  1.53it/s]\u001b[A\n","Iteration:   8% 145/1851 [01:28<18:37,  1.53it/s]\u001b[A\n","Iteration:   8% 146/1851 [01:29<18:36,  1.53it/s]\u001b[A\n","Iteration:   8% 147/1851 [01:29<18:37,  1.52it/s]\u001b[A\n","Iteration:   8% 148/1851 [01:30<18:37,  1.52it/s]\u001b[A\n","Iteration:   8% 149/1851 [01:31<18:35,  1.53it/s]\u001b[A\n","Iteration:   8% 150/1851 [01:31<18:32,  1.53it/s]\u001b[A\n","Iteration:   8% 151/1851 [01:32<18:30,  1.53it/s]\u001b[A\n","Iteration:   8% 152/1851 [01:33<18:27,  1.53it/s]\u001b[A\n","Iteration:   8% 153/1851 [01:33<18:26,  1.54it/s]\u001b[A\n","Iteration:   8% 154/1851 [01:34<18:24,  1.54it/s]\u001b[A\n","Iteration:   8% 155/1851 [01:35<18:21,  1.54it/s]\u001b[A\n","Iteration:   8% 156/1851 [01:35<18:20,  1.54it/s]\u001b[A\n","Iteration:   8% 157/1851 [01:36<18:18,  1.54it/s]\u001b[A\n","Iteration:   9% 158/1851 [01:37<18:15,  1.55it/s]\u001b[A\n","Iteration:   9% 159/1851 [01:37<18:16,  1.54it/s]\u001b[A\n","Iteration:   9% 160/1851 [01:38<18:12,  1.55it/s]\u001b[A\n","Iteration:   9% 161/1851 [01:38<18:09,  1.55it/s]\u001b[A\n","Iteration:   9% 162/1851 [01:39<18:05,  1.56it/s]\u001b[A\n","Iteration:   9% 163/1851 [01:40<18:02,  1.56it/s]\u001b[A\n","Iteration:   9% 164/1851 [01:40<17:59,  1.56it/s]\u001b[A\n","Iteration:   9% 165/1851 [01:41<17:57,  1.56it/s]\u001b[A\n","Iteration:   9% 166/1851 [01:42<17:59,  1.56it/s]\u001b[A\n","Iteration:   9% 167/1851 [01:42<17:58,  1.56it/s]\u001b[A\n","Iteration:   9% 168/1851 [01:43<17:56,  1.56it/s]\u001b[A\n","Iteration:   9% 169/1851 [01:44<17:56,  1.56it/s]\u001b[A\n","Iteration:   9% 170/1851 [01:44<17:53,  1.57it/s]\u001b[A\n","Iteration:   9% 171/1851 [01:45<17:50,  1.57it/s]\u001b[A\n","Iteration:   9% 172/1851 [01:45<17:48,  1.57it/s]\u001b[A\n","Iteration:   9% 173/1851 [01:46<17:45,  1.57it/s]\u001b[A\n","Iteration:   9% 174/1851 [01:47<17:44,  1.58it/s]\u001b[A\n","Iteration:   9% 175/1851 [01:47<17:40,  1.58it/s]\u001b[A\n","Iteration:  10% 176/1851 [01:48<17:40,  1.58it/s]\u001b[A\n","Iteration:  10% 177/1851 [01:49<17:39,  1.58it/s]\u001b[A\n","Iteration:  10% 178/1851 [01:49<17:38,  1.58it/s]\u001b[A\n","Iteration:  10% 179/1851 [01:50<17:35,  1.58it/s]\u001b[A\n","Iteration:  10% 180/1851 [01:51<17:35,  1.58it/s]\u001b[A\n","Iteration:  10% 181/1851 [01:51<17:33,  1.59it/s]\u001b[A\n","Iteration:  10% 182/1851 [01:52<17:30,  1.59it/s]\u001b[A\n","Iteration:  10% 183/1851 [01:52<17:27,  1.59it/s]\u001b[A\n","Iteration:  10% 184/1851 [01:53<17:26,  1.59it/s]\u001b[A\n","Iteration:  10% 185/1851 [01:54<17:22,  1.60it/s]\u001b[A\n","Iteration:  10% 186/1851 [01:54<17:23,  1.60it/s]\u001b[A\n","Iteration:  10% 187/1851 [01:55<17:25,  1.59it/s]\u001b[A\n","Iteration:  10% 188/1851 [01:56<17:21,  1.60it/s]\u001b[A\n","Iteration:  10% 189/1851 [01:56<17:23,  1.59it/s]\u001b[A\n","Iteration:  10% 190/1851 [01:57<17:22,  1.59it/s]\u001b[A\n","Iteration:  10% 191/1851 [01:57<17:24,  1.59it/s]\u001b[A\n","Iteration:  10% 192/1851 [01:58<17:21,  1.59it/s]\u001b[A\n","Iteration:  10% 193/1851 [01:59<17:21,  1.59it/s]\u001b[A\n","Iteration:  10% 194/1851 [01:59<17:18,  1.60it/s]\u001b[A\n","Iteration:  11% 195/1851 [02:00<17:14,  1.60it/s]\u001b[A\n","Iteration:  11% 196/1851 [02:01<17:15,  1.60it/s]\u001b[A\n","Iteration:  11% 197/1851 [02:01<17:13,  1.60it/s]\u001b[A\n","Iteration:  11% 198/1851 [02:02<17:15,  1.60it/s]\u001b[A\n","Iteration:  11% 199/1851 [02:02<17:14,  1.60it/s]\u001b[A\n","Iteration:  11% 200/1851 [02:03<17:16,  1.59it/s]\u001b[A\n","Iteration:  11% 201/1851 [02:04<17:12,  1.60it/s]\u001b[A\n","Iteration:  11% 202/1851 [02:04<17:10,  1.60it/s]\u001b[A\n","Iteration:  11% 203/1851 [02:05<17:08,  1.60it/s]\u001b[A\n","Iteration:  11% 204/1851 [02:06<17:08,  1.60it/s]\u001b[A\n","Iteration:  11% 205/1851 [02:06<17:06,  1.60it/s]\u001b[A\n","Iteration:  11% 206/1851 [02:07<17:04,  1.60it/s]\u001b[A\n","Iteration:  11% 207/1851 [02:07<17:03,  1.61it/s]\u001b[A\n","Iteration:  11% 208/1851 [02:08<17:01,  1.61it/s]\u001b[A\n","Iteration:  11% 209/1851 [02:09<17:02,  1.61it/s]\u001b[A\n","Iteration:  11% 210/1851 [02:09<17:04,  1.60it/s]\u001b[A\n","Iteration:  11% 211/1851 [02:10<17:01,  1.61it/s]\u001b[A\n","Iteration:  11% 212/1851 [02:11<16:59,  1.61it/s]\u001b[A\n","Iteration:  12% 213/1851 [02:11<17:04,  1.60it/s]\u001b[A\n","Iteration:  12% 214/1851 [02:12<17:04,  1.60it/s]\u001b[A\n","Iteration:  12% 215/1851 [02:12<17:06,  1.59it/s]\u001b[A\n","Iteration:  12% 216/1851 [02:13<17:04,  1.60it/s]\u001b[A\n","Iteration:  12% 217/1851 [02:14<17:05,  1.59it/s]\u001b[A\n","Iteration:  12% 218/1851 [02:14<17:01,  1.60it/s]\u001b[A\n","Iteration:  12% 219/1851 [02:15<16:58,  1.60it/s]\u001b[A\n","Iteration:  12% 220/1851 [02:16<17:00,  1.60it/s]\u001b[A\n","Iteration:  12% 221/1851 [02:16<16:56,  1.60it/s]\u001b[A\n","Iteration:  12% 222/1851 [02:17<16:55,  1.60it/s]\u001b[A\n","Iteration:  12% 223/1851 [02:17<16:56,  1.60it/s]\u001b[A\n","Iteration:  12% 224/1851 [02:18<16:58,  1.60it/s]\u001b[A\n","Iteration:  12% 225/1851 [02:19<16:55,  1.60it/s]\u001b[A\n","Iteration:  12% 226/1851 [02:19<16:58,  1.60it/s]\u001b[A\n","Iteration:  12% 227/1851 [02:20<16:57,  1.60it/s]\u001b[A\n","Iteration:  12% 228/1851 [02:21<16:57,  1.59it/s]\u001b[A\n","Iteration:  12% 229/1851 [02:21<16:58,  1.59it/s]\u001b[A\n","Iteration:  12% 230/1851 [02:22<16:53,  1.60it/s]\u001b[A\n","Iteration:  12% 231/1851 [02:22<16:49,  1.60it/s]\u001b[A\n","Iteration:  13% 232/1851 [02:23<16:47,  1.61it/s]\u001b[A\n","Iteration:  13% 233/1851 [02:24<16:47,  1.61it/s]\u001b[A\n","Iteration:  13% 234/1851 [02:24<16:50,  1.60it/s]\u001b[A\n","Iteration:  13% 235/1851 [02:25<16:51,  1.60it/s]\u001b[A\n","Iteration:  13% 236/1851 [02:26<16:47,  1.60it/s]\u001b[A\n","Iteration:  13% 237/1851 [02:26<16:46,  1.60it/s]\u001b[A\n","Iteration:  13% 238/1851 [02:27<16:50,  1.60it/s]\u001b[A\n","Iteration:  13% 239/1851 [02:27<16:52,  1.59it/s]\u001b[A\n","Iteration:  13% 240/1851 [02:28<16:49,  1.60it/s]\u001b[A\n","Iteration:  13% 241/1851 [02:29<16:47,  1.60it/s]\u001b[A\n","Iteration:  13% 242/1851 [02:29<16:45,  1.60it/s]\u001b[A\n","Iteration:  13% 243/1851 [02:30<16:46,  1.60it/s]\u001b[A\n","Iteration:  13% 244/1851 [02:31<16:48,  1.59it/s]\u001b[A\n","Iteration:  13% 245/1851 [02:31<16:47,  1.59it/s]\u001b[A\n","Iteration:  13% 246/1851 [02:32<16:45,  1.60it/s]\u001b[A\n","Iteration:  13% 247/1851 [02:32<16:48,  1.59it/s]\u001b[A\n","Iteration:  13% 248/1851 [02:33<16:44,  1.60it/s]\u001b[A\n","Iteration:  13% 249/1851 [02:34<16:42,  1.60it/s]\u001b[A\n","Iteration:  14% 250/1851 [02:34<16:40,  1.60it/s]\u001b[A\n","Iteration:  14% 251/1851 [02:35<16:39,  1.60it/s]\u001b[A\n","Iteration:  14% 252/1851 [02:36<16:44,  1.59it/s]\u001b[A\n","Iteration:  14% 253/1851 [02:36<16:41,  1.59it/s]\u001b[A\n","Iteration:  14% 254/1851 [02:37<16:44,  1.59it/s]\u001b[A\n","Iteration:  14% 255/1851 [02:37<16:42,  1.59it/s]\u001b[A\n","Iteration:  14% 256/1851 [02:38<16:42,  1.59it/s]\u001b[A\n","Iteration:  14% 257/1851 [02:39<16:42,  1.59it/s]\u001b[A\n","Iteration:  14% 258/1851 [02:39<16:43,  1.59it/s]\u001b[A\n","Iteration:  14% 259/1851 [02:40<16:41,  1.59it/s]\u001b[A\n","Iteration:  14% 260/1851 [02:41<16:42,  1.59it/s]\u001b[A\n","Iteration:  14% 261/1851 [02:41<16:40,  1.59it/s]\u001b[A\n","Iteration:  14% 262/1851 [02:42<16:39,  1.59it/s]\u001b[A\n","Iteration:  14% 263/1851 [02:43<16:39,  1.59it/s]\u001b[A\n","Iteration:  14% 264/1851 [02:43<16:38,  1.59it/s]\u001b[A\n","Iteration:  14% 265/1851 [02:44<16:37,  1.59it/s]\u001b[A\n","Iteration:  14% 266/1851 [02:44<16:37,  1.59it/s]\u001b[A\n","Iteration:  14% 267/1851 [02:45<16:35,  1.59it/s]\u001b[A\n","Iteration:  14% 268/1851 [02:46<16:36,  1.59it/s]\u001b[A\n","Iteration:  15% 269/1851 [02:46<16:35,  1.59it/s]\u001b[A\n","Iteration:  15% 270/1851 [02:47<16:35,  1.59it/s]\u001b[A\n","Iteration:  15% 271/1851 [02:48<16:33,  1.59it/s]\u001b[A\n","Iteration:  15% 272/1851 [02:48<16:34,  1.59it/s]\u001b[A\n","Iteration:  15% 273/1851 [02:49<16:35,  1.59it/s]\u001b[A\n","Iteration:  15% 274/1851 [02:49<16:34,  1.59it/s]\u001b[A\n","Iteration:  15% 275/1851 [02:50<16:34,  1.58it/s]\u001b[A\n","Iteration:  15% 276/1851 [02:51<16:33,  1.58it/s]\u001b[A\n","Iteration:  15% 277/1851 [02:51<16:33,  1.58it/s]\u001b[A\n","Iteration:  15% 278/1851 [02:52<16:33,  1.58it/s]\u001b[A\n","Iteration:  15% 279/1851 [02:53<16:33,  1.58it/s]\u001b[A\n","Iteration:  15% 280/1851 [02:53<16:31,  1.58it/s]\u001b[A\n","Iteration:  15% 281/1851 [02:54<16:34,  1.58it/s]\u001b[A\n","Iteration:  15% 282/1851 [02:55<16:33,  1.58it/s]\u001b[A\n","Iteration:  15% 283/1851 [02:55<16:34,  1.58it/s]\u001b[A\n","Iteration:  15% 284/1851 [02:56<16:32,  1.58it/s]\u001b[A\n","Iteration:  15% 285/1851 [02:56<16:31,  1.58it/s]\u001b[A\n","Iteration:  15% 286/1851 [02:57<16:29,  1.58it/s]\u001b[A\n","Iteration:  16% 287/1851 [02:58<16:30,  1.58it/s]\u001b[A\n","Iteration:  16% 288/1851 [02:58<16:32,  1.58it/s]\u001b[A\n","Iteration:  16% 289/1851 [02:59<16:31,  1.57it/s]\u001b[A\n","Iteration:  16% 290/1851 [03:00<16:29,  1.58it/s]\u001b[A\n","Iteration:  16% 291/1851 [03:00<16:26,  1.58it/s]\u001b[A\n","Iteration:  16% 292/1851 [03:01<16:26,  1.58it/s]\u001b[A\n","Iteration:  16% 293/1851 [03:01<16:26,  1.58it/s]\u001b[A\n","Iteration:  16% 294/1851 [03:02<16:28,  1.58it/s]\u001b[A\n","Iteration:  16% 295/1851 [03:03<16:26,  1.58it/s]\u001b[A\n","Iteration:  16% 296/1851 [03:03<16:24,  1.58it/s]\u001b[A\n","Iteration:  16% 297/1851 [03:04<16:23,  1.58it/s]\u001b[A\n","Iteration:  16% 298/1851 [03:05<16:22,  1.58it/s]\u001b[A\n","Iteration:  16% 299/1851 [03:05<16:22,  1.58it/s]\u001b[A\n","Iteration:  16% 300/1851 [03:06<16:21,  1.58it/s]\u001b[A\n","Iteration:  16% 301/1851 [03:07<16:20,  1.58it/s]\u001b[A\n","Iteration:  16% 302/1851 [03:07<16:23,  1.58it/s]\u001b[A\n","Iteration:  16% 303/1851 [03:08<16:22,  1.58it/s]\u001b[A\n","Iteration:  16% 304/1851 [03:08<16:21,  1.58it/s]\u001b[A\n","Iteration:  16% 305/1851 [03:09<16:19,  1.58it/s]\u001b[A\n","Iteration:  17% 306/1851 [03:10<16:19,  1.58it/s]\u001b[A\n","Iteration:  17% 307/1851 [03:10<16:17,  1.58it/s]\u001b[A\n","Iteration:  17% 308/1851 [03:11<16:18,  1.58it/s]\u001b[A\n","Iteration:  17% 309/1851 [03:12<16:17,  1.58it/s]\u001b[A\n","Iteration:  17% 310/1851 [03:12<16:16,  1.58it/s]\u001b[A\n","Iteration:  17% 311/1851 [03:13<16:16,  1.58it/s]\u001b[A\n","Iteration:  17% 312/1851 [03:14<16:14,  1.58it/s]\u001b[A\n","Iteration:  17% 313/1851 [03:14<16:16,  1.58it/s]\u001b[A\n","Iteration:  17% 314/1851 [03:15<16:15,  1.58it/s]\u001b[A\n","Iteration:  17% 315/1851 [03:15<16:13,  1.58it/s]\u001b[A\n","Iteration:  17% 316/1851 [03:16<16:11,  1.58it/s]\u001b[A\n","Iteration:  17% 317/1851 [03:17<16:09,  1.58it/s]\u001b[A\n","Iteration:  17% 318/1851 [03:17<16:10,  1.58it/s]\u001b[A\n","Iteration:  17% 319/1851 [03:18<16:08,  1.58it/s]\u001b[A\n","Iteration:  17% 320/1851 [03:19<16:07,  1.58it/s]\u001b[A\n","Iteration:  17% 321/1851 [03:19<16:06,  1.58it/s]\u001b[A\n","Iteration:  17% 322/1851 [03:20<16:06,  1.58it/s]\u001b[A\n","Iteration:  17% 323/1851 [03:20<16:05,  1.58it/s]\u001b[A\n","Iteration:  18% 324/1851 [03:21<16:03,  1.58it/s]\u001b[A\n","Iteration:  18% 325/1851 [03:22<16:03,  1.58it/s]\u001b[A\n","Iteration:  18% 326/1851 [03:22<16:01,  1.59it/s]\u001b[A\n","Iteration:  18% 327/1851 [03:23<16:00,  1.59it/s]\u001b[A\n","Iteration:  18% 328/1851 [03:24<16:00,  1.59it/s]\u001b[A\n","Iteration:  18% 329/1851 [03:24<15:58,  1.59it/s]\u001b[A\n","Iteration:  18% 330/1851 [03:25<16:02,  1.58it/s]\u001b[A\n","Iteration:  18% 331/1851 [03:26<15:59,  1.58it/s]\u001b[A\n","Iteration:  18% 332/1851 [03:26<15:58,  1.59it/s]\u001b[A\n","Iteration:  18% 333/1851 [03:27<15:57,  1.59it/s]\u001b[A\n","Iteration:  18% 334/1851 [03:27<15:55,  1.59it/s]\u001b[A\n","Iteration:  18% 335/1851 [03:28<15:54,  1.59it/s]\u001b[A\n","Iteration:  18% 336/1851 [03:29<15:55,  1.59it/s]\u001b[A\n","Iteration:  18% 337/1851 [03:29<15:53,  1.59it/s]\u001b[A\n","Iteration:  18% 338/1851 [03:30<15:51,  1.59it/s]\u001b[A\n","Iteration:  18% 339/1851 [03:31<15:53,  1.58it/s]\u001b[A\n","Iteration:  18% 340/1851 [03:31<15:51,  1.59it/s]\u001b[A\n","Iteration:  18% 341/1851 [03:32<15:50,  1.59it/s]\u001b[A\n","Iteration:  18% 342/1851 [03:32<15:46,  1.59it/s]\u001b[A\n","Iteration:  19% 343/1851 [03:33<15:47,  1.59it/s]\u001b[A\n","Iteration:  19% 344/1851 [03:34<15:47,  1.59it/s]\u001b[A\n","Iteration:  19% 345/1851 [03:34<15:48,  1.59it/s]\u001b[A\n","Iteration:  19% 346/1851 [03:35<15:47,  1.59it/s]\u001b[A\n","Iteration:  19% 347/1851 [03:36<15:46,  1.59it/s]\u001b[A\n","Iteration:  19% 348/1851 [03:36<15:44,  1.59it/s]\u001b[A\n","Iteration:  19% 349/1851 [03:37<15:43,  1.59it/s]\u001b[A\n","Iteration:  19% 350/1851 [03:37<15:44,  1.59it/s]\u001b[A\n","Iteration:  19% 351/1851 [03:38<15:43,  1.59it/s]\u001b[A\n","Iteration:  19% 352/1851 [03:39<15:43,  1.59it/s]\u001b[A\n","Iteration:  19% 353/1851 [03:39<15:42,  1.59it/s]\u001b[A\n","Iteration:  19% 354/1851 [03:40<15:40,  1.59it/s]\u001b[A\n","Iteration:  19% 355/1851 [03:41<15:40,  1.59it/s]\u001b[A\n","Iteration:  19% 356/1851 [03:41<15:39,  1.59it/s]\u001b[A\n","Iteration:  19% 357/1851 [03:42<15:38,  1.59it/s]\u001b[A\n","Iteration:  19% 358/1851 [03:43<15:38,  1.59it/s]\u001b[A\n","Iteration:  19% 359/1851 [03:43<15:40,  1.59it/s]\u001b[A\n","Iteration:  19% 360/1851 [03:44<15:39,  1.59it/s]\u001b[A\n","Iteration:  20% 361/1851 [03:44<15:38,  1.59it/s]\u001b[A\n","Iteration:  20% 362/1851 [03:45<15:36,  1.59it/s]\u001b[A\n","Iteration:  20% 363/1851 [03:46<15:34,  1.59it/s]\u001b[A\n","Iteration:  20% 364/1851 [03:46<15:35,  1.59it/s]\u001b[A\n","Iteration:  20% 365/1851 [03:47<15:35,  1.59it/s]\u001b[A\n","Iteration:  20% 366/1851 [03:48<15:35,  1.59it/s]\u001b[A\n","Iteration:  20% 367/1851 [03:48<15:33,  1.59it/s]\u001b[A\n","Iteration:  20% 368/1851 [03:49<15:34,  1.59it/s]\u001b[A\n","Iteration:  20% 369/1851 [03:49<15:31,  1.59it/s]\u001b[A\n","Iteration:  20% 370/1851 [03:50<15:29,  1.59it/s]\u001b[A\n","Iteration:  20% 371/1851 [03:51<15:33,  1.59it/s]\u001b[A\n","Iteration:  20% 372/1851 [03:51<15:29,  1.59it/s]\u001b[A\n","Iteration:  20% 373/1851 [03:52<15:29,  1.59it/s]\u001b[A\n","Iteration:  20% 374/1851 [03:53<15:32,  1.58it/s]\u001b[A\n","Iteration:  20% 375/1851 [03:53<15:29,  1.59it/s]\u001b[A\n","Iteration:  20% 376/1851 [03:54<15:28,  1.59it/s]\u001b[A\n","Iteration:  20% 377/1851 [03:54<15:27,  1.59it/s]\u001b[A\n","Iteration:  20% 378/1851 [03:55<15:24,  1.59it/s]\u001b[A\n","Iteration:  20% 379/1851 [03:56<15:24,  1.59it/s]\u001b[A\n","Iteration:  21% 380/1851 [03:56<15:23,  1.59it/s]\u001b[A\n","Iteration:  21% 381/1851 [03:57<15:24,  1.59it/s]\u001b[A\n","Iteration:  21% 382/1851 [03:58<15:22,  1.59it/s]\u001b[A\n","Iteration:  21% 383/1851 [03:58<15:20,  1.59it/s]\u001b[A\n","Iteration:  21% 384/1851 [03:59<15:22,  1.59it/s]\u001b[A\n","Iteration:  21% 385/1851 [03:59<15:21,  1.59it/s]\u001b[A\n","Iteration:  21% 386/1851 [04:00<15:20,  1.59it/s]\u001b[A\n","Iteration:  21% 387/1851 [04:01<15:20,  1.59it/s]\u001b[A\n","Iteration:  21% 388/1851 [04:01<15:19,  1.59it/s]\u001b[A\n","Iteration:  21% 389/1851 [04:02<15:18,  1.59it/s]\u001b[A\n","Iteration:  21% 390/1851 [04:03<15:16,  1.59it/s]\u001b[A\n","Iteration:  21% 391/1851 [04:03<15:16,  1.59it/s]\u001b[A\n","Iteration:  21% 392/1851 [04:04<15:17,  1.59it/s]\u001b[A\n","Iteration:  21% 393/1851 [04:05<15:16,  1.59it/s]\u001b[A\n","Iteration:  21% 394/1851 [04:05<15:16,  1.59it/s]\u001b[A\n","Iteration:  21% 395/1851 [04:06<15:15,  1.59it/s]\u001b[A\n","Iteration:  21% 396/1851 [04:06<15:13,  1.59it/s]\u001b[A\n","Iteration:  21% 397/1851 [04:07<15:14,  1.59it/s]\u001b[A\n","Iteration:  22% 398/1851 [04:08<15:14,  1.59it/s]\u001b[A\n","Iteration:  22% 399/1851 [04:08<15:11,  1.59it/s]\u001b[A\n","Iteration:  22% 400/1851 [04:09<15:09,  1.59it/s]\u001b[A\n","Iteration:  22% 401/1851 [04:10<15:10,  1.59it/s]\u001b[A\n","Iteration:  22% 402/1851 [04:10<15:10,  1.59it/s]\u001b[A\n","Iteration:  22% 403/1851 [04:11<15:12,  1.59it/s]\u001b[A\n","Iteration:  22% 404/1851 [04:11<15:09,  1.59it/s]\u001b[A\n","Iteration:  22% 405/1851 [04:12<15:10,  1.59it/s]\u001b[A\n","Iteration:  22% 406/1851 [04:13<15:09,  1.59it/s]\u001b[A\n","Iteration:  22% 407/1851 [04:13<15:08,  1.59it/s]\u001b[A\n","Iteration:  22% 408/1851 [04:14<15:07,  1.59it/s]\u001b[A\n","Iteration:  22% 409/1851 [04:15<15:07,  1.59it/s]\u001b[A\n","Iteration:  22% 410/1851 [04:15<15:06,  1.59it/s]\u001b[A\n","Iteration:  22% 411/1851 [04:16<15:05,  1.59it/s]\u001b[A\n","Iteration:  22% 412/1851 [04:16<15:03,  1.59it/s]\u001b[A\n","Iteration:  22% 413/1851 [04:17<15:02,  1.59it/s]\u001b[A\n","Iteration:  22% 414/1851 [04:18<15:02,  1.59it/s]\u001b[A\n","Iteration:  22% 415/1851 [04:18<15:03,  1.59it/s]\u001b[A\n","Iteration:  22% 416/1851 [04:19<15:00,  1.59it/s]\u001b[A\n","Iteration:  23% 417/1851 [04:20<15:00,  1.59it/s]\u001b[A\n","Iteration:  23% 418/1851 [04:20<14:59,  1.59it/s]\u001b[A\n","Iteration:  23% 419/1851 [04:21<14:59,  1.59it/s]\u001b[A\n","Iteration:  23% 420/1851 [04:21<14:57,  1.59it/s]\u001b[A\n","Iteration:  23% 421/1851 [04:22<14:59,  1.59it/s]\u001b[A\n","Iteration:  23% 422/1851 [04:23<14:58,  1.59it/s]\u001b[A\n","Iteration:  23% 423/1851 [04:23<15:00,  1.59it/s]\u001b[A\n","Iteration:  23% 424/1851 [04:24<15:00,  1.59it/s]\u001b[A\n","Iteration:  23% 425/1851 [04:25<14:58,  1.59it/s]\u001b[A\n","Iteration:  23% 426/1851 [04:25<14:58,  1.59it/s]\u001b[A\n","Iteration:  23% 427/1851 [04:26<14:57,  1.59it/s]\u001b[A\n","Iteration:  23% 428/1851 [04:27<14:56,  1.59it/s]\u001b[A\n","Iteration:  23% 429/1851 [04:27<14:56,  1.59it/s]\u001b[A\n","Iteration:  23% 430/1851 [04:28<14:55,  1.59it/s]\u001b[A\n","Iteration:  23% 431/1851 [04:28<14:53,  1.59it/s]\u001b[A\n","Iteration:  23% 432/1851 [04:29<14:53,  1.59it/s]\u001b[A\n","Iteration:  23% 433/1851 [04:30<14:52,  1.59it/s]\u001b[A\n","Iteration:  23% 434/1851 [04:30<14:54,  1.58it/s]\u001b[A\n","Iteration:  24% 435/1851 [04:31<14:52,  1.59it/s]\u001b[A\n","Iteration:  24% 436/1851 [04:32<14:51,  1.59it/s]\u001b[A\n","Iteration:  24% 437/1851 [04:32<14:54,  1.58it/s]\u001b[A\n","Iteration:  24% 438/1851 [04:33<14:52,  1.58it/s]\u001b[A\n","Iteration:  24% 439/1851 [04:33<14:50,  1.59it/s]\u001b[A\n","Iteration:  24% 440/1851 [04:34<14:49,  1.59it/s]\u001b[A\n","Iteration:  24% 441/1851 [04:35<14:49,  1.59it/s]\u001b[A\n","Iteration:  24% 442/1851 [04:35<14:49,  1.58it/s]\u001b[A\n","Iteration:  24% 443/1851 [04:36<14:49,  1.58it/s]\u001b[A\n","Iteration:  24% 444/1851 [04:37<14:48,  1.58it/s]\u001b[A\n","Iteration:  24% 445/1851 [04:37<14:48,  1.58it/s]\u001b[A\n","Iteration:  24% 446/1851 [04:38<14:46,  1.58it/s]\u001b[A\n","Iteration:  24% 447/1851 [04:39<14:47,  1.58it/s]\u001b[A\n","Iteration:  24% 448/1851 [04:39<14:46,  1.58it/s]\u001b[A\n","Iteration:  24% 449/1851 [04:40<14:44,  1.59it/s]\u001b[A\n","Iteration:  24% 450/1851 [04:40<14:45,  1.58it/s]\u001b[A\n","Iteration:  24% 451/1851 [04:41<14:43,  1.58it/s]\u001b[A\n","Iteration:  24% 452/1851 [04:42<14:42,  1.59it/s]\u001b[A\n","Iteration:  24% 453/1851 [04:42<14:41,  1.59it/s]\u001b[A\n","Iteration:  25% 454/1851 [04:43<14:41,  1.58it/s]\u001b[A\n","Iteration:  25% 455/1851 [04:44<14:41,  1.58it/s]\u001b[A\n","Iteration:  25% 456/1851 [04:44<14:40,  1.59it/s]\u001b[A\n","Iteration:  25% 457/1851 [04:45<14:37,  1.59it/s]\u001b[A\n","Iteration:  25% 458/1851 [04:45<14:38,  1.59it/s]\u001b[A\n","Iteration:  25% 459/1851 [04:46<14:37,  1.59it/s]\u001b[A\n","Iteration:  25% 460/1851 [04:47<14:36,  1.59it/s]\u001b[A\n","Iteration:  25% 461/1851 [04:47<14:36,  1.59it/s]\u001b[A\n","Iteration:  25% 462/1851 [04:48<14:35,  1.59it/s]\u001b[A\n","Iteration:  25% 463/1851 [04:49<14:37,  1.58it/s]\u001b[A\n","Iteration:  25% 464/1851 [04:49<14:34,  1.59it/s]\u001b[A\n","Iteration:  25% 465/1851 [04:50<14:33,  1.59it/s]\u001b[A\n","Iteration:  25% 466/1851 [04:50<14:31,  1.59it/s]\u001b[A\n","Iteration:  25% 467/1851 [04:51<14:32,  1.59it/s]\u001b[A\n","Iteration:  25% 468/1851 [04:52<14:32,  1.59it/s]\u001b[A\n","Iteration:  25% 469/1851 [04:52<14:32,  1.58it/s]\u001b[A\n","Iteration:  25% 470/1851 [04:53<14:31,  1.58it/s]\u001b[A\n","Iteration:  25% 471/1851 [04:54<14:29,  1.59it/s]\u001b[A\n","Iteration:  25% 472/1851 [04:54<14:29,  1.59it/s]\u001b[A\n","Iteration:  26% 473/1851 [04:55<14:29,  1.59it/s]\u001b[A\n","Iteration:  26% 474/1851 [04:56<14:27,  1.59it/s]\u001b[A\n","Iteration:  26% 475/1851 [04:56<14:28,  1.58it/s]\u001b[A\n","Iteration:  26% 476/1851 [04:57<14:27,  1.59it/s]\u001b[A\n","Iteration:  26% 477/1851 [04:57<14:25,  1.59it/s]\u001b[A\n","Iteration:  26% 478/1851 [04:58<14:25,  1.59it/s]\u001b[A\n","Iteration:  26% 479/1851 [04:59<14:24,  1.59it/s]\u001b[A\n","Iteration:  26% 480/1851 [04:59<14:25,  1.58it/s]\u001b[A\n","Iteration:  26% 481/1851 [05:00<14:24,  1.59it/s]\u001b[A\n","Iteration:  26% 482/1851 [05:01<14:23,  1.59it/s]\u001b[A\n","Iteration:  26% 483/1851 [05:01<14:22,  1.59it/s]\u001b[A\n","Iteration:  26% 484/1851 [05:02<14:22,  1.59it/s]\u001b[A\n","Iteration:  26% 485/1851 [05:02<14:21,  1.59it/s]\u001b[A\n","Iteration:  26% 486/1851 [05:03<14:21,  1.59it/s]\u001b[A\n","Iteration:  26% 487/1851 [05:04<14:21,  1.58it/s]\u001b[A\n","Iteration:  26% 488/1851 [05:04<14:20,  1.58it/s]\u001b[A\n","Iteration:  26% 489/1851 [05:05<14:19,  1.58it/s]\u001b[A\n","Iteration:  26% 490/1851 [05:06<14:19,  1.58it/s]\u001b[A\n","Iteration:  27% 491/1851 [05:06<14:18,  1.58it/s]\u001b[A\n","Iteration:  27% 492/1851 [05:07<14:19,  1.58it/s]\u001b[A\n","Iteration:  27% 493/1851 [05:08<14:18,  1.58it/s]\u001b[A\n","Iteration:  27% 494/1851 [05:08<14:18,  1.58it/s]\u001b[A\n","Iteration:  27% 495/1851 [05:09<14:15,  1.58it/s]\u001b[A\n","Iteration:  27% 496/1851 [05:09<14:15,  1.58it/s]\u001b[A\n","Iteration:  27% 497/1851 [05:10<14:15,  1.58it/s]\u001b[A\n","Iteration:  27% 498/1851 [05:11<14:15,  1.58it/s]\u001b[A\n","Iteration:  27% 499/1851 [05:11<14:13,  1.58it/s]\u001b[A\n","Iteration:  27% 500/1851 [05:12<14:12,  1.58it/s]\u001b[A\n","Iteration:  27% 501/1851 [05:13<14:11,  1.58it/s]\u001b[A\n","Iteration:  27% 502/1851 [05:13<14:09,  1.59it/s]\u001b[A\n","Iteration:  27% 503/1851 [05:14<14:09,  1.59it/s]\u001b[A\n","Iteration:  27% 504/1851 [05:14<14:07,  1.59it/s]\u001b[A\n","Iteration:  27% 505/1851 [05:15<14:05,  1.59it/s]\u001b[A\n","Iteration:  27% 506/1851 [05:16<14:06,  1.59it/s]\u001b[A\n","Iteration:  27% 507/1851 [05:16<14:07,  1.59it/s]\u001b[A\n","Iteration:  27% 508/1851 [05:17<14:06,  1.59it/s]\u001b[A\n","Iteration:  27% 509/1851 [05:18<14:04,  1.59it/s]\u001b[A\n","Iteration:  28% 510/1851 [05:18<14:06,  1.58it/s]\u001b[A\n","Iteration:  28% 511/1851 [05:19<14:05,  1.58it/s]\u001b[A\n","Iteration:  28% 512/1851 [05:20<14:04,  1.59it/s]\u001b[A\n","Iteration:  28% 513/1851 [05:20<14:03,  1.59it/s]\u001b[A\n","Iteration:  28% 514/1851 [05:21<14:02,  1.59it/s]\u001b[A\n","Iteration:  28% 515/1851 [05:21<14:01,  1.59it/s]\u001b[A\n","Iteration:  28% 516/1851 [05:22<14:02,  1.58it/s]\u001b[A\n","Iteration:  28% 517/1851 [05:23<14:03,  1.58it/s]\u001b[A\n","Iteration:  28% 518/1851 [05:23<14:02,  1.58it/s]\u001b[A\n","Iteration:  28% 519/1851 [05:24<13:59,  1.59it/s]\u001b[A\n","Iteration:  28% 520/1851 [05:25<13:59,  1.59it/s]\u001b[A\n","Iteration:  28% 521/1851 [05:25<13:59,  1.58it/s]\u001b[A\n","Iteration:  28% 522/1851 [05:26<13:57,  1.59it/s]\u001b[A\n","Iteration:  28% 523/1851 [05:26<13:58,  1.58it/s]\u001b[A\n","Iteration:  28% 524/1851 [05:27<13:56,  1.59it/s]\u001b[A\n","Iteration:  28% 525/1851 [05:28<13:55,  1.59it/s]\u001b[A\n","Iteration:  28% 526/1851 [05:28<13:54,  1.59it/s]\u001b[A\n","Iteration:  28% 527/1851 [05:29<13:55,  1.58it/s]\u001b[A\n","Iteration:  29% 528/1851 [05:30<13:54,  1.59it/s]\u001b[A\n","Iteration:  29% 529/1851 [05:30<13:55,  1.58it/s]\u001b[A\n","Iteration:  29% 530/1851 [05:31<13:54,  1.58it/s]\u001b[A\n","Iteration:  29% 531/1851 [05:32<13:54,  1.58it/s]\u001b[A\n","Iteration:  29% 532/1851 [05:32<13:54,  1.58it/s]\u001b[A\n","Iteration:  29% 533/1851 [05:33<13:53,  1.58it/s]\u001b[A\n","Iteration:  29% 534/1851 [05:33<13:51,  1.58it/s]\u001b[A\n","Iteration:  29% 535/1851 [05:34<13:50,  1.58it/s]\u001b[A\n","Iteration:  29% 536/1851 [05:35<13:50,  1.58it/s]\u001b[A\n","Iteration:  29% 537/1851 [05:35<13:49,  1.58it/s]\u001b[A\n","Iteration:  29% 538/1851 [05:36<13:48,  1.58it/s]\u001b[A\n","Iteration:  29% 539/1851 [05:37<13:49,  1.58it/s]\u001b[A\n","Iteration:  29% 540/1851 [05:37<13:48,  1.58it/s]\u001b[A\n","Iteration:  29% 541/1851 [05:38<13:48,  1.58it/s]\u001b[A\n","Iteration:  29% 542/1851 [05:38<13:47,  1.58it/s]\u001b[A\n","Iteration:  29% 543/1851 [05:39<13:47,  1.58it/s]\u001b[A\n","Iteration:  29% 544/1851 [05:40<13:47,  1.58it/s]\u001b[A\n","Iteration:  29% 545/1851 [05:40<13:48,  1.58it/s]\u001b[A\n","Iteration:  29% 546/1851 [05:41<13:46,  1.58it/s]\u001b[A\n","Iteration:  30% 547/1851 [05:42<13:46,  1.58it/s]\u001b[A\n","Iteration:  30% 548/1851 [05:42<13:45,  1.58it/s]\u001b[A\n","Iteration:  30% 549/1851 [05:43<13:42,  1.58it/s]\u001b[A\n","Iteration:  30% 550/1851 [05:44<13:42,  1.58it/s]\u001b[A\n","Iteration:  30% 551/1851 [05:44<13:41,  1.58it/s]\u001b[A\n","Iteration:  30% 552/1851 [05:45<13:41,  1.58it/s]\u001b[A\n","Iteration:  30% 553/1851 [05:45<13:39,  1.58it/s]\u001b[A\n","Iteration:  30% 554/1851 [05:46<13:41,  1.58it/s]\u001b[A\n","Iteration:  30% 555/1851 [05:47<13:42,  1.58it/s]\u001b[A\n","Iteration:  30% 556/1851 [05:47<13:40,  1.58it/s]\u001b[A\n","Iteration:  30% 557/1851 [05:48<13:39,  1.58it/s]\u001b[A\n","Iteration:  30% 558/1851 [05:49<13:38,  1.58it/s]\u001b[A\n","Iteration:  30% 559/1851 [05:49<13:36,  1.58it/s]\u001b[A\n","Iteration:  30% 560/1851 [05:50<13:35,  1.58it/s]\u001b[A\n","Iteration:  30% 561/1851 [05:50<13:33,  1.59it/s]\u001b[A\n","Iteration:  30% 562/1851 [05:51<13:32,  1.59it/s]\u001b[A\n","Iteration:  30% 563/1851 [05:52<13:33,  1.58it/s]\u001b[A\n","Iteration:  30% 564/1851 [05:52<13:31,  1.59it/s]\u001b[A\n","Iteration:  31% 565/1851 [05:53<13:30,  1.59it/s]\u001b[A\n","Iteration:  31% 566/1851 [05:54<13:30,  1.59it/s]\u001b[A\n","Iteration:  31% 567/1851 [05:54<13:32,  1.58it/s]\u001b[A\n","Iteration:  31% 568/1851 [05:55<13:33,  1.58it/s]\u001b[A\n","Iteration:  31% 569/1851 [05:56<13:29,  1.58it/s]\u001b[A\n","Iteration:  31% 570/1851 [05:56<13:30,  1.58it/s]\u001b[A\n","Iteration:  31% 571/1851 [05:57<13:29,  1.58it/s]\u001b[A\n","Iteration:  31% 572/1851 [05:57<13:29,  1.58it/s]\u001b[A\n","Iteration:  31% 573/1851 [05:58<13:28,  1.58it/s]\u001b[A\n","Iteration:  31% 574/1851 [05:59<13:28,  1.58it/s]\u001b[A\n","Iteration:  31% 575/1851 [05:59<13:27,  1.58it/s]\u001b[A\n","Iteration:  31% 576/1851 [06:00<13:25,  1.58it/s]\u001b[A\n","Iteration:  31% 577/1851 [06:01<13:24,  1.58it/s]\u001b[A\n","Iteration:  31% 578/1851 [06:01<13:24,  1.58it/s]\u001b[A\n","Iteration:  31% 579/1851 [06:02<13:24,  1.58it/s]\u001b[A\n","Iteration:  31% 580/1851 [06:02<13:24,  1.58it/s]\u001b[A\n","Iteration:  31% 581/1851 [06:03<13:21,  1.59it/s]\u001b[A\n","Iteration:  31% 582/1851 [06:04<13:20,  1.59it/s]\u001b[A\n","Iteration:  31% 583/1851 [06:04<13:19,  1.59it/s]\u001b[A\n","Iteration:  32% 584/1851 [06:05<13:18,  1.59it/s]\u001b[A\n","Iteration:  32% 585/1851 [06:06<13:18,  1.59it/s]\u001b[A\n","Iteration:  32% 586/1851 [06:06<13:19,  1.58it/s]\u001b[A\n","Iteration:  32% 587/1851 [06:07<13:19,  1.58it/s]\u001b[A\n","Iteration:  32% 588/1851 [06:08<13:17,  1.58it/s]\u001b[A\n","Iteration:  32% 589/1851 [06:08<13:19,  1.58it/s]\u001b[A\n","Iteration:  32% 590/1851 [06:09<13:18,  1.58it/s]\u001b[A\n","Iteration:  32% 591/1851 [06:09<13:18,  1.58it/s]\u001b[A\n","Iteration:  32% 592/1851 [06:10<13:17,  1.58it/s]\u001b[A\n","Iteration:  32% 593/1851 [06:11<13:15,  1.58it/s]\u001b[A\n","Iteration:  32% 594/1851 [06:11<13:15,  1.58it/s]\u001b[A\n","Iteration:  32% 595/1851 [06:12<13:14,  1.58it/s]\u001b[A\n","Iteration:  32% 596/1851 [06:13<13:13,  1.58it/s]\u001b[A\n","Iteration:  32% 597/1851 [06:13<13:13,  1.58it/s]\u001b[A\n","Iteration:  32% 598/1851 [06:14<13:12,  1.58it/s]\u001b[A\n","Iteration:  32% 599/1851 [06:15<13:12,  1.58it/s]\u001b[A\n","Iteration:  32% 600/1851 [06:15<13:11,  1.58it/s]\u001b[A\n","Iteration:  32% 601/1851 [06:16<13:10,  1.58it/s]\u001b[A\n","Iteration:  33% 602/1851 [06:16<13:09,  1.58it/s]\u001b[A\n","Iteration:  33% 603/1851 [06:17<13:08,  1.58it/s]\u001b[A\n","Iteration:  33% 604/1851 [06:18<13:09,  1.58it/s]\u001b[A\n","Iteration:  33% 605/1851 [06:18<13:07,  1.58it/s]\u001b[A\n","Iteration:  33% 606/1851 [06:19<13:06,  1.58it/s]\u001b[A\n","Iteration:  33% 607/1851 [06:20<13:04,  1.59it/s]\u001b[A\n","Iteration:  33% 608/1851 [06:20<13:03,  1.59it/s]\u001b[A\n","Iteration:  33% 609/1851 [06:21<13:05,  1.58it/s]\u001b[A\n","Iteration:  33% 610/1851 [06:21<13:05,  1.58it/s]\u001b[A\n","Iteration:  33% 611/1851 [06:22<13:05,  1.58it/s]\u001b[A\n","Iteration:  33% 612/1851 [06:23<13:04,  1.58it/s]\u001b[A\n","Iteration:  33% 613/1851 [06:23<13:04,  1.58it/s]\u001b[A\n","Iteration:  33% 614/1851 [06:24<13:02,  1.58it/s]\u001b[A\n","Iteration:  33% 615/1851 [06:25<13:01,  1.58it/s]\u001b[A\n","Iteration:  33% 616/1851 [06:25<13:01,  1.58it/s]\u001b[A\n","Iteration:  33% 617/1851 [06:26<12:59,  1.58it/s]\u001b[A\n","Iteration:  33% 618/1851 [06:27<12:58,  1.58it/s]\u001b[A\n","Iteration:  33% 619/1851 [06:27<12:59,  1.58it/s]\u001b[A\n","Iteration:  33% 620/1851 [06:28<12:57,  1.58it/s]\u001b[A\n","Iteration:  34% 621/1851 [06:28<12:57,  1.58it/s]\u001b[A\n","Iteration:  34% 622/1851 [06:29<12:56,  1.58it/s]\u001b[A\n","Iteration:  34% 623/1851 [06:30<12:57,  1.58it/s]\u001b[A\n","Iteration:  34% 624/1851 [06:30<12:56,  1.58it/s]\u001b[A\n","Iteration:  34% 625/1851 [06:31<12:53,  1.58it/s]\u001b[A\n","Iteration:  34% 626/1851 [06:32<12:55,  1.58it/s]\u001b[A\n","Iteration:  34% 627/1851 [06:32<12:52,  1.58it/s]\u001b[A\n","Iteration:  34% 628/1851 [06:33<12:52,  1.58it/s]\u001b[A\n","Iteration:  34% 629/1851 [06:33<12:53,  1.58it/s]\u001b[A\n","Iteration:  34% 630/1851 [06:34<12:51,  1.58it/s]\u001b[A\n","Iteration:  34% 631/1851 [06:35<12:52,  1.58it/s]\u001b[A\n","Iteration:  34% 632/1851 [06:35<12:52,  1.58it/s]\u001b[A\n","Iteration:  34% 633/1851 [06:36<12:51,  1.58it/s]\u001b[A\n","Iteration:  34% 634/1851 [06:37<12:49,  1.58it/s]\u001b[A\n","Iteration:  34% 635/1851 [06:37<12:50,  1.58it/s]\u001b[A\n","Iteration:  34% 636/1851 [06:38<12:48,  1.58it/s]\u001b[A\n","Iteration:  34% 637/1851 [06:39<12:47,  1.58it/s]\u001b[A\n","Iteration:  34% 638/1851 [06:39<12:46,  1.58it/s]\u001b[A\n","Iteration:  35% 639/1851 [06:40<12:45,  1.58it/s]\u001b[A\n","Iteration:  35% 640/1851 [06:40<12:45,  1.58it/s]\u001b[A\n","Iteration:  35% 641/1851 [06:41<12:43,  1.58it/s]\u001b[A\n","Iteration:  35% 642/1851 [06:42<12:43,  1.58it/s]\u001b[A\n","Iteration:  35% 643/1851 [06:42<12:43,  1.58it/s]\u001b[A\n","Iteration:  35% 644/1851 [06:43<12:45,  1.58it/s]\u001b[A\n","Iteration:  35% 645/1851 [06:44<12:44,  1.58it/s]\u001b[A\n","Iteration:  35% 646/1851 [06:44<12:42,  1.58it/s]\u001b[A\n","Iteration:  35% 647/1851 [06:45<12:41,  1.58it/s]\u001b[A\n","Iteration:  35% 648/1851 [06:45<12:39,  1.58it/s]\u001b[A\n","Iteration:  35% 649/1851 [06:46<12:39,  1.58it/s]\u001b[A\n","Iteration:  35% 650/1851 [06:47<12:38,  1.58it/s]\u001b[A\n","Iteration:  35% 651/1851 [06:47<12:38,  1.58it/s]\u001b[A\n","Iteration:  35% 652/1851 [06:48<12:37,  1.58it/s]\u001b[A\n","Iteration:  35% 653/1851 [06:49<12:36,  1.58it/s]\u001b[A\n","Iteration:  35% 654/1851 [06:49<12:36,  1.58it/s]\u001b[A\n","Iteration:  35% 655/1851 [06:50<12:35,  1.58it/s]\u001b[A\n","Iteration:  35% 656/1851 [06:51<12:35,  1.58it/s]\u001b[A\n","Iteration:  35% 657/1851 [06:51<12:34,  1.58it/s]\u001b[A\n","Iteration:  36% 658/1851 [06:52<12:35,  1.58it/s]\u001b[A\n","Iteration:  36% 659/1851 [06:52<12:34,  1.58it/s]\u001b[A\n","Iteration:  36% 660/1851 [06:53<12:34,  1.58it/s]\u001b[A\n","Iteration:  36% 661/1851 [06:54<12:34,  1.58it/s]\u001b[A\n","Iteration:  36% 662/1851 [06:54<12:33,  1.58it/s]\u001b[A\n","Iteration:  36% 663/1851 [06:55<12:31,  1.58it/s]\u001b[A\n","Iteration:  36% 664/1851 [06:56<12:30,  1.58it/s]\u001b[A\n","Iteration:  36% 665/1851 [06:56<12:29,  1.58it/s]\u001b[A\n","Iteration:  36% 666/1851 [06:57<12:28,  1.58it/s]\u001b[A\n","Iteration:  36% 667/1851 [06:58<12:29,  1.58it/s]\u001b[A\n","Iteration:  36% 668/1851 [06:58<12:30,  1.58it/s]\u001b[A\n","Iteration:  36% 669/1851 [06:59<12:29,  1.58it/s]\u001b[A\n","Iteration:  36% 670/1851 [06:59<12:27,  1.58it/s]\u001b[A\n","Iteration:  36% 671/1851 [07:00<12:26,  1.58it/s]\u001b[A\n","Iteration:  36% 672/1851 [07:01<12:25,  1.58it/s]\u001b[A\n","Iteration:  36% 673/1851 [07:01<12:25,  1.58it/s]\u001b[A\n","Iteration:  36% 674/1851 [07:02<12:24,  1.58it/s]\u001b[A\n","Iteration:  36% 675/1851 [07:03<12:23,  1.58it/s]\u001b[A\n","Iteration:  37% 676/1851 [07:03<12:23,  1.58it/s]\u001b[A\n","Iteration:  37% 677/1851 [07:04<12:23,  1.58it/s]\u001b[A\n","Iteration:  37% 678/1851 [07:04<12:22,  1.58it/s]\u001b[A\n","Iteration:  37% 679/1851 [07:05<12:20,  1.58it/s]\u001b[A\n","Iteration:  37% 680/1851 [07:06<12:20,  1.58it/s]\u001b[A\n","Iteration:  37% 681/1851 [07:06<12:18,  1.58it/s]\u001b[A\n","Iteration:  37% 682/1851 [07:07<12:17,  1.59it/s]\u001b[A\n","Iteration:  37% 683/1851 [07:08<12:17,  1.58it/s]\u001b[A\n","Iteration:  37% 684/1851 [07:08<12:20,  1.58it/s]\u001b[A\n","Iteration:  37% 685/1851 [07:09<12:17,  1.58it/s]\u001b[A\n","Iteration:  37% 686/1851 [07:10<12:16,  1.58it/s]\u001b[A\n","Iteration:  37% 687/1851 [07:10<12:16,  1.58it/s]\u001b[A\n","Iteration:  37% 688/1851 [07:11<12:14,  1.58it/s]\u001b[A\n","Iteration:  37% 689/1851 [07:11<12:14,  1.58it/s]\u001b[A\n","Iteration:  37% 690/1851 [07:12<12:13,  1.58it/s]\u001b[A\n","Iteration:  37% 691/1851 [07:13<12:14,  1.58it/s]\u001b[A\n","Iteration:  37% 692/1851 [07:13<12:13,  1.58it/s]\u001b[A\n","Iteration:  37% 693/1851 [07:14<12:11,  1.58it/s]\u001b[A\n","Iteration:  37% 694/1851 [07:15<12:11,  1.58it/s]\u001b[A\n","Iteration:  38% 695/1851 [07:15<12:13,  1.58it/s]\u001b[A\n","Iteration:  38% 696/1851 [07:16<12:11,  1.58it/s]\u001b[A\n","Iteration:  38% 697/1851 [07:16<12:11,  1.58it/s]\u001b[A\n","Iteration:  38% 698/1851 [07:17<12:10,  1.58it/s]\u001b[A\n","Iteration:  38% 699/1851 [07:18<12:08,  1.58it/s]\u001b[A\n","Iteration:  38% 700/1851 [07:18<12:09,  1.58it/s]\u001b[A\n","Iteration:  38% 701/1851 [07:19<12:06,  1.58it/s]\u001b[A\n","Iteration:  38% 702/1851 [07:20<12:07,  1.58it/s]\u001b[A\n","Iteration:  38% 703/1851 [07:20<12:06,  1.58it/s]\u001b[A\n","Iteration:  38% 704/1851 [07:21<12:04,  1.58it/s]\u001b[A\n","Iteration:  38% 705/1851 [07:22<12:04,  1.58it/s]\u001b[A\n","Iteration:  38% 706/1851 [07:22<12:02,  1.58it/s]\u001b[A\n","Iteration:  38% 707/1851 [07:23<12:03,  1.58it/s]\u001b[A\n","Iteration:  38% 708/1851 [07:23<12:02,  1.58it/s]\u001b[A\n","Iteration:  38% 709/1851 [07:24<12:02,  1.58it/s]\u001b[A\n","Iteration:  38% 710/1851 [07:25<12:00,  1.58it/s]\u001b[A\n","Iteration:  38% 711/1851 [07:25<11:59,  1.58it/s]\u001b[A\n","Iteration:  38% 712/1851 [07:26<11:59,  1.58it/s]\u001b[A\n","Iteration:  39% 713/1851 [07:27<11:59,  1.58it/s]\u001b[A\n","Iteration:  39% 714/1851 [07:27<11:59,  1.58it/s]\u001b[A\n","Iteration:  39% 715/1851 [07:28<11:58,  1.58it/s]\u001b[A\n","Iteration:  39% 716/1851 [07:29<11:58,  1.58it/s]\u001b[A\n","Iteration:  39% 717/1851 [07:29<11:56,  1.58it/s]\u001b[A\n","Iteration:  39% 718/1851 [07:30<11:57,  1.58it/s]\u001b[A\n","Iteration:  39% 719/1851 [07:30<11:57,  1.58it/s]\u001b[A\n","Iteration:  39% 720/1851 [07:31<11:57,  1.58it/s]\u001b[A\n","Iteration:  39% 721/1851 [07:32<11:54,  1.58it/s]\u001b[A\n","Iteration:  39% 722/1851 [07:32<11:52,  1.58it/s]\u001b[A\n","Iteration:  39% 723/1851 [07:33<11:52,  1.58it/s]\u001b[A\n","Iteration:  39% 724/1851 [07:34<11:51,  1.58it/s]\u001b[A\n","Iteration:  39% 725/1851 [07:34<11:51,  1.58it/s]\u001b[A\n","Iteration:  39% 726/1851 [07:35<11:52,  1.58it/s]\u001b[A\n","Iteration:  39% 727/1851 [07:35<11:52,  1.58it/s]\u001b[A\n","Iteration:  39% 728/1851 [07:36<11:51,  1.58it/s]\u001b[A\n","Iteration:  39% 729/1851 [07:37<11:49,  1.58it/s]\u001b[A\n","Iteration:  39% 730/1851 [07:37<11:50,  1.58it/s]\u001b[A\n","Iteration:  39% 731/1851 [07:38<11:50,  1.58it/s]\u001b[A\n","Iteration:  40% 732/1851 [07:39<11:47,  1.58it/s]\u001b[A\n","Iteration:  40% 733/1851 [07:39<11:47,  1.58it/s]\u001b[A\n","Iteration:  40% 734/1851 [07:40<11:45,  1.58it/s]\u001b[A\n","Iteration:  40% 735/1851 [07:41<11:45,  1.58it/s]\u001b[A\n","Iteration:  40% 736/1851 [07:41<11:44,  1.58it/s]\u001b[A\n","Iteration:  40% 737/1851 [07:42<11:43,  1.58it/s]\u001b[A\n","Iteration:  40% 738/1851 [07:42<11:43,  1.58it/s]\u001b[A\n","Iteration:  40% 739/1851 [07:43<11:42,  1.58it/s]\u001b[A\n","Iteration:  40% 740/1851 [07:44<11:43,  1.58it/s]\u001b[A\n","Iteration:  40% 741/1851 [07:44<11:42,  1.58it/s]\u001b[A\n","Iteration:  40% 742/1851 [07:45<11:42,  1.58it/s]\u001b[A\n","Iteration:  40% 743/1851 [07:46<11:40,  1.58it/s]\u001b[A\n","Iteration:  40% 744/1851 [07:46<11:39,  1.58it/s]\u001b[A\n","Iteration:  40% 745/1851 [07:47<11:39,  1.58it/s]\u001b[A\n","Iteration:  40% 746/1851 [07:47<11:39,  1.58it/s]\u001b[A\n","Iteration:  40% 747/1851 [07:48<11:39,  1.58it/s]\u001b[A\n","Iteration:  40% 748/1851 [07:49<11:37,  1.58it/s]\u001b[A\n","Iteration:  40% 749/1851 [07:49<11:37,  1.58it/s]\u001b[A\n","Iteration:  41% 750/1851 [07:50<11:36,  1.58it/s]\u001b[A\n","Iteration:  41% 751/1851 [07:51<11:36,  1.58it/s]\u001b[A\n","Iteration:  41% 752/1851 [07:51<11:35,  1.58it/s]\u001b[A\n","Iteration:  41% 753/1851 [07:52<11:36,  1.58it/s]\u001b[A\n","Iteration:  41% 754/1851 [07:53<11:35,  1.58it/s]\u001b[A\n","Iteration:  41% 755/1851 [07:53<11:34,  1.58it/s]\u001b[A\n","Iteration:  41% 756/1851 [07:54<11:33,  1.58it/s]\u001b[A\n","Iteration:  41% 757/1851 [07:54<11:31,  1.58it/s]\u001b[A\n","Iteration:  41% 758/1851 [07:55<11:29,  1.58it/s]\u001b[A\n","Iteration:  41% 759/1851 [07:56<11:29,  1.58it/s]\u001b[A\n","Iteration:  41% 760/1851 [07:56<11:28,  1.58it/s]\u001b[A\n","Iteration:  41% 761/1851 [07:57<11:29,  1.58it/s]\u001b[A\n","Iteration:  41% 762/1851 [07:58<11:28,  1.58it/s]\u001b[A\n","Iteration:  41% 763/1851 [07:58<11:27,  1.58it/s]\u001b[A\n","Iteration:  41% 764/1851 [07:59<11:26,  1.58it/s]\u001b[A\n","Iteration:  41% 765/1851 [07:59<11:25,  1.58it/s]\u001b[A\n","Iteration:  41% 766/1851 [08:00<11:23,  1.59it/s]\u001b[A\n","Iteration:  41% 767/1851 [08:01<11:24,  1.58it/s]\u001b[A\n","Iteration:  41% 768/1851 [08:01<11:22,  1.59it/s]\u001b[A\n","Iteration:  42% 769/1851 [08:02<11:22,  1.58it/s]\u001b[A\n","Iteration:  42% 770/1851 [08:03<11:23,  1.58it/s]\u001b[A\n","Iteration:  42% 771/1851 [08:03<11:21,  1.58it/s]\u001b[A\n","Iteration:  42% 772/1851 [08:04<11:21,  1.58it/s]\u001b[A\n","Iteration:  42% 773/1851 [08:05<11:20,  1.58it/s]\u001b[A\n","Iteration:  42% 774/1851 [08:05<11:20,  1.58it/s]\u001b[A\n","Iteration:  42% 775/1851 [08:06<11:20,  1.58it/s]\u001b[A\n","Iteration:  42% 776/1851 [08:06<11:19,  1.58it/s]\u001b[A\n","Iteration:  42% 777/1851 [08:07<11:20,  1.58it/s]\u001b[A\n","Iteration:  42% 778/1851 [08:08<11:18,  1.58it/s]\u001b[A\n","Iteration:  42% 779/1851 [08:08<11:18,  1.58it/s]\u001b[A\n","Iteration:  42% 780/1851 [08:09<11:18,  1.58it/s]\u001b[A\n","Iteration:  42% 781/1851 [08:10<11:16,  1.58it/s]\u001b[A\n","Iteration:  42% 782/1851 [08:10<11:16,  1.58it/s]\u001b[A\n","Iteration:  42% 783/1851 [08:11<11:14,  1.58it/s]\u001b[A\n","Iteration:  42% 784/1851 [08:11<11:13,  1.58it/s]\u001b[A\n","Iteration:  42% 785/1851 [08:12<11:12,  1.59it/s]\u001b[A\n","Iteration:  42% 786/1851 [08:13<11:12,  1.58it/s]\u001b[A\n","Iteration:  43% 787/1851 [08:13<11:12,  1.58it/s]\u001b[A\n","Iteration:  43% 788/1851 [08:14<11:11,  1.58it/s]\u001b[A\n","Iteration:  43% 789/1851 [08:15<11:10,  1.58it/s]\u001b[A\n","Iteration:  43% 790/1851 [08:15<11:12,  1.58it/s]\u001b[A\n","Iteration:  43% 791/1851 [08:16<11:11,  1.58it/s]\u001b[A\n","Iteration:  43% 792/1851 [08:17<11:10,  1.58it/s]\u001b[A\n","Iteration:  43% 793/1851 [08:17<11:09,  1.58it/s]\u001b[A\n","Iteration:  43% 794/1851 [08:18<11:06,  1.59it/s]\u001b[A\n","Iteration:  43% 795/1851 [08:18<11:06,  1.58it/s]\u001b[A\n","Iteration:  43% 796/1851 [08:19<11:06,  1.58it/s]\u001b[A\n","Iteration:  43% 797/1851 [08:20<11:06,  1.58it/s]\u001b[A\n","Iteration:  43% 798/1851 [08:20<11:06,  1.58it/s]\u001b[A\n","Iteration:  43% 799/1851 [08:21<11:05,  1.58it/s]\u001b[A\n","Iteration:  43% 800/1851 [08:22<11:04,  1.58it/s]\u001b[A\n","Iteration:  43% 801/1851 [08:22<11:03,  1.58it/s]\u001b[A\n","Iteration:  43% 802/1851 [08:23<11:02,  1.58it/s]\u001b[A\n","Iteration:  43% 803/1851 [08:24<11:03,  1.58it/s]\u001b[A\n","Iteration:  43% 804/1851 [08:24<11:02,  1.58it/s]\u001b[A\n","Iteration:  43% 805/1851 [08:25<11:02,  1.58it/s]\u001b[A\n","Iteration:  44% 806/1851 [08:25<11:00,  1.58it/s]\u001b[A\n","Iteration:  44% 807/1851 [08:26<10:59,  1.58it/s]\u001b[A\n","Iteration:  44% 808/1851 [08:27<10:58,  1.58it/s]\u001b[A\n","Iteration:  44% 809/1851 [08:27<10:58,  1.58it/s]\u001b[A\n","Iteration:  44% 810/1851 [08:28<10:57,  1.58it/s]\u001b[A\n","Iteration:  44% 811/1851 [08:29<10:55,  1.59it/s]\u001b[A\n","Iteration:  44% 812/1851 [08:29<10:54,  1.59it/s]\u001b[A\n","Iteration:  44% 813/1851 [08:30<10:54,  1.59it/s]\u001b[A\n","Iteration:  44% 814/1851 [08:30<10:55,  1.58it/s]\u001b[A\n","Iteration:  44% 815/1851 [08:31<10:52,  1.59it/s]\u001b[A\n","Iteration:  44% 816/1851 [08:32<10:54,  1.58it/s]\u001b[A\n","Iteration:  44% 817/1851 [08:32<10:51,  1.59it/s]\u001b[A\n","Iteration:  44% 818/1851 [08:33<10:51,  1.58it/s]\u001b[A\n","Iteration:  44% 819/1851 [08:34<10:50,  1.59it/s]\u001b[A\n","Iteration:  44% 820/1851 [08:34<10:50,  1.58it/s]\u001b[A\n","Iteration:  44% 821/1851 [08:35<10:51,  1.58it/s]\u001b[A\n","Iteration:  44% 822/1851 [08:36<10:51,  1.58it/s]\u001b[A\n","Iteration:  44% 823/1851 [08:36<10:50,  1.58it/s]\u001b[A\n","Iteration:  45% 824/1851 [08:37<10:50,  1.58it/s]\u001b[A\n","Iteration:  45% 825/1851 [08:37<10:48,  1.58it/s]\u001b[A\n","Iteration:  45% 826/1851 [08:38<10:47,  1.58it/s]\u001b[A\n","Iteration:  45% 827/1851 [08:39<10:47,  1.58it/s]\u001b[A\n","Iteration:  45% 828/1851 [08:39<10:46,  1.58it/s]\u001b[A\n","Iteration:  45% 829/1851 [08:40<10:45,  1.58it/s]\u001b[A\n","Iteration:  45% 830/1851 [08:41<10:45,  1.58it/s]\u001b[A\n","Iteration:  45% 831/1851 [08:41<10:45,  1.58it/s]\u001b[A\n","Iteration:  45% 832/1851 [08:42<10:44,  1.58it/s]\u001b[A\n","Iteration:  45% 833/1851 [08:42<10:44,  1.58it/s]\u001b[A\n","Iteration:  45% 834/1851 [08:43<10:42,  1.58it/s]\u001b[A\n","Iteration:  45% 835/1851 [08:44<10:41,  1.58it/s]\u001b[A\n","Iteration:  45% 836/1851 [08:44<10:42,  1.58it/s]\u001b[A\n","Iteration:  45% 837/1851 [08:45<10:41,  1.58it/s]\u001b[A\n","Iteration:  45% 838/1851 [08:46<10:41,  1.58it/s]\u001b[A\n","Iteration:  45% 839/1851 [08:46<10:40,  1.58it/s]\u001b[A\n","Iteration:  45% 840/1851 [08:47<10:40,  1.58it/s]\u001b[A\n","Iteration:  45% 841/1851 [08:48<10:40,  1.58it/s]\u001b[A\n","Iteration:  45% 842/1851 [08:48<10:38,  1.58it/s]\u001b[A\n","Iteration:  46% 843/1851 [08:49<10:37,  1.58it/s]\u001b[A\n","Iteration:  46% 844/1851 [08:49<10:36,  1.58it/s]\u001b[A\n","Iteration:  46% 845/1851 [08:50<10:36,  1.58it/s]\u001b[A\n","Iteration:  46% 846/1851 [08:51<10:36,  1.58it/s]\u001b[A\n","Iteration:  46% 847/1851 [08:51<10:34,  1.58it/s]\u001b[A\n","Iteration:  46% 848/1851 [08:52<10:34,  1.58it/s]\u001b[A\n","Iteration:  46% 849/1851 [08:53<10:33,  1.58it/s]\u001b[A\n","Iteration:  46% 850/1851 [08:53<10:33,  1.58it/s]\u001b[A\n","Iteration:  46% 851/1851 [08:54<10:33,  1.58it/s]\u001b[A\n","Iteration:  46% 852/1851 [08:54<10:31,  1.58it/s]\u001b[A\n","Iteration:  46% 853/1851 [08:55<10:31,  1.58it/s]\u001b[A\n","Iteration:  46% 854/1851 [08:56<10:31,  1.58it/s]\u001b[A\n","Iteration:  46% 855/1851 [08:56<10:31,  1.58it/s]\u001b[A\n","Iteration:  46% 856/1851 [08:57<10:30,  1.58it/s]\u001b[A\n","Iteration:  46% 857/1851 [08:58<10:29,  1.58it/s]\u001b[A\n","Iteration:  46% 858/1851 [08:58<10:28,  1.58it/s]\u001b[A\n","Iteration:  46% 859/1851 [08:59<10:28,  1.58it/s]\u001b[A\n","Iteration:  46% 860/1851 [09:00<10:27,  1.58it/s]\u001b[A\n","Iteration:  47% 861/1851 [09:00<10:26,  1.58it/s]\u001b[A\n","Iteration:  47% 862/1851 [09:01<10:24,  1.58it/s]\u001b[A\n","Iteration:  47% 863/1851 [09:01<10:25,  1.58it/s]\u001b[A\n","Iteration:  47% 864/1851 [09:02<10:25,  1.58it/s]\u001b[A\n","Iteration:  47% 865/1851 [09:03<10:24,  1.58it/s]\u001b[A\n","Iteration:  47% 866/1851 [09:03<10:24,  1.58it/s]\u001b[A\n","Iteration:  47% 867/1851 [09:04<10:23,  1.58it/s]\u001b[A\n","Iteration:  47% 868/1851 [09:05<10:22,  1.58it/s]\u001b[A\n","Iteration:  47% 869/1851 [09:05<10:20,  1.58it/s]\u001b[A\n","Iteration:  47% 870/1851 [09:06<10:20,  1.58it/s]\u001b[A\n","Iteration:  47% 871/1851 [09:07<10:20,  1.58it/s]\u001b[A\n","Iteration:  47% 872/1851 [09:07<10:19,  1.58it/s]\u001b[A\n","Iteration:  47% 873/1851 [09:08<10:20,  1.58it/s]\u001b[A\n","Iteration:  47% 874/1851 [09:08<10:19,  1.58it/s]\u001b[A\n","Iteration:  47% 875/1851 [09:09<10:18,  1.58it/s]\u001b[A\n","Iteration:  47% 876/1851 [09:10<10:19,  1.58it/s]\u001b[A\n","Iteration:  47% 877/1851 [09:10<10:17,  1.58it/s]\u001b[A\n","Iteration:  47% 878/1851 [09:11<10:17,  1.58it/s]\u001b[A\n","Iteration:  47% 879/1851 [09:12<10:16,  1.58it/s]\u001b[A\n","Iteration:  48% 880/1851 [09:12<10:14,  1.58it/s]\u001b[A\n","Iteration:  48% 881/1851 [09:13<10:14,  1.58it/s]\u001b[A\n","Iteration:  48% 882/1851 [09:13<10:13,  1.58it/s]\u001b[A\n","Iteration:  48% 883/1851 [09:14<10:12,  1.58it/s]\u001b[A\n","Iteration:  48% 884/1851 [09:15<10:12,  1.58it/s]\u001b[A\n","Iteration:  48% 885/1851 [09:15<10:12,  1.58it/s]\u001b[A\n","Iteration:  48% 886/1851 [09:16<10:13,  1.57it/s]\u001b[A\n","Iteration:  48% 887/1851 [09:17<10:10,  1.58it/s]\u001b[A\n","Iteration:  48% 888/1851 [09:17<10:09,  1.58it/s]\u001b[A\n","Iteration:  48% 889/1851 [09:18<10:09,  1.58it/s]\u001b[A\n","Iteration:  48% 890/1851 [09:19<10:08,  1.58it/s]\u001b[A\n","Iteration:  48% 891/1851 [09:19<10:08,  1.58it/s]\u001b[A\n","Iteration:  48% 892/1851 [09:20<10:07,  1.58it/s]\u001b[A\n","Iteration:  48% 893/1851 [09:20<10:06,  1.58it/s]\u001b[A\n","Iteration:  48% 894/1851 [09:21<10:07,  1.58it/s]\u001b[A\n","Iteration:  48% 895/1851 [09:22<10:06,  1.58it/s]\u001b[A\n","Iteration:  48% 896/1851 [09:22<10:04,  1.58it/s]\u001b[A\n","Iteration:  48% 897/1851 [09:23<10:03,  1.58it/s]\u001b[A\n","Iteration:  49% 898/1851 [09:24<10:03,  1.58it/s]\u001b[A\n","Iteration:  49% 899/1851 [09:24<10:01,  1.58it/s]\u001b[A\n","Iteration:  49% 900/1851 [09:25<10:00,  1.58it/s]\u001b[A\n","Iteration:  49% 901/1851 [09:26<10:00,  1.58it/s]\u001b[A\n","Iteration:  49% 902/1851 [09:26<10:01,  1.58it/s]\u001b[A\n","Iteration:  49% 903/1851 [09:27<09:59,  1.58it/s]\u001b[A\n","Iteration:  49% 904/1851 [09:27<09:59,  1.58it/s]\u001b[A\n","Iteration:  49% 905/1851 [09:28<09:57,  1.58it/s]\u001b[A\n","Iteration:  49% 906/1851 [09:29<09:57,  1.58it/s]\u001b[A\n","Iteration:  49% 907/1851 [09:29<09:56,  1.58it/s]\u001b[A\n","Iteration:  49% 908/1851 [09:30<09:56,  1.58it/s]\u001b[A\n","Iteration:  49% 909/1851 [09:31<09:55,  1.58it/s]\u001b[A\n","Iteration:  49% 910/1851 [09:31<09:54,  1.58it/s]\u001b[A\n","Iteration:  49% 911/1851 [09:32<09:54,  1.58it/s]\u001b[A\n","Iteration:  49% 912/1851 [09:32<09:53,  1.58it/s]\u001b[A\n","Iteration:  49% 913/1851 [09:33<09:54,  1.58it/s]\u001b[A\n","Iteration:  49% 914/1851 [09:34<09:53,  1.58it/s]\u001b[A\n","Iteration:  49% 915/1851 [09:34<09:52,  1.58it/s]\u001b[A\n","Iteration:  49% 916/1851 [09:35<09:52,  1.58it/s]\u001b[A\n","Iteration:  50% 917/1851 [09:36<09:52,  1.58it/s]\u001b[A\n","Iteration:  50% 918/1851 [09:36<09:50,  1.58it/s]\u001b[A\n","Iteration:  50% 919/1851 [09:37<09:49,  1.58it/s]\u001b[A\n","Iteration:  50% 920/1851 [09:38<09:49,  1.58it/s]\u001b[A\n","Iteration:  50% 921/1851 [09:38<09:48,  1.58it/s]\u001b[A\n","Iteration:  50% 922/1851 [09:39<09:47,  1.58it/s]\u001b[A\n","Iteration:  50% 923/1851 [09:39<09:45,  1.58it/s]\u001b[A\n","Iteration:  50% 924/1851 [09:40<09:45,  1.58it/s]\u001b[A\n","Iteration:  50% 925/1851 [09:41<09:44,  1.58it/s]\u001b[A\n","Iteration:  50% 926/1851 [09:41<09:45,  1.58it/s]\u001b[A\n","Iteration:  50% 927/1851 [09:42<09:44,  1.58it/s]\u001b[A\n","Iteration:  50% 928/1851 [09:43<09:43,  1.58it/s]\u001b[A\n","Iteration:  50% 929/1851 [09:43<09:43,  1.58it/s]\u001b[A\n","Iteration:  50% 930/1851 [09:44<09:42,  1.58it/s]\u001b[A\n","Iteration:  50% 931/1851 [09:45<09:42,  1.58it/s]\u001b[A\n","Iteration:  50% 932/1851 [09:45<09:41,  1.58it/s]\u001b[A\n","Iteration:  50% 933/1851 [09:46<09:40,  1.58it/s]\u001b[A\n","Iteration:  50% 934/1851 [09:46<09:40,  1.58it/s]\u001b[A\n","Iteration:  51% 935/1851 [09:47<09:39,  1.58it/s]\u001b[A\n","Iteration:  51% 936/1851 [09:48<09:40,  1.58it/s]\u001b[A\n","Iteration:  51% 937/1851 [09:48<09:39,  1.58it/s]\u001b[A\n","Iteration:  51% 938/1851 [09:49<09:37,  1.58it/s]\u001b[A\n","Iteration:  51% 939/1851 [09:50<09:38,  1.58it/s]\u001b[A\n","Iteration:  51% 940/1851 [09:50<09:38,  1.58it/s]\u001b[A\n","Iteration:  51% 941/1851 [09:51<09:38,  1.57it/s]\u001b[A\n","Iteration:  51% 942/1851 [09:51<09:36,  1.58it/s]\u001b[A\n","Iteration:  51% 943/1851 [09:52<09:35,  1.58it/s]\u001b[A\n","Iteration:  51% 944/1851 [09:53<09:34,  1.58it/s]\u001b[A\n","Iteration:  51% 945/1851 [09:53<09:32,  1.58it/s]\u001b[A\n","Iteration:  51% 946/1851 [09:54<09:31,  1.58it/s]\u001b[A\n","Iteration:  51% 947/1851 [09:55<09:30,  1.58it/s]\u001b[A\n","Iteration:  51% 948/1851 [09:55<09:30,  1.58it/s]\u001b[A\n","Iteration:  51% 949/1851 [09:56<09:29,  1.58it/s]\u001b[A\n","Iteration:  51% 950/1851 [09:57<09:30,  1.58it/s]\u001b[A\n","Iteration:  51% 951/1851 [09:57<09:28,  1.58it/s]\u001b[A\n","Iteration:  51% 952/1851 [09:58<09:28,  1.58it/s]\u001b[A\n","Iteration:  51% 953/1851 [09:58<09:28,  1.58it/s]\u001b[A\n","Iteration:  52% 954/1851 [09:59<09:27,  1.58it/s]\u001b[A\n","Iteration:  52% 955/1851 [10:00<09:27,  1.58it/s]\u001b[A\n","Iteration:  52% 956/1851 [10:00<09:26,  1.58it/s]\u001b[A\n","Iteration:  52% 957/1851 [10:01<09:25,  1.58it/s]\u001b[A\n","Iteration:  52% 958/1851 [10:02<09:24,  1.58it/s]\u001b[A\n","Iteration:  52% 959/1851 [10:02<09:24,  1.58it/s]\u001b[A\n","Iteration:  52% 960/1851 [10:03<09:23,  1.58it/s]\u001b[A\n","Iteration:  52% 961/1851 [10:03<09:23,  1.58it/s]\u001b[A\n","Iteration:  52% 962/1851 [10:04<09:23,  1.58it/s]\u001b[A\n","Iteration:  52% 963/1851 [10:05<09:23,  1.58it/s]\u001b[A\n","Iteration:  52% 964/1851 [10:05<09:21,  1.58it/s]\u001b[A\n","Iteration:  52% 965/1851 [10:06<09:20,  1.58it/s]\u001b[A\n","Iteration:  52% 966/1851 [10:07<09:20,  1.58it/s]\u001b[A\n","Iteration:  52% 967/1851 [10:07<09:19,  1.58it/s]\u001b[A\n","Iteration:  52% 968/1851 [10:08<09:17,  1.58it/s]\u001b[A\n","Iteration:  52% 969/1851 [10:09<09:17,  1.58it/s]\u001b[A\n","Iteration:  52% 970/1851 [10:09<09:17,  1.58it/s]\u001b[A\n","Iteration:  52% 971/1851 [10:10<09:16,  1.58it/s]\u001b[A\n","Iteration:  53% 972/1851 [10:10<09:16,  1.58it/s]\u001b[A\n","Iteration:  53% 973/1851 [10:11<09:17,  1.57it/s]\u001b[A\n","Iteration:  53% 974/1851 [10:12<09:15,  1.58it/s]\u001b[A\n","Iteration:  53% 975/1851 [10:12<09:14,  1.58it/s]\u001b[A\n","Iteration:  53% 976/1851 [10:13<09:14,  1.58it/s]\u001b[A\n","Iteration:  53% 977/1851 [10:14<09:13,  1.58it/s]\u001b[A\n","Iteration:  53% 978/1851 [10:14<09:13,  1.58it/s]\u001b[A\n","Iteration:  53% 979/1851 [10:15<09:13,  1.57it/s]\u001b[A\n","Iteration:  53% 980/1851 [10:16<09:11,  1.58it/s]\u001b[A\n","Iteration:  53% 981/1851 [10:16<09:10,  1.58it/s]\u001b[A\n","Iteration:  53% 982/1851 [10:17<09:09,  1.58it/s]\u001b[A\n","Iteration:  53% 983/1851 [10:17<09:09,  1.58it/s]\u001b[A\n","Iteration:  53% 984/1851 [10:18<09:09,  1.58it/s]\u001b[A\n","Iteration:  53% 985/1851 [10:19<09:09,  1.58it/s]\u001b[A\n","Iteration:  53% 986/1851 [10:19<09:09,  1.58it/s]\u001b[A\n","Iteration:  53% 987/1851 [10:20<09:07,  1.58it/s]\u001b[A\n","Iteration:  53% 988/1851 [10:21<09:05,  1.58it/s]\u001b[A\n","Iteration:  53% 989/1851 [10:21<09:06,  1.58it/s]\u001b[A\n","Iteration:  53% 990/1851 [10:22<09:04,  1.58it/s]\u001b[A\n","Iteration:  54% 991/1851 [10:22<09:03,  1.58it/s]\u001b[A\n","Iteration:  54% 992/1851 [10:23<09:03,  1.58it/s]\u001b[A\n","Iteration:  54% 993/1851 [10:24<09:02,  1.58it/s]\u001b[A\n","Iteration:  54% 994/1851 [10:24<09:01,  1.58it/s]\u001b[A\n","Iteration:  54% 995/1851 [10:25<09:01,  1.58it/s]\u001b[A\n","Iteration:  54% 996/1851 [10:26<09:01,  1.58it/s]\u001b[A\n","Iteration:  54% 997/1851 [10:26<09:00,  1.58it/s]\u001b[A\n","Iteration:  54% 998/1851 [10:27<08:59,  1.58it/s]\u001b[A\n","Iteration:  54% 999/1851 [10:28<09:00,  1.58it/s]\u001b[A\n","Iteration:  54% 1000/1851 [10:28<08:59,  1.58it/s]\u001b[A\n","Iteration:  54% 1001/1851 [10:29<08:58,  1.58it/s]\u001b[A\n","Iteration:  54% 1002/1851 [10:29<08:58,  1.58it/s]\u001b[A\n","Iteration:  54% 1003/1851 [10:30<08:58,  1.57it/s]\u001b[A\n","Iteration:  54% 1004/1851 [10:31<08:58,  1.57it/s]\u001b[A\n","Iteration:  54% 1005/1851 [10:31<08:55,  1.58it/s]\u001b[A\n","Iteration:  54% 1006/1851 [10:32<08:55,  1.58it/s]\u001b[A\n","Iteration:  54% 1007/1851 [10:33<08:55,  1.58it/s]\u001b[A\n","Iteration:  54% 1008/1851 [10:33<08:54,  1.58it/s]\u001b[A\n","Iteration:  55% 1009/1851 [10:34<08:54,  1.58it/s]\u001b[A\n","Iteration:  55% 1010/1851 [10:35<08:52,  1.58it/s]\u001b[A\n","Iteration:  55% 1011/1851 [10:35<08:51,  1.58it/s]\u001b[A\n","Iteration:  55% 1012/1851 [10:36<08:51,  1.58it/s]\u001b[A\n","Iteration:  55% 1013/1851 [10:36<08:51,  1.58it/s]\u001b[A\n","Iteration:  55% 1014/1851 [10:37<08:50,  1.58it/s]\u001b[A\n","Iteration:  55% 1015/1851 [10:38<08:50,  1.58it/s]\u001b[A\n","Iteration:  55% 1016/1851 [10:38<08:49,  1.58it/s]\u001b[A\n","Iteration:  55% 1017/1851 [10:39<08:48,  1.58it/s]\u001b[A\n","Iteration:  55% 1018/1851 [10:40<08:47,  1.58it/s]\u001b[A\n","Iteration:  55% 1019/1851 [10:40<08:47,  1.58it/s]\u001b[A\n","Iteration:  55% 1020/1851 [10:41<08:45,  1.58it/s]\u001b[A\n","Iteration:  55% 1021/1851 [10:41<08:45,  1.58it/s]\u001b[A\n","Iteration:  55% 1022/1851 [10:42<08:45,  1.58it/s]\u001b[A\n","Iteration:  55% 1023/1851 [10:43<08:44,  1.58it/s]\u001b[A\n","Iteration:  55% 1024/1851 [10:43<08:43,  1.58it/s]\u001b[A\n","Iteration:  55% 1025/1851 [10:44<08:43,  1.58it/s]\u001b[A\n","Iteration:  55% 1026/1851 [10:45<08:42,  1.58it/s]\u001b[A\n","Iteration:  55% 1027/1851 [10:45<08:41,  1.58it/s]\u001b[A\n","Iteration:  56% 1028/1851 [10:46<08:41,  1.58it/s]\u001b[A\n","Iteration:  56% 1029/1851 [10:47<08:40,  1.58it/s]\u001b[A\n","Iteration:  56% 1030/1851 [10:47<08:40,  1.58it/s]\u001b[A\n","Iteration:  56% 1031/1851 [10:48<08:38,  1.58it/s]\u001b[A\n","Iteration:  56% 1032/1851 [10:48<08:37,  1.58it/s]\u001b[A\n","Iteration:  56% 1033/1851 [10:49<08:37,  1.58it/s]\u001b[A\n","Iteration:  56% 1034/1851 [10:50<08:38,  1.58it/s]\u001b[A\n","Iteration:  56% 1035/1851 [10:50<08:36,  1.58it/s]\u001b[A\n","Iteration:  56% 1036/1851 [10:51<08:36,  1.58it/s]\u001b[A\n","Iteration:  56% 1037/1851 [10:52<08:34,  1.58it/s]\u001b[A\n","Iteration:  56% 1038/1851 [10:52<08:36,  1.57it/s]\u001b[A\n","Iteration:  56% 1039/1851 [10:53<08:35,  1.58it/s]\u001b[A\n","Iteration:  56% 1040/1851 [10:54<08:34,  1.58it/s]\u001b[A\n","Iteration:  56% 1041/1851 [10:54<08:32,  1.58it/s]\u001b[A\n","Iteration:  56% 1042/1851 [10:55<08:31,  1.58it/s]\u001b[A\n","Iteration:  56% 1043/1851 [10:55<08:30,  1.58it/s]\u001b[A\n","Iteration:  56% 1044/1851 [10:56<08:31,  1.58it/s]\u001b[A\n","Iteration:  56% 1045/1851 [10:57<08:30,  1.58it/s]\u001b[A\n","Iteration:  57% 1046/1851 [10:57<08:29,  1.58it/s]\u001b[A\n","Iteration:  57% 1047/1851 [10:58<08:29,  1.58it/s]\u001b[A\n","Iteration:  57% 1048/1851 [10:59<08:29,  1.58it/s]\u001b[A\n","Iteration:  57% 1049/1851 [10:59<08:28,  1.58it/s]\u001b[A\n","Iteration:  57% 1050/1851 [11:00<08:27,  1.58it/s]\u001b[A\n","Iteration:  57% 1051/1851 [11:00<08:26,  1.58it/s]\u001b[A\n","Iteration:  57% 1052/1851 [11:01<08:24,  1.58it/s]\u001b[A\n","Iteration:  57% 1053/1851 [11:02<08:23,  1.58it/s]\u001b[A\n","Iteration:  57% 1054/1851 [11:02<08:23,  1.58it/s]\u001b[A\n","Iteration:  57% 1055/1851 [11:03<08:22,  1.58it/s]\u001b[A\n","Iteration:  57% 1056/1851 [11:04<08:22,  1.58it/s]\u001b[A\n","Iteration:  57% 1057/1851 [11:04<08:21,  1.58it/s]\u001b[A\n","Iteration:  57% 1058/1851 [11:05<08:21,  1.58it/s]\u001b[A\n","Iteration:  57% 1059/1851 [11:06<08:20,  1.58it/s]\u001b[A\n","Iteration:  57% 1060/1851 [11:06<08:19,  1.58it/s]\u001b[A\n","Iteration:  57% 1061/1851 [11:07<08:18,  1.59it/s]\u001b[A\n","Iteration:  57% 1062/1851 [11:07<08:17,  1.59it/s]\u001b[A\n","Iteration:  57% 1063/1851 [11:08<08:16,  1.59it/s]\u001b[A\n","Iteration:  57% 1064/1851 [11:09<08:17,  1.58it/s]\u001b[A\n","Iteration:  58% 1065/1851 [11:09<08:16,  1.58it/s]\u001b[A\n","Iteration:  58% 1066/1851 [11:10<08:14,  1.59it/s]\u001b[A\n","Iteration:  58% 1067/1851 [11:11<08:15,  1.58it/s]\u001b[A\n","Iteration:  58% 1068/1851 [11:11<08:15,  1.58it/s]\u001b[A\n","Iteration:  58% 1069/1851 [11:12<08:13,  1.58it/s]\u001b[A\n","Iteration:  58% 1070/1851 [11:12<08:13,  1.58it/s]\u001b[A\n","Iteration:  58% 1071/1851 [11:13<08:12,  1.58it/s]\u001b[A\n","Iteration:  58% 1072/1851 [11:14<08:12,  1.58it/s]\u001b[A\n","Iteration:  58% 1073/1851 [11:14<08:13,  1.58it/s]\u001b[A\n","Iteration:  58% 1074/1851 [11:15<08:11,  1.58it/s]\u001b[A\n","Iteration:  58% 1075/1851 [11:16<08:11,  1.58it/s]\u001b[A\n","Iteration:  58% 1076/1851 [11:16<08:08,  1.59it/s]\u001b[A\n","Iteration:  58% 1077/1851 [11:17<08:07,  1.59it/s]\u001b[A\n","Iteration:  58% 1078/1851 [11:18<08:07,  1.59it/s]\u001b[A\n","Iteration:  58% 1079/1851 [11:18<08:07,  1.58it/s]\u001b[A\n","Iteration:  58% 1080/1851 [11:19<08:05,  1.59it/s]\u001b[A\n","Iteration:  58% 1081/1851 [11:19<08:05,  1.58it/s]\u001b[A\n","Iteration:  58% 1082/1851 [11:20<08:06,  1.58it/s]\u001b[A\n","Iteration:  59% 1083/1851 [11:21<08:04,  1.59it/s]\u001b[A\n","Iteration:  59% 1084/1851 [11:21<08:04,  1.58it/s]\u001b[A\n","Iteration:  59% 1085/1851 [11:22<08:03,  1.59it/s]\u001b[A\n","Iteration:  59% 1086/1851 [11:23<08:02,  1.59it/s]\u001b[A\n","Iteration:  59% 1087/1851 [11:23<08:03,  1.58it/s]\u001b[A\n","Iteration:  59% 1088/1851 [11:24<08:01,  1.58it/s]\u001b[A\n","Iteration:  59% 1089/1851 [11:24<08:00,  1.59it/s]\u001b[A\n","Iteration:  59% 1090/1851 [11:25<08:00,  1.58it/s]\u001b[A\n","Iteration:  59% 1091/1851 [11:26<07:59,  1.59it/s]\u001b[A\n","Iteration:  59% 1092/1851 [11:26<08:00,  1.58it/s]\u001b[A\n","Iteration:  59% 1093/1851 [11:27<07:58,  1.58it/s]\u001b[A\n","Iteration:  59% 1094/1851 [11:28<07:58,  1.58it/s]\u001b[A\n","Iteration:  59% 1095/1851 [11:28<07:58,  1.58it/s]\u001b[A\n","Iteration:  59% 1096/1851 [11:29<07:57,  1.58it/s]\u001b[A\n","Iteration:  59% 1097/1851 [11:30<07:56,  1.58it/s]\u001b[A\n","Iteration:  59% 1098/1851 [11:30<07:54,  1.59it/s]\u001b[A\n","Iteration:  59% 1099/1851 [11:31<07:53,  1.59it/s]\u001b[A\n","Iteration:  59% 1100/1851 [11:31<07:53,  1.59it/s]\u001b[A\n","Iteration:  59% 1101/1851 [11:32<07:52,  1.59it/s]\u001b[A\n","Iteration:  60% 1102/1851 [11:33<07:52,  1.58it/s]\u001b[A\n","Iteration:  60% 1103/1851 [11:33<07:52,  1.58it/s]\u001b[A\n","Iteration:  60% 1104/1851 [11:34<07:51,  1.58it/s]\u001b[A\n","Iteration:  60% 1105/1851 [11:35<07:50,  1.59it/s]\u001b[A\n","Iteration:  60% 1106/1851 [11:35<07:50,  1.58it/s]\u001b[A\n","Iteration:  60% 1107/1851 [11:36<07:48,  1.59it/s]\u001b[A\n","Iteration:  60% 1108/1851 [11:36<07:48,  1.59it/s]\u001b[A\n","Iteration:  60% 1109/1851 [11:37<07:47,  1.59it/s]\u001b[A\n","Iteration:  60% 1110/1851 [11:38<07:46,  1.59it/s]\u001b[A\n","Iteration:  60% 1111/1851 [11:38<07:46,  1.59it/s]\u001b[A\n","Iteration:  60% 1112/1851 [11:39<07:46,  1.58it/s]\u001b[A\n","Iteration:  60% 1113/1851 [11:40<07:45,  1.58it/s]\u001b[A\n","Iteration:  60% 1114/1851 [11:40<07:45,  1.58it/s]\u001b[A\n","Iteration:  60% 1115/1851 [11:41<07:44,  1.59it/s]\u001b[A\n","Iteration:  60% 1116/1851 [11:42<07:42,  1.59it/s]\u001b[A\n","Iteration:  60% 1117/1851 [11:42<07:43,  1.58it/s]\u001b[A\n","Iteration:  60% 1118/1851 [11:43<07:42,  1.59it/s]\u001b[A\n","Iteration:  60% 1119/1851 [11:43<07:42,  1.58it/s]\u001b[A\n","Iteration:  61% 1120/1851 [11:44<07:41,  1.58it/s]\u001b[A\n","Iteration:  61% 1121/1851 [11:45<07:41,  1.58it/s]\u001b[A\n","Iteration:  61% 1122/1851 [11:45<07:40,  1.58it/s]\u001b[A\n","Iteration:  61% 1123/1851 [11:46<07:39,  1.58it/s]\u001b[A\n","Iteration:  61% 1124/1851 [11:47<07:39,  1.58it/s]\u001b[A\n","Iteration:  61% 1125/1851 [11:47<07:38,  1.58it/s]\u001b[A\n","Iteration:  61% 1126/1851 [11:48<07:37,  1.58it/s]\u001b[A\n","Iteration:  61% 1127/1851 [11:48<07:36,  1.59it/s]\u001b[A\n","Iteration:  61% 1128/1851 [11:49<07:36,  1.58it/s]\u001b[A\n","Iteration:  61% 1129/1851 [11:50<07:35,  1.59it/s]\u001b[A\n","Iteration:  61% 1130/1851 [11:50<07:35,  1.58it/s]\u001b[A\n","Iteration:  61% 1131/1851 [11:51<07:34,  1.59it/s]\u001b[A\n","Iteration:  61% 1132/1851 [11:52<07:33,  1.59it/s]\u001b[A\n","Iteration:  61% 1133/1851 [11:52<07:33,  1.58it/s]\u001b[A\n","Iteration:  61% 1134/1851 [11:53<07:32,  1.58it/s]\u001b[A\n","Iteration:  61% 1135/1851 [11:54<07:31,  1.59it/s]\u001b[A\n","Iteration:  61% 1136/1851 [11:54<07:32,  1.58it/s]\u001b[A\n","Iteration:  61% 1137/1851 [11:55<07:31,  1.58it/s]\u001b[A\n","Iteration:  61% 1138/1851 [11:55<07:30,  1.58it/s]\u001b[A\n","Iteration:  62% 1139/1851 [11:56<07:30,  1.58it/s]\u001b[A\n","Iteration:  62% 1140/1851 [11:57<07:28,  1.58it/s]\u001b[A\n","Iteration:  62% 1141/1851 [11:57<07:29,  1.58it/s]\u001b[A\n","Iteration:  62% 1142/1851 [11:58<07:27,  1.58it/s]\u001b[A\n","Iteration:  62% 1143/1851 [11:59<07:26,  1.58it/s]\u001b[A\n","Iteration:  62% 1144/1851 [11:59<07:26,  1.58it/s]\u001b[A\n","Iteration:  62% 1145/1851 [12:00<07:24,  1.59it/s]\u001b[A\n","Iteration:  62% 1146/1851 [12:00<07:24,  1.59it/s]\u001b[A\n","Iteration:  62% 1147/1851 [12:01<07:23,  1.59it/s]\u001b[A\n","Iteration:  62% 1148/1851 [12:02<07:23,  1.59it/s]\u001b[A\n","Iteration:  62% 1149/1851 [12:02<07:22,  1.59it/s]\u001b[A\n","Iteration:  62% 1150/1851 [12:03<07:21,  1.59it/s]\u001b[A\n","Iteration:  62% 1151/1851 [12:04<07:21,  1.59it/s]\u001b[A\n","Iteration:  62% 1152/1851 [12:04<07:20,  1.59it/s]\u001b[A\n","Iteration:  62% 1153/1851 [12:05<07:20,  1.59it/s]\u001b[A\n","Iteration:  62% 1154/1851 [12:05<07:18,  1.59it/s]\u001b[A\n","Iteration:  62% 1155/1851 [12:06<07:17,  1.59it/s]\u001b[A\n","Iteration:  62% 1156/1851 [12:07<07:18,  1.59it/s]\u001b[A\n","Iteration:  63% 1157/1851 [12:07<07:17,  1.59it/s]\u001b[A\n","Iteration:  63% 1158/1851 [12:08<07:17,  1.58it/s]\u001b[A\n","Iteration:  63% 1159/1851 [12:09<07:15,  1.59it/s]\u001b[A\n","Iteration:  63% 1160/1851 [12:09<07:15,  1.59it/s]\u001b[A\n","Iteration:  63% 1161/1851 [12:10<07:14,  1.59it/s]\u001b[A\n","Iteration:  63% 1162/1851 [12:11<07:13,  1.59it/s]\u001b[A\n","Iteration:  63% 1163/1851 [12:11<07:13,  1.59it/s]\u001b[A\n","Iteration:  63% 1164/1851 [12:12<07:12,  1.59it/s]\u001b[A\n","Iteration:  63% 1165/1851 [12:12<07:11,  1.59it/s]\u001b[A\n","Iteration:  63% 1166/1851 [12:13<07:10,  1.59it/s]\u001b[A\n","Iteration:  63% 1167/1851 [12:14<07:10,  1.59it/s]\u001b[A\n","Iteration:  63% 1168/1851 [12:14<07:10,  1.59it/s]\u001b[A\n","Iteration:  63% 1169/1851 [12:15<07:09,  1.59it/s]\u001b[A\n","Iteration:  63% 1170/1851 [12:16<07:08,  1.59it/s]\u001b[A\n","Iteration:  63% 1171/1851 [12:16<07:07,  1.59it/s]\u001b[A\n","Iteration:  63% 1172/1851 [12:17<07:07,  1.59it/s]\u001b[A\n","Iteration:  63% 1173/1851 [12:17<07:07,  1.59it/s]\u001b[A\n","Iteration:  63% 1174/1851 [12:18<07:06,  1.59it/s]\u001b[A\n","Iteration:  63% 1175/1851 [12:19<07:07,  1.58it/s]\u001b[A\n","Iteration:  64% 1176/1851 [12:19<07:06,  1.58it/s]\u001b[A\n","Iteration:  64% 1177/1851 [12:20<07:05,  1.59it/s]\u001b[A\n","Iteration:  64% 1178/1851 [12:21<07:03,  1.59it/s]\u001b[A\n","Iteration:  64% 1179/1851 [12:21<07:03,  1.59it/s]\u001b[A\n","Iteration:  64% 1180/1851 [12:22<07:02,  1.59it/s]\u001b[A\n","Iteration:  64% 1181/1851 [12:23<07:03,  1.58it/s]\u001b[A\n","Iteration:  64% 1182/1851 [12:23<07:02,  1.59it/s]\u001b[A\n","Iteration:  64% 1183/1851 [12:24<07:01,  1.58it/s]\u001b[A\n","Iteration:  64% 1184/1851 [12:24<07:00,  1.58it/s]\u001b[A\n","Iteration:  64% 1185/1851 [12:25<06:59,  1.59it/s]\u001b[A\n","Iteration:  64% 1186/1851 [12:26<06:59,  1.59it/s]\u001b[A\n","Iteration:  64% 1187/1851 [12:26<06:58,  1.58it/s]\u001b[A\n","Iteration:  64% 1188/1851 [12:27<06:57,  1.59it/s]\u001b[A\n","Iteration:  64% 1189/1851 [12:28<06:57,  1.58it/s]\u001b[A\n","Iteration:  64% 1190/1851 [12:28<06:55,  1.59it/s]\u001b[A\n","Iteration:  64% 1191/1851 [12:29<06:55,  1.59it/s]\u001b[A\n","Iteration:  64% 1192/1851 [12:29<06:54,  1.59it/s]\u001b[A\n","Iteration:  64% 1193/1851 [12:30<06:53,  1.59it/s]\u001b[A\n","Iteration:  65% 1194/1851 [12:31<06:53,  1.59it/s]\u001b[A\n","Iteration:  65% 1195/1851 [12:31<06:54,  1.58it/s]\u001b[A\n","Iteration:  65% 1196/1851 [12:32<06:52,  1.59it/s]\u001b[A\n","Iteration:  65% 1197/1851 [12:33<06:51,  1.59it/s]\u001b[A\n","Iteration:  65% 1198/1851 [12:33<06:52,  1.58it/s]\u001b[A\n","Iteration:  65% 1199/1851 [12:34<06:51,  1.58it/s]\u001b[A\n","Iteration:  65% 1200/1851 [12:34<06:50,  1.59it/s]\u001b[A\n","Iteration:  65% 1201/1851 [12:35<06:49,  1.59it/s]\u001b[A\n","Iteration:  65% 1202/1851 [12:36<06:49,  1.59it/s]\u001b[A\n","Iteration:  65% 1203/1851 [12:36<06:48,  1.59it/s]\u001b[A\n","Iteration:  65% 1204/1851 [12:37<06:49,  1.58it/s]\u001b[A\n","Iteration:  65% 1205/1851 [12:38<06:48,  1.58it/s]\u001b[A\n","Iteration:  65% 1206/1851 [12:38<06:46,  1.59it/s]\u001b[A\n","Iteration:  65% 1207/1851 [12:39<06:45,  1.59it/s]\u001b[A\n","Iteration:  65% 1208/1851 [12:40<06:45,  1.59it/s]\u001b[A\n","Iteration:  65% 1209/1851 [12:40<06:45,  1.58it/s]\u001b[A\n","Iteration:  65% 1210/1851 [12:41<06:43,  1.59it/s]\u001b[A\n","Iteration:  65% 1211/1851 [12:41<06:43,  1.59it/s]\u001b[A\n","Iteration:  65% 1212/1851 [12:42<06:42,  1.59it/s]\u001b[A\n","Iteration:  66% 1213/1851 [12:43<06:40,  1.59it/s]\u001b[A\n","Iteration:  66% 1214/1851 [12:43<06:42,  1.58it/s]\u001b[A\n","Iteration:  66% 1215/1851 [12:44<06:40,  1.59it/s]\u001b[A\n","Iteration:  66% 1216/1851 [12:45<06:39,  1.59it/s]\u001b[A\n","Iteration:  66% 1217/1851 [12:45<06:38,  1.59it/s]\u001b[A\n","Iteration:  66% 1218/1851 [12:46<06:38,  1.59it/s]\u001b[A\n","Iteration:  66% 1219/1851 [12:46<06:37,  1.59it/s]\u001b[A\n","Iteration:  66% 1220/1851 [12:47<06:36,  1.59it/s]\u001b[A\n","Iteration:  66% 1221/1851 [12:48<06:36,  1.59it/s]\u001b[A\n","Iteration:  66% 1222/1851 [12:48<06:36,  1.59it/s]\u001b[A\n","Iteration:  66% 1223/1851 [12:49<06:36,  1.58it/s]\u001b[A\n","Iteration:  66% 1224/1851 [12:50<06:35,  1.59it/s]\u001b[A\n","Iteration:  66% 1225/1851 [12:50<06:34,  1.59it/s]\u001b[A\n","Iteration:  66% 1226/1851 [12:51<06:33,  1.59it/s]\u001b[A\n","Iteration:  66% 1227/1851 [12:51<06:33,  1.59it/s]\u001b[A\n","Iteration:  66% 1228/1851 [12:52<06:32,  1.59it/s]\u001b[A\n","Iteration:  66% 1229/1851 [12:53<06:31,  1.59it/s]\u001b[A\n","Iteration:  66% 1230/1851 [12:53<06:31,  1.59it/s]\u001b[A\n","Iteration:  67% 1231/1851 [12:54<06:30,  1.59it/s]\u001b[A\n","Iteration:  67% 1232/1851 [12:55<06:31,  1.58it/s]\u001b[A\n","Iteration:  67% 1233/1851 [12:55<06:29,  1.59it/s]\u001b[A\n","Iteration:  67% 1234/1851 [12:56<06:28,  1.59it/s]\u001b[A\n","Iteration:  67% 1235/1851 [12:57<06:27,  1.59it/s]\u001b[A\n","Iteration:  67% 1236/1851 [12:57<06:27,  1.59it/s]\u001b[A\n","Iteration:  67% 1237/1851 [12:58<06:26,  1.59it/s]\u001b[A\n","Iteration:  67% 1238/1851 [12:58<06:26,  1.59it/s]\u001b[A\n","Iteration:  67% 1239/1851 [12:59<06:26,  1.58it/s]\u001b[A\n","Iteration:  67% 1240/1851 [13:00<06:25,  1.58it/s]\u001b[A\n","Iteration:  67% 1241/1851 [13:00<06:24,  1.58it/s]\u001b[A\n","Iteration:  67% 1242/1851 [13:01<06:23,  1.59it/s]\u001b[A\n","Iteration:  67% 1243/1851 [13:02<06:22,  1.59it/s]\u001b[A\n","Iteration:  67% 1244/1851 [13:02<06:22,  1.59it/s]\u001b[A\n","Iteration:  67% 1245/1851 [13:03<06:21,  1.59it/s]\u001b[A\n","Iteration:  67% 1246/1851 [13:03<06:20,  1.59it/s]\u001b[A\n","Iteration:  67% 1247/1851 [13:04<06:20,  1.59it/s]\u001b[A\n","Iteration:  67% 1248/1851 [13:05<06:20,  1.59it/s]\u001b[A\n","Iteration:  67% 1249/1851 [13:05<06:19,  1.59it/s]\u001b[A\n","Iteration:  68% 1250/1851 [13:06<06:18,  1.59it/s]\u001b[A\n","Iteration:  68% 1251/1851 [13:07<06:17,  1.59it/s]\u001b[A\n","Iteration:  68% 1252/1851 [13:07<06:16,  1.59it/s]\u001b[A\n","Iteration:  68% 1253/1851 [13:08<06:16,  1.59it/s]\u001b[A\n","Iteration:  68% 1254/1851 [13:09<06:15,  1.59it/s]\u001b[A\n","Iteration:  68% 1255/1851 [13:09<06:15,  1.59it/s]\u001b[A\n","Iteration:  68% 1256/1851 [13:10<06:14,  1.59it/s]\u001b[A\n","Iteration:  68% 1257/1851 [13:10<06:14,  1.59it/s]\u001b[A\n","Iteration:  68% 1258/1851 [13:11<06:13,  1.59it/s]\u001b[A\n","Iteration:  68% 1259/1851 [13:12<06:12,  1.59it/s]\u001b[A\n","Iteration:  68% 1260/1851 [13:12<06:11,  1.59it/s]\u001b[A\n","Iteration:  68% 1261/1851 [13:13<06:10,  1.59it/s]\u001b[A\n","Iteration:  68% 1262/1851 [13:14<06:10,  1.59it/s]\u001b[A\n","Iteration:  68% 1263/1851 [13:14<06:10,  1.59it/s]\u001b[A\n","Iteration:  68% 1264/1851 [13:15<06:10,  1.59it/s]\u001b[A\n","Iteration:  68% 1265/1851 [13:15<06:10,  1.58it/s]\u001b[A\n","Iteration:  68% 1266/1851 [13:16<06:08,  1.59it/s]\u001b[A\n","Iteration:  68% 1267/1851 [13:17<06:07,  1.59it/s]\u001b[A\n","Iteration:  69% 1268/1851 [13:17<06:08,  1.58it/s]\u001b[A\n","Iteration:  69% 1269/1851 [13:18<06:08,  1.58it/s]\u001b[A\n","Iteration:  69% 1270/1851 [13:19<06:07,  1.58it/s]\u001b[A\n","Iteration:  69% 1271/1851 [13:19<06:07,  1.58it/s]\u001b[A\n","Iteration:  69% 1272/1851 [13:20<06:06,  1.58it/s]\u001b[A\n","Iteration:  69% 1273/1851 [13:20<06:05,  1.58it/s]\u001b[A\n","Iteration:  69% 1274/1851 [13:21<06:05,  1.58it/s]\u001b[A\n","Iteration:  69% 1275/1851 [13:22<06:04,  1.58it/s]\u001b[A\n","Iteration:  69% 1276/1851 [13:22<06:02,  1.58it/s]\u001b[A\n","Iteration:  69% 1277/1851 [13:23<06:01,  1.59it/s]\u001b[A\n","Iteration:  69% 1278/1851 [13:24<06:00,  1.59it/s]\u001b[A\n","Iteration:  69% 1279/1851 [13:24<06:00,  1.59it/s]\u001b[A\n","Iteration:  69% 1280/1851 [13:25<05:59,  1.59it/s]\u001b[A\n","Iteration:  69% 1281/1851 [13:26<05:59,  1.59it/s]\u001b[A\n","Iteration:  69% 1282/1851 [13:26<05:58,  1.59it/s]\u001b[A\n","Iteration:  69% 1283/1851 [13:27<05:58,  1.59it/s]\u001b[A\n","Iteration:  69% 1284/1851 [13:27<05:57,  1.58it/s]\u001b[A\n","Iteration:  69% 1285/1851 [13:28<05:56,  1.59it/s]\u001b[A\n","Iteration:  69% 1286/1851 [13:29<05:55,  1.59it/s]\u001b[A\n","Iteration:  70% 1287/1851 [13:29<05:55,  1.59it/s]\u001b[A\n","Iteration:  70% 1288/1851 [13:30<05:54,  1.59it/s]\u001b[A\n","Iteration:  70% 1289/1851 [13:31<05:53,  1.59it/s]\u001b[A\n","Iteration:  70% 1290/1851 [13:31<05:53,  1.59it/s]\u001b[A\n","Iteration:  70% 1291/1851 [13:32<05:53,  1.58it/s]\u001b[A\n","Iteration:  70% 1292/1851 [13:32<05:53,  1.58it/s]\u001b[A\n","Iteration:  70% 1293/1851 [13:33<05:52,  1.58it/s]\u001b[A\n","Iteration:  70% 1294/1851 [13:34<05:52,  1.58it/s]\u001b[A\n","Iteration:  70% 1295/1851 [13:34<05:51,  1.58it/s]\u001b[A\n","Iteration:  70% 1296/1851 [13:35<05:49,  1.59it/s]\u001b[A\n","Iteration:  70% 1297/1851 [13:36<05:49,  1.59it/s]\u001b[A\n","Iteration:  70% 1298/1851 [13:36<05:48,  1.59it/s]\u001b[A\n","Iteration:  70% 1299/1851 [13:37<05:47,  1.59it/s]\u001b[A\n","Iteration:  70% 1300/1851 [13:38<05:48,  1.58it/s]\u001b[A\n","Iteration:  70% 1301/1851 [13:38<05:47,  1.58it/s]\u001b[A\n","Iteration:  70% 1302/1851 [13:39<05:47,  1.58it/s]\u001b[A\n","Iteration:  70% 1303/1851 [13:39<05:46,  1.58it/s]\u001b[A\n","Iteration:  70% 1304/1851 [13:40<05:45,  1.58it/s]\u001b[A\n","Iteration:  71% 1305/1851 [13:41<05:44,  1.58it/s]\u001b[A\n","Iteration:  71% 1306/1851 [13:41<05:44,  1.58it/s]\u001b[A\n","Iteration:  71% 1307/1851 [13:42<05:43,  1.59it/s]\u001b[A\n","Iteration:  71% 1308/1851 [13:43<05:41,  1.59it/s]\u001b[A\n","Iteration:  71% 1309/1851 [13:43<05:41,  1.59it/s]\u001b[A\n","Iteration:  71% 1310/1851 [13:44<05:41,  1.58it/s]\u001b[A\n","Iteration:  71% 1311/1851 [13:44<05:41,  1.58it/s]\u001b[A\n","Iteration:  71% 1312/1851 [13:45<05:40,  1.58it/s]\u001b[A\n","Iteration:  71% 1313/1851 [13:46<05:39,  1.58it/s]\u001b[A\n","Iteration:  71% 1314/1851 [13:46<05:40,  1.58it/s]\u001b[A\n","Iteration:  71% 1315/1851 [13:47<05:38,  1.58it/s]\u001b[A\n","Iteration:  71% 1316/1851 [13:48<05:37,  1.58it/s]\u001b[A\n","Iteration:  71% 1317/1851 [13:48<05:37,  1.58it/s]\u001b[A\n","Iteration:  71% 1318/1851 [13:49<05:36,  1.58it/s]\u001b[A\n","Iteration:  71% 1319/1851 [13:50<05:36,  1.58it/s]\u001b[A\n","Iteration:  71% 1320/1851 [13:50<05:35,  1.58it/s]\u001b[A\n","Iteration:  71% 1321/1851 [13:51<05:35,  1.58it/s]\u001b[A\n","Iteration:  71% 1322/1851 [13:51<05:34,  1.58it/s]\u001b[A\n","Iteration:  71% 1323/1851 [13:52<05:33,  1.58it/s]\u001b[A\n","Iteration:  72% 1324/1851 [13:53<05:32,  1.58it/s]\u001b[A\n","Iteration:  72% 1325/1851 [13:53<05:31,  1.59it/s]\u001b[A\n","Iteration:  72% 1326/1851 [13:54<05:30,  1.59it/s]\u001b[A\n","Iteration:  72% 1327/1851 [13:55<05:29,  1.59it/s]\u001b[A\n","Iteration:  72% 1328/1851 [13:55<05:29,  1.59it/s]\u001b[A\n","Iteration:  72% 1329/1851 [13:56<05:29,  1.58it/s]\u001b[A\n","Iteration:  72% 1330/1851 [13:56<05:31,  1.57it/s]\u001b[A\n","Iteration:  72% 1331/1851 [13:57<05:30,  1.57it/s]\u001b[A\n","Iteration:  72% 1332/1851 [13:58<05:29,  1.58it/s]\u001b[A\n","Iteration:  72% 1333/1851 [13:58<05:28,  1.57it/s]\u001b[A\n","Iteration:  72% 1334/1851 [13:59<05:28,  1.58it/s]\u001b[A\n","Iteration:  72% 1335/1851 [14:00<05:26,  1.58it/s]\u001b[A\n","Iteration:  72% 1336/1851 [14:00<05:26,  1.58it/s]\u001b[A\n","Iteration:  72% 1337/1851 [14:01<05:25,  1.58it/s]\u001b[A\n","Iteration:  72% 1338/1851 [14:02<05:25,  1.58it/s]\u001b[A\n","Iteration:  72% 1339/1851 [14:02<05:23,  1.58it/s]\u001b[A\n","Iteration:  72% 1340/1851 [14:03<05:22,  1.58it/s]\u001b[A\n","Iteration:  72% 1341/1851 [14:03<05:22,  1.58it/s]\u001b[A\n","Iteration:  73% 1342/1851 [14:04<05:21,  1.58it/s]\u001b[A\n","Iteration:  73% 1343/1851 [14:05<05:20,  1.58it/s]\u001b[A\n","Iteration:  73% 1344/1851 [14:05<05:19,  1.58it/s]\u001b[A\n","Iteration:  73% 1345/1851 [14:06<05:19,  1.58it/s]\u001b[A\n","Iteration:  73% 1346/1851 [14:07<05:19,  1.58it/s]\u001b[A\n","Iteration:  73% 1347/1851 [14:07<05:18,  1.58it/s]\u001b[A\n","Iteration:  73% 1348/1851 [14:08<05:17,  1.58it/s]\u001b[A\n","Iteration:  73% 1349/1851 [14:08<05:16,  1.58it/s]\u001b[A\n","Iteration:  73% 1350/1851 [14:09<05:15,  1.59it/s]\u001b[A\n","Iteration:  73% 1351/1851 [14:10<05:15,  1.59it/s]\u001b[A\n","Iteration:  73% 1352/1851 [14:10<05:15,  1.58it/s]\u001b[A\n","Iteration:  73% 1353/1851 [14:11<05:14,  1.58it/s]\u001b[A\n","Iteration:  73% 1354/1851 [14:12<05:14,  1.58it/s]\u001b[A\n","Iteration:  73% 1355/1851 [14:12<05:13,  1.58it/s]\u001b[A\n","Iteration:  73% 1356/1851 [14:13<05:12,  1.58it/s]\u001b[A\n","Iteration:  73% 1357/1851 [14:14<05:12,  1.58it/s]\u001b[A\n","Iteration:  73% 1358/1851 [14:14<05:12,  1.58it/s]\u001b[A\n","Iteration:  73% 1359/1851 [14:15<05:11,  1.58it/s]\u001b[A\n","Iteration:  73% 1360/1851 [14:15<05:11,  1.58it/s]\u001b[A\n","Iteration:  74% 1361/1851 [14:16<05:10,  1.58it/s]\u001b[A\n","Iteration:  74% 1362/1851 [14:17<05:09,  1.58it/s]\u001b[A\n","Iteration:  74% 1363/1851 [14:17<05:08,  1.58it/s]\u001b[A\n","Iteration:  74% 1364/1851 [14:18<05:07,  1.58it/s]\u001b[A\n","Iteration:  74% 1365/1851 [14:19<05:06,  1.58it/s]\u001b[A\n","Iteration:  74% 1366/1851 [14:19<05:06,  1.58it/s]\u001b[A\n","Iteration:  74% 1367/1851 [14:20<05:05,  1.59it/s]\u001b[A\n","Iteration:  74% 1368/1851 [14:21<05:05,  1.58it/s]\u001b[A\n","Iteration:  74% 1369/1851 [14:21<05:04,  1.58it/s]\u001b[A\n","Iteration:  74% 1370/1851 [14:22<05:04,  1.58it/s]\u001b[A\n","Iteration:  74% 1371/1851 [14:22<05:03,  1.58it/s]\u001b[A\n","Iteration:  74% 1372/1851 [14:23<05:03,  1.58it/s]\u001b[A\n","Iteration:  74% 1373/1851 [14:24<05:03,  1.58it/s]\u001b[A\n","Iteration:  74% 1374/1851 [14:24<05:01,  1.58it/s]\u001b[A\n","Iteration:  74% 1375/1851 [14:25<05:00,  1.58it/s]\u001b[A\n","Iteration:  74% 1376/1851 [14:26<05:00,  1.58it/s]\u001b[A\n","Iteration:  74% 1377/1851 [14:26<04:59,  1.58it/s]\u001b[A\n","Iteration:  74% 1378/1851 [14:27<04:59,  1.58it/s]\u001b[A\n","Iteration:  75% 1379/1851 [14:27<04:58,  1.58it/s]\u001b[A\n","Iteration:  75% 1380/1851 [14:28<04:58,  1.58it/s]\u001b[A\n","Iteration:  75% 1381/1851 [14:29<04:57,  1.58it/s]\u001b[A\n","Iteration:  75% 1382/1851 [14:29<04:56,  1.58it/s]\u001b[A\n","Iteration:  75% 1383/1851 [14:30<04:55,  1.58it/s]\u001b[A\n","Iteration:  75% 1384/1851 [14:31<04:55,  1.58it/s]\u001b[A\n","Iteration:  75% 1385/1851 [14:31<04:54,  1.58it/s]\u001b[A\n","Iteration:  75% 1386/1851 [14:32<04:54,  1.58it/s]\u001b[A\n","Iteration:  75% 1387/1851 [14:33<04:53,  1.58it/s]\u001b[A\n","Iteration:  75% 1388/1851 [14:33<04:52,  1.58it/s]\u001b[A\n","Iteration:  75% 1389/1851 [14:34<04:52,  1.58it/s]\u001b[A\n","Iteration:  75% 1390/1851 [14:34<04:51,  1.58it/s]\u001b[A\n","Iteration:  75% 1391/1851 [14:35<04:51,  1.58it/s]\u001b[A\n","Iteration:  75% 1392/1851 [14:36<04:51,  1.58it/s]\u001b[A\n","Iteration:  75% 1393/1851 [14:36<04:50,  1.58it/s]\u001b[A\n","Iteration:  75% 1394/1851 [14:37<04:49,  1.58it/s]\u001b[A\n","Iteration:  75% 1395/1851 [14:38<04:49,  1.57it/s]\u001b[A\n","Iteration:  75% 1396/1851 [14:38<04:49,  1.57it/s]\u001b[A\n","Iteration:  75% 1397/1851 [14:39<04:48,  1.58it/s]\u001b[A\n","Iteration:  76% 1398/1851 [14:39<04:47,  1.57it/s]\u001b[A\n","Iteration:  76% 1399/1851 [14:40<04:47,  1.57it/s]\u001b[A\n","Iteration:  76% 1400/1851 [14:41<04:45,  1.58it/s]\u001b[A\n","Iteration:  76% 1401/1851 [14:41<04:45,  1.58it/s]\u001b[A\n","Iteration:  76% 1402/1851 [14:42<04:43,  1.58it/s]\u001b[A\n","Iteration:  76% 1403/1851 [14:43<04:42,  1.58it/s]\u001b[A\n","Iteration:  76% 1404/1851 [14:43<04:42,  1.58it/s]\u001b[A\n","Iteration:  76% 1405/1851 [14:44<04:41,  1.58it/s]\u001b[A\n","Iteration:  76% 1406/1851 [14:45<04:40,  1.58it/s]\u001b[A\n","Iteration:  76% 1407/1851 [14:45<04:40,  1.58it/s]\u001b[A\n","Iteration:  76% 1408/1851 [14:46<04:40,  1.58it/s]\u001b[A\n","Iteration:  76% 1409/1851 [14:46<04:40,  1.58it/s]\u001b[A\n","Iteration:  76% 1410/1851 [14:47<04:38,  1.58it/s]\u001b[A\n","Iteration:  76% 1411/1851 [14:48<04:38,  1.58it/s]\u001b[A\n","Iteration:  76% 1412/1851 [14:48<04:37,  1.58it/s]\u001b[A\n","Iteration:  76% 1413/1851 [14:49<04:36,  1.58it/s]\u001b[A\n","Iteration:  76% 1414/1851 [14:50<04:35,  1.58it/s]\u001b[A\n","Iteration:  76% 1415/1851 [14:50<04:35,  1.58it/s]\u001b[A\n","Iteration:  76% 1416/1851 [14:51<04:34,  1.58it/s]\u001b[A\n","Iteration:  77% 1417/1851 [14:52<04:34,  1.58it/s]\u001b[A\n","Iteration:  77% 1418/1851 [14:52<04:34,  1.58it/s]\u001b[A\n","Iteration:  77% 1419/1851 [14:53<04:33,  1.58it/s]\u001b[A\n","Iteration:  77% 1420/1851 [14:53<04:32,  1.58it/s]\u001b[A\n","Iteration:  77% 1421/1851 [14:54<04:32,  1.58it/s]\u001b[A\n","Iteration:  77% 1422/1851 [14:55<04:31,  1.58it/s]\u001b[A\n","Iteration:  77% 1423/1851 [14:55<04:30,  1.58it/s]\u001b[A\n","Iteration:  77% 1424/1851 [14:56<04:29,  1.58it/s]\u001b[A\n","Iteration:  77% 1425/1851 [14:57<04:29,  1.58it/s]\u001b[A\n","Iteration:  77% 1426/1851 [14:57<04:29,  1.58it/s]\u001b[A\n","Iteration:  77% 1427/1851 [14:58<04:28,  1.58it/s]\u001b[A\n","Iteration:  77% 1428/1851 [14:58<04:27,  1.58it/s]\u001b[A\n","Iteration:  77% 1429/1851 [14:59<04:27,  1.58it/s]\u001b[A\n","Iteration:  77% 1430/1851 [15:00<04:26,  1.58it/s]\u001b[A\n","Iteration:  77% 1431/1851 [15:00<04:26,  1.58it/s]\u001b[A\n","Iteration:  77% 1432/1851 [15:01<04:25,  1.58it/s]\u001b[A\n","Iteration:  77% 1433/1851 [15:02<04:24,  1.58it/s]\u001b[A\n","Iteration:  77% 1434/1851 [15:02<04:23,  1.58it/s]\u001b[A\n","Iteration:  78% 1435/1851 [15:03<04:23,  1.58it/s]\u001b[A\n","Iteration:  78% 1436/1851 [15:04<04:23,  1.58it/s]\u001b[A\n","Iteration:  78% 1437/1851 [15:04<04:23,  1.57it/s]\u001b[A\n","Iteration:  78% 1438/1851 [15:05<04:22,  1.58it/s]\u001b[A\n","Iteration:  78% 1439/1851 [15:05<04:21,  1.58it/s]\u001b[A\n","Iteration:  78% 1440/1851 [15:06<04:20,  1.58it/s]\u001b[A\n","Iteration:  78% 1441/1851 [15:07<04:20,  1.57it/s]\u001b[A\n","Iteration:  78% 1442/1851 [15:07<04:19,  1.57it/s]\u001b[A\n","Iteration:  78% 1443/1851 [15:08<04:19,  1.57it/s]\u001b[A\n","Iteration:  78% 1444/1851 [15:09<04:18,  1.57it/s]\u001b[A\n","Iteration:  78% 1445/1851 [15:09<04:17,  1.58it/s]\u001b[A\n","Iteration:  78% 1446/1851 [15:10<04:16,  1.58it/s]\u001b[A\n","Iteration:  78% 1447/1851 [15:11<04:15,  1.58it/s]\u001b[A\n","Iteration:  78% 1448/1851 [15:11<04:16,  1.57it/s]\u001b[A\n","Iteration:  78% 1449/1851 [15:12<04:14,  1.58it/s]\u001b[A\n","Iteration:  78% 1450/1851 [15:12<04:13,  1.58it/s]\u001b[A\n","Iteration:  78% 1451/1851 [15:13<04:13,  1.58it/s]\u001b[A\n","Iteration:  78% 1452/1851 [15:14<04:13,  1.58it/s]\u001b[A\n","Iteration:  78% 1453/1851 [15:14<04:12,  1.58it/s]\u001b[A\n","Iteration:  79% 1454/1851 [15:15<04:11,  1.58it/s]\u001b[A\n","Iteration:  79% 1455/1851 [15:16<04:10,  1.58it/s]\u001b[A\n","Iteration:  79% 1456/1851 [15:16<04:10,  1.58it/s]\u001b[A\n","Iteration:  79% 1457/1851 [15:17<04:09,  1.58it/s]\u001b[A\n","Iteration:  79% 1458/1851 [15:17<04:08,  1.58it/s]\u001b[A\n","Iteration:  79% 1459/1851 [15:18<04:08,  1.58it/s]\u001b[A\n","Iteration:  79% 1460/1851 [15:19<04:07,  1.58it/s]\u001b[A\n","Iteration:  79% 1461/1851 [15:19<04:07,  1.58it/s]\u001b[A\n","Iteration:  79% 1462/1851 [15:20<04:06,  1.58it/s]\u001b[A\n","Iteration:  79% 1463/1851 [15:21<04:05,  1.58it/s]\u001b[A\n","Iteration:  79% 1464/1851 [15:21<04:05,  1.58it/s]\u001b[A\n","Iteration:  79% 1465/1851 [15:22<04:04,  1.58it/s]\u001b[A\n","Iteration:  79% 1466/1851 [15:23<04:03,  1.58it/s]\u001b[A\n","Iteration:  79% 1467/1851 [15:23<04:02,  1.58it/s]\u001b[A\n","Iteration:  79% 1468/1851 [15:24<04:02,  1.58it/s]\u001b[A\n","Iteration:  79% 1469/1851 [15:24<04:01,  1.58it/s]\u001b[A\n","Iteration:  79% 1470/1851 [15:25<04:00,  1.58it/s]\u001b[A\n","Iteration:  79% 1471/1851 [15:26<04:00,  1.58it/s]\u001b[A\n","Iteration:  80% 1472/1851 [15:26<03:59,  1.58it/s]\u001b[A\n","Iteration:  80% 1473/1851 [15:27<03:59,  1.58it/s]\u001b[A\n","Iteration:  80% 1474/1851 [15:28<03:58,  1.58it/s]\u001b[A\n","Iteration:  80% 1475/1851 [15:28<03:58,  1.58it/s]\u001b[A\n","Iteration:  80% 1476/1851 [15:29<03:57,  1.58it/s]\u001b[A\n","Iteration:  80% 1477/1851 [15:30<03:56,  1.58it/s]\u001b[A\n","Iteration:  80% 1478/1851 [15:30<03:56,  1.58it/s]\u001b[A\n","Iteration:  80% 1479/1851 [15:31<03:55,  1.58it/s]\u001b[A\n","Iteration:  80% 1480/1851 [15:31<03:55,  1.58it/s]\u001b[A\n","Iteration:  80% 1481/1851 [15:32<03:54,  1.58it/s]\u001b[A\n","Iteration:  80% 1482/1851 [15:33<03:54,  1.58it/s]\u001b[A\n","Iteration:  80% 1483/1851 [15:33<03:53,  1.58it/s]\u001b[A\n","Iteration:  80% 1484/1851 [15:34<03:52,  1.58it/s]\u001b[A\n","Iteration:  80% 1485/1851 [15:35<03:51,  1.58it/s]\u001b[A\n","Iteration:  80% 1486/1851 [15:35<03:50,  1.58it/s]\u001b[A\n","Iteration:  80% 1487/1851 [15:36<03:50,  1.58it/s]\u001b[A\n","Iteration:  80% 1488/1851 [15:36<03:50,  1.58it/s]\u001b[A\n","Iteration:  80% 1489/1851 [15:37<03:48,  1.58it/s]\u001b[A\n","Iteration:  80% 1490/1851 [15:38<03:48,  1.58it/s]\u001b[A\n","Iteration:  81% 1491/1851 [15:38<03:47,  1.58it/s]\u001b[A\n","Iteration:  81% 1492/1851 [15:39<03:47,  1.58it/s]\u001b[A\n","Iteration:  81% 1493/1851 [15:40<03:47,  1.58it/s]\u001b[A\n","Iteration:  81% 1494/1851 [15:40<03:46,  1.58it/s]\u001b[A\n","Iteration:  81% 1495/1851 [15:41<03:46,  1.57it/s]\u001b[A\n","Iteration:  81% 1496/1851 [15:42<03:45,  1.58it/s]\u001b[A\n","Iteration:  81% 1497/1851 [15:42<03:44,  1.57it/s]\u001b[A\n","Iteration:  81% 1498/1851 [15:43<03:44,  1.58it/s]\u001b[A\n","Iteration:  81% 1499/1851 [15:43<03:43,  1.58it/s]\u001b[A\n","Iteration:  81% 1500/1851 [15:44<03:42,  1.58it/s]\u001b[A\n","Iteration:  81% 1501/1851 [15:45<03:41,  1.58it/s]\u001b[A\n","Iteration:  81% 1502/1851 [15:45<03:40,  1.58it/s]\u001b[A\n","Iteration:  81% 1503/1851 [15:46<03:40,  1.58it/s]\u001b[A\n","Iteration:  81% 1504/1851 [15:47<03:39,  1.58it/s]\u001b[A\n","Iteration:  81% 1505/1851 [15:47<03:39,  1.57it/s]\u001b[A\n","Iteration:  81% 1506/1851 [15:48<03:38,  1.58it/s]\u001b[A\n","Iteration:  81% 1507/1851 [15:49<03:37,  1.58it/s]\u001b[A\n","Iteration:  81% 1508/1851 [15:49<03:37,  1.58it/s]\u001b[A\n","Iteration:  82% 1509/1851 [15:50<03:36,  1.58it/s]\u001b[A\n","Iteration:  82% 1510/1851 [15:50<03:36,  1.58it/s]\u001b[A\n","Iteration:  82% 1511/1851 [15:51<03:35,  1.58it/s]\u001b[A\n","Iteration:  82% 1512/1851 [15:52<03:34,  1.58it/s]\u001b[A\n","Iteration:  82% 1513/1851 [15:52<03:34,  1.58it/s]\u001b[A\n","Iteration:  82% 1514/1851 [15:53<03:33,  1.58it/s]\u001b[A\n","Iteration:  82% 1515/1851 [15:54<03:33,  1.57it/s]\u001b[A\n","Iteration:  82% 1516/1851 [15:54<03:32,  1.58it/s]\u001b[A\n","Iteration:  82% 1517/1851 [15:55<03:31,  1.58it/s]\u001b[A\n","Iteration:  82% 1518/1851 [15:56<03:31,  1.58it/s]\u001b[A\n","Iteration:  82% 1519/1851 [15:56<03:30,  1.58it/s]\u001b[A\n","Iteration:  82% 1520/1851 [15:57<03:29,  1.58it/s]\u001b[A\n","Iteration:  82% 1521/1851 [15:57<03:29,  1.58it/s]\u001b[A\n","Iteration:  82% 1522/1851 [15:58<03:28,  1.58it/s]\u001b[A\n","Iteration:  82% 1523/1851 [15:59<03:28,  1.58it/s]\u001b[A\n","Iteration:  82% 1524/1851 [15:59<03:27,  1.58it/s]\u001b[A\n","Iteration:  82% 1525/1851 [16:00<03:26,  1.58it/s]\u001b[A\n","Iteration:  82% 1526/1851 [16:01<03:25,  1.58it/s]\u001b[A\n","Iteration:  82% 1527/1851 [16:01<03:25,  1.58it/s]\u001b[A\n","Iteration:  83% 1528/1851 [16:02<03:24,  1.58it/s]\u001b[A\n","Iteration:  83% 1529/1851 [16:02<03:23,  1.58it/s]\u001b[A\n","Iteration:  83% 1530/1851 [16:03<03:23,  1.58it/s]\u001b[A\n","Iteration:  83% 1531/1851 [16:04<03:22,  1.58it/s]\u001b[A\n","Iteration:  83% 1532/1851 [16:04<03:21,  1.58it/s]\u001b[A\n","Iteration:  83% 1533/1851 [16:05<03:20,  1.58it/s]\u001b[A\n","Iteration:  83% 1534/1851 [16:06<03:20,  1.58it/s]\u001b[A\n","Iteration:  83% 1535/1851 [16:06<03:19,  1.58it/s]\u001b[A\n","Iteration:  83% 1536/1851 [16:07<03:19,  1.58it/s]\u001b[A\n","Iteration:  83% 1537/1851 [16:08<03:18,  1.58it/s]\u001b[A\n","Iteration:  83% 1538/1851 [16:08<03:18,  1.58it/s]\u001b[A\n","Iteration:  83% 1539/1851 [16:09<03:17,  1.58it/s]\u001b[A\n","Iteration:  83% 1540/1851 [16:09<03:17,  1.58it/s]\u001b[A\n","Iteration:  83% 1541/1851 [16:10<03:16,  1.57it/s]\u001b[A\n","Iteration:  83% 1542/1851 [16:11<03:16,  1.57it/s]\u001b[A\n","Iteration:  83% 1543/1851 [16:11<03:15,  1.57it/s]\u001b[A\n","Iteration:  83% 1544/1851 [16:12<03:14,  1.58it/s]\u001b[A\n","Iteration:  83% 1545/1851 [16:13<03:14,  1.58it/s]\u001b[A\n","Iteration:  84% 1546/1851 [16:13<03:13,  1.57it/s]\u001b[A\n","Iteration:  84% 1547/1851 [16:14<03:12,  1.58it/s]\u001b[A\n","Iteration:  84% 1548/1851 [16:15<03:11,  1.58it/s]\u001b[A\n","Iteration:  84% 1549/1851 [16:15<03:10,  1.58it/s]\u001b[A\n","Iteration:  84% 1550/1851 [16:16<03:10,  1.58it/s]\u001b[A\n","Iteration:  84% 1551/1851 [16:16<03:09,  1.58it/s]\u001b[A\n","Iteration:  84% 1552/1851 [16:17<03:09,  1.58it/s]\u001b[A\n","Iteration:  84% 1553/1851 [16:18<03:08,  1.58it/s]\u001b[A\n","Iteration:  84% 1554/1851 [16:18<03:07,  1.58it/s]\u001b[A\n","Iteration:  84% 1555/1851 [16:19<03:07,  1.58it/s]\u001b[A\n","Iteration:  84% 1556/1851 [16:20<03:06,  1.58it/s]\u001b[A\n","Iteration:  84% 1557/1851 [16:20<03:06,  1.58it/s]\u001b[A\n","Iteration:  84% 1558/1851 [16:21<03:05,  1.58it/s]\u001b[A\n","Iteration:  84% 1559/1851 [16:21<03:04,  1.58it/s]\u001b[A\n","Iteration:  84% 1560/1851 [16:22<03:04,  1.58it/s]\u001b[A\n","Iteration:  84% 1561/1851 [16:23<03:03,  1.58it/s]\u001b[A\n","Iteration:  84% 1562/1851 [16:23<03:02,  1.58it/s]\u001b[A\n","Iteration:  84% 1563/1851 [16:24<03:02,  1.58it/s]\u001b[A\n","Iteration:  84% 1564/1851 [16:25<03:01,  1.58it/s]\u001b[A\n","Iteration:  85% 1565/1851 [16:25<03:00,  1.58it/s]\u001b[A\n","Iteration:  85% 1566/1851 [16:26<03:00,  1.58it/s]\u001b[A\n","Iteration:  85% 1567/1851 [16:27<02:59,  1.58it/s]\u001b[A\n","Iteration:  85% 1568/1851 [16:27<02:59,  1.58it/s]\u001b[A\n","Iteration:  85% 1569/1851 [16:28<02:58,  1.58it/s]\u001b[A\n","Iteration:  85% 1570/1851 [16:28<02:57,  1.58it/s]\u001b[A\n","Iteration:  85% 1571/1851 [16:29<02:57,  1.58it/s]\u001b[A\n","Iteration:  85% 1572/1851 [16:30<02:56,  1.58it/s]\u001b[A\n","Iteration:  85% 1573/1851 [16:30<02:56,  1.58it/s]\u001b[A\n","Iteration:  85% 1574/1851 [16:31<02:55,  1.58it/s]\u001b[A\n","Iteration:  85% 1575/1851 [16:32<02:54,  1.58it/s]\u001b[A\n","Iteration:  85% 1576/1851 [16:32<02:54,  1.58it/s]\u001b[A\n","Iteration:  85% 1577/1851 [16:33<02:53,  1.58it/s]\u001b[A\n","Iteration:  85% 1578/1851 [16:33<02:53,  1.58it/s]\u001b[A\n","Iteration:  85% 1579/1851 [16:34<02:52,  1.57it/s]\u001b[A\n","Iteration:  85% 1580/1851 [16:35<02:52,  1.57it/s]\u001b[A\n","Iteration:  85% 1581/1851 [16:35<02:51,  1.57it/s]\u001b[A\n","Iteration:  85% 1582/1851 [16:36<02:50,  1.58it/s]\u001b[A\n","Iteration:  86% 1583/1851 [16:37<02:49,  1.58it/s]\u001b[A\n","Iteration:  86% 1584/1851 [16:37<02:49,  1.58it/s]\u001b[A\n","Iteration:  86% 1585/1851 [16:38<02:48,  1.58it/s]\u001b[A\n","Iteration:  86% 1586/1851 [16:39<02:47,  1.58it/s]\u001b[A\n","Iteration:  86% 1587/1851 [16:39<02:46,  1.58it/s]\u001b[A\n","Iteration:  86% 1588/1851 [16:40<02:46,  1.58it/s]\u001b[A\n","Iteration:  86% 1589/1851 [16:40<02:45,  1.58it/s]\u001b[A\n","Iteration:  86% 1590/1851 [16:41<02:45,  1.58it/s]\u001b[A\n","Iteration:  86% 1591/1851 [16:42<02:44,  1.58it/s]\u001b[A\n","Iteration:  86% 1592/1851 [16:42<02:43,  1.58it/s]\u001b[A\n","Iteration:  86% 1593/1851 [16:43<02:43,  1.58it/s]\u001b[A\n","Iteration:  86% 1594/1851 [16:44<02:42,  1.58it/s]\u001b[A\n","Iteration:  86% 1595/1851 [16:44<02:41,  1.58it/s]\u001b[A\n","Iteration:  86% 1596/1851 [16:45<02:41,  1.58it/s]\u001b[A\n","Iteration:  86% 1597/1851 [16:46<02:40,  1.58it/s]\u001b[A\n","Iteration:  86% 1598/1851 [16:46<02:40,  1.58it/s]\u001b[A\n","Iteration:  86% 1599/1851 [16:47<02:39,  1.58it/s]\u001b[A\n","Iteration:  86% 1600/1851 [16:47<02:38,  1.58it/s]\u001b[A\n","Iteration:  86% 1601/1851 [16:48<02:38,  1.58it/s]\u001b[A\n","Iteration:  87% 1602/1851 [16:49<02:37,  1.58it/s]\u001b[A\n","Iteration:  87% 1603/1851 [16:49<02:37,  1.58it/s]\u001b[A\n","Iteration:  87% 1604/1851 [16:50<02:36,  1.58it/s]\u001b[A\n","Iteration:  87% 1605/1851 [16:51<02:35,  1.58it/s]\u001b[A\n","Iteration:  87% 1606/1851 [16:51<02:34,  1.58it/s]\u001b[A\n","Iteration:  87% 1607/1851 [16:52<02:34,  1.58it/s]\u001b[A\n","Iteration:  87% 1608/1851 [16:52<02:33,  1.58it/s]\u001b[A\n","Iteration:  87% 1609/1851 [16:53<02:33,  1.58it/s]\u001b[A\n","Iteration:  87% 1610/1851 [16:54<02:32,  1.58it/s]\u001b[A\n","Iteration:  87% 1611/1851 [16:54<02:32,  1.58it/s]\u001b[A\n","Iteration:  87% 1612/1851 [16:55<02:31,  1.58it/s]\u001b[A\n","Iteration:  87% 1613/1851 [16:56<02:30,  1.58it/s]\u001b[A\n","Iteration:  87% 1614/1851 [16:56<02:29,  1.58it/s]\u001b[A\n","Iteration:  87% 1615/1851 [16:57<02:28,  1.59it/s]\u001b[A\n","Iteration:  87% 1616/1851 [16:58<02:28,  1.58it/s]\u001b[A\n","Iteration:  87% 1617/1851 [16:58<02:27,  1.58it/s]\u001b[A\n","Iteration:  87% 1618/1851 [16:59<02:27,  1.58it/s]\u001b[A\n","Iteration:  87% 1619/1851 [16:59<02:26,  1.58it/s]\u001b[A\n","Iteration:  88% 1620/1851 [17:00<02:25,  1.58it/s]\u001b[A\n","Iteration:  88% 1621/1851 [17:01<02:25,  1.58it/s]\u001b[A\n","Iteration:  88% 1622/1851 [17:01<02:24,  1.58it/s]\u001b[A\n","Iteration:  88% 1623/1851 [17:02<02:23,  1.59it/s]\u001b[A\n","Iteration:  88% 1624/1851 [17:03<02:22,  1.59it/s]\u001b[A\n","Iteration:  88% 1625/1851 [17:03<02:22,  1.59it/s]\u001b[A\n","Iteration:  88% 1626/1851 [17:04<02:21,  1.59it/s]\u001b[A\n","Iteration:  88% 1627/1851 [17:04<02:21,  1.59it/s]\u001b[A\n","Iteration:  88% 1628/1851 [17:05<02:20,  1.58it/s]\u001b[A\n","Iteration:  88% 1629/1851 [17:06<02:20,  1.58it/s]\u001b[A\n","Iteration:  88% 1630/1851 [17:06<02:20,  1.58it/s]\u001b[A\n","Iteration:  88% 1631/1851 [17:07<02:19,  1.58it/s]\u001b[A\n","Iteration:  88% 1632/1851 [17:08<02:18,  1.58it/s]\u001b[A\n","Iteration:  88% 1633/1851 [17:08<02:18,  1.58it/s]\u001b[A\n","Iteration:  88% 1634/1851 [17:09<02:17,  1.57it/s]\u001b[A\n","Iteration:  88% 1635/1851 [17:10<02:16,  1.58it/s]\u001b[A\n","Iteration:  88% 1636/1851 [17:10<02:16,  1.58it/s]\u001b[A\n","Iteration:  88% 1637/1851 [17:11<02:15,  1.58it/s]\u001b[A\n","Iteration:  88% 1638/1851 [17:11<02:14,  1.58it/s]\u001b[A\n","Iteration:  89% 1639/1851 [17:12<02:14,  1.58it/s]\u001b[A\n","Iteration:  89% 1640/1851 [17:13<02:13,  1.58it/s]\u001b[A\n","Iteration:  89% 1641/1851 [17:13<02:12,  1.58it/s]\u001b[A\n","Iteration:  89% 1642/1851 [17:14<02:12,  1.58it/s]\u001b[A\n","Iteration:  89% 1643/1851 [17:15<02:11,  1.58it/s]\u001b[A\n","Iteration:  89% 1644/1851 [17:15<02:11,  1.58it/s]\u001b[A\n","Iteration:  89% 1645/1851 [17:16<02:10,  1.58it/s]\u001b[A\n","Iteration:  89% 1646/1851 [17:17<02:10,  1.58it/s]\u001b[A\n","Iteration:  89% 1647/1851 [17:17<02:09,  1.58it/s]\u001b[A\n","Iteration:  89% 1648/1851 [17:18<02:08,  1.58it/s]\u001b[A\n","Iteration:  89% 1649/1851 [17:18<02:07,  1.58it/s]\u001b[A\n","Iteration:  89% 1650/1851 [17:19<02:07,  1.58it/s]\u001b[A\n","Iteration:  89% 1651/1851 [17:20<02:06,  1.58it/s]\u001b[A\n","Iteration:  89% 1652/1851 [17:20<02:06,  1.58it/s]\u001b[A\n","Iteration:  89% 1653/1851 [17:21<02:05,  1.58it/s]\u001b[A\n","Iteration:  89% 1654/1851 [17:22<02:04,  1.58it/s]\u001b[A\n","Iteration:  89% 1655/1851 [17:22<02:04,  1.58it/s]\u001b[A\n","Iteration:  89% 1656/1851 [17:23<02:03,  1.58it/s]\u001b[A\n","Iteration:  90% 1657/1851 [17:23<02:02,  1.58it/s]\u001b[A\n","Iteration:  90% 1658/1851 [17:24<02:02,  1.58it/s]\u001b[A\n","Iteration:  90% 1659/1851 [17:25<02:01,  1.58it/s]\u001b[A\n","Iteration:  90% 1660/1851 [17:25<02:00,  1.58it/s]\u001b[A\n","Iteration:  90% 1661/1851 [17:26<02:00,  1.58it/s]\u001b[A\n","Iteration:  90% 1662/1851 [17:27<01:59,  1.58it/s]\u001b[A\n","Iteration:  90% 1663/1851 [17:27<01:59,  1.58it/s]\u001b[A\n","Iteration:  90% 1664/1851 [17:28<01:58,  1.58it/s]\u001b[A\n","Iteration:  90% 1665/1851 [17:29<01:57,  1.58it/s]\u001b[A\n","Iteration:  90% 1666/1851 [17:29<01:56,  1.58it/s]\u001b[A\n","Iteration:  90% 1667/1851 [17:30<01:56,  1.58it/s]\u001b[A\n","Iteration:  90% 1668/1851 [17:30<01:55,  1.58it/s]\u001b[A\n","Iteration:  90% 1669/1851 [17:31<01:55,  1.58it/s]\u001b[A\n","Iteration:  90% 1670/1851 [17:32<01:54,  1.58it/s]\u001b[A\n","Iteration:  90% 1671/1851 [17:32<01:54,  1.58it/s]\u001b[A\n","Iteration:  90% 1672/1851 [17:33<01:53,  1.58it/s]\u001b[A\n","Iteration:  90% 1673/1851 [17:34<01:52,  1.58it/s]\u001b[A\n","Iteration:  90% 1674/1851 [17:34<01:52,  1.58it/s]\u001b[A\n","Iteration:  90% 1675/1851 [17:35<01:51,  1.58it/s]\u001b[A\n","Iteration:  91% 1676/1851 [17:36<01:50,  1.58it/s]\u001b[A\n","Iteration:  91% 1677/1851 [17:36<01:49,  1.58it/s]\u001b[A\n","Iteration:  91% 1678/1851 [17:37<01:49,  1.58it/s]\u001b[A\n","Iteration:  91% 1679/1851 [17:37<01:48,  1.59it/s]\u001b[A\n","Iteration:  91% 1680/1851 [17:38<01:47,  1.59it/s]\u001b[A\n","Iteration:  91% 1681/1851 [17:39<01:47,  1.59it/s]\u001b[A\n","Iteration:  91% 1682/1851 [17:39<01:46,  1.59it/s]\u001b[A\n","Iteration:  91% 1683/1851 [17:40<01:46,  1.58it/s]\u001b[A\n","Iteration:  91% 1684/1851 [17:41<01:45,  1.58it/s]\u001b[A\n","Iteration:  91% 1685/1851 [17:41<01:44,  1.58it/s]\u001b[A\n","Iteration:  91% 1686/1851 [17:42<01:44,  1.58it/s]\u001b[A\n","Iteration:  91% 1687/1851 [17:42<01:43,  1.58it/s]\u001b[A\n","Iteration:  91% 1688/1851 [17:43<01:43,  1.58it/s]\u001b[A\n","Iteration:  91% 1689/1851 [17:44<01:42,  1.58it/s]\u001b[A\n","Iteration:  91% 1690/1851 [17:44<01:41,  1.58it/s]\u001b[A\n","Iteration:  91% 1691/1851 [17:45<01:41,  1.58it/s]\u001b[A\n","Iteration:  91% 1692/1851 [17:46<01:40,  1.58it/s]\u001b[A\n","Iteration:  91% 1693/1851 [17:46<01:40,  1.58it/s]\u001b[A\n","Iteration:  92% 1694/1851 [17:47<01:39,  1.58it/s]\u001b[A\n","Iteration:  92% 1695/1851 [17:48<01:38,  1.58it/s]\u001b[A\n","Iteration:  92% 1696/1851 [17:48<01:38,  1.58it/s]\u001b[A\n","Iteration:  92% 1697/1851 [17:49<01:37,  1.58it/s]\u001b[A\n","Iteration:  92% 1698/1851 [17:49<01:36,  1.58it/s]\u001b[A\n","Iteration:  92% 1699/1851 [17:50<01:36,  1.58it/s]\u001b[A\n","Iteration:  92% 1700/1851 [17:51<01:35,  1.58it/s]\u001b[A\n","Iteration:  92% 1701/1851 [17:51<01:34,  1.58it/s]\u001b[A\n","Iteration:  92% 1702/1851 [17:52<01:34,  1.58it/s]\u001b[A\n","Iteration:  92% 1703/1851 [17:53<01:33,  1.58it/s]\u001b[A\n","Iteration:  92% 1704/1851 [17:53<01:33,  1.58it/s]\u001b[A\n","Iteration:  92% 1705/1851 [17:54<01:32,  1.58it/s]\u001b[A\n","Iteration:  92% 1706/1851 [17:54<01:31,  1.58it/s]\u001b[A\n","Iteration:  92% 1707/1851 [17:55<01:31,  1.58it/s]\u001b[A\n","Iteration:  92% 1708/1851 [17:56<01:30,  1.58it/s]\u001b[A\n","Iteration:  92% 1709/1851 [17:56<01:29,  1.58it/s]\u001b[A\n","Iteration:  92% 1710/1851 [17:57<01:29,  1.58it/s]\u001b[A\n","Iteration:  92% 1711/1851 [17:58<01:28,  1.58it/s]\u001b[A\n","Iteration:  92% 1712/1851 [17:58<01:27,  1.58it/s]\u001b[A\n","Iteration:  93% 1713/1851 [17:59<01:27,  1.58it/s]\u001b[A\n","Iteration:  93% 1714/1851 [18:00<01:26,  1.58it/s]\u001b[A\n","Iteration:  93% 1715/1851 [18:00<01:25,  1.59it/s]\u001b[A\n","Iteration:  93% 1716/1851 [18:01<01:25,  1.58it/s]\u001b[A\n","Iteration:  93% 1717/1851 [18:01<01:24,  1.58it/s]\u001b[A\n","Iteration:  93% 1718/1851 [18:02<01:24,  1.58it/s]\u001b[A\n","Iteration:  93% 1719/1851 [18:03<01:23,  1.58it/s]\u001b[A\n","Iteration:  93% 1720/1851 [18:03<01:22,  1.58it/s]\u001b[A\n","Iteration:  93% 1721/1851 [18:04<01:22,  1.58it/s]\u001b[A\n","Iteration:  93% 1722/1851 [18:05<01:21,  1.58it/s]\u001b[A\n","Iteration:  93% 1723/1851 [18:05<01:20,  1.58it/s]\u001b[A\n","Iteration:  93% 1724/1851 [18:06<01:20,  1.58it/s]\u001b[A\n","Iteration:  93% 1725/1851 [18:06<01:19,  1.58it/s]\u001b[A\n","Iteration:  93% 1726/1851 [18:07<01:19,  1.58it/s]\u001b[A\n","Iteration:  93% 1727/1851 [18:08<01:18,  1.58it/s]\u001b[A\n","Iteration:  93% 1728/1851 [18:08<01:17,  1.58it/s]\u001b[A\n","Iteration:  93% 1729/1851 [18:09<01:17,  1.58it/s]\u001b[A\n","Iteration:  93% 1730/1851 [18:10<01:16,  1.58it/s]\u001b[A\n","Iteration:  94% 1731/1851 [18:10<01:15,  1.58it/s]\u001b[A\n","Iteration:  94% 1732/1851 [18:11<01:15,  1.58it/s]\u001b[A\n","Iteration:  94% 1733/1851 [18:12<01:14,  1.58it/s]\u001b[A\n","Iteration:  94% 1734/1851 [18:12<01:14,  1.58it/s]\u001b[A\n","Iteration:  94% 1735/1851 [18:13<01:13,  1.58it/s]\u001b[A\n","Iteration:  94% 1736/1851 [18:13<01:12,  1.58it/s]\u001b[A\n","Iteration:  94% 1737/1851 [18:14<01:12,  1.58it/s]\u001b[A\n","Iteration:  94% 1738/1851 [18:15<01:11,  1.58it/s]\u001b[A\n","Iteration:  94% 1739/1851 [18:15<01:11,  1.58it/s]\u001b[A\n","Iteration:  94% 1740/1851 [18:16<01:10,  1.58it/s]\u001b[A\n","Iteration:  94% 1741/1851 [18:17<01:09,  1.58it/s]\u001b[A\n","Iteration:  94% 1742/1851 [18:17<01:08,  1.58it/s]\u001b[A\n","Iteration:  94% 1743/1851 [18:18<01:08,  1.58it/s]\u001b[A\n","Iteration:  94% 1744/1851 [18:19<01:07,  1.58it/s]\u001b[A\n","Iteration:  94% 1745/1851 [18:19<01:07,  1.58it/s]\u001b[A\n","Iteration:  94% 1746/1851 [18:20<01:06,  1.58it/s]\u001b[A\n","Iteration:  94% 1747/1851 [18:20<01:05,  1.58it/s]\u001b[A\n","Iteration:  94% 1748/1851 [18:21<01:05,  1.58it/s]\u001b[A\n","Iteration:  94% 1749/1851 [18:22<01:04,  1.58it/s]\u001b[A\n","Iteration:  95% 1750/1851 [18:22<01:03,  1.58it/s]\u001b[A\n","Iteration:  95% 1751/1851 [18:23<01:03,  1.58it/s]\u001b[A\n","Iteration:  95% 1752/1851 [18:24<01:02,  1.58it/s]\u001b[A\n","Iteration:  95% 1753/1851 [18:24<01:02,  1.58it/s]\u001b[A\n","Iteration:  95% 1754/1851 [18:25<01:01,  1.58it/s]\u001b[A\n","Iteration:  95% 1755/1851 [18:25<01:00,  1.58it/s]\u001b[A\n","Iteration:  95% 1756/1851 [18:26<01:00,  1.58it/s]\u001b[A\n","Iteration:  95% 1757/1851 [18:27<00:59,  1.58it/s]\u001b[A\n","Iteration:  95% 1758/1851 [18:27<00:58,  1.58it/s]\u001b[A\n","Iteration:  95% 1759/1851 [18:28<00:58,  1.58it/s]\u001b[A\n","Iteration:  95% 1760/1851 [18:29<00:57,  1.58it/s]\u001b[A\n","Iteration:  95% 1761/1851 [18:29<00:56,  1.58it/s]\u001b[A\n","Iteration:  95% 1762/1851 [18:30<00:56,  1.58it/s]\u001b[A\n","Iteration:  95% 1763/1851 [18:31<00:55,  1.58it/s]\u001b[A\n","Iteration:  95% 1764/1851 [18:31<00:54,  1.58it/s]\u001b[A\n","Iteration:  95% 1765/1851 [18:32<00:54,  1.58it/s]\u001b[A\n","Iteration:  95% 1766/1851 [18:32<00:53,  1.58it/s]\u001b[A\n","Iteration:  95% 1767/1851 [18:33<00:53,  1.58it/s]\u001b[A\n","Iteration:  96% 1768/1851 [18:34<00:52,  1.58it/s]\u001b[A\n","Iteration:  96% 1769/1851 [18:34<00:51,  1.58it/s]\u001b[A\n","Iteration:  96% 1770/1851 [18:35<00:51,  1.58it/s]\u001b[A\n","Iteration:  96% 1771/1851 [18:36<00:50,  1.58it/s]\u001b[A\n","Iteration:  96% 1772/1851 [18:36<00:50,  1.58it/s]\u001b[A\n","Iteration:  96% 1773/1851 [18:37<00:49,  1.58it/s]\u001b[A\n","Iteration:  96% 1774/1851 [18:37<00:48,  1.58it/s]\u001b[A\n","Iteration:  96% 1775/1851 [18:38<00:48,  1.58it/s]\u001b[A\n","Iteration:  96% 1776/1851 [18:39<00:47,  1.58it/s]\u001b[A\n","Iteration:  96% 1777/1851 [18:39<00:46,  1.58it/s]\u001b[A\n","Iteration:  96% 1778/1851 [18:40<00:46,  1.59it/s]\u001b[A\n","Iteration:  96% 1779/1851 [18:41<00:45,  1.59it/s]\u001b[A\n","Iteration:  96% 1780/1851 [18:41<00:44,  1.58it/s]\u001b[A\n","Iteration:  96% 1781/1851 [18:42<00:44,  1.58it/s]\u001b[A\n","Iteration:  96% 1782/1851 [18:43<00:43,  1.58it/s]\u001b[A\n","Iteration:  96% 1783/1851 [18:43<00:43,  1.58it/s]\u001b[A\n","Iteration:  96% 1784/1851 [18:44<00:42,  1.58it/s]\u001b[A\n","Iteration:  96% 1785/1851 [18:44<00:41,  1.58it/s]\u001b[A\n","Iteration:  96% 1786/1851 [18:45<00:41,  1.58it/s]\u001b[A\n","Iteration:  97% 1787/1851 [18:46<00:40,  1.58it/s]\u001b[A\n","Iteration:  97% 1788/1851 [18:46<00:39,  1.58it/s]\u001b[A\n","Iteration:  97% 1789/1851 [18:47<00:39,  1.58it/s]\u001b[A\n","Iteration:  97% 1790/1851 [18:48<00:38,  1.58it/s]\u001b[A\n","Iteration:  97% 1791/1851 [18:48<00:38,  1.58it/s]\u001b[A\n","Iteration:  97% 1792/1851 [18:49<00:37,  1.58it/s]\u001b[A\n","Iteration:  97% 1793/1851 [18:50<00:36,  1.58it/s]\u001b[A\n","Iteration:  97% 1794/1851 [18:50<00:36,  1.58it/s]\u001b[A\n","Iteration:  97% 1795/1851 [18:51<00:35,  1.58it/s]\u001b[A\n","Iteration:  97% 1796/1851 [18:51<00:34,  1.58it/s]\u001b[A\n","Iteration:  97% 1797/1851 [18:52<00:34,  1.58it/s]\u001b[A\n","Iteration:  97% 1798/1851 [18:53<00:33,  1.58it/s]\u001b[A\n","Iteration:  97% 1799/1851 [18:53<00:32,  1.58it/s]\u001b[A\n","Iteration:  97% 1800/1851 [18:54<00:32,  1.58it/s]\u001b[A\n","Iteration:  97% 1801/1851 [18:55<00:31,  1.58it/s]\u001b[A\n","Iteration:  97% 1802/1851 [18:55<00:30,  1.59it/s]\u001b[A\n","Iteration:  97% 1803/1851 [18:56<00:30,  1.58it/s]\u001b[A\n","Iteration:  97% 1804/1851 [18:56<00:29,  1.58it/s]\u001b[A\n","Iteration:  98% 1805/1851 [18:57<00:29,  1.58it/s]\u001b[A\n","Iteration:  98% 1806/1851 [18:58<00:28,  1.58it/s]\u001b[A\n","Iteration:  98% 1807/1851 [18:58<00:27,  1.58it/s]\u001b[A\n","Iteration:  98% 1808/1851 [18:59<00:27,  1.58it/s]\u001b[A\n","Iteration:  98% 1809/1851 [19:00<00:26,  1.58it/s]\u001b[A\n","Iteration:  98% 1810/1851 [19:00<00:25,  1.58it/s]\u001b[A\n","Iteration:  98% 1811/1851 [19:01<00:25,  1.58it/s]\u001b[A\n","Iteration:  98% 1812/1851 [19:02<00:24,  1.58it/s]\u001b[A\n","Iteration:  98% 1813/1851 [19:02<00:24,  1.58it/s]\u001b[A\n","Iteration:  98% 1814/1851 [19:03<00:23,  1.58it/s]\u001b[A\n","Iteration:  98% 1815/1851 [19:03<00:22,  1.58it/s]\u001b[A\n","Iteration:  98% 1816/1851 [19:04<00:22,  1.58it/s]\u001b[A\n","Iteration:  98% 1817/1851 [19:05<00:21,  1.58it/s]\u001b[A\n","Iteration:  98% 1818/1851 [19:05<00:20,  1.58it/s]\u001b[A\n","Iteration:  98% 1819/1851 [19:06<00:20,  1.58it/s]\u001b[A\n","Iteration:  98% 1820/1851 [19:07<00:19,  1.58it/s]\u001b[A\n","Iteration:  98% 1821/1851 [19:07<00:18,  1.58it/s]\u001b[A\n","Iteration:  98% 1822/1851 [19:08<00:18,  1.58it/s]\u001b[A\n","Iteration:  98% 1823/1851 [19:08<00:17,  1.58it/s]\u001b[A\n","Iteration:  99% 1824/1851 [19:09<00:17,  1.58it/s]\u001b[A\n","Iteration:  99% 1825/1851 [19:10<00:16,  1.58it/s]\u001b[A\n","Iteration:  99% 1826/1851 [19:10<00:15,  1.59it/s]\u001b[A\n","Iteration:  99% 1827/1851 [19:11<00:15,  1.58it/s]\u001b[A\n","Iteration:  99% 1828/1851 [19:12<00:14,  1.58it/s]\u001b[A\n","Iteration:  99% 1829/1851 [19:12<00:13,  1.58it/s]\u001b[A\n","Iteration:  99% 1830/1851 [19:13<00:13,  1.58it/s]\u001b[A\n","Iteration:  99% 1831/1851 [19:14<00:12,  1.58it/s]\u001b[A\n","Iteration:  99% 1832/1851 [19:14<00:12,  1.58it/s]\u001b[A\n","Iteration:  99% 1833/1851 [19:15<00:11,  1.58it/s]\u001b[A\n","Iteration:  99% 1834/1851 [19:15<00:10,  1.58it/s]\u001b[A\n","Iteration:  99% 1835/1851 [19:16<00:10,  1.58it/s]\u001b[A\n","Iteration:  99% 1836/1851 [19:17<00:09,  1.58it/s]\u001b[A\n","Iteration:  99% 1837/1851 [19:17<00:08,  1.58it/s]\u001b[A\n","Iteration:  99% 1838/1851 [19:18<00:08,  1.58it/s]\u001b[A\n","Iteration:  99% 1839/1851 [19:19<00:07,  1.58it/s]\u001b[A\n","Iteration:  99% 1840/1851 [19:19<00:06,  1.58it/s]\u001b[A\n","Iteration:  99% 1841/1851 [19:20<00:06,  1.58it/s]\u001b[A\n","Iteration: 100% 1842/1851 [19:20<00:05,  1.58it/s]\u001b[A\n","Iteration: 100% 1843/1851 [19:21<00:05,  1.58it/s]\u001b[A\n","Iteration: 100% 1844/1851 [19:22<00:04,  1.58it/s]\u001b[A\n","Iteration: 100% 1845/1851 [19:22<00:03,  1.57it/s]\u001b[A\n","Iteration: 100% 1846/1851 [19:23<00:03,  1.58it/s]\u001b[A\n","Iteration: 100% 1847/1851 [19:24<00:02,  1.58it/s]\u001b[A\n","Iteration: 100% 1848/1851 [19:24<00:01,  1.58it/s]\u001b[A\n","Iteration: 100% 1849/1851 [19:25<00:01,  1.57it/s]\u001b[A\n","Iteration: 100% 1850/1851 [19:26<00:00,  1.58it/s]\u001b[A\n","Iteration: 100% 1851/1851 [19:26<00:00,  1.59it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","[2022-08-16 07:47:31,931][__main__][DEBUG] - epoch is 0\n","[2022-08-16 07:47:31,932][__main__][DEBUG] - validation loss is tensor(0.3383, device='cuda:0')\n","Epoch:   1% 1/100 [23:21<38:33:07, 1401.89s/it]\n","Iteration:   0% 0/1851 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\n","Iteration:   0% 1/1851 [00:01<52:45,  1.71s/it]\u001b[A\n","Iteration:   0% 2/1851 [00:02<33:19,  1.08s/it]\u001b[A\n","Iteration:   0% 3/1851 [00:02<26:53,  1.15it/s]\u001b[A\n","Iteration:   0% 4/1851 [00:03<23:56,  1.29it/s]\u001b[A\n","Iteration:   0% 5/1851 [00:04<22:14,  1.38it/s]\u001b[A\n","Iteration:   0% 6/1851 [00:04<21:16,  1.45it/s]\u001b[A\n","Iteration:   0% 7/1851 [00:05<20:38,  1.49it/s]\u001b[A\n","Iteration:   0% 8/1851 [00:06<20:14,  1.52it/s]\u001b[A\n","Iteration:   0% 9/1851 [00:06<19:59,  1.54it/s]\u001b[A\n","Iteration:   1% 10/1851 [00:07<19:48,  1.55it/s]\u001b[A\n","Iteration:   1% 11/1851 [00:08<19:40,  1.56it/s]\u001b[A\n","Iteration:   1% 12/1851 [00:08<19:34,  1.57it/s]\u001b[A\n","Iteration:   1% 13/1851 [00:09<19:28,  1.57it/s]\u001b[A\n","Iteration:   1% 14/1851 [00:09<19:24,  1.58it/s]\u001b[A\n","Iteration:   1% 15/1851 [00:10<19:21,  1.58it/s]\u001b[A\n","Iteration:   1% 16/1851 [00:11<19:21,  1.58it/s]\u001b[A\n","Iteration:   1% 17/1851 [00:11<19:20,  1.58it/s]\u001b[A\n","Iteration:   1% 18/1851 [00:12<19:18,  1.58it/s]\u001b[A\n","Iteration:   1% 19/1851 [00:13<19:18,  1.58it/s]\u001b[A\n","Iteration:   1% 20/1851 [00:13<19:20,  1.58it/s]\u001b[A\n","Iteration:   1% 21/1851 [00:14<19:17,  1.58it/s]\u001b[A\n","Iteration:   1% 22/1851 [00:14<19:17,  1.58it/s]\u001b[A\n","Iteration:   1% 23/1851 [00:15<19:14,  1.58it/s]\u001b[A\n","Iteration:   1% 24/1851 [00:16<19:12,  1.59it/s]\u001b[A\n","Iteration:   1% 25/1851 [00:16<19:17,  1.58it/s]\u001b[A\n","Iteration:   1% 26/1851 [00:17<19:15,  1.58it/s]\u001b[A\n","Iteration:   1% 27/1851 [00:18<19:12,  1.58it/s]\u001b[A\n","Iteration:   2% 28/1851 [00:18<19:11,  1.58it/s]\u001b[A\n","Iteration:   2% 29/1851 [00:19<19:10,  1.58it/s]\u001b[A\n","Iteration:   2% 30/1851 [00:20<19:10,  1.58it/s]\u001b[A\n","Iteration:   2% 31/1851 [00:20<19:09,  1.58it/s]\u001b[A\n","Iteration:   2% 32/1851 [00:21<19:08,  1.58it/s]\u001b[A\n","Iteration:   2% 33/1851 [00:21<19:08,  1.58it/s]\u001b[A\n","Iteration:   2% 34/1851 [00:22<19:07,  1.58it/s]\u001b[A\n","Iteration:   2% 35/1851 [00:23<19:10,  1.58it/s]\u001b[A\n","Iteration:   2% 36/1851 [00:23<19:09,  1.58it/s]\u001b[A\n","Iteration:   2% 37/1851 [00:24<19:08,  1.58it/s]\u001b[A\n","Iteration:   2% 38/1851 [00:25<19:07,  1.58it/s]\u001b[A\n","Iteration:   2% 39/1851 [00:25<19:08,  1.58it/s]\u001b[A\n","Iteration:   2% 40/1851 [00:26<19:07,  1.58it/s]\u001b[A\n","Iteration:   2% 41/1851 [00:26<19:05,  1.58it/s]\u001b[A\n","Iteration:   2% 42/1851 [00:27<19:04,  1.58it/s]\u001b[A\n","Iteration:   2% 43/1851 [00:28<19:05,  1.58it/s]\u001b[A\n","Iteration:   2% 44/1851 [00:28<19:05,  1.58it/s]\u001b[A\n","Iteration:   2% 45/1851 [00:29<19:03,  1.58it/s]\u001b[A\n","Iteration:   2% 46/1851 [00:30<19:04,  1.58it/s]\u001b[A\n","Iteration:   3% 47/1851 [00:30<19:03,  1.58it/s]\u001b[A\n","Iteration:   3% 48/1851 [00:31<19:01,  1.58it/s]\u001b[A\n","Iteration:   3% 49/1851 [00:32<19:01,  1.58it/s]\u001b[A\n","Iteration:   3% 50/1851 [00:32<19:01,  1.58it/s]\u001b[A\n","Iteration:   3% 51/1851 [00:33<19:00,  1.58it/s]\u001b[A\n","Iteration:   3% 52/1851 [00:33<18:56,  1.58it/s]\u001b[A\n","Iteration:   3% 53/1851 [00:34<18:57,  1.58it/s]\u001b[A\n","Iteration:   3% 54/1851 [00:35<18:57,  1.58it/s]\u001b[A\n","Iteration:   3% 55/1851 [00:35<18:58,  1.58it/s]\u001b[A\n","Iteration:   3% 56/1851 [00:36<18:59,  1.57it/s]\u001b[A\n","Iteration:   3% 57/1851 [00:37<18:58,  1.58it/s]\u001b[A\n","Iteration:   3% 58/1851 [00:37<19:00,  1.57it/s]\u001b[A\n","Iteration:   3% 59/1851 [00:38<18:59,  1.57it/s]\u001b[A\n","Iteration:   3% 60/1851 [00:39<18:57,  1.57it/s]\u001b[A\n","Iteration:   3% 61/1851 [00:39<18:55,  1.58it/s]\u001b[A\n","Iteration:   3% 62/1851 [00:40<18:55,  1.58it/s]\u001b[A\n","Iteration:   3% 63/1851 [00:40<18:53,  1.58it/s]\u001b[A\n","Iteration:   3% 64/1851 [00:41<18:52,  1.58it/s]\u001b[A\n","Iteration:   4% 65/1851 [00:42<18:53,  1.58it/s]\u001b[A\n","Iteration:   4% 66/1851 [00:42<18:51,  1.58it/s]\u001b[A\n","Iteration:   4% 67/1851 [00:43<18:53,  1.57it/s]\u001b[A\n","Iteration:   4% 68/1851 [00:44<18:52,  1.57it/s]\u001b[A\n","Iteration:   4% 69/1851 [00:44<18:50,  1.58it/s]\u001b[A\n","Iteration:   4% 70/1851 [00:45<18:51,  1.57it/s]\u001b[A\n","Iteration:   4% 71/1851 [00:46<18:50,  1.57it/s]\u001b[A\n","Iteration:   4% 72/1851 [00:46<18:51,  1.57it/s]\u001b[A\n","Iteration:   4% 73/1851 [00:47<18:49,  1.57it/s]\u001b[A\n","Iteration:   4% 74/1851 [00:47<18:48,  1.57it/s]\u001b[A\n","Iteration:   4% 75/1851 [00:48<18:46,  1.58it/s]\u001b[A\n","Iteration:   4% 76/1851 [00:49<18:43,  1.58it/s]\u001b[A\n","Iteration:   4% 77/1851 [00:49<18:43,  1.58it/s]\u001b[A\n","Iteration:   4% 78/1851 [00:50<18:42,  1.58it/s]\u001b[A\n","Iteration:   4% 79/1851 [00:51<18:41,  1.58it/s]\u001b[A\n","Iteration:   4% 80/1851 [00:51<18:41,  1.58it/s]\u001b[A\n","Iteration:   4% 81/1851 [00:52<18:39,  1.58it/s]\u001b[A\n","Iteration:   4% 82/1851 [00:52<18:40,  1.58it/s]\u001b[A\n","Iteration:   4% 83/1851 [00:53<18:42,  1.57it/s]\u001b[A\n","Iteration:   5% 84/1851 [00:54<18:38,  1.58it/s]\u001b[A\n","Iteration:   5% 85/1851 [00:54<18:38,  1.58it/s]\u001b[A\n","Iteration:   5% 86/1851 [00:55<18:37,  1.58it/s]\u001b[A\n","Iteration:   5% 87/1851 [00:56<18:37,  1.58it/s]\u001b[A\n","Iteration:   5% 88/1851 [00:56<18:36,  1.58it/s]\u001b[A\n","Iteration:   5% 89/1851 [00:57<18:35,  1.58it/s]\u001b[A\n","Iteration:   5% 90/1851 [00:58<18:35,  1.58it/s]\u001b[A\n","Iteration:   5% 91/1851 [00:58<18:34,  1.58it/s]\u001b[A\n","Iteration:   5% 92/1851 [00:59<18:33,  1.58it/s]\u001b[A\n","Iteration:   5% 93/1851 [00:59<18:32,  1.58it/s]\u001b[A\n","Iteration:   5% 94/1851 [01:00<18:32,  1.58it/s]\u001b[A\n","Iteration:   5% 95/1851 [01:01<18:33,  1.58it/s]\u001b[A\n","Iteration:   5% 96/1851 [01:01<18:31,  1.58it/s]\u001b[A\n","Iteration:   5% 97/1851 [01:02<18:29,  1.58it/s]\u001b[A\n","Iteration:   5% 98/1851 [01:03<18:30,  1.58it/s]\u001b[A\n","Iteration:   5% 99/1851 [01:03<18:27,  1.58it/s]\u001b[A\n","Iteration:   5% 100/1851 [01:04<18:28,  1.58it/s]\u001b[A\n","Iteration:   5% 101/1851 [01:05<18:25,  1.58it/s]\u001b[A\n","Iteration:   6% 102/1851 [01:05<18:27,  1.58it/s]\u001b[A\n","Iteration:   6% 103/1851 [01:06<18:25,  1.58it/s]\u001b[A\n","Iteration:   6% 104/1851 [01:06<18:26,  1.58it/s]\u001b[A\n","Iteration:   6% 105/1851 [01:07<18:27,  1.58it/s]\u001b[A\n","Iteration:   6% 106/1851 [01:08<18:25,  1.58it/s]\u001b[A\n","Iteration:   6% 107/1851 [01:08<18:25,  1.58it/s]\u001b[A\n","Iteration:   6% 108/1851 [01:09<18:25,  1.58it/s]\u001b[A\n","Iteration:   6% 109/1851 [01:10<18:25,  1.58it/s]\u001b[A\n","Iteration:   6% 110/1851 [01:10<18:24,  1.58it/s]\u001b[A\n","Iteration:   6% 111/1851 [01:11<18:23,  1.58it/s]\u001b[A\n","Iteration:   6% 112/1851 [01:11<18:22,  1.58it/s]\u001b[A\n","Iteration:   6% 113/1851 [01:12<18:22,  1.58it/s]\u001b[A\n","Iteration:   6% 114/1851 [01:13<18:22,  1.58it/s]\u001b[A\n","Iteration:   6% 115/1851 [01:13<18:17,  1.58it/s]\u001b[A\n","Iteration:   6% 116/1851 [01:14<18:15,  1.58it/s]\u001b[A\n","Iteration:   6% 117/1851 [01:15<18:16,  1.58it/s]\u001b[A\n","Iteration:   6% 118/1851 [01:15<18:15,  1.58it/s]\u001b[A\n","Iteration:   6% 119/1851 [01:16<18:16,  1.58it/s]\u001b[A\n","Iteration:   6% 120/1851 [01:17<18:16,  1.58it/s]\u001b[A\n","Iteration:   7% 121/1851 [01:17<18:13,  1.58it/s]\u001b[A\n","Iteration:   7% 122/1851 [01:18<18:11,  1.58it/s]\u001b[A\n","Iteration:   7% 123/1851 [01:18<18:10,  1.58it/s]\u001b[A\n","Iteration:   7% 124/1851 [01:19<18:09,  1.59it/s]\u001b[A\n","Iteration:   7% 125/1851 [01:20<18:08,  1.59it/s]\u001b[A\n","Iteration:   7% 126/1851 [01:20<18:06,  1.59it/s]\u001b[A\n","Iteration:   7% 127/1851 [01:21<18:07,  1.59it/s]\u001b[A\n","Iteration:   7% 128/1851 [01:22<18:05,  1.59it/s]\u001b[A\n","Iteration:   7% 129/1851 [01:22<18:05,  1.59it/s]\u001b[A\n","Iteration:   7% 130/1851 [01:23<18:05,  1.58it/s]\u001b[A\n","Iteration:   7% 131/1851 [01:23<18:04,  1.59it/s]\u001b[A\n","Iteration:   7% 132/1851 [01:24<18:04,  1.58it/s]\u001b[A\n","Iteration:   7% 133/1851 [01:25<18:04,  1.58it/s]\u001b[A\n","Iteration:   7% 134/1851 [01:25<18:03,  1.58it/s]\u001b[A\n","Iteration:   7% 135/1851 [01:26<18:02,  1.59it/s]\u001b[A\n","Iteration:   7% 136/1851 [01:27<18:00,  1.59it/s]\u001b[A\n","Iteration:   7% 137/1851 [01:27<18:01,  1.59it/s]\u001b[A\n","Iteration:   7% 138/1851 [01:28<18:00,  1.59it/s]\u001b[A\n","Iteration:   8% 139/1851 [01:29<18:04,  1.58it/s]\u001b[A\n","Iteration:   8% 140/1851 [01:29<18:01,  1.58it/s]\u001b[A\n","Iteration:   8% 141/1851 [01:30<18:00,  1.58it/s]\u001b[A\n","Iteration:   8% 142/1851 [01:30<17:59,  1.58it/s]\u001b[A\n","Iteration:   8% 143/1851 [01:31<17:59,  1.58it/s]\u001b[A\n","Iteration:   8% 144/1851 [01:32<18:00,  1.58it/s]\u001b[A\n","Iteration:   8% 145/1851 [01:32<17:58,  1.58it/s]\u001b[A\n","Iteration:   8% 146/1851 [01:33<17:57,  1.58it/s]\u001b[A\n","Iteration:   8% 147/1851 [01:34<17:53,  1.59it/s]\u001b[A\n","Iteration:   8% 148/1851 [01:34<17:53,  1.59it/s]\u001b[A\n","Iteration:   8% 149/1851 [01:35<17:53,  1.59it/s]\u001b[A\n","Iteration:   8% 150/1851 [01:35<17:53,  1.58it/s]\u001b[A\n","Iteration:   8% 151/1851 [01:36<17:53,  1.58it/s]\u001b[A\n","Iteration:   8% 152/1851 [01:37<17:52,  1.58it/s]\u001b[A\n","Iteration:   8% 153/1851 [01:37<17:51,  1.58it/s]\u001b[A\n","Iteration:   8% 154/1851 [01:38<17:49,  1.59it/s]\u001b[A\n","Iteration:   8% 155/1851 [01:39<17:48,  1.59it/s]\u001b[A\n","Iteration:   8% 156/1851 [01:39<17:48,  1.59it/s]\u001b[A\n","Iteration:   8% 157/1851 [01:40<17:48,  1.58it/s]\u001b[A\n","Iteration:   9% 158/1851 [01:41<17:48,  1.58it/s]\u001b[A\n","Iteration:   9% 159/1851 [01:41<17:48,  1.58it/s]\u001b[A\n","Iteration:   9% 160/1851 [01:42<17:46,  1.59it/s]\u001b[A\n","Iteration:   9% 161/1851 [01:42<17:46,  1.58it/s]\u001b[A\n","Iteration:   9% 162/1851 [01:43<17:47,  1.58it/s]\u001b[A\n","Iteration:   9% 163/1851 [01:44<17:46,  1.58it/s]\u001b[A\n","Iteration:   9% 164/1851 [01:44<17:46,  1.58it/s]\u001b[A\n","Iteration:   9% 165/1851 [01:45<17:43,  1.59it/s]\u001b[A\n","Iteration:   9% 166/1851 [01:46<17:44,  1.58it/s]\u001b[A\n","Iteration:   9% 167/1851 [01:46<17:41,  1.59it/s]\u001b[A\n","Iteration:   9% 168/1851 [01:47<17:41,  1.59it/s]\u001b[A\n","Iteration:   9% 169/1851 [01:47<17:40,  1.59it/s]\u001b[A\n","Iteration:   9% 170/1851 [01:48<17:40,  1.59it/s]\u001b[A\n","Iteration:   9% 171/1851 [01:49<17:39,  1.59it/s]\u001b[A\n","Iteration:   9% 172/1851 [01:49<17:39,  1.58it/s]\u001b[A\n","Iteration:   9% 173/1851 [01:50<17:38,  1.58it/s]\u001b[A\n","Iteration:   9% 174/1851 [01:51<17:38,  1.58it/s]\u001b[A\n","Iteration:   9% 175/1851 [01:51<17:39,  1.58it/s]\u001b[A\n","Iteration:  10% 176/1851 [01:52<17:40,  1.58it/s]\u001b[A\n","Iteration:  10% 177/1851 [01:53<17:39,  1.58it/s]\u001b[A\n","Iteration:  10% 178/1851 [01:53<17:38,  1.58it/s]\u001b[A\n","Iteration:  10% 179/1851 [01:54<17:37,  1.58it/s]\u001b[A\n","Iteration:  10% 180/1851 [01:54<17:35,  1.58it/s]\u001b[A\n","Iteration:  10% 181/1851 [01:55<17:35,  1.58it/s]\u001b[A\n","Iteration:  10% 182/1851 [01:56<17:35,  1.58it/s]\u001b[A\n","Iteration:  10% 183/1851 [01:56<17:32,  1.58it/s]\u001b[A\n","Iteration:  10% 184/1851 [01:57<17:34,  1.58it/s]\u001b[A\n","Iteration:  10% 185/1851 [01:58<17:29,  1.59it/s]\u001b[A\n","Iteration:  10% 186/1851 [01:58<17:30,  1.58it/s]\u001b[A\n","Iteration:  10% 187/1851 [01:59<17:30,  1.58it/s]\u001b[A\n","Iteration:  10% 188/1851 [01:59<17:28,  1.59it/s]\u001b[A\n","Iteration:  10% 189/1851 [02:00<17:29,  1.58it/s]\u001b[A\n","Iteration:  10% 190/1851 [02:01<17:29,  1.58it/s]\u001b[A\n","Iteration:  10% 191/1851 [02:01<17:29,  1.58it/s]\u001b[A\n","Iteration:  10% 192/1851 [02:02<17:26,  1.58it/s]\u001b[A\n","Iteration:  10% 193/1851 [02:03<17:25,  1.59it/s]\u001b[A\n","Iteration:  10% 194/1851 [02:03<17:24,  1.59it/s]\u001b[A\n","Iteration:  11% 195/1851 [02:04<17:27,  1.58it/s]\u001b[A\n","Iteration:  11% 196/1851 [02:05<17:25,  1.58it/s]\u001b[A\n","Iteration:  11% 197/1851 [02:05<17:23,  1.59it/s]\u001b[A\n","Iteration:  11% 198/1851 [02:06<17:23,  1.58it/s]\u001b[A\n","Iteration:  11% 199/1851 [02:06<17:22,  1.58it/s]\u001b[A\n","Iteration:  11% 200/1851 [02:07<17:23,  1.58it/s]\u001b[A\n","Iteration:  11% 201/1851 [02:08<17:21,  1.58it/s]\u001b[A\n","Iteration:  11% 202/1851 [02:08<17:19,  1.59it/s]\u001b[A\n","Iteration:  11% 203/1851 [02:09<17:18,  1.59it/s]\u001b[A\n","Iteration:  11% 204/1851 [02:10<17:22,  1.58it/s]\u001b[A\n","Iteration:  11% 205/1851 [02:10<17:19,  1.58it/s]\u001b[A\n","Iteration:  11% 206/1851 [02:11<17:18,  1.58it/s]\u001b[A\n","Iteration:  11% 207/1851 [02:11<17:18,  1.58it/s]\u001b[A\n","Iteration:  11% 208/1851 [02:12<17:16,  1.59it/s]\u001b[A\n","Iteration:  11% 209/1851 [02:13<17:16,  1.58it/s]\u001b[A\n","Iteration:  11% 210/1851 [02:13<17:15,  1.58it/s]\u001b[A\n","Iteration:  11% 211/1851 [02:14<17:13,  1.59it/s]\u001b[A\n","Iteration:  11% 212/1851 [02:15<17:12,  1.59it/s]\u001b[A\n","Iteration:  12% 213/1851 [02:15<17:10,  1.59it/s]\u001b[A\n","Iteration:  12% 214/1851 [02:16<17:11,  1.59it/s]\u001b[A\n","Iteration:  12% 215/1851 [02:17<17:11,  1.59it/s]\u001b[A\n","Iteration:  12% 216/1851 [02:17<17:12,  1.58it/s]\u001b[A\n","Iteration:  12% 217/1851 [02:18<17:11,  1.58it/s]\u001b[A\n","Iteration:  12% 218/1851 [02:18<17:09,  1.59it/s]\u001b[A\n","Iteration:  12% 219/1851 [02:19<17:10,  1.58it/s]\u001b[A\n","Iteration:  12% 220/1851 [02:20<17:08,  1.59it/s]\u001b[A\n","Iteration:  12% 221/1851 [02:20<17:09,  1.58it/s]\u001b[A\n","Iteration:  12% 222/1851 [02:21<17:08,  1.58it/s]\u001b[A\n","Iteration:  12% 223/1851 [02:22<17:06,  1.59it/s]\u001b[A\n","Iteration:  12% 224/1851 [02:22<17:05,  1.59it/s]\u001b[A\n","Iteration:  12% 225/1851 [02:23<17:04,  1.59it/s]\u001b[A\n","Iteration:  12% 226/1851 [02:23<17:04,  1.59it/s]\u001b[A\n","Iteration:  12% 227/1851 [02:24<17:04,  1.59it/s]\u001b[A\n","Iteration:  12% 228/1851 [02:25<17:00,  1.59it/s]\u001b[A\n","Iteration:  12% 229/1851 [02:25<17:00,  1.59it/s]\u001b[A\n","Iteration:  12% 230/1851 [02:26<17:01,  1.59it/s]\u001b[A\n","Iteration:  12% 231/1851 [02:27<17:00,  1.59it/s]\u001b[A\n","Iteration:  13% 232/1851 [02:27<17:01,  1.59it/s]\u001b[A\n","Iteration:  13% 233/1851 [02:28<17:01,  1.58it/s]\u001b[A\n","Iteration:  13% 234/1851 [02:29<17:01,  1.58it/s]\u001b[A\n","Iteration:  13% 235/1851 [02:29<16:58,  1.59it/s]\u001b[A\n","Iteration:  13% 236/1851 [02:30<17:00,  1.58it/s]\u001b[A\n","Iteration:  13% 237/1851 [02:30<16:57,  1.59it/s]\u001b[A\n","Iteration:  13% 238/1851 [02:31<16:57,  1.59it/s]\u001b[A\n","Iteration:  13% 239/1851 [02:32<16:56,  1.59it/s]\u001b[A\n","Iteration:  13% 240/1851 [02:32<16:57,  1.58it/s]\u001b[A\n","Iteration:  13% 241/1851 [02:33<16:55,  1.58it/s]\u001b[A\n","Iteration:  13% 242/1851 [02:34<16:55,  1.58it/s]\u001b[A\n","Iteration:  13% 243/1851 [02:34<16:53,  1.59it/s]\u001b[A\n","Iteration:  13% 244/1851 [02:35<16:53,  1.59it/s]\u001b[A\n","Iteration:  13% 245/1851 [02:35<16:52,  1.59it/s]\u001b[A\n","Iteration:  13% 246/1851 [02:36<16:52,  1.59it/s]\u001b[A\n","Iteration:  13% 247/1851 [02:37<16:50,  1.59it/s]\u001b[A\n","Iteration:  13% 248/1851 [02:37<16:52,  1.58it/s]\u001b[A\n","Iteration:  13% 249/1851 [02:38<16:51,  1.58it/s]\u001b[A\n","Iteration:  14% 250/1851 [02:39<16:51,  1.58it/s]\u001b[A\n","Iteration:  14% 251/1851 [02:39<16:50,  1.58it/s]\u001b[A\n","Iteration:  14% 252/1851 [02:40<16:50,  1.58it/s]\u001b[A\n","Iteration:  14% 253/1851 [02:40<16:50,  1.58it/s]\u001b[A\n","Iteration:  14% 254/1851 [02:41<16:50,  1.58it/s]\u001b[A\n","Iteration:  14% 255/1851 [02:42<16:49,  1.58it/s]\u001b[A\n","Iteration:  14% 256/1851 [02:42<16:49,  1.58it/s]\u001b[A\n","Iteration:  14% 257/1851 [02:43<16:46,  1.58it/s]\u001b[A\n","Iteration:  14% 258/1851 [02:44<16:43,  1.59it/s]\u001b[A\n","Iteration:  14% 259/1851 [02:44<16:46,  1.58it/s]\u001b[A\n","Iteration:  14% 260/1851 [02:45<16:43,  1.59it/s]\u001b[A\n","Iteration:  14% 261/1851 [02:46<16:41,  1.59it/s]\u001b[A\n","Iteration:  14% 262/1851 [02:46<16:41,  1.59it/s]\u001b[A\n","Iteration:  14% 263/1851 [02:47<16:44,  1.58it/s]\u001b[A\n","Iteration:  14% 264/1851 [02:47<16:43,  1.58it/s]\u001b[A\n","Iteration:  14% 265/1851 [02:48<16:42,  1.58it/s]\u001b[A\n","Iteration:  14% 266/1851 [02:49<16:39,  1.59it/s]\u001b[A\n","Iteration:  14% 267/1851 [02:49<16:38,  1.59it/s]\u001b[A\n","Iteration:  14% 268/1851 [02:50<16:37,  1.59it/s]\u001b[A\n","Iteration:  15% 269/1851 [02:51<16:36,  1.59it/s]\u001b[A\n","Iteration:  15% 270/1851 [02:51<16:36,  1.59it/s]\u001b[A\n","Iteration:  15% 271/1851 [02:52<16:35,  1.59it/s]\u001b[A\n","Iteration:  15% 272/1851 [02:52<16:36,  1.58it/s]\u001b[A\n","Iteration:  15% 273/1851 [02:53<16:33,  1.59it/s]\u001b[A\n","Iteration:  15% 274/1851 [02:54<16:33,  1.59it/s]\u001b[A\n","Iteration:  15% 275/1851 [02:54<16:34,  1.59it/s]\u001b[A\n","Iteration:  15% 276/1851 [02:55<16:32,  1.59it/s]\u001b[A\n","Iteration:  15% 277/1851 [02:56<16:33,  1.58it/s]\u001b[A\n","Iteration:  15% 278/1851 [02:56<16:33,  1.58it/s]\u001b[A\n","Iteration:  15% 279/1851 [02:57<16:31,  1.59it/s]\u001b[A\n","Iteration:  15% 280/1851 [02:58<16:30,  1.59it/s]\u001b[A\n","Iteration:  15% 281/1851 [02:58<16:30,  1.59it/s]\u001b[A\n","Iteration:  15% 282/1851 [02:59<16:29,  1.59it/s]\u001b[A\n","Iteration:  15% 283/1851 [02:59<16:27,  1.59it/s]\u001b[A\n","Iteration:  15% 284/1851 [03:00<16:28,  1.59it/s]\u001b[A\n","Iteration:  15% 285/1851 [03:01<16:28,  1.58it/s]\u001b[A\n","Iteration:  15% 286/1851 [03:01<16:25,  1.59it/s]\u001b[A\n","Iteration:  16% 287/1851 [03:02<16:27,  1.58it/s]\u001b[A\n","Iteration:  16% 288/1851 [03:03<16:27,  1.58it/s]\u001b[A\n","Iteration:  16% 289/1851 [03:03<16:29,  1.58it/s]\u001b[A\n","Iteration:  16% 290/1851 [03:04<16:27,  1.58it/s]\u001b[A\n","Iteration:  16% 291/1851 [03:04<16:25,  1.58it/s]\u001b[A\n","Iteration:  16% 292/1851 [03:05<16:24,  1.58it/s]\u001b[A\n","Iteration:  16% 293/1851 [03:06<16:22,  1.59it/s]\u001b[A\n","Iteration:  16% 294/1851 [03:06<16:22,  1.58it/s]\u001b[A\n","Iteration:  16% 295/1851 [03:07<16:21,  1.58it/s]\u001b[A\n","Iteration:  16% 296/1851 [03:08<16:21,  1.58it/s]\u001b[A\n","Iteration:  16% 297/1851 [03:08<16:21,  1.58it/s]\u001b[A\n","Iteration:  16% 298/1851 [03:09<16:16,  1.59it/s]\u001b[A\n","Iteration:  16% 299/1851 [03:10<16:17,  1.59it/s]\u001b[A\n","Iteration:  16% 300/1851 [03:10<16:18,  1.58it/s]\u001b[A\n","Iteration:  16% 301/1851 [03:11<16:19,  1.58it/s]\u001b[A\n","Iteration:  16% 302/1851 [03:11<16:19,  1.58it/s]\u001b[A\n","Iteration:  16% 303/1851 [03:12<16:18,  1.58it/s]\u001b[A\n","Iteration:  16% 304/1851 [03:13<16:18,  1.58it/s]\u001b[A\n","Iteration:  16% 305/1851 [03:13<16:14,  1.59it/s]\u001b[A\n","Iteration:  17% 306/1851 [03:14<16:17,  1.58it/s]\u001b[A\n","Iteration:  17% 307/1851 [03:15<16:16,  1.58it/s]\u001b[A\n","Iteration:  17% 308/1851 [03:15<16:14,  1.58it/s]\u001b[A\n","Iteration:  17% 309/1851 [03:16<16:15,  1.58it/s]\u001b[A\n","Iteration:  17% 310/1851 [03:16<16:14,  1.58it/s]\u001b[A\n","Iteration:  17% 311/1851 [03:17<16:14,  1.58it/s]\u001b[A\n","Iteration:  17% 312/1851 [03:18<16:13,  1.58it/s]\u001b[A\n","Iteration:  17% 313/1851 [03:18<16:13,  1.58it/s]\u001b[A\n","Iteration:  17% 314/1851 [03:19<16:12,  1.58it/s]\u001b[A\n","Iteration:  17% 315/1851 [03:20<16:12,  1.58it/s]\u001b[A\n","Iteration:  17% 316/1851 [03:20<16:11,  1.58it/s]\u001b[A\n","Iteration:  17% 317/1851 [03:21<16:11,  1.58it/s]\u001b[A\n","Iteration:  17% 318/1851 [03:22<16:09,  1.58it/s]\u001b[A\n","Iteration:  17% 319/1851 [03:22<16:06,  1.58it/s]\u001b[A\n","Iteration:  17% 320/1851 [03:23<16:06,  1.58it/s]\u001b[A\n","Iteration:  17% 321/1851 [03:23<16:05,  1.58it/s]\u001b[A\n","Iteration:  17% 322/1851 [03:24<16:06,  1.58it/s]\u001b[A\n","Iteration:  17% 323/1851 [03:25<16:04,  1.58it/s]\u001b[A\n","Iteration:  18% 324/1851 [03:25<16:04,  1.58it/s]\u001b[A\n","Iteration:  18% 325/1851 [03:26<16:03,  1.58it/s]\u001b[A\n","Iteration:  18% 326/1851 [03:27<16:03,  1.58it/s]\u001b[A\n","Iteration:  18% 327/1851 [03:27<16:01,  1.58it/s]\u001b[A\n","Iteration:  18% 328/1851 [03:28<16:01,  1.58it/s]\u001b[A\n","Iteration:  18% 329/1851 [03:28<16:02,  1.58it/s]\u001b[A\n","Iteration:  18% 330/1851 [03:29<16:03,  1.58it/s]\u001b[A\n","Iteration:  18% 331/1851 [03:30<16:01,  1.58it/s]\u001b[A\n","Iteration:  18% 332/1851 [03:30<15:59,  1.58it/s]\u001b[A\n","Iteration:  18% 333/1851 [03:31<16:00,  1.58it/s]\u001b[A\n","Iteration:  18% 334/1851 [03:32<15:56,  1.59it/s]\u001b[A\n","Iteration:  18% 335/1851 [03:32<15:55,  1.59it/s]\u001b[A\n","Iteration:  18% 336/1851 [03:33<15:56,  1.58it/s]\u001b[A\n","Iteration:  18% 337/1851 [03:34<15:54,  1.59it/s]\u001b[A\n","Iteration:  18% 338/1851 [03:34<15:53,  1.59it/s]\u001b[A\n","Iteration:  18% 339/1851 [03:35<15:53,  1.59it/s]\u001b[A\n","Iteration:  18% 340/1851 [03:35<15:53,  1.59it/s]\u001b[A\n","Iteration:  18% 341/1851 [03:36<15:52,  1.59it/s]\u001b[A\n","Iteration:  18% 342/1851 [03:37<15:52,  1.58it/s]\u001b[A\n","Iteration:  19% 343/1851 [03:37<15:52,  1.58it/s]\u001b[A\n","Iteration:  19% 344/1851 [03:38<15:52,  1.58it/s]\u001b[A\n","Iteration:  19% 345/1851 [03:39<15:52,  1.58it/s]\u001b[A\n","Iteration:  19% 346/1851 [03:39<15:52,  1.58it/s]\u001b[A\n","Iteration:  19% 347/1851 [03:40<15:49,  1.58it/s]\u001b[A\n","Iteration:  19% 348/1851 [03:40<15:49,  1.58it/s]\u001b[A\n","Iteration:  19% 349/1851 [03:41<15:48,  1.58it/s]\u001b[A\n","Iteration:  19% 350/1851 [03:42<15:48,  1.58it/s]\u001b[A\n","Iteration:  19% 351/1851 [03:42<15:46,  1.58it/s]\u001b[A\n","Iteration:  19% 352/1851 [03:43<15:45,  1.58it/s]\u001b[A\n","Iteration:  19% 353/1851 [03:44<15:46,  1.58it/s]\u001b[A\n","Iteration:  19% 354/1851 [03:44<15:45,  1.58it/s]\u001b[A\n","Iteration:  19% 355/1851 [03:45<15:44,  1.58it/s]\u001b[A\n","Iteration:  19% 356/1851 [03:46<15:44,  1.58it/s]\u001b[A\n","Iteration:  19% 357/1851 [03:46<15:43,  1.58it/s]\u001b[A\n","Iteration:  19% 358/1851 [03:47<15:44,  1.58it/s]\u001b[A\n","Iteration:  19% 359/1851 [03:47<15:41,  1.58it/s]\u001b[A\n","Iteration:  19% 360/1851 [03:48<15:40,  1.59it/s]\u001b[A\n","Iteration:  20% 361/1851 [03:49<15:40,  1.58it/s]\u001b[A\n","Iteration:  20% 362/1851 [03:49<15:39,  1.58it/s]\u001b[A\n","Iteration:  20% 363/1851 [03:50<15:38,  1.59it/s]\u001b[A\n","Iteration:  20% 364/1851 [03:51<15:38,  1.58it/s]\u001b[A\n","Iteration:  20% 365/1851 [03:51<15:35,  1.59it/s]\u001b[A\n","Iteration:  20% 366/1851 [03:52<15:36,  1.59it/s]\u001b[A\n","Iteration:  20% 367/1851 [03:52<15:36,  1.58it/s]\u001b[A\n","Iteration:  20% 368/1851 [03:53<15:37,  1.58it/s]\u001b[A\n","Iteration:  20% 369/1851 [03:54<15:36,  1.58it/s]\u001b[A\n","Iteration:  20% 370/1851 [03:54<15:35,  1.58it/s]\u001b[A\n","Iteration:  20% 371/1851 [03:55<15:35,  1.58it/s]\u001b[A\n","Iteration:  20% 372/1851 [03:56<15:33,  1.59it/s]\u001b[A\n","Iteration:  20% 373/1851 [03:56<15:32,  1.58it/s]\u001b[A\n","Iteration:  20% 374/1851 [03:57<15:32,  1.58it/s]\u001b[A\n","Iteration:  20% 375/1851 [03:58<15:33,  1.58it/s]\u001b[A\n","Iteration:  20% 376/1851 [03:58<15:33,  1.58it/s]\u001b[A\n","Iteration:  20% 377/1851 [03:59<15:31,  1.58it/s]\u001b[A\n","Iteration:  20% 378/1851 [03:59<15:30,  1.58it/s]\u001b[A\n","Iteration:  20% 379/1851 [04:00<15:29,  1.58it/s]\u001b[A\n","Iteration:  21% 380/1851 [04:01<15:28,  1.58it/s]\u001b[A\n","Iteration:  21% 381/1851 [04:01<15:27,  1.59it/s]\u001b[A\n","Iteration:  21% 382/1851 [04:02<15:25,  1.59it/s]\u001b[A\n","Iteration:  21% 383/1851 [04:03<15:25,  1.59it/s]\u001b[A\n","Iteration:  21% 384/1851 [04:03<15:24,  1.59it/s]\u001b[A\n","Iteration:  21% 385/1851 [04:04<15:23,  1.59it/s]\u001b[A\n","Iteration:  21% 386/1851 [04:04<15:20,  1.59it/s]\u001b[A\n","Iteration:  21% 387/1851 [04:05<15:22,  1.59it/s]\u001b[A\n","Iteration:  21% 388/1851 [04:06<15:21,  1.59it/s]\u001b[A\n","Iteration:  21% 389/1851 [04:06<15:21,  1.59it/s]\u001b[A\n","Iteration:  21% 390/1851 [04:07<15:23,  1.58it/s]\u001b[A\n","Iteration:  21% 391/1851 [04:08<15:20,  1.59it/s]\u001b[A\n","Iteration:  21% 392/1851 [04:08<15:18,  1.59it/s]\u001b[A\n","Iteration:  21% 393/1851 [04:09<15:18,  1.59it/s]\u001b[A\n","Iteration:  21% 394/1851 [04:10<15:18,  1.59it/s]\u001b[A\n","Iteration:  21% 395/1851 [04:10<15:18,  1.58it/s]\u001b[A\n","Iteration:  21% 396/1851 [04:11<15:16,  1.59it/s]\u001b[A\n","Iteration:  21% 397/1851 [04:11<15:16,  1.59it/s]\u001b[A\n","Iteration:  22% 398/1851 [04:12<15:14,  1.59it/s]\u001b[A\n","Iteration:  22% 399/1851 [04:13<15:16,  1.59it/s]\u001b[A\n","Iteration:  22% 400/1851 [04:13<15:13,  1.59it/s]\u001b[A\n","Iteration:  22% 401/1851 [04:14<15:15,  1.58it/s]\u001b[A\n","Iteration:  22% 402/1851 [04:15<15:12,  1.59it/s]\u001b[A\n","Iteration:  22% 403/1851 [04:15<15:11,  1.59it/s]\u001b[A\n","Iteration:  22% 404/1851 [04:16<15:11,  1.59it/s]\u001b[A\n","Iteration:  22% 405/1851 [04:16<15:11,  1.59it/s]\u001b[A\n","Iteration:  22% 406/1851 [04:17<15:09,  1.59it/s]\u001b[A\n","Iteration:  22% 407/1851 [04:18<15:06,  1.59it/s]\u001b[A\n","Iteration:  22% 408/1851 [04:18<15:10,  1.59it/s]\u001b[A\n","Iteration:  22% 409/1851 [04:19<15:08,  1.59it/s]\u001b[A\n","Iteration:  22% 410/1851 [04:20<15:09,  1.58it/s]\u001b[A\n","Iteration:  22% 411/1851 [04:20<15:09,  1.58it/s]\u001b[A\n","Iteration:  22% 412/1851 [04:21<15:13,  1.58it/s]\u001b[A\n","Iteration:  22% 413/1851 [04:21<15:10,  1.58it/s]\u001b[A\n","Iteration:  22% 414/1851 [04:22<15:09,  1.58it/s]\u001b[A\n","Iteration:  22% 415/1851 [04:23<15:09,  1.58it/s]\u001b[A\n","Iteration:  22% 416/1851 [04:23<15:06,  1.58it/s]\u001b[A\n","Iteration:  23% 417/1851 [04:24<15:05,  1.58it/s]\u001b[A\n","Iteration:  23% 418/1851 [04:25<15:05,  1.58it/s]\u001b[A\n","Iteration:  23% 419/1851 [04:25<15:03,  1.59it/s]\u001b[A\n","Iteration:  23% 420/1851 [04:26<15:01,  1.59it/s]\u001b[A\n","Iteration:  23% 421/1851 [04:27<15:02,  1.58it/s]\u001b[A\n","Iteration:  23% 422/1851 [04:27<14:59,  1.59it/s]\u001b[A\n","Iteration:  23% 423/1851 [04:28<14:59,  1.59it/s]\u001b[A\n","Iteration:  23% 424/1851 [04:28<14:57,  1.59it/s]\u001b[A\n","Iteration:  23% 425/1851 [04:29<14:57,  1.59it/s]\u001b[A\n","Iteration:  23% 426/1851 [04:30<14:57,  1.59it/s]\u001b[A\n","Iteration:  23% 427/1851 [04:30<14:57,  1.59it/s]\u001b[A\n","Iteration:  23% 428/1851 [04:31<14:55,  1.59it/s]\u001b[A\n","Iteration:  23% 429/1851 [04:32<14:57,  1.59it/s]\u001b[A\n","Iteration:  23% 430/1851 [04:32<14:55,  1.59it/s]\u001b[A\n","Iteration:  23% 431/1851 [04:33<14:55,  1.59it/s]\u001b[A\n","Iteration:  23% 432/1851 [04:33<14:54,  1.59it/s]\u001b[A\n","Iteration:  23% 433/1851 [04:34<14:54,  1.58it/s]\u001b[A\n","Iteration:  23% 434/1851 [04:35<14:52,  1.59it/s]\u001b[A\n","Iteration:  24% 435/1851 [04:35<14:50,  1.59it/s]\u001b[A\n","Iteration:  24% 436/1851 [04:36<14:51,  1.59it/s]\u001b[A\n","Iteration:  24% 437/1851 [04:37<14:52,  1.58it/s]\u001b[A\n","Iteration:  24% 438/1851 [04:37<14:50,  1.59it/s]\u001b[A\n","Iteration:  24% 439/1851 [04:38<14:50,  1.59it/s]\u001b[A\n","Iteration:  24% 440/1851 [04:39<14:49,  1.59it/s]\u001b[A\n","Iteration:  24% 441/1851 [04:39<14:52,  1.58it/s]\u001b[A\n","Iteration:  24% 442/1851 [04:40<14:50,  1.58it/s]\u001b[A\n","Iteration:  24% 443/1851 [04:40<14:49,  1.58it/s]\u001b[A\n","Iteration:  24% 444/1851 [04:41<14:48,  1.58it/s]\u001b[A\n","Iteration:  24% 445/1851 [04:42<14:46,  1.59it/s]\u001b[A\n","Iteration:  24% 446/1851 [04:42<14:46,  1.58it/s]\u001b[A\n","Iteration:  24% 447/1851 [04:43<14:45,  1.58it/s]\u001b[A\n","Iteration:  24% 448/1851 [04:44<14:45,  1.58it/s]\u001b[A\n","Iteration:  24% 449/1851 [04:44<14:46,  1.58it/s]\u001b[A\n","Iteration:  24% 450/1851 [04:45<14:45,  1.58it/s]\u001b[A\n","Iteration:  24% 451/1851 [04:45<14:44,  1.58it/s]\u001b[A\n","Iteration:  24% 452/1851 [04:46<14:44,  1.58it/s]\u001b[A\n","Iteration:  24% 453/1851 [04:47<14:41,  1.59it/s]\u001b[A\n","Iteration:  25% 454/1851 [04:47<14:41,  1.58it/s]\u001b[A\n","Iteration:  25% 455/1851 [04:48<14:41,  1.58it/s]\u001b[A\n","Iteration:  25% 456/1851 [04:49<14:39,  1.59it/s]\u001b[A\n","Iteration:  25% 457/1851 [04:49<14:38,  1.59it/s]\u001b[A\n","Iteration:  25% 458/1851 [04:50<14:40,  1.58it/s]\u001b[A\n","Iteration:  25% 459/1851 [04:51<14:39,  1.58it/s]\u001b[A\n","Iteration:  25% 460/1851 [04:51<14:38,  1.58it/s]\u001b[A\n","Iteration:  25% 461/1851 [04:52<14:38,  1.58it/s]\u001b[A\n","Iteration:  25% 462/1851 [04:52<14:38,  1.58it/s]\u001b[A\n","Iteration:  25% 463/1851 [04:53<14:36,  1.58it/s]\u001b[A\n","Iteration:  25% 464/1851 [04:54<14:35,  1.59it/s]\u001b[A\n","Iteration:  25% 465/1851 [04:54<14:33,  1.59it/s]\u001b[A\n","Iteration:  25% 466/1851 [04:55<14:33,  1.59it/s]\u001b[A\n","Iteration:  25% 467/1851 [04:56<14:33,  1.58it/s]\u001b[A\n","Iteration:  25% 468/1851 [04:56<14:32,  1.59it/s]\u001b[A\n","Iteration:  25% 469/1851 [04:57<14:29,  1.59it/s]\u001b[A\n","Iteration:  25% 470/1851 [04:57<14:29,  1.59it/s]\u001b[A\n","Iteration:  25% 471/1851 [04:58<14:29,  1.59it/s]\u001b[A\n","Iteration:  25% 472/1851 [04:59<14:30,  1.58it/s]\u001b[A\n","Iteration:  26% 473/1851 [04:59<14:28,  1.59it/s]\u001b[A\n","Iteration:  26% 474/1851 [05:00<14:27,  1.59it/s]\u001b[A\n","Iteration:  26% 475/1851 [05:01<14:28,  1.59it/s]\u001b[A\n","Iteration:  26% 476/1851 [05:01<14:27,  1.59it/s]\u001b[A\n","Iteration:  26% 477/1851 [05:02<14:27,  1.58it/s]\u001b[A\n","Iteration:  26% 478/1851 [05:02<14:25,  1.59it/s]\u001b[A\n","Iteration:  26% 479/1851 [05:03<14:24,  1.59it/s]\u001b[A\n","Iteration:  26% 480/1851 [05:04<14:23,  1.59it/s]\u001b[A\n","Iteration:  26% 481/1851 [05:04<14:23,  1.59it/s]\u001b[A\n","Iteration:  26% 482/1851 [05:05<14:22,  1.59it/s]\u001b[A\n","Iteration:  26% 483/1851 [05:06<14:21,  1.59it/s]\u001b[A\n","Iteration:  26% 484/1851 [05:06<14:21,  1.59it/s]\u001b[A\n","Iteration:  26% 485/1851 [05:07<14:22,  1.58it/s]\u001b[A\n","Iteration:  26% 486/1851 [05:08<14:20,  1.59it/s]\u001b[A\n","Iteration:  26% 487/1851 [05:08<14:20,  1.58it/s]\u001b[A\n","Iteration:  26% 488/1851 [05:09<14:21,  1.58it/s]\u001b[A\n","Iteration:  26% 489/1851 [05:09<14:21,  1.58it/s]\u001b[A\n","Iteration:  26% 490/1851 [05:10<14:19,  1.58it/s]\u001b[A\n","Iteration:  27% 491/1851 [05:11<14:18,  1.58it/s]\u001b[A\n","Iteration:  27% 492/1851 [05:11<14:18,  1.58it/s]\u001b[A\n","Iteration:  27% 493/1851 [05:12<14:17,  1.58it/s]\u001b[A\n","Iteration:  27% 494/1851 [05:13<14:15,  1.59it/s]\u001b[A\n","Iteration:  27% 495/1851 [05:13<14:16,  1.58it/s]\u001b[A\n","Iteration:  27% 496/1851 [05:14<14:14,  1.59it/s]\u001b[A\n","Iteration:  27% 497/1851 [05:14<14:13,  1.59it/s]\u001b[A\n","Iteration:  27% 498/1851 [05:15<14:13,  1.59it/s]\u001b[A\n","Iteration:  27% 499/1851 [05:16<14:13,  1.58it/s]\u001b[A\n","Iteration:  27% 500/1851 [05:16<14:15,  1.58it/s]\u001b[A\n","Iteration:  27% 501/1851 [05:17<14:13,  1.58it/s]\u001b[A\n","Iteration:  27% 502/1851 [05:18<14:10,  1.59it/s]\u001b[A\n","Iteration:  27% 503/1851 [05:18<14:10,  1.58it/s]\u001b[A\n","Iteration:  27% 504/1851 [05:19<14:11,  1.58it/s]\u001b[A\n","Iteration:  27% 505/1851 [05:20<14:10,  1.58it/s]\u001b[A\n","Iteration:  27% 506/1851 [05:20<14:09,  1.58it/s]\u001b[A\n","Iteration:  27% 507/1851 [05:21<14:06,  1.59it/s]\u001b[A\n","Iteration:  27% 508/1851 [05:21<14:06,  1.59it/s]\u001b[A\n","Iteration:  27% 509/1851 [05:22<14:05,  1.59it/s]\u001b[A\n","Iteration:  28% 510/1851 [05:23<14:06,  1.59it/s]\u001b[A\n","Iteration:  28% 511/1851 [05:23<14:06,  1.58it/s]\u001b[A\n","Iteration:  28% 512/1851 [05:24<14:03,  1.59it/s]\u001b[A\n","Iteration:  28% 513/1851 [05:25<14:02,  1.59it/s]\u001b[A\n","Iteration:  28% 514/1851 [05:25<14:03,  1.58it/s]\u001b[A\n","Iteration:  28% 515/1851 [05:26<14:03,  1.58it/s]\u001b[A\n","Iteration:  28% 516/1851 [05:26<14:03,  1.58it/s]\u001b[A\n","Iteration:  28% 517/1851 [05:27<14:04,  1.58it/s]\u001b[A\n","Iteration:  28% 518/1851 [05:28<14:03,  1.58it/s]\u001b[A\n","Iteration:  28% 519/1851 [05:28<14:03,  1.58it/s]\u001b[A\n","Iteration:  28% 520/1851 [05:29<14:03,  1.58it/s]\u001b[A\n","Iteration:  28% 521/1851 [05:30<14:03,  1.58it/s]\u001b[A\n","Iteration:  28% 522/1851 [05:30<14:01,  1.58it/s]\u001b[A\n","Iteration:  28% 523/1851 [05:31<14:00,  1.58it/s]\u001b[A\n","Iteration:  28% 524/1851 [05:32<13:56,  1.59it/s]\u001b[A\n","Iteration:  28% 525/1851 [05:32<13:55,  1.59it/s]\u001b[A\n","Iteration:  28% 526/1851 [05:33<13:56,  1.58it/s]\u001b[A\n","Iteration:  28% 527/1851 [05:33<13:58,  1.58it/s]\u001b[A\n","Iteration:  29% 528/1851 [05:34<13:55,  1.58it/s]\u001b[A\n","Iteration:  29% 529/1851 [05:35<13:56,  1.58it/s]\u001b[A\n","Iteration:  29% 530/1851 [05:35<13:54,  1.58it/s]\u001b[A\n","Iteration:  29% 531/1851 [05:36<13:54,  1.58it/s]\u001b[A\n","Iteration:  29% 532/1851 [05:37<13:55,  1.58it/s]\u001b[A\n","Iteration:  29% 533/1851 [05:37<13:54,  1.58it/s]\u001b[A\n","Iteration:  29% 534/1851 [05:38<13:52,  1.58it/s]\u001b[A\n","Iteration:  29% 535/1851 [05:38<13:52,  1.58it/s]\u001b[A\n","Iteration:  29% 536/1851 [05:39<13:51,  1.58it/s]\u001b[A\n","Iteration:  29% 537/1851 [05:40<13:51,  1.58it/s]\u001b[A\n","Iteration:  29% 538/1851 [05:40<13:50,  1.58it/s]\u001b[A\n","Iteration:  29% 539/1851 [05:41<13:48,  1.58it/s]\u001b[A\n","Iteration:  29% 540/1851 [05:42<13:48,  1.58it/s]\u001b[A\n","Iteration:  29% 541/1851 [05:42<13:46,  1.58it/s]\u001b[A\n","Iteration:  29% 542/1851 [05:43<13:45,  1.59it/s]\u001b[A\n","Iteration:  29% 543/1851 [05:44<13:43,  1.59it/s]\u001b[A\n","Iteration:  29% 544/1851 [05:44<13:44,  1.59it/s]\u001b[A\n","Iteration:  29% 545/1851 [05:45<13:44,  1.58it/s]\u001b[A\n","Iteration:  29% 546/1851 [05:45<13:43,  1.58it/s]\u001b[A\n","Iteration:  30% 547/1851 [05:46<13:42,  1.59it/s]\u001b[A\n","Iteration:  30% 548/1851 [05:47<13:42,  1.58it/s]\u001b[A\n","Iteration:  30% 549/1851 [05:47<13:40,  1.59it/s]\u001b[A\n","Iteration:  30% 550/1851 [05:48<13:40,  1.58it/s]\u001b[A\n","Iteration:  30% 551/1851 [05:49<13:41,  1.58it/s]\u001b[A\n","Iteration:  30% 552/1851 [05:49<13:40,  1.58it/s]\u001b[A\n","Iteration:  30% 553/1851 [05:50<13:40,  1.58it/s]\u001b[A\n","Iteration:  30% 554/1851 [05:50<13:39,  1.58it/s]\u001b[A\n","Iteration:  30% 555/1851 [05:51<13:39,  1.58it/s]\u001b[A\n","Iteration:  30% 556/1851 [05:52<13:38,  1.58it/s]\u001b[A\n","Iteration:  30% 557/1851 [05:52<14:00,  1.54it/s]\u001b[A\n","Iteration:  30% 558/1851 [05:53<13:59,  1.54it/s]\u001b[A\n","Iteration:  30% 559/1851 [05:54<13:51,  1.55it/s]\u001b[A\n","Iteration:  30% 560/1851 [05:54<13:44,  1.57it/s]\u001b[A\n","Iteration:  30% 561/1851 [05:55<13:41,  1.57it/s]\u001b[A\n","Iteration:  30% 562/1851 [05:56<13:37,  1.58it/s]\u001b[A\n","Iteration:  30% 563/1851 [05:56<13:38,  1.57it/s]\u001b[A\n","Iteration:  30% 564/1851 [05:57<13:37,  1.57it/s]\u001b[A\n","Iteration:  31% 565/1851 [05:58<13:35,  1.58it/s]\u001b[A\n","Iteration:  31% 566/1851 [05:58<13:33,  1.58it/s]\u001b[A\n","Iteration:  31% 567/1851 [05:59<13:32,  1.58it/s]\u001b[A\n","Iteration:  31% 568/1851 [05:59<13:32,  1.58it/s]\u001b[A\n","Iteration:  31% 569/1851 [06:00<13:30,  1.58it/s]\u001b[A\n","Iteration:  31% 570/1851 [06:01<13:29,  1.58it/s]\u001b[A\n","Iteration:  31% 571/1851 [06:01<13:29,  1.58it/s]\u001b[A\n","Iteration:  31% 572/1851 [06:02<13:28,  1.58it/s]\u001b[A\n","Iteration:  31% 573/1851 [06:03<13:27,  1.58it/s]\u001b[A\n","Iteration:  31% 574/1851 [06:03<13:28,  1.58it/s]\u001b[A\n","Iteration:  31% 575/1851 [06:04<13:28,  1.58it/s]\u001b[A\n","Iteration:  31% 576/1851 [06:04<13:26,  1.58it/s]\u001b[A\n","Iteration:  31% 577/1851 [06:05<13:25,  1.58it/s]\u001b[A\n","Iteration:  31% 578/1851 [06:06<13:24,  1.58it/s]\u001b[A\n","Iteration:  31% 579/1851 [06:06<13:23,  1.58it/s]\u001b[A\n","Iteration:  31% 580/1851 [06:07<13:22,  1.58it/s]\u001b[A\n","Iteration:  31% 581/1851 [06:08<13:22,  1.58it/s]\u001b[A\n","Iteration:  31% 582/1851 [06:08<13:22,  1.58it/s]\u001b[A\n","Iteration:  31% 583/1851 [06:09<13:21,  1.58it/s]\u001b[A\n","Iteration:  32% 584/1851 [06:10<13:21,  1.58it/s]\u001b[A\n","Iteration:  32% 585/1851 [06:10<13:21,  1.58it/s]\u001b[A\n","Iteration:  32% 586/1851 [06:11<13:20,  1.58it/s]\u001b[A\n","Iteration:  32% 587/1851 [06:11<13:18,  1.58it/s]\u001b[A\n","Iteration:  32% 588/1851 [06:12<13:17,  1.58it/s]\u001b[A\n","Iteration:  32% 589/1851 [06:13<13:17,  1.58it/s]\u001b[A\n","Iteration:  32% 590/1851 [06:13<13:14,  1.59it/s]\u001b[A\n","Iteration:  32% 591/1851 [06:14<13:14,  1.59it/s]\u001b[A\n","Iteration:  32% 592/1851 [06:15<13:13,  1.59it/s]\u001b[A\n","Iteration:  32% 593/1851 [06:15<13:14,  1.58it/s]\u001b[A\n","Iteration:  32% 594/1851 [06:16<13:12,  1.59it/s]\u001b[A\n","Iteration:  32% 595/1851 [06:16<13:13,  1.58it/s]\u001b[A\n","Iteration:  32% 596/1851 [06:17<13:13,  1.58it/s]\u001b[A\n","Iteration:  32% 597/1851 [06:18<13:12,  1.58it/s]\u001b[A\n","Iteration:  32% 598/1851 [06:18<13:13,  1.58it/s]\u001b[A\n","Iteration:  32% 599/1851 [06:19<13:11,  1.58it/s]\u001b[A\n","Iteration:  32% 600/1851 [06:20<13:09,  1.58it/s]\u001b[A\n","Iteration:  32% 601/1851 [06:20<13:10,  1.58it/s]\u001b[A\n","Iteration:  33% 602/1851 [06:21<13:08,  1.58it/s]\u001b[A\n","Iteration:  33% 603/1851 [06:22<13:07,  1.58it/s]\u001b[A\n","Iteration:  33% 604/1851 [06:22<13:06,  1.59it/s]\u001b[A\n","Iteration:  33% 605/1851 [06:23<13:06,  1.58it/s]\u001b[A\n","Iteration:  33% 606/1851 [06:23<13:07,  1.58it/s]\u001b[A\n","Iteration:  33% 607/1851 [06:24<13:06,  1.58it/s]\u001b[A\n","Iteration:  33% 608/1851 [06:25<13:06,  1.58it/s]\u001b[A\n","Iteration:  33% 609/1851 [06:25<13:05,  1.58it/s]\u001b[A\n","Iteration:  33% 610/1851 [06:26<13:05,  1.58it/s]\u001b[A\n","Iteration:  33% 611/1851 [06:27<13:03,  1.58it/s]\u001b[A\n","Iteration:  33% 612/1851 [06:27<13:03,  1.58it/s]\u001b[A\n","Iteration:  33% 613/1851 [06:28<13:03,  1.58it/s]\u001b[A\n","Iteration:  33% 614/1851 [06:28<13:01,  1.58it/s]\u001b[A\n","Iteration:  33% 615/1851 [06:29<13:01,  1.58it/s]\u001b[A\n","Iteration:  33% 616/1851 [06:30<13:01,  1.58it/s]\u001b[A\n","Iteration:  33% 617/1851 [06:30<13:03,  1.58it/s]\u001b[A\n","Iteration:  33% 618/1851 [06:31<13:00,  1.58it/s]\u001b[A\n","Iteration:  33% 619/1851 [06:32<12:57,  1.58it/s]\u001b[A\n","Iteration:  33% 620/1851 [06:32<12:56,  1.58it/s]\u001b[A\n","Iteration:  34% 621/1851 [06:33<12:57,  1.58it/s]\u001b[A\n","Iteration:  34% 622/1851 [06:34<12:55,  1.58it/s]\u001b[A\n","Iteration:  34% 623/1851 [06:34<12:56,  1.58it/s]\u001b[A\n","Iteration:  34% 624/1851 [06:35<12:54,  1.58it/s]\u001b[A\n","Iteration:  34% 625/1851 [06:35<12:54,  1.58it/s]\u001b[A\n","Iteration:  34% 626/1851 [06:36<12:53,  1.58it/s]\u001b[A\n","Iteration:  34% 627/1851 [06:37<12:54,  1.58it/s]\u001b[A\n","Iteration:  34% 628/1851 [06:37<12:53,  1.58it/s]\u001b[A\n","Iteration:  34% 629/1851 [06:38<12:52,  1.58it/s]\u001b[A\n","Iteration:  34% 630/1851 [06:39<12:51,  1.58it/s]\u001b[A\n","Iteration:  34% 631/1851 [06:39<12:50,  1.58it/s]\u001b[A\n","Iteration:  34% 632/1851 [06:40<12:50,  1.58it/s]\u001b[A\n","Iteration:  34% 633/1851 [06:40<12:49,  1.58it/s]\u001b[A\n","Iteration:  34% 634/1851 [06:41<12:47,  1.59it/s]\u001b[A\n","Iteration:  34% 635/1851 [06:42<12:45,  1.59it/s]\u001b[A\n","Iteration:  34% 636/1851 [06:42<12:45,  1.59it/s]\u001b[A\n","Iteration:  34% 637/1851 [06:43<12:47,  1.58it/s]\u001b[A\n","Iteration:  34% 638/1851 [06:44<12:46,  1.58it/s]\u001b[A\n","Iteration:  35% 639/1851 [06:44<12:46,  1.58it/s]\u001b[A\n","Iteration:  35% 640/1851 [06:45<12:46,  1.58it/s]\u001b[A\n","Iteration:  35% 641/1851 [06:46<12:46,  1.58it/s]\u001b[A\n","Iteration:  35% 642/1851 [06:46<12:46,  1.58it/s]\u001b[A\n","Iteration:  35% 643/1851 [06:47<12:44,  1.58it/s]\u001b[A\n","Iteration:  35% 644/1851 [06:47<12:44,  1.58it/s]\u001b[A\n","Iteration:  35% 645/1851 [06:48<12:43,  1.58it/s]\u001b[A\n","Iteration:  35% 646/1851 [06:49<12:42,  1.58it/s]\u001b[A\n","Iteration:  35% 647/1851 [06:49<12:43,  1.58it/s]\u001b[A\n","Iteration:  35% 648/1851 [06:50<12:42,  1.58it/s]\u001b[A\n","Iteration:  35% 649/1851 [06:51<12:41,  1.58it/s]\u001b[A\n","Iteration:  35% 650/1851 [06:51<12:40,  1.58it/s]\u001b[A\n","Iteration:  35% 651/1851 [06:52<12:40,  1.58it/s]\u001b[A\n","Iteration:  35% 652/1851 [06:53<12:40,  1.58it/s]\u001b[A\n","Iteration:  35% 653/1851 [06:53<12:38,  1.58it/s]\u001b[A\n","Iteration:  35% 654/1851 [06:54<12:38,  1.58it/s]\u001b[A\n","Iteration:  35% 655/1851 [06:54<12:38,  1.58it/s]\u001b[A\n","Iteration:  35% 656/1851 [06:55<12:35,  1.58it/s]\u001b[A\n","Iteration:  35% 657/1851 [06:56<12:35,  1.58it/s]\u001b[A\n","Iteration:  36% 658/1851 [06:56<12:34,  1.58it/s]\u001b[A\n","Iteration:  36% 659/1851 [06:57<12:34,  1.58it/s]\u001b[A\n","Iteration:  36% 660/1851 [06:58<12:32,  1.58it/s]\u001b[A\n","Iteration:  36% 661/1851 [06:58<12:33,  1.58it/s]\u001b[A\n","Iteration:  36% 662/1851 [06:59<12:31,  1.58it/s]\u001b[A\n","Iteration:  36% 663/1851 [06:59<12:31,  1.58it/s]\u001b[A\n","Iteration:  36% 664/1851 [07:00<12:32,  1.58it/s]\u001b[A\n","Iteration:  36% 665/1851 [07:01<12:31,  1.58it/s]\u001b[A\n","Iteration:  36% 666/1851 [07:01<12:30,  1.58it/s]\u001b[A\n","Iteration:  36% 667/1851 [07:02<12:29,  1.58it/s]\u001b[A\n","Iteration:  36% 668/1851 [07:03<12:28,  1.58it/s]\u001b[A\n","Iteration:  36% 669/1851 [07:03<12:27,  1.58it/s]\u001b[A\n","Iteration:  36% 670/1851 [07:04<12:27,  1.58it/s]\u001b[A\n","Iteration:  36% 671/1851 [07:05<12:26,  1.58it/s]\u001b[A\n","Iteration:  36% 672/1851 [07:05<12:26,  1.58it/s]\u001b[A\n","Iteration:  36% 673/1851 [07:06<12:23,  1.58it/s]\u001b[A\n","Iteration:  36% 674/1851 [07:06<12:24,  1.58it/s]\u001b[A\n","Iteration:  36% 675/1851 [07:07<12:23,  1.58it/s]\u001b[A\n","Iteration:  37% 676/1851 [07:08<12:23,  1.58it/s]\u001b[A\n","Iteration:  37% 677/1851 [07:08<12:22,  1.58it/s]\u001b[A\n","Iteration:  37% 678/1851 [07:09<12:24,  1.58it/s]\u001b[A\n","Iteration:  37% 679/1851 [07:10<12:23,  1.58it/s]\u001b[A\n","Iteration:  37% 680/1851 [07:10<12:21,  1.58it/s]\u001b[A\n","Iteration:  37% 681/1851 [07:11<12:18,  1.58it/s]\u001b[A\n","Iteration:  37% 682/1851 [07:11<12:18,  1.58it/s]\u001b[A\n","Iteration:  37% 683/1851 [07:12<12:17,  1.58it/s]\u001b[A\n","Iteration:  37% 684/1851 [07:13<12:18,  1.58it/s]\u001b[A\n","Iteration:  37% 685/1851 [07:13<12:17,  1.58it/s]\u001b[A\n","Iteration:  37% 686/1851 [07:14<12:17,  1.58it/s]\u001b[A\n","Iteration:  37% 687/1851 [07:15<12:17,  1.58it/s]\u001b[A\n","Iteration:  37% 688/1851 [07:15<12:17,  1.58it/s]\u001b[A\n","Iteration:  37% 689/1851 [07:16<12:16,  1.58it/s]\u001b[A\n","Iteration:  37% 690/1851 [07:17<12:14,  1.58it/s]\u001b[A\n","Iteration:  37% 691/1851 [07:17<12:14,  1.58it/s]\u001b[A\n","Iteration:  37% 692/1851 [07:18<12:13,  1.58it/s]\u001b[A\n","Iteration:  37% 693/1851 [07:18<12:15,  1.57it/s]\u001b[A\n","Iteration:  37% 694/1851 [07:19<12:14,  1.58it/s]\u001b[A\n","Iteration:  38% 695/1851 [07:20<12:11,  1.58it/s]\u001b[A\n","Iteration:  38% 696/1851 [07:20<12:10,  1.58it/s]\u001b[A\n","Iteration:  38% 697/1851 [07:21<12:09,  1.58it/s]\u001b[A\n","Iteration:  38% 698/1851 [07:22<12:09,  1.58it/s]\u001b[A\n","Iteration:  38% 699/1851 [07:22<12:09,  1.58it/s]\u001b[A\n","Iteration:  38% 700/1851 [07:23<12:10,  1.58it/s]\u001b[A\n","Iteration:  38% 701/1851 [07:24<12:09,  1.58it/s]\u001b[A\n","Iteration:  38% 702/1851 [07:24<12:09,  1.58it/s]\u001b[A\n","Iteration:  38% 703/1851 [07:25<12:07,  1.58it/s]\u001b[A\n","Iteration:  38% 704/1851 [07:25<12:05,  1.58it/s]\u001b[A\n","Iteration:  38% 705/1851 [07:26<12:03,  1.58it/s]\u001b[A\n","Iteration:  38% 706/1851 [07:27<12:04,  1.58it/s]\u001b[A\n","Iteration:  38% 707/1851 [07:27<12:04,  1.58it/s]\u001b[A\n","Iteration:  38% 708/1851 [07:28<12:04,  1.58it/s]\u001b[A\n","Iteration:  38% 709/1851 [07:29<12:05,  1.57it/s]\u001b[A\n","Iteration:  38% 710/1851 [07:29<12:02,  1.58it/s]\u001b[A\n","Iteration:  38% 711/1851 [07:30<12:02,  1.58it/s]\u001b[A\n","Iteration:  38% 712/1851 [07:31<12:01,  1.58it/s]\u001b[A\n","Iteration:  39% 713/1851 [07:31<12:01,  1.58it/s]\u001b[A\n","Iteration:  39% 714/1851 [07:32<11:59,  1.58it/s]\u001b[A\n","Iteration:  39% 715/1851 [07:32<11:59,  1.58it/s]\u001b[A\n","Iteration:  39% 716/1851 [07:33<11:58,  1.58it/s]\u001b[A\n","Iteration:  39% 717/1851 [07:34<11:57,  1.58it/s]\u001b[A\n","Iteration:  39% 718/1851 [07:34<11:57,  1.58it/s]\u001b[A\n","Iteration:  39% 719/1851 [07:35<11:55,  1.58it/s]\u001b[A\n","Iteration:  39% 720/1851 [07:36<11:54,  1.58it/s]\u001b[A\n","Iteration:  39% 721/1851 [07:36<11:56,  1.58it/s]\u001b[A\n","Iteration:  39% 722/1851 [07:37<11:54,  1.58it/s]\u001b[A\n","Iteration:  39% 723/1851 [07:37<11:53,  1.58it/s]\u001b[A\n","Iteration:  39% 724/1851 [07:38<11:53,  1.58it/s]\u001b[A\n","Iteration:  39% 725/1851 [07:39<11:54,  1.58it/s]\u001b[A\n","Iteration:  39% 726/1851 [07:39<11:53,  1.58it/s]\u001b[A\n","Iteration:  39% 727/1851 [07:40<11:52,  1.58it/s]\u001b[A\n","Iteration:  39% 728/1851 [07:41<11:51,  1.58it/s]\u001b[A\n","Iteration:  39% 729/1851 [07:41<11:50,  1.58it/s]\u001b[A\n","Iteration:  39% 730/1851 [07:42<11:50,  1.58it/s]\u001b[A\n","Iteration:  39% 731/1851 [07:43<11:50,  1.58it/s]\u001b[A\n","Iteration:  40% 732/1851 [07:43<11:49,  1.58it/s]\u001b[A\n","Iteration:  40% 733/1851 [07:44<11:48,  1.58it/s]\u001b[A\n","Iteration:  40% 734/1851 [07:44<11:48,  1.58it/s]\u001b[A\n","Iteration:  40% 735/1851 [07:45<11:46,  1.58it/s]\u001b[A\n","Iteration:  40% 736/1851 [07:46<11:46,  1.58it/s]\u001b[A\n","Iteration:  40% 737/1851 [07:46<11:46,  1.58it/s]\u001b[A\n","Iteration:  40% 738/1851 [07:47<11:45,  1.58it/s]\u001b[A\n","Iteration:  40% 739/1851 [07:48<11:44,  1.58it/s]\u001b[A\n","Iteration:  40% 740/1851 [07:48<11:44,  1.58it/s]\u001b[A\n","Iteration:  40% 741/1851 [07:49<11:43,  1.58it/s]\u001b[A\n","Iteration:  40% 742/1851 [07:50<11:41,  1.58it/s]\u001b[A\n","Iteration:  40% 743/1851 [07:50<11:41,  1.58it/s]\u001b[A\n","Iteration:  40% 744/1851 [07:51<11:41,  1.58it/s]\u001b[A\n","Iteration:  40% 745/1851 [07:51<11:39,  1.58it/s]\u001b[A\n","Iteration:  40% 746/1851 [07:52<11:40,  1.58it/s]\u001b[A\n","Iteration:  40% 747/1851 [07:53<11:38,  1.58it/s]\u001b[A\n","Iteration:  40% 748/1851 [07:53<11:38,  1.58it/s]\u001b[A\n","Iteration:  40% 749/1851 [07:54<11:37,  1.58it/s]\u001b[A\n","Iteration:  41% 750/1851 [07:55<11:36,  1.58it/s]\u001b[A\n","Iteration:  41% 751/1851 [07:55<11:34,  1.58it/s]\u001b[A\n","Iteration:  41% 752/1851 [07:56<11:34,  1.58it/s]\u001b[A\n","Iteration:  41% 753/1851 [07:56<11:35,  1.58it/s]\u001b[A\n","Iteration:  41% 754/1851 [07:57<11:35,  1.58it/s]\u001b[A\n","Iteration:  41% 755/1851 [07:58<11:35,  1.57it/s]\u001b[A\n","Iteration:  41% 756/1851 [07:58<11:34,  1.58it/s]\u001b[A\n","Iteration:  41% 757/1851 [07:59<11:33,  1.58it/s]\u001b[A\n","Iteration:  41% 758/1851 [08:00<11:32,  1.58it/s]\u001b[A\n","Iteration:  41% 759/1851 [08:00<11:31,  1.58it/s]\u001b[A\n","Iteration:  41% 760/1851 [08:01<11:30,  1.58it/s]\u001b[A\n","Iteration:  41% 761/1851 [08:02<11:30,  1.58it/s]\u001b[A\n","Iteration:  41% 762/1851 [08:02<11:29,  1.58it/s]\u001b[A\n","Iteration:  41% 763/1851 [08:03<11:28,  1.58it/s]\u001b[A\n","Iteration:  41% 764/1851 [08:03<11:28,  1.58it/s]\u001b[A\n","Iteration:  41% 765/1851 [08:04<11:27,  1.58it/s]\u001b[A\n","Iteration:  41% 766/1851 [08:05<11:26,  1.58it/s]\u001b[A\n","Iteration:  41% 767/1851 [08:05<11:26,  1.58it/s]\u001b[A\n","Iteration:  41% 768/1851 [08:06<11:25,  1.58it/s]\u001b[A\n","Iteration:  42% 769/1851 [08:07<11:25,  1.58it/s]\u001b[A\n","Iteration:  42% 770/1851 [08:07<11:23,  1.58it/s]\u001b[A\n","Iteration:  42% 771/1851 [08:08<11:23,  1.58it/s]\u001b[A\n","Iteration:  42% 772/1851 [08:09<11:24,  1.58it/s]\u001b[A\n","Iteration:  42% 773/1851 [08:09<11:22,  1.58it/s]\u001b[A\n","Iteration:  42% 774/1851 [08:10<11:22,  1.58it/s]\u001b[A\n","Iteration:  42% 775/1851 [08:10<11:21,  1.58it/s]\u001b[A\n","Iteration:  42% 776/1851 [08:11<11:21,  1.58it/s]\u001b[A\n","Iteration:  42% 777/1851 [08:12<11:21,  1.58it/s]\u001b[A\n","Iteration:  42% 778/1851 [08:12<11:19,  1.58it/s]\u001b[A\n","Iteration:  42% 779/1851 [08:13<11:20,  1.58it/s]\u001b[A\n","Iteration:  42% 780/1851 [08:14<11:19,  1.58it/s]\u001b[A\n","Iteration:  42% 781/1851 [08:14<11:18,  1.58it/s]\u001b[A\n","Iteration:  42% 782/1851 [08:15<11:18,  1.58it/s]\u001b[A\n","Iteration:  42% 783/1851 [08:15<11:17,  1.58it/s]\u001b[A\n","Iteration:  42% 784/1851 [08:16<11:16,  1.58it/s]\u001b[A\n","Iteration:  42% 785/1851 [08:17<11:15,  1.58it/s]\u001b[A\n","Iteration:  42% 786/1851 [08:17<11:15,  1.58it/s]\u001b[A\n","Iteration:  43% 787/1851 [08:18<11:14,  1.58it/s]\u001b[A\n","Iteration:  43% 788/1851 [08:19<11:14,  1.58it/s]\u001b[A\n","Iteration:  43% 789/1851 [08:19<11:13,  1.58it/s]\u001b[A\n","Iteration:  43% 790/1851 [08:20<11:12,  1.58it/s]\u001b[A\n","Iteration:  43% 791/1851 [08:21<11:11,  1.58it/s]\u001b[A\n","Iteration:  43% 792/1851 [08:21<11:10,  1.58it/s]\u001b[A\n","Iteration:  43% 793/1851 [08:22<11:11,  1.58it/s]\u001b[A\n","Iteration:  43% 794/1851 [08:22<11:10,  1.58it/s]\u001b[A\n","Iteration:  43% 795/1851 [08:23<11:10,  1.58it/s]\u001b[A\n","Iteration:  43% 796/1851 [08:24<11:07,  1.58it/s]\u001b[A\n","Iteration:  43% 797/1851 [08:24<11:06,  1.58it/s]\u001b[A\n","Iteration:  43% 798/1851 [08:25<11:06,  1.58it/s]\u001b[A\n","Iteration:  43% 799/1851 [08:26<11:05,  1.58it/s]\u001b[A\n","Iteration:  43% 800/1851 [08:26<11:04,  1.58it/s]\u001b[A\n","Iteration:  43% 801/1851 [08:27<11:03,  1.58it/s]\u001b[A\n","Iteration:  43% 802/1851 [08:28<11:03,  1.58it/s]\u001b[A\n","Iteration:  43% 803/1851 [08:28<11:03,  1.58it/s]\u001b[A\n","Iteration:  43% 804/1851 [08:29<11:01,  1.58it/s]\u001b[A\n","Iteration:  43% 805/1851 [08:29<11:01,  1.58it/s]\u001b[A\n","Iteration:  44% 806/1851 [08:30<11:00,  1.58it/s]\u001b[A\n","Iteration:  44% 807/1851 [08:31<11:01,  1.58it/s]\u001b[A\n","Iteration:  44% 808/1851 [08:31<11:00,  1.58it/s]\u001b[A\n","Iteration:  44% 809/1851 [08:32<11:00,  1.58it/s]\u001b[A\n","Iteration:  44% 810/1851 [08:33<10:59,  1.58it/s]\u001b[A\n","Iteration:  44% 811/1851 [08:33<10:57,  1.58it/s]\u001b[A\n","Iteration:  44% 812/1851 [08:34<10:57,  1.58it/s]\u001b[A\n","Iteration:  44% 813/1851 [08:34<10:57,  1.58it/s]\u001b[A\n","Iteration:  44% 814/1851 [08:35<10:56,  1.58it/s]\u001b[A\n","Iteration:  44% 815/1851 [08:36<10:57,  1.57it/s]\u001b[A\n","Iteration:  44% 816/1851 [08:36<10:56,  1.58it/s]\u001b[A\n","Iteration:  44% 817/1851 [08:37<10:56,  1.58it/s]\u001b[A\n","Iteration:  44% 818/1851 [08:38<10:54,  1.58it/s]\u001b[A\n","Iteration:  44% 819/1851 [08:38<10:53,  1.58it/s]\u001b[A\n","Iteration:  44% 820/1851 [08:39<10:51,  1.58it/s]\u001b[A\n","Iteration:  44% 821/1851 [08:40<10:51,  1.58it/s]\u001b[A\n","Iteration:  44% 822/1851 [08:40<10:51,  1.58it/s]\u001b[A\n","Iteration:  44% 823/1851 [08:41<10:49,  1.58it/s]\u001b[A\n","Iteration:  45% 824/1851 [08:41<10:48,  1.58it/s]\u001b[A\n","Iteration:  45% 825/1851 [08:42<10:48,  1.58it/s]\u001b[A\n","Iteration:  45% 826/1851 [08:43<10:48,  1.58it/s]\u001b[A\n","Iteration:  45% 827/1851 [08:43<10:48,  1.58it/s]\u001b[A\n","Iteration:  45% 828/1851 [08:44<10:48,  1.58it/s]\u001b[A\n","Iteration:  45% 829/1851 [08:45<10:46,  1.58it/s]\u001b[A\n","Iteration:  45% 830/1851 [08:45<10:46,  1.58it/s]\u001b[A\n","Iteration:  45% 831/1851 [08:46<10:44,  1.58it/s]\u001b[A\n","Iteration:  45% 832/1851 [08:47<10:44,  1.58it/s]\u001b[A\n","Iteration:  45% 833/1851 [08:47<10:45,  1.58it/s]\u001b[A\n","Iteration:  45% 834/1851 [08:48<10:44,  1.58it/s]\u001b[A\n","Iteration:  45% 835/1851 [08:48<10:44,  1.58it/s]\u001b[A\n","Iteration:  45% 836/1851 [08:49<10:41,  1.58it/s]\u001b[A\n","Iteration:  45% 837/1851 [08:50<10:41,  1.58it/s]\u001b[A\n","Iteration:  45% 838/1851 [08:50<10:40,  1.58it/s]\u001b[A\n","Iteration:  45% 839/1851 [08:51<10:40,  1.58it/s]\u001b[A\n","Iteration:  45% 840/1851 [08:52<10:38,  1.58it/s]\u001b[A\n","Iteration:  45% 841/1851 [08:52<10:38,  1.58it/s]\u001b[A\n","Iteration:  45% 842/1851 [08:53<10:37,  1.58it/s]\u001b[A\n","Iteration:  46% 843/1851 [08:53<10:37,  1.58it/s]\u001b[A\n","Iteration:  46% 844/1851 [08:54<10:37,  1.58it/s]\u001b[A\n","Iteration:  46% 845/1851 [08:55<10:37,  1.58it/s]\u001b[A\n","Iteration:  46% 846/1851 [08:55<10:35,  1.58it/s]\u001b[A\n","Iteration:  46% 847/1851 [08:56<10:35,  1.58it/s]\u001b[A\n","Iteration:  46% 848/1851 [08:57<10:34,  1.58it/s]\u001b[A\n","Iteration:  46% 849/1851 [08:57<10:32,  1.58it/s]\u001b[A\n","Iteration:  46% 850/1851 [08:58<10:33,  1.58it/s]\u001b[A\n","Iteration:  46% 851/1851 [08:59<10:33,  1.58it/s]\u001b[A\n","Iteration:  46% 852/1851 [08:59<10:32,  1.58it/s]\u001b[A\n","Iteration:  46% 853/1851 [09:00<10:31,  1.58it/s]\u001b[A\n","Iteration:  46% 854/1851 [09:00<10:30,  1.58it/s]\u001b[A\n","Iteration:  46% 855/1851 [09:01<10:30,  1.58it/s]\u001b[A\n","Iteration:  46% 856/1851 [09:02<10:29,  1.58it/s]\u001b[A\n","Iteration:  46% 857/1851 [09:02<10:29,  1.58it/s]\u001b[A\n","Iteration:  46% 858/1851 [09:03<10:28,  1.58it/s]\u001b[A\n","Iteration:  46% 859/1851 [09:04<10:27,  1.58it/s]\u001b[A\n","Iteration:  46% 860/1851 [09:04<10:27,  1.58it/s]\u001b[A\n","Iteration:  47% 861/1851 [09:05<10:24,  1.58it/s]\u001b[A\n","Iteration:  47% 862/1851 [09:05<10:25,  1.58it/s]\u001b[A\n","Iteration:  47% 863/1851 [09:06<10:24,  1.58it/s]\u001b[A\n","Iteration:  47% 864/1851 [09:07<10:24,  1.58it/s]\u001b[A\n","Iteration:  47% 865/1851 [09:07<10:23,  1.58it/s]\u001b[A\n","Iteration:  47% 866/1851 [09:08<10:22,  1.58it/s]\u001b[A\n","Iteration:  47% 867/1851 [09:09<10:21,  1.58it/s]\u001b[A\n","Iteration:  47% 868/1851 [09:09<10:21,  1.58it/s]\u001b[A\n","Iteration:  47% 869/1851 [09:10<10:20,  1.58it/s]\u001b[A\n","Iteration:  47% 870/1851 [09:11<10:20,  1.58it/s]\u001b[A\n","Iteration:  47% 871/1851 [09:11<10:21,  1.58it/s]\u001b[A\n","Iteration:  47% 872/1851 [09:12<10:19,  1.58it/s]\u001b[A\n","Iteration:  47% 873/1851 [09:12<10:17,  1.58it/s]\u001b[A\n","Iteration:  47% 874/1851 [09:13<10:18,  1.58it/s]\u001b[A\n","Iteration:  47% 875/1851 [09:14<10:17,  1.58it/s]\u001b[A\n","Iteration:  47% 876/1851 [09:14<10:16,  1.58it/s]\u001b[A\n","Iteration:  47% 877/1851 [09:15<10:15,  1.58it/s]\u001b[A\n","Iteration:  47% 878/1851 [09:16<10:15,  1.58it/s]\u001b[A\n","Iteration:  47% 879/1851 [09:16<10:14,  1.58it/s]\u001b[A\n","Iteration:  48% 880/1851 [09:17<10:15,  1.58it/s]\u001b[A\n","Iteration:  48% 881/1851 [09:18<10:13,  1.58it/s]\u001b[A\n","Iteration:  48% 882/1851 [09:18<10:12,  1.58it/s]\u001b[A\n","Iteration:  48% 883/1851 [09:19<10:11,  1.58it/s]\u001b[A\n","Iteration:  48% 884/1851 [09:19<10:12,  1.58it/s]\u001b[A\n","Iteration:  48% 885/1851 [09:20<10:11,  1.58it/s]\u001b[A\n","Iteration:  48% 886/1851 [09:21<10:10,  1.58it/s]\u001b[A\n","Iteration:  48% 887/1851 [09:21<10:08,  1.58it/s]\u001b[A\n","Iteration:  48% 888/1851 [09:22<10:07,  1.59it/s]\u001b[A\n","Iteration:  48% 889/1851 [09:23<10:06,  1.59it/s]\u001b[A\n","Iteration:  48% 890/1851 [09:23<10:06,  1.58it/s]\u001b[A\n","Iteration:  48% 891/1851 [09:24<10:05,  1.59it/s]\u001b[A\n","Iteration:  48% 892/1851 [09:24<10:05,  1.58it/s]\u001b[A\n","Iteration:  48% 893/1851 [09:25<10:03,  1.59it/s]\u001b[A\n","Iteration:  48% 894/1851 [09:26<10:03,  1.59it/s]\u001b[A\n","Iteration:  48% 895/1851 [09:26<10:03,  1.58it/s]\u001b[A\n","Iteration:  48% 896/1851 [09:27<10:03,  1.58it/s]\u001b[A\n","Iteration:  48% 897/1851 [09:28<10:03,  1.58it/s]\u001b[A\n","Iteration:  49% 898/1851 [09:28<10:04,  1.58it/s]\u001b[A\n","Iteration:  49% 899/1851 [09:29<10:01,  1.58it/s]\u001b[A\n","Iteration:  49% 900/1851 [09:30<10:00,  1.58it/s]\u001b[A\n","Iteration:  49% 901/1851 [09:30<10:00,  1.58it/s]\u001b[A\n","Iteration:  49% 902/1851 [09:31<09:59,  1.58it/s]\u001b[A\n","Iteration:  49% 903/1851 [09:31<09:58,  1.58it/s]\u001b[A\n","Iteration:  49% 904/1851 [09:32<09:59,  1.58it/s]\u001b[A\n","Iteration:  49% 905/1851 [09:33<09:58,  1.58it/s]\u001b[A\n","Iteration:  49% 906/1851 [09:33<09:57,  1.58it/s]\u001b[A\n","Iteration:  49% 907/1851 [09:34<09:56,  1.58it/s]\u001b[A\n","Iteration:  49% 908/1851 [09:35<09:54,  1.59it/s]\u001b[A\n","Iteration:  49% 909/1851 [09:35<09:54,  1.58it/s]\u001b[A\n","Iteration:  49% 910/1851 [09:36<09:53,  1.59it/s]\u001b[A\n","Iteration:  49% 911/1851 [09:36<09:53,  1.58it/s]\u001b[A\n","Iteration:  49% 912/1851 [09:37<09:51,  1.59it/s]\u001b[A\n","Iteration:  49% 913/1851 [09:38<09:52,  1.58it/s]\u001b[A\n","Iteration:  49% 914/1851 [09:38<09:51,  1.58it/s]\u001b[A\n","Iteration:  49% 915/1851 [09:39<09:50,  1.59it/s]\u001b[A\n","Iteration:  49% 916/1851 [09:40<09:51,  1.58it/s]\u001b[A\n","Iteration:  50% 917/1851 [09:40<09:50,  1.58it/s]\u001b[A\n","Iteration:  50% 918/1851 [09:41<09:49,  1.58it/s]\u001b[A\n","Iteration:  50% 919/1851 [09:42<09:48,  1.58it/s]\u001b[A\n","Iteration:  50% 920/1851 [09:42<09:47,  1.58it/s]\u001b[A\n","Iteration:  50% 921/1851 [09:43<09:47,  1.58it/s]\u001b[A\n","Iteration:  50% 922/1851 [09:43<09:45,  1.59it/s]\u001b[A\n","Iteration:  50% 923/1851 [09:44<09:46,  1.58it/s]\u001b[A\n","Iteration:  50% 924/1851 [09:45<09:45,  1.58it/s]\u001b[A\n","Iteration:  50% 925/1851 [09:45<09:44,  1.58it/s]\u001b[A\n","Iteration:  50% 926/1851 [09:46<09:44,  1.58it/s]\u001b[A\n","Iteration:  50% 927/1851 [09:47<09:43,  1.58it/s]\u001b[A\n","Iteration:  50% 928/1851 [09:47<09:43,  1.58it/s]\u001b[A\n","Iteration:  50% 929/1851 [09:48<09:43,  1.58it/s]\u001b[A\n","Iteration:  50% 930/1851 [09:48<09:42,  1.58it/s]\u001b[A\n","Iteration:  50% 931/1851 [09:49<09:41,  1.58it/s]\u001b[A\n","Iteration:  50% 932/1851 [09:50<09:42,  1.58it/s]\u001b[A\n","Iteration:  50% 933/1851 [09:50<09:41,  1.58it/s]\u001b[A\n","Iteration:  50% 934/1851 [09:51<09:39,  1.58it/s]\u001b[A\n","Iteration:  51% 935/1851 [09:52<09:39,  1.58it/s]\u001b[A\n","Iteration:  51% 936/1851 [09:52<09:37,  1.58it/s]\u001b[A\n","Iteration:  51% 937/1851 [09:53<09:37,  1.58it/s]\u001b[A\n","Iteration:  51% 938/1851 [09:54<09:35,  1.59it/s]\u001b[A\n","Iteration:  51% 939/1851 [09:54<09:35,  1.58it/s]\u001b[A\n","Iteration:  51% 940/1851 [09:55<09:35,  1.58it/s]\u001b[A\n","Iteration:  51% 941/1851 [09:55<09:36,  1.58it/s]\u001b[A\n","Iteration:  51% 942/1851 [09:56<09:35,  1.58it/s]\u001b[A\n","Iteration:  51% 943/1851 [09:57<09:35,  1.58it/s]\u001b[A\n","Iteration:  51% 944/1851 [09:57<09:33,  1.58it/s]\u001b[A\n","Iteration:  51% 945/1851 [09:58<09:33,  1.58it/s]\u001b[A\n","Iteration:  51% 946/1851 [09:59<09:33,  1.58it/s]\u001b[A\n","Iteration:  51% 947/1851 [09:59<09:31,  1.58it/s]\u001b[A\n","Iteration:  51% 948/1851 [10:00<09:30,  1.58it/s]\u001b[A\n","Iteration:  51% 949/1851 [10:00<09:30,  1.58it/s]\u001b[A\n","Iteration:  51% 950/1851 [10:01<09:29,  1.58it/s]\u001b[A\n","Iteration:  51% 951/1851 [10:02<09:29,  1.58it/s]\u001b[A\n","Iteration:  51% 952/1851 [10:02<09:29,  1.58it/s]\u001b[A\n","Iteration:  51% 953/1851 [10:03<09:28,  1.58it/s]\u001b[A\n","Iteration:  52% 954/1851 [10:04<09:27,  1.58it/s]\u001b[A\n","Iteration:  52% 955/1851 [10:04<09:26,  1.58it/s]\u001b[A\n","Iteration:  52% 956/1851 [10:05<09:25,  1.58it/s]\u001b[A\n","Iteration:  52% 957/1851 [10:06<09:25,  1.58it/s]\u001b[A\n","Iteration:  52% 958/1851 [10:06<09:26,  1.58it/s]\u001b[A\n","Iteration:  52% 959/1851 [10:07<09:24,  1.58it/s]\u001b[A\n","Iteration:  52% 960/1851 [10:07<09:24,  1.58it/s]\u001b[A\n","Iteration:  52% 961/1851 [10:08<09:24,  1.58it/s]\u001b[A\n","Iteration:  52% 962/1851 [10:09<09:23,  1.58it/s]\u001b[A\n","Iteration:  52% 963/1851 [10:09<09:21,  1.58it/s]\u001b[A\n","Iteration:  52% 964/1851 [10:10<09:21,  1.58it/s]\u001b[A\n","Iteration:  52% 965/1851 [10:11<09:19,  1.58it/s]\u001b[A\n","Iteration:  52% 966/1851 [10:11<09:19,  1.58it/s]\u001b[A\n","Iteration:  52% 967/1851 [10:12<09:18,  1.58it/s]\u001b[A\n","Iteration:  52% 968/1851 [10:12<09:18,  1.58it/s]\u001b[A\n","Iteration:  52% 969/1851 [10:13<09:18,  1.58it/s]\u001b[A\n","Iteration:  52% 970/1851 [10:14<09:16,  1.58it/s]\u001b[A\n","Iteration:  52% 971/1851 [10:14<09:16,  1.58it/s]\u001b[A\n","Iteration:  53% 972/1851 [10:15<09:16,  1.58it/s]\u001b[A\n","Iteration:  53% 973/1851 [10:16<09:14,  1.58it/s]\u001b[A\n","Iteration:  53% 974/1851 [10:16<09:13,  1.58it/s]\u001b[A\n","Iteration:  53% 975/1851 [10:17<09:12,  1.59it/s]\u001b[A\n","Iteration:  53% 976/1851 [10:18<09:11,  1.59it/s]\u001b[A\n","Iteration:  53% 977/1851 [10:18<09:12,  1.58it/s]\u001b[A\n","Iteration:  53% 978/1851 [10:19<09:11,  1.58it/s]\u001b[A\n","Iteration:  53% 979/1851 [10:19<09:10,  1.58it/s]\u001b[A\n","Iteration:  53% 980/1851 [10:20<09:10,  1.58it/s]\u001b[A\n","Iteration:  53% 981/1851 [10:21<09:09,  1.58it/s]\u001b[A\n","Iteration:  53% 982/1851 [10:21<09:09,  1.58it/s]\u001b[A\n","Iteration:  53% 983/1851 [10:22<09:09,  1.58it/s]\u001b[A\n","Iteration:  53% 984/1851 [10:23<09:08,  1.58it/s]\u001b[A\n","Iteration:  53% 985/1851 [10:23<09:06,  1.58it/s]\u001b[A\n","Iteration:  53% 986/1851 [10:24<09:06,  1.58it/s]\u001b[A\n","Iteration:  53% 987/1851 [10:25<09:06,  1.58it/s]\u001b[A\n","Iteration:  53% 988/1851 [10:25<09:06,  1.58it/s]\u001b[A\n","Iteration:  53% 989/1851 [10:26<09:04,  1.58it/s]\u001b[A\n","Iteration:  53% 990/1851 [10:26<09:04,  1.58it/s]\u001b[A\n","Iteration:  54% 991/1851 [10:27<09:02,  1.59it/s]\u001b[A\n","Iteration:  54% 992/1851 [10:28<09:02,  1.58it/s]\u001b[A\n","Iteration:  54% 993/1851 [10:28<09:02,  1.58it/s]\u001b[A\n","Iteration:  54% 994/1851 [10:29<09:01,  1.58it/s]\u001b[A\n","Iteration:  54% 995/1851 [10:30<09:01,  1.58it/s]\u001b[A\n","Iteration:  54% 996/1851 [10:30<09:00,  1.58it/s]\u001b[A\n","Iteration:  54% 997/1851 [10:31<08:59,  1.58it/s]\u001b[A\n","Iteration:  54% 998/1851 [10:31<08:59,  1.58it/s]\u001b[A\n","Iteration:  54% 999/1851 [10:32<08:59,  1.58it/s]\u001b[A\n","Iteration:  54% 1000/1851 [10:33<08:58,  1.58it/s]\u001b[A\n","Iteration:  54% 1001/1851 [10:33<08:59,  1.58it/s]\u001b[A\n","Iteration:  54% 1002/1851 [10:34<08:57,  1.58it/s]\u001b[A\n","Iteration:  54% 1003/1851 [10:35<08:58,  1.57it/s]\u001b[A\n","Iteration:  54% 1004/1851 [10:35<08:56,  1.58it/s]\u001b[A\n","Iteration:  54% 1005/1851 [10:36<08:55,  1.58it/s]\u001b[A\n","Iteration:  54% 1006/1851 [10:37<08:55,  1.58it/s]\u001b[A\n","Iteration:  54% 1007/1851 [10:37<08:53,  1.58it/s]\u001b[A\n","Iteration:  54% 1008/1851 [10:38<08:54,  1.58it/s]\u001b[A\n","Iteration:  55% 1009/1851 [10:38<08:53,  1.58it/s]\u001b[A\n","Iteration:  55% 1010/1851 [10:39<08:52,  1.58it/s]\u001b[A\n","Iteration:  55% 1011/1851 [10:40<08:51,  1.58it/s]\u001b[A\n","Iteration:  55% 1012/1851 [10:40<08:51,  1.58it/s]\u001b[A\n","Iteration:  55% 1013/1851 [10:41<08:49,  1.58it/s]\u001b[A\n","Iteration:  55% 1014/1851 [10:42<08:49,  1.58it/s]\u001b[A\n","Iteration:  55% 1015/1851 [10:42<08:47,  1.58it/s]\u001b[A\n","Iteration:  55% 1016/1851 [10:43<08:46,  1.59it/s]\u001b[A\n","Iteration:  55% 1017/1851 [10:43<08:46,  1.58it/s]\u001b[A\n","Iteration:  55% 1018/1851 [10:44<08:46,  1.58it/s]\u001b[A\n","Iteration:  55% 1019/1851 [10:45<08:45,  1.58it/s]\u001b[A\n","Iteration:  55% 1020/1851 [10:45<08:45,  1.58it/s]\u001b[A\n","Iteration:  55% 1021/1851 [10:46<08:44,  1.58it/s]\u001b[A\n","Iteration:  55% 1022/1851 [10:47<08:44,  1.58it/s]\u001b[A\n","Iteration:  55% 1023/1851 [10:47<08:43,  1.58it/s]\u001b[A\n","Iteration:  55% 1024/1851 [10:48<08:42,  1.58it/s]\u001b[A\n","Iteration:  55% 1025/1851 [10:49<08:42,  1.58it/s]\u001b[A\n","Iteration:  55% 1026/1851 [10:49<08:42,  1.58it/s]\u001b[A\n","Iteration:  55% 1027/1851 [10:50<08:40,  1.58it/s]\u001b[A\n","Iteration:  56% 1028/1851 [10:50<08:40,  1.58it/s]\u001b[A\n","Iteration:  56% 1029/1851 [10:51<08:38,  1.58it/s]\u001b[A\n","Iteration:  56% 1030/1851 [10:52<08:39,  1.58it/s]\u001b[A\n","Iteration:  56% 1031/1851 [10:52<08:38,  1.58it/s]\u001b[A\n","Iteration:  56% 1032/1851 [10:53<08:38,  1.58it/s]\u001b[A\n","Iteration:  56% 1033/1851 [10:54<08:38,  1.58it/s]\u001b[A\n","Iteration:  56% 1034/1851 [10:54<08:36,  1.58it/s]\u001b[A\n","Iteration:  56% 1035/1851 [10:55<08:36,  1.58it/s]\u001b[A\n","Iteration:  56% 1036/1851 [10:55<08:34,  1.58it/s]\u001b[A\n","Iteration:  56% 1037/1851 [10:56<08:33,  1.58it/s]\u001b[A\n","Iteration:  56% 1038/1851 [10:57<08:33,  1.58it/s]\u001b[A\n","Iteration:  56% 1039/1851 [10:57<08:32,  1.58it/s]\u001b[A\n","Iteration:  56% 1040/1851 [10:58<08:33,  1.58it/s]\u001b[A\n","Iteration:  56% 1041/1851 [10:59<08:32,  1.58it/s]\u001b[A\n","Iteration:  56% 1042/1851 [10:59<08:31,  1.58it/s]\u001b[A\n","Iteration:  56% 1043/1851 [11:00<08:31,  1.58it/s]\u001b[A\n","Iteration:  56% 1044/1851 [11:01<08:30,  1.58it/s]\u001b[A\n","Iteration:  56% 1045/1851 [11:01<08:29,  1.58it/s]\u001b[A\n","Iteration:  57% 1046/1851 [11:02<08:30,  1.58it/s]\u001b[A\n","Iteration:  57% 1047/1851 [11:02<08:29,  1.58it/s]\u001b[A\n","Iteration:  57% 1048/1851 [11:03<08:29,  1.58it/s]\u001b[A\n","Iteration:  57% 1049/1851 [11:04<08:28,  1.58it/s]\u001b[A\n","Iteration:  57% 1050/1851 [11:04<08:27,  1.58it/s]\u001b[A\n","Iteration:  57% 1051/1851 [11:05<08:26,  1.58it/s]\u001b[A\n","Iteration:  57% 1052/1851 [11:06<08:24,  1.58it/s]\u001b[A\n","Iteration:  57% 1053/1851 [11:06<08:25,  1.58it/s]\u001b[A\n","Iteration:  57% 1054/1851 [11:07<08:24,  1.58it/s]\u001b[A\n","Iteration:  57% 1055/1851 [11:08<08:24,  1.58it/s]\u001b[A\n","Iteration:  57% 1056/1851 [11:08<08:23,  1.58it/s]\u001b[A\n","Iteration:  57% 1057/1851 [11:09<08:23,  1.58it/s]\u001b[A\n","Iteration:  57% 1058/1851 [11:09<08:23,  1.58it/s]\u001b[A\n","Iteration:  57% 1059/1851 [11:10<08:22,  1.58it/s]\u001b[A\n","Iteration:  57% 1060/1851 [11:11<08:21,  1.58it/s]\u001b[A\n","Iteration:  57% 1061/1851 [11:11<08:20,  1.58it/s]\u001b[A\n","Iteration:  57% 1062/1851 [11:12<08:19,  1.58it/s]\u001b[A\n","Iteration:  57% 1063/1851 [11:13<08:18,  1.58it/s]\u001b[A\n","Iteration:  57% 1064/1851 [11:13<08:17,  1.58it/s]\u001b[A\n","Iteration:  58% 1065/1851 [11:14<08:17,  1.58it/s]\u001b[A\n","Iteration:  58% 1066/1851 [11:14<08:17,  1.58it/s]\u001b[A\n","Iteration:  58% 1067/1851 [11:15<08:16,  1.58it/s]\u001b[A\n","Iteration:  58% 1068/1851 [11:16<08:15,  1.58it/s]\u001b[A\n","Iteration:  58% 1069/1851 [11:16<08:15,  1.58it/s]\u001b[A\n","Iteration:  58% 1070/1851 [11:17<08:14,  1.58it/s]\u001b[A\n","Iteration:  58% 1071/1851 [11:18<08:14,  1.58it/s]\u001b[A\n","Iteration:  58% 1072/1851 [11:18<08:13,  1.58it/s]\u001b[A\n","Iteration:  58% 1073/1851 [11:19<08:12,  1.58it/s]\u001b[A\n","Iteration:  58% 1074/1851 [11:20<08:11,  1.58it/s]\u001b[A\n","Iteration:  58% 1075/1851 [11:20<08:11,  1.58it/s]\u001b[A\n","Iteration:  58% 1076/1851 [11:21<08:10,  1.58it/s]\u001b[A\n","Iteration:  58% 1077/1851 [11:21<08:10,  1.58it/s]\u001b[A\n","Iteration:  58% 1078/1851 [11:22<08:08,  1.58it/s]\u001b[A\n","Iteration:  58% 1079/1851 [11:23<08:09,  1.58it/s]\u001b[A\n","Iteration:  58% 1080/1851 [11:23<08:07,  1.58it/s]\u001b[A\n","Iteration:  58% 1081/1851 [11:24<08:06,  1.58it/s]\u001b[A\n","Iteration:  58% 1082/1851 [11:25<08:05,  1.58it/s]\u001b[A\n","Iteration:  59% 1083/1851 [11:25<08:05,  1.58it/s]\u001b[A\n","Iteration:  59% 1084/1851 [11:26<08:03,  1.58it/s]\u001b[A\n","Iteration:  59% 1085/1851 [11:27<08:04,  1.58it/s]\u001b[A\n","Iteration:  59% 1086/1851 [11:27<08:04,  1.58it/s]\u001b[A\n","Iteration:  59% 1087/1851 [11:28<08:03,  1.58it/s]\u001b[A\n","Iteration:  59% 1088/1851 [11:28<08:02,  1.58it/s]\u001b[A\n","Iteration:  59% 1089/1851 [11:29<08:02,  1.58it/s]\u001b[A\n","Iteration:  59% 1090/1851 [11:30<08:02,  1.58it/s]\u001b[A\n","Iteration:  59% 1091/1851 [11:30<08:01,  1.58it/s]\u001b[A\n","Iteration:  59% 1092/1851 [11:31<08:00,  1.58it/s]\u001b[A\n","Iteration:  59% 1093/1851 [11:32<07:58,  1.58it/s]\u001b[A\n","Iteration:  59% 1094/1851 [11:32<07:57,  1.58it/s]\u001b[A\n","Iteration:  59% 1095/1851 [11:33<07:57,  1.58it/s]\u001b[A\n","Iteration:  59% 1096/1851 [11:33<07:56,  1.58it/s]\u001b[A\n","Iteration:  59% 1097/1851 [11:34<07:56,  1.58it/s]\u001b[A\n","Iteration:  59% 1098/1851 [11:35<07:55,  1.58it/s]\u001b[A\n","Iteration:  59% 1099/1851 [11:35<07:55,  1.58it/s]\u001b[A\n","Iteration:  59% 1100/1851 [11:36<07:55,  1.58it/s]\u001b[A\n","Iteration:  59% 1101/1851 [11:37<07:54,  1.58it/s]\u001b[A\n","Iteration:  60% 1102/1851 [11:37<07:53,  1.58it/s]\u001b[A\n","Iteration:  60% 1103/1851 [11:38<07:52,  1.58it/s]\u001b[A\n","Iteration:  60% 1104/1851 [11:39<07:51,  1.59it/s]\u001b[A\n","Iteration:  60% 1105/1851 [11:39<07:50,  1.58it/s]\u001b[A\n","Iteration:  60% 1106/1851 [11:40<07:49,  1.59it/s]\u001b[A\n","Iteration:  60% 1107/1851 [11:40<07:49,  1.58it/s]\u001b[A\n","Iteration:  60% 1108/1851 [11:41<07:48,  1.59it/s]\u001b[A\n","Iteration:  60% 1109/1851 [11:42<07:47,  1.59it/s]\u001b[A\n","Iteration:  60% 1110/1851 [11:42<07:47,  1.58it/s]\u001b[A\n","Iteration:  60% 1111/1851 [11:43<07:47,  1.58it/s]\u001b[A\n","Iteration:  60% 1112/1851 [11:44<07:46,  1.58it/s]\u001b[A\n","Iteration:  60% 1113/1851 [11:44<07:45,  1.58it/s]\u001b[A\n","Iteration:  60% 1114/1851 [11:45<07:45,  1.58it/s]\u001b[A\n","Iteration:  60% 1115/1851 [11:45<07:44,  1.58it/s]\u001b[A\n","Iteration:  60% 1116/1851 [11:46<07:44,  1.58it/s]\u001b[A\n","Iteration:  60% 1117/1851 [11:47<07:44,  1.58it/s]\u001b[A\n","Iteration:  60% 1118/1851 [11:47<07:43,  1.58it/s]\u001b[A\n","Iteration:  60% 1119/1851 [11:48<07:43,  1.58it/s]\u001b[A\n","Iteration:  61% 1120/1851 [11:49<07:42,  1.58it/s]\u001b[A\n","Iteration:  61% 1121/1851 [11:49<07:41,  1.58it/s]\u001b[A\n","Iteration:  61% 1122/1851 [11:50<07:40,  1.58it/s]\u001b[A\n","Iteration:  61% 1123/1851 [11:51<07:39,  1.58it/s]\u001b[A\n","Iteration:  61% 1124/1851 [11:51<07:41,  1.58it/s]\u001b[A\n","Iteration:  61% 1125/1851 [11:52<07:40,  1.58it/s]\u001b[A\n","Iteration:  61% 1126/1851 [11:52<07:38,  1.58it/s]\u001b[A\n","Iteration:  61% 1127/1851 [11:53<07:38,  1.58it/s]\u001b[A\n","Iteration:  61% 1128/1851 [11:54<07:37,  1.58it/s]\u001b[A\n","Iteration:  61% 1129/1851 [11:54<07:36,  1.58it/s]\u001b[A\n","Iteration:  61% 1130/1851 [11:55<07:35,  1.58it/s]\u001b[A\n","Iteration:  61% 1131/1851 [11:56<07:35,  1.58it/s]\u001b[A\n","Iteration:  61% 1132/1851 [11:56<07:36,  1.58it/s]\u001b[A\n","Iteration:  61% 1133/1851 [11:57<07:35,  1.58it/s]\u001b[A\n","Iteration:  61% 1134/1851 [11:57<07:34,  1.58it/s]\u001b[A\n","Iteration:  61% 1135/1851 [11:58<07:34,  1.58it/s]\u001b[A\n","Iteration:  61% 1136/1851 [11:59<07:32,  1.58it/s]\u001b[A\n","Iteration:  61% 1137/1851 [11:59<07:32,  1.58it/s]\u001b[A\n","Iteration:  61% 1138/1851 [12:00<07:31,  1.58it/s]\u001b[A\n","Iteration:  62% 1139/1851 [12:01<07:31,  1.58it/s]\u001b[A\n","Iteration:  62% 1140/1851 [12:01<07:30,  1.58it/s]\u001b[A\n","Iteration:  62% 1141/1851 [12:02<07:30,  1.58it/s]\u001b[A\n","Iteration:  62% 1142/1851 [12:03<07:30,  1.57it/s]\u001b[A\n","Iteration:  62% 1143/1851 [12:03<07:28,  1.58it/s]\u001b[A\n","Iteration:  62% 1144/1851 [12:04<07:30,  1.57it/s]\u001b[A\n","Iteration:  62% 1145/1851 [12:04<07:29,  1.57it/s]\u001b[A\n","Iteration:  62% 1146/1851 [12:05<07:27,  1.58it/s]\u001b[A\n","Iteration:  62% 1147/1851 [12:06<07:26,  1.58it/s]\u001b[A\n","Iteration:  62% 1148/1851 [12:06<07:25,  1.58it/s]\u001b[A\n","Iteration:  62% 1149/1851 [12:07<07:24,  1.58it/s]\u001b[A\n","Iteration:  62% 1150/1851 [12:08<07:23,  1.58it/s]\u001b[A\n","Iteration:  62% 1151/1851 [12:08<07:22,  1.58it/s]\u001b[A\n","Iteration:  62% 1152/1851 [12:09<07:21,  1.58it/s]\u001b[A\n","Iteration:  62% 1153/1851 [12:10<07:21,  1.58it/s]\u001b[A\n","Iteration:  62% 1154/1851 [12:10<07:20,  1.58it/s]\u001b[A\n","Iteration:  62% 1155/1851 [12:11<07:19,  1.58it/s]\u001b[A\n","Iteration:  62% 1156/1851 [12:11<07:18,  1.58it/s]\u001b[A\n","Iteration:  63% 1157/1851 [12:12<07:18,  1.58it/s]\u001b[A\n","Iteration:  63% 1158/1851 [12:13<07:17,  1.58it/s]\u001b[A\n","Iteration:  63% 1159/1851 [12:13<07:17,  1.58it/s]\u001b[A\n","Iteration:  63% 1160/1851 [12:14<07:16,  1.58it/s]\u001b[A\n","Iteration:  63% 1161/1851 [12:15<07:16,  1.58it/s]\u001b[A\n","Iteration:  63% 1162/1851 [12:15<07:16,  1.58it/s]\u001b[A\n","Iteration:  63% 1163/1851 [12:16<07:16,  1.58it/s]\u001b[A\n","Iteration:  63% 1164/1851 [12:16<07:15,  1.58it/s]\u001b[A\n","Iteration:  63% 1165/1851 [12:17<07:14,  1.58it/s]\u001b[A\n","Iteration:  63% 1166/1851 [12:18<07:12,  1.58it/s]\u001b[A\n","Iteration:  63% 1167/1851 [12:18<07:12,  1.58it/s]\u001b[A\n","Iteration:  63% 1168/1851 [12:19<07:13,  1.58it/s]\u001b[A\n","Iteration:  63% 1169/1851 [12:20<07:12,  1.58it/s]\u001b[A\n","Iteration:  63% 1170/1851 [12:20<07:11,  1.58it/s]\u001b[A\n","Iteration:  63% 1171/1851 [12:21<07:10,  1.58it/s]\u001b[A\n","Iteration:  63% 1172/1851 [12:22<07:09,  1.58it/s]\u001b[A\n","Iteration:  63% 1173/1851 [12:22<07:09,  1.58it/s]\u001b[A\n","Iteration:  63% 1174/1851 [12:23<07:08,  1.58it/s]\u001b[A\n","Iteration:  63% 1175/1851 [12:23<07:09,  1.58it/s]\u001b[A\n","Iteration:  64% 1176/1851 [12:24<07:07,  1.58it/s]\u001b[A\n","Iteration:  64% 1177/1851 [12:25<07:06,  1.58it/s]\u001b[A\n","Iteration:  64% 1178/1851 [12:25<07:06,  1.58it/s]\u001b[A\n","Iteration:  64% 1179/1851 [12:26<07:04,  1.58it/s]\u001b[A\n","Iteration:  64% 1180/1851 [12:27<07:04,  1.58it/s]\u001b[A\n","Iteration:  64% 1181/1851 [12:27<07:04,  1.58it/s]\u001b[A\n","Iteration:  64% 1182/1851 [12:28<07:03,  1.58it/s]\u001b[A\n","Iteration:  64% 1183/1851 [12:29<07:02,  1.58it/s]\u001b[A\n","Iteration:  64% 1184/1851 [12:29<07:04,  1.57it/s]\u001b[A\n","Iteration:  64% 1185/1851 [12:30<07:02,  1.58it/s]\u001b[A\n","Iteration:  64% 1186/1851 [12:30<07:01,  1.58it/s]\u001b[A\n","Iteration:  64% 1187/1851 [12:31<07:01,  1.58it/s]\u001b[A\n","Iteration:  64% 1188/1851 [12:32<07:00,  1.58it/s]\u001b[A\n","Iteration:  64% 1189/1851 [12:32<06:59,  1.58it/s]\u001b[A\n","Iteration:  64% 1190/1851 [12:33<06:58,  1.58it/s]\u001b[A\n","Iteration:  64% 1191/1851 [12:34<06:57,  1.58it/s]\u001b[A\n","Iteration:  64% 1192/1851 [12:34<06:56,  1.58it/s]\u001b[A\n","Iteration:  64% 1193/1851 [12:35<06:55,  1.58it/s]\u001b[A\n","Iteration:  65% 1194/1851 [12:35<06:54,  1.58it/s]\u001b[A\n","Iteration:  65% 1195/1851 [12:36<06:55,  1.58it/s]\u001b[A\n","Iteration:  65% 1196/1851 [12:37<06:54,  1.58it/s]\u001b[A\n","Iteration:  65% 1197/1851 [12:37<06:53,  1.58it/s]\u001b[A\n","Iteration:  65% 1198/1851 [12:38<06:53,  1.58it/s]\u001b[A\n","Iteration:  65% 1199/1851 [12:39<06:51,  1.58it/s]\u001b[A\n","Iteration:  65% 1200/1851 [12:39<06:51,  1.58it/s]\u001b[A\n","Iteration:  65% 1201/1851 [12:40<06:51,  1.58it/s]\u001b[A\n","Iteration:  65% 1202/1851 [12:41<06:50,  1.58it/s]\u001b[A\n","Iteration:  65% 1203/1851 [12:41<06:50,  1.58it/s]\u001b[A\n","Iteration:  65% 1204/1851 [12:42<06:49,  1.58it/s]\u001b[A\n","Iteration:  65% 1205/1851 [12:42<06:49,  1.58it/s]\u001b[A\n","Iteration:  65% 1206/1851 [12:43<06:48,  1.58it/s]\u001b[A\n","Iteration:  65% 1207/1851 [12:44<06:47,  1.58it/s]\u001b[A\n","Iteration:  65% 1208/1851 [12:44<06:46,  1.58it/s]\u001b[A\n","Iteration:  65% 1209/1851 [12:45<06:46,  1.58it/s]\u001b[A\n","Iteration:  65% 1210/1851 [12:46<06:44,  1.58it/s]\u001b[A\n","Iteration:  65% 1211/1851 [12:46<06:44,  1.58it/s]\u001b[A\n","Iteration:  65% 1212/1851 [12:47<06:44,  1.58it/s]\u001b[A\n","Iteration:  66% 1213/1851 [12:48<06:43,  1.58it/s]\u001b[A\n","Iteration:  66% 1214/1851 [12:48<06:43,  1.58it/s]\u001b[A\n","Iteration:  66% 1215/1851 [12:49<06:42,  1.58it/s]\u001b[A\n","Iteration:  66% 1216/1851 [12:49<06:41,  1.58it/s]\u001b[A\n","Iteration:  66% 1217/1851 [12:50<06:42,  1.58it/s]\u001b[A\n","Iteration:  66% 1218/1851 [12:51<06:41,  1.58it/s]\u001b[A\n","Iteration:  66% 1219/1851 [12:51<06:40,  1.58it/s]\u001b[A\n","Iteration:  66% 1220/1851 [12:52<06:40,  1.57it/s]\u001b[A\n","Iteration:  66% 1221/1851 [12:53<06:40,  1.57it/s]\u001b[A\n","Iteration:  66% 1222/1851 [12:53<06:39,  1.57it/s]\u001b[A\n","Iteration:  66% 1223/1851 [12:54<06:38,  1.58it/s]\u001b[A\n","Iteration:  66% 1224/1851 [12:54<06:37,  1.58it/s]\u001b[A\n","Iteration:  66% 1225/1851 [12:55<06:36,  1.58it/s]\u001b[A\n","Iteration:  66% 1226/1851 [12:56<06:35,  1.58it/s]\u001b[A\n","Iteration:  66% 1227/1851 [12:56<06:35,  1.58it/s]\u001b[A\n","Iteration:  66% 1228/1851 [12:57<06:34,  1.58it/s]\u001b[A\n","Iteration:  66% 1229/1851 [12:58<06:32,  1.59it/s]\u001b[A\n","Iteration:  66% 1230/1851 [12:58<06:33,  1.58it/s]\u001b[A\n","Iteration:  67% 1231/1851 [12:59<06:32,  1.58it/s]\u001b[A\n","Iteration:  67% 1232/1851 [13:00<06:31,  1.58it/s]\u001b[A\n","Iteration:  67% 1233/1851 [13:00<06:30,  1.58it/s]\u001b[A\n","Iteration:  67% 1234/1851 [13:01<06:30,  1.58it/s]\u001b[A\n","Iteration:  67% 1235/1851 [13:01<06:29,  1.58it/s]\u001b[A\n","Iteration:  67% 1236/1851 [13:02<06:29,  1.58it/s]\u001b[A\n","Iteration:  67% 1237/1851 [13:03<06:29,  1.58it/s]\u001b[A\n","Iteration:  67% 1238/1851 [13:03<06:28,  1.58it/s]\u001b[A\n","Iteration:  67% 1239/1851 [13:04<06:28,  1.58it/s]\u001b[A\n","Iteration:  67% 1240/1851 [13:05<06:27,  1.58it/s]\u001b[A\n","Iteration:  67% 1241/1851 [13:05<06:26,  1.58it/s]\u001b[A\n","Iteration:  67% 1242/1851 [13:06<06:25,  1.58it/s]\u001b[A\n","Iteration:  67% 1243/1851 [13:07<06:25,  1.58it/s]\u001b[A\n","Iteration:  67% 1244/1851 [13:07<06:25,  1.57it/s]\u001b[A\n","Iteration:  67% 1245/1851 [13:08<06:24,  1.58it/s]\u001b[A\n","Iteration:  67% 1246/1851 [13:08<06:23,  1.58it/s]\u001b[A\n","Iteration:  67% 1247/1851 [13:09<06:23,  1.58it/s]\u001b[A\n","Iteration:  67% 1248/1851 [13:10<06:21,  1.58it/s]\u001b[A\n","Iteration:  67% 1249/1851 [13:10<06:21,  1.58it/s]\u001b[A\n","Iteration:  68% 1250/1851 [13:11<06:21,  1.58it/s]\u001b[A\n","Iteration:  68% 1251/1851 [13:12<06:20,  1.58it/s]\u001b[A\n","Iteration:  68% 1252/1851 [13:12<06:20,  1.58it/s]\u001b[A\n","Iteration:  68% 1253/1851 [13:13<06:18,  1.58it/s]\u001b[A\n","Iteration:  68% 1254/1851 [13:13<06:17,  1.58it/s]\u001b[A\n","Iteration:  68% 1255/1851 [13:14<06:17,  1.58it/s]\u001b[A\n","Iteration:  68% 1256/1851 [13:15<06:16,  1.58it/s]\u001b[A\n","Iteration:  68% 1257/1851 [13:15<06:16,  1.58it/s]\u001b[A\n","Iteration:  68% 1258/1851 [13:16<06:15,  1.58it/s]\u001b[A\n","Iteration:  68% 1259/1851 [13:17<06:15,  1.58it/s]\u001b[A\n","Iteration:  68% 1260/1851 [13:17<06:14,  1.58it/s]\u001b[A\n","Iteration:  68% 1261/1851 [13:18<06:13,  1.58it/s]\u001b[A\n","Iteration:  68% 1262/1851 [13:19<06:12,  1.58it/s]\u001b[A\n","Iteration:  68% 1263/1851 [13:19<06:13,  1.58it/s]\u001b[A\n","Iteration:  68% 1264/1851 [13:20<06:11,  1.58it/s]\u001b[A\n","Iteration:  68% 1265/1851 [13:20<06:11,  1.58it/s]\u001b[A\n","Iteration:  68% 1266/1851 [13:21<06:10,  1.58it/s]\u001b[A\n","Iteration:  68% 1267/1851 [13:22<06:09,  1.58it/s]\u001b[A\n","Iteration:  69% 1268/1851 [13:22<06:08,  1.58it/s]\u001b[A\n","Iteration:  69% 1269/1851 [13:23<06:07,  1.58it/s]\u001b[A\n","Iteration:  69% 1270/1851 [13:24<06:07,  1.58it/s]\u001b[A\n","Iteration:  69% 1271/1851 [13:24<06:07,  1.58it/s]\u001b[A\n","Iteration:  69% 1272/1851 [13:25<06:06,  1.58it/s]\u001b[A\n","Iteration:  69% 1273/1851 [13:26<06:06,  1.58it/s]\u001b[A\n","Iteration:  69% 1274/1851 [13:26<06:05,  1.58it/s]\u001b[A\n","Iteration:  69% 1275/1851 [13:27<06:04,  1.58it/s]\u001b[A\n","Iteration:  69% 1276/1851 [13:27<06:04,  1.58it/s]\u001b[A\n","Iteration:  69% 1277/1851 [13:28<06:03,  1.58it/s]\u001b[A\n","Iteration:  69% 1278/1851 [13:29<06:02,  1.58it/s]\u001b[A\n","Iteration:  69% 1279/1851 [13:29<06:02,  1.58it/s]\u001b[A\n","Iteration:  69% 1280/1851 [13:30<06:02,  1.58it/s]\u001b[A\n","Iteration:  69% 1281/1851 [13:31<06:01,  1.57it/s]\u001b[A\n","Iteration:  69% 1282/1851 [13:31<06:01,  1.57it/s]\u001b[A\n","Iteration:  69% 1283/1851 [13:32<06:00,  1.58it/s]\u001b[A\n","Iteration:  69% 1284/1851 [13:33<05:59,  1.58it/s]\u001b[A\n","Iteration:  69% 1285/1851 [13:33<05:58,  1.58it/s]\u001b[A\n","Iteration:  69% 1286/1851 [13:34<05:58,  1.58it/s]\u001b[A\n","Iteration:  70% 1287/1851 [13:34<05:57,  1.58it/s]\u001b[A\n","Iteration:  70% 1288/1851 [13:35<05:56,  1.58it/s]\u001b[A\n","Iteration:  70% 1289/1851 [13:36<05:55,  1.58it/s]\u001b[A\n","Iteration:  70% 1290/1851 [13:36<05:56,  1.58it/s]\u001b[A\n","Iteration:  70% 1291/1851 [13:37<05:54,  1.58it/s]\u001b[A\n","Iteration:  70% 1292/1851 [13:38<05:53,  1.58it/s]\u001b[A\n","Iteration:  70% 1293/1851 [13:38<05:53,  1.58it/s]\u001b[A\n","Iteration:  70% 1294/1851 [13:39<05:52,  1.58it/s]\u001b[A\n","Iteration:  70% 1295/1851 [13:39<05:51,  1.58it/s]\u001b[A\n","Iteration:  70% 1296/1851 [13:40<05:50,  1.58it/s]\u001b[A\n","Iteration:  70% 1297/1851 [13:41<05:50,  1.58it/s]\u001b[A\n","Iteration:  70% 1298/1851 [13:41<05:51,  1.58it/s]\u001b[A\n","Iteration:  70% 1299/1851 [13:42<05:49,  1.58it/s]\u001b[A\n","Iteration:  70% 1300/1851 [13:43<05:49,  1.57it/s]\u001b[A\n","Iteration:  70% 1301/1851 [13:43<05:48,  1.58it/s]\u001b[A\n","Iteration:  70% 1302/1851 [13:44<05:47,  1.58it/s]\u001b[A\n","Iteration:  70% 1303/1851 [13:45<05:47,  1.58it/s]\u001b[A\n","Iteration:  70% 1304/1851 [13:45<05:46,  1.58it/s]\u001b[A\n","Iteration:  71% 1305/1851 [13:46<05:46,  1.58it/s]\u001b[A\n","Iteration:  71% 1306/1851 [13:46<05:45,  1.58it/s]\u001b[A\n","Iteration:  71% 1307/1851 [13:47<05:45,  1.58it/s]\u001b[A\n","Iteration:  71% 1308/1851 [13:48<05:44,  1.58it/s]\u001b[A\n","Iteration:  71% 1309/1851 [13:48<05:43,  1.58it/s]\u001b[A\n","Iteration:  71% 1310/1851 [13:49<05:42,  1.58it/s]\u001b[A\n","Iteration:  71% 1311/1851 [13:50<05:41,  1.58it/s]\u001b[A\n","Iteration:  71% 1312/1851 [13:50<05:41,  1.58it/s]\u001b[A\n","Iteration:  71% 1313/1851 [13:51<05:40,  1.58it/s]\u001b[A\n","Iteration:  71% 1314/1851 [13:51<05:38,  1.58it/s]\u001b[A\n","Iteration:  71% 1315/1851 [13:52<05:38,  1.58it/s]\u001b[A\n","Iteration:  71% 1316/1851 [13:53<05:37,  1.58it/s]\u001b[A\n","Iteration:  71% 1317/1851 [13:53<05:37,  1.58it/s]\u001b[A\n","Iteration:  71% 1318/1851 [13:54<05:37,  1.58it/s]\u001b[A\n","Iteration:  71% 1319/1851 [13:55<05:36,  1.58it/s]\u001b[A\n","Iteration:  71% 1320/1851 [13:55<05:35,  1.58it/s]\u001b[A\n","Iteration:  71% 1321/1851 [13:56<05:35,  1.58it/s]\u001b[A\n","Iteration:  71% 1322/1851 [13:57<05:35,  1.58it/s]\u001b[A\n","Iteration:  71% 1323/1851 [13:57<05:34,  1.58it/s]\u001b[A\n","Iteration:  72% 1324/1851 [13:58<05:34,  1.58it/s]\u001b[A\n","Iteration:  72% 1325/1851 [13:58<05:33,  1.58it/s]\u001b[A\n","Iteration:  72% 1326/1851 [13:59<05:32,  1.58it/s]\u001b[A\n","Iteration:  72% 1327/1851 [14:00<05:31,  1.58it/s]\u001b[A\n","Iteration:  72% 1328/1851 [14:00<05:30,  1.58it/s]\u001b[A\n","Iteration:  72% 1329/1851 [14:01<05:30,  1.58it/s]\u001b[A\n","Iteration:  72% 1330/1851 [14:02<05:29,  1.58it/s]\u001b[A\n","Iteration:  72% 1331/1851 [14:02<05:29,  1.58it/s]\u001b[A\n","Iteration:  72% 1332/1851 [14:03<05:28,  1.58it/s]\u001b[A\n","Iteration:  72% 1333/1851 [14:04<05:28,  1.58it/s]\u001b[A\n","Iteration:  72% 1334/1851 [14:04<05:27,  1.58it/s]\u001b[A\n","Iteration:  72% 1335/1851 [14:05<05:26,  1.58it/s]\u001b[A\n","Iteration:  72% 1336/1851 [14:05<05:25,  1.58it/s]\u001b[A\n","Iteration:  72% 1337/1851 [14:06<05:25,  1.58it/s]\u001b[A\n","Iteration:  72% 1338/1851 [14:07<05:24,  1.58it/s]\u001b[A\n","Iteration:  72% 1339/1851 [14:07<05:24,  1.58it/s]\u001b[A\n","Iteration:  72% 1340/1851 [14:08<05:24,  1.58it/s]\u001b[A\n","Iteration:  72% 1341/1851 [14:09<05:23,  1.58it/s]\u001b[A\n","Iteration:  73% 1342/1851 [14:09<05:22,  1.58it/s]\u001b[A\n","Iteration:  73% 1343/1851 [14:10<05:21,  1.58it/s]\u001b[A\n","Iteration:  73% 1344/1851 [14:10<05:20,  1.58it/s]\u001b[A\n","Iteration:  73% 1345/1851 [14:11<05:19,  1.58it/s]\u001b[A\n","Iteration:  73% 1346/1851 [14:12<05:18,  1.58it/s]\u001b[A\n","Iteration:  73% 1347/1851 [14:12<05:18,  1.58it/s]\u001b[A\n","Iteration:  73% 1348/1851 [14:13<05:18,  1.58it/s]\u001b[A\n","Iteration:  73% 1349/1851 [14:14<05:18,  1.58it/s]\u001b[A\n","Iteration:  73% 1350/1851 [14:14<05:17,  1.58it/s]\u001b[A\n","Iteration:  73% 1351/1851 [14:15<05:16,  1.58it/s]\u001b[A\n","Iteration:  73% 1352/1851 [14:16<05:16,  1.58it/s]\u001b[A\n","Iteration:  73% 1353/1851 [14:16<05:16,  1.58it/s]\u001b[A\n","Iteration:  73% 1354/1851 [14:17<05:15,  1.58it/s]\u001b[A\n","Iteration:  73% 1355/1851 [14:17<05:14,  1.58it/s]\u001b[A\n","Iteration:  73% 1356/1851 [14:18<05:13,  1.58it/s]\u001b[A\n","Iteration:  73% 1357/1851 [14:19<05:12,  1.58it/s]\u001b[A\n","Iteration:  73% 1358/1851 [14:19<05:12,  1.58it/s]\u001b[A\n","Iteration:  73% 1359/1851 [14:20<05:11,  1.58it/s]\u001b[A\n","Iteration:  73% 1360/1851 [14:21<05:11,  1.58it/s]\u001b[A\n","Iteration:  74% 1361/1851 [14:21<05:10,  1.58it/s]\u001b[A\n","Iteration:  74% 1362/1851 [14:22<05:09,  1.58it/s]\u001b[A\n","Iteration:  74% 1363/1851 [14:23<05:09,  1.58it/s]\u001b[A\n","Iteration:  74% 1364/1851 [14:23<05:08,  1.58it/s]\u001b[A\n","Iteration:  74% 1365/1851 [14:24<05:07,  1.58it/s]\u001b[A\n","Iteration:  74% 1366/1851 [14:24<05:07,  1.58it/s]\u001b[A\n","Iteration:  74% 1367/1851 [14:25<05:07,  1.58it/s]\u001b[A\n","Iteration:  74% 1368/1851 [14:26<05:06,  1.58it/s]\u001b[A\n","Iteration:  74% 1369/1851 [14:26<05:05,  1.58it/s]\u001b[A\n","Iteration:  74% 1370/1851 [14:27<05:04,  1.58it/s]\u001b[A\n","Iteration:  74% 1371/1851 [14:28<05:04,  1.58it/s]\u001b[A\n","Iteration:  74% 1372/1851 [14:28<05:03,  1.58it/s]\u001b[A\n","Iteration:  74% 1373/1851 [14:29<05:03,  1.58it/s]\u001b[A\n","Iteration:  74% 1374/1851 [14:30<05:02,  1.58it/s]\u001b[A\n","Iteration:  74% 1375/1851 [14:30<05:01,  1.58it/s]\u001b[A\n","Iteration:  74% 1376/1851 [14:31<05:00,  1.58it/s]\u001b[A\n","Iteration:  74% 1377/1851 [14:31<04:59,  1.58it/s]\u001b[A\n","Iteration:  74% 1378/1851 [14:32<04:59,  1.58it/s]\u001b[A\n","Iteration:  75% 1379/1851 [14:33<04:58,  1.58it/s]\u001b[A\n","Iteration:  75% 1380/1851 [14:33<04:58,  1.58it/s]\u001b[A\n","Iteration:  75% 1381/1851 [14:34<04:56,  1.58it/s]\u001b[A\n","Iteration:  75% 1382/1851 [14:35<04:56,  1.58it/s]\u001b[A\n","Iteration:  75% 1383/1851 [14:35<04:56,  1.58it/s]\u001b[A\n","Iteration:  75% 1384/1851 [14:36<04:55,  1.58it/s]\u001b[A\n","Iteration:  75% 1385/1851 [14:36<04:54,  1.58it/s]\u001b[A\n","Iteration:  75% 1386/1851 [14:37<04:54,  1.58it/s]\u001b[A\n","Iteration:  75% 1387/1851 [14:38<04:54,  1.58it/s]\u001b[A\n","Iteration:  75% 1388/1851 [14:38<04:53,  1.58it/s]\u001b[A\n","Iteration:  75% 1389/1851 [14:39<04:52,  1.58it/s]\u001b[A\n","Iteration:  75% 1390/1851 [14:40<04:52,  1.58it/s]\u001b[A\n","Iteration:  75% 1391/1851 [14:40<04:51,  1.58it/s]\u001b[A\n","Iteration:  75% 1392/1851 [14:41<04:50,  1.58it/s]\u001b[A\n","Iteration:  75% 1393/1851 [14:42<04:50,  1.58it/s]\u001b[A\n","Iteration:  75% 1394/1851 [14:42<04:48,  1.58it/s]\u001b[A\n","Iteration:  75% 1395/1851 [14:43<04:48,  1.58it/s]\u001b[A\n","Iteration:  75% 1396/1851 [14:43<04:47,  1.58it/s]\u001b[A\n","Iteration:  75% 1397/1851 [14:44<04:47,  1.58it/s]\u001b[A\n","Iteration:  76% 1398/1851 [14:45<04:46,  1.58it/s]\u001b[A\n","Iteration:  76% 1399/1851 [14:45<04:46,  1.58it/s]\u001b[A\n","Iteration:  76% 1400/1851 [14:46<04:45,  1.58it/s]\u001b[A\n","Iteration:  76% 1401/1851 [14:47<04:44,  1.58it/s]\u001b[A\n","Iteration:  76% 1402/1851 [14:47<04:43,  1.58it/s]\u001b[A\n","Iteration:  76% 1403/1851 [14:48<04:43,  1.58it/s]\u001b[A\n","Iteration:  76% 1404/1851 [14:48<04:43,  1.58it/s]\u001b[A\n","Iteration:  76% 1405/1851 [14:49<04:42,  1.58it/s]\u001b[A\n","Iteration:  76% 1406/1851 [14:50<04:41,  1.58it/s]\u001b[A\n","Iteration:  76% 1407/1851 [14:50<04:41,  1.58it/s]\u001b[A\n","Iteration:  76% 1408/1851 [14:51<04:40,  1.58it/s]\u001b[A\n","Iteration:  76% 1409/1851 [14:52<04:39,  1.58it/s]\u001b[A\n","Iteration:  76% 1410/1851 [14:52<04:39,  1.58it/s]\u001b[A\n","Iteration:  76% 1411/1851 [14:53<04:37,  1.58it/s]\u001b[A\n","Iteration:  76% 1412/1851 [14:54<04:37,  1.58it/s]\u001b[A\n","Iteration:  76% 1413/1851 [14:54<04:37,  1.58it/s]\u001b[A\n","Iteration:  76% 1414/1851 [14:55<04:36,  1.58it/s]\u001b[A\n","Iteration:  76% 1415/1851 [14:55<04:35,  1.58it/s]\u001b[A\n","Iteration:  76% 1416/1851 [14:56<04:35,  1.58it/s]\u001b[A\n","Iteration:  77% 1417/1851 [14:57<04:34,  1.58it/s]\u001b[A\n","Iteration:  77% 1418/1851 [14:57<04:34,  1.58it/s]\u001b[A\n","Iteration:  77% 1419/1851 [14:58<04:33,  1.58it/s]\u001b[A\n","Iteration:  77% 1420/1851 [14:59<04:32,  1.58it/s]\u001b[A\n","Iteration:  77% 1421/1851 [14:59<04:32,  1.58it/s]\u001b[A\n","Iteration:  77% 1422/1851 [15:00<04:31,  1.58it/s]\u001b[A\n","Iteration:  77% 1423/1851 [15:01<04:31,  1.58it/s]\u001b[A\n","Iteration:  77% 1424/1851 [15:01<04:30,  1.58it/s]\u001b[A\n","Iteration:  77% 1425/1851 [15:02<04:29,  1.58it/s]\u001b[A\n","Iteration:  77% 1426/1851 [15:02<04:29,  1.58it/s]\u001b[A\n","Iteration:  77% 1427/1851 [15:03<04:28,  1.58it/s]\u001b[A\n","Iteration:  77% 1428/1851 [15:04<04:27,  1.58it/s]\u001b[A\n","Iteration:  77% 1429/1851 [15:04<04:27,  1.58it/s]\u001b[A\n","Iteration:  77% 1430/1851 [15:05<04:26,  1.58it/s]\u001b[A\n","Iteration:  77% 1431/1851 [15:06<04:25,  1.58it/s]\u001b[A\n","Iteration:  77% 1432/1851 [15:06<04:24,  1.58it/s]\u001b[A\n","Iteration:  77% 1433/1851 [15:07<04:23,  1.58it/s]\u001b[A\n","Iteration:  77% 1434/1851 [15:07<04:23,  1.58it/s]\u001b[A\n","Iteration:  78% 1435/1851 [15:08<04:22,  1.58it/s]\u001b[A\n","Iteration:  78% 1436/1851 [15:09<04:22,  1.58it/s]\u001b[A\n","Iteration:  78% 1437/1851 [15:09<04:21,  1.58it/s]\u001b[A\n","Iteration:  78% 1438/1851 [15:10<04:21,  1.58it/s]\u001b[A\n","Iteration:  78% 1439/1851 [15:11<04:20,  1.58it/s]\u001b[A\n","Iteration:  78% 1440/1851 [15:11<04:19,  1.58it/s]\u001b[A\n","Iteration:  78% 1441/1851 [15:12<04:18,  1.58it/s]\u001b[A\n","Iteration:  78% 1442/1851 [15:13<04:18,  1.58it/s]\u001b[A\n","Iteration:  78% 1443/1851 [15:13<04:17,  1.58it/s]\u001b[A\n","Iteration:  78% 1444/1851 [15:14<04:17,  1.58it/s]\u001b[A\n","Iteration:  78% 1445/1851 [15:14<04:16,  1.58it/s]\u001b[A\n","Iteration:  78% 1446/1851 [15:15<04:16,  1.58it/s]\u001b[A\n","Iteration:  78% 1447/1851 [15:16<04:16,  1.58it/s]\u001b[A\n","Iteration:  78% 1448/1851 [15:16<04:15,  1.58it/s]\u001b[A\n","Iteration:  78% 1449/1851 [15:17<04:14,  1.58it/s]\u001b[A\n","Iteration:  78% 1450/1851 [15:18<04:13,  1.58it/s]\u001b[A\n","Iteration:  78% 1451/1851 [15:18<04:13,  1.58it/s]\u001b[A\n","Iteration:  78% 1452/1851 [15:19<04:12,  1.58it/s]\u001b[A\n","Iteration:  78% 1453/1851 [15:19<04:11,  1.58it/s]\u001b[A\n","Iteration:  79% 1454/1851 [15:20<04:11,  1.58it/s]\u001b[A\n","Iteration:  79% 1455/1851 [15:21<04:11,  1.58it/s]\u001b[A\n","Iteration:  79% 1456/1851 [15:21<04:10,  1.58it/s]\u001b[A\n","Iteration:  79% 1457/1851 [15:22<04:09,  1.58it/s]\u001b[A\n","Iteration:  79% 1458/1851 [15:23<04:08,  1.58it/s]\u001b[A\n","Iteration:  79% 1459/1851 [15:23<04:07,  1.58it/s]\u001b[A\n","Iteration:  79% 1460/1851 [15:24<04:07,  1.58it/s]\u001b[A\n","Iteration:  79% 1461/1851 [15:25<04:06,  1.58it/s]\u001b[A\n","Iteration:  79% 1462/1851 [15:25<04:05,  1.58it/s]\u001b[A\n","Iteration:  79% 1463/1851 [15:26<04:05,  1.58it/s]\u001b[A\n","Iteration:  79% 1464/1851 [15:26<04:04,  1.58it/s]\u001b[A\n","Iteration:  79% 1465/1851 [15:27<04:04,  1.58it/s]\u001b[A\n","Iteration:  79% 1466/1851 [15:28<04:03,  1.58it/s]\u001b[A\n","Iteration:  79% 1467/1851 [15:28<04:02,  1.58it/s]\u001b[A\n","Iteration:  79% 1468/1851 [15:29<04:02,  1.58it/s]\u001b[A\n","Iteration:  79% 1469/1851 [15:30<04:01,  1.58it/s]\u001b[A\n","Iteration:  79% 1470/1851 [15:30<04:00,  1.58it/s]\u001b[A\n","Iteration:  79% 1471/1851 [15:31<03:59,  1.58it/s]\u001b[A\n","Iteration:  80% 1472/1851 [15:32<03:59,  1.58it/s]\u001b[A\n","Iteration:  80% 1473/1851 [15:32<03:58,  1.58it/s]\u001b[A\n","Iteration:  80% 1474/1851 [15:33<03:57,  1.59it/s]\u001b[A\n","Iteration:  80% 1475/1851 [15:33<03:57,  1.58it/s]\u001b[A\n","Iteration:  80% 1476/1851 [15:34<03:56,  1.58it/s]\u001b[A\n","Iteration:  80% 1477/1851 [15:35<03:56,  1.58it/s]\u001b[A\n","Iteration:  80% 1478/1851 [15:35<03:55,  1.58it/s]\u001b[A\n","Iteration:  80% 1479/1851 [15:36<03:55,  1.58it/s]\u001b[A\n","Iteration:  80% 1480/1851 [15:37<03:54,  1.58it/s]\u001b[A\n","Iteration:  80% 1481/1851 [15:37<03:53,  1.58it/s]\u001b[A\n","Iteration:  80% 1482/1851 [15:38<03:53,  1.58it/s]\u001b[A\n","Iteration:  80% 1483/1851 [15:38<03:52,  1.58it/s]\u001b[A\n","Iteration:  80% 1484/1851 [15:39<03:52,  1.58it/s]\u001b[A\n","Iteration:  80% 1485/1851 [15:40<03:51,  1.58it/s]\u001b[A\n","Iteration:  80% 1486/1851 [15:40<03:50,  1.58it/s]\u001b[A\n","Iteration:  80% 1487/1851 [15:41<03:50,  1.58it/s]\u001b[A\n","Iteration:  80% 1488/1851 [15:42<03:49,  1.58it/s]\u001b[A\n","Iteration:  80% 1489/1851 [15:42<03:48,  1.58it/s]\u001b[A\n","Iteration:  80% 1490/1851 [15:43<03:47,  1.58it/s]\u001b[A\n","Iteration:  81% 1491/1851 [15:44<03:47,  1.59it/s]\u001b[A\n","Iteration:  81% 1492/1851 [15:44<03:46,  1.58it/s]\u001b[A\n","Iteration:  81% 1493/1851 [15:45<03:46,  1.58it/s]\u001b[A\n","Iteration:  81% 1494/1851 [15:45<03:45,  1.58it/s]\u001b[A\n","Iteration:  81% 1495/1851 [15:46<03:45,  1.58it/s]\u001b[A\n","Iteration:  81% 1496/1851 [15:47<03:44,  1.58it/s]\u001b[A\n","Iteration:  81% 1497/1851 [15:47<03:43,  1.58it/s]\u001b[A\n","Iteration:  81% 1498/1851 [15:48<03:42,  1.58it/s]\u001b[A\n","Iteration:  81% 1499/1851 [15:49<03:42,  1.58it/s]\u001b[A\n","Iteration:  81% 1500/1851 [15:49<03:41,  1.58it/s]\u001b[A\n","Iteration:  81% 1501/1851 [15:50<03:41,  1.58it/s]\u001b[A\n","Iteration:  81% 1502/1851 [15:50<03:40,  1.58it/s]\u001b[A\n","Iteration:  81% 1503/1851 [15:51<03:39,  1.58it/s]\u001b[A\n","Iteration:  81% 1504/1851 [15:52<03:39,  1.58it/s]\u001b[A\n","Iteration:  81% 1505/1851 [15:52<03:38,  1.58it/s]\u001b[A\n","Iteration:  81% 1506/1851 [15:53<03:38,  1.58it/s]\u001b[A\n","Iteration:  81% 1507/1851 [15:54<03:38,  1.58it/s]\u001b[A\n","Iteration:  81% 1508/1851 [15:54<03:37,  1.58it/s]\u001b[A\n","Iteration:  82% 1509/1851 [15:55<03:36,  1.58it/s]\u001b[A\n","Iteration:  82% 1510/1851 [15:56<03:35,  1.58it/s]\u001b[A\n","Iteration:  82% 1511/1851 [15:56<03:34,  1.58it/s]\u001b[A\n","Iteration:  82% 1512/1851 [15:57<03:34,  1.58it/s]\u001b[A\n","Iteration:  82% 1513/1851 [15:57<03:33,  1.58it/s]\u001b[A\n","Iteration:  82% 1514/1851 [15:58<03:33,  1.58it/s]\u001b[A\n","Iteration:  82% 1515/1851 [15:59<03:32,  1.58it/s]\u001b[A\n","Iteration:  82% 1516/1851 [15:59<03:31,  1.58it/s]\u001b[A\n","Iteration:  82% 1517/1851 [16:00<03:31,  1.58it/s]\u001b[A\n","Iteration:  82% 1518/1851 [16:01<03:30,  1.58it/s]\u001b[A\n","Iteration:  82% 1519/1851 [16:01<03:29,  1.58it/s]\u001b[A\n","Iteration:  82% 1520/1851 [16:02<03:28,  1.58it/s]\u001b[A\n","Iteration:  82% 1521/1851 [16:02<03:28,  1.58it/s]\u001b[A\n","Iteration:  82% 1522/1851 [16:03<03:27,  1.59it/s]\u001b[A\n","Iteration:  82% 1523/1851 [16:04<03:27,  1.58it/s]\u001b[A\n","Iteration:  82% 1524/1851 [16:04<03:26,  1.58it/s]\u001b[A\n","Iteration:  82% 1525/1851 [16:05<03:26,  1.58it/s]\u001b[A\n","Iteration:  82% 1526/1851 [16:06<03:25,  1.58it/s]\u001b[A\n","Iteration:  82% 1527/1851 [16:06<03:24,  1.58it/s]\u001b[A\n","Iteration:  83% 1528/1851 [16:07<03:24,  1.58it/s]\u001b[A\n","Iteration:  83% 1529/1851 [16:08<03:23,  1.58it/s]\u001b[A\n","Iteration:  83% 1530/1851 [16:08<03:22,  1.58it/s]\u001b[A\n","Iteration:  83% 1531/1851 [16:09<03:22,  1.58it/s]\u001b[A\n","Iteration:  83% 1532/1851 [16:09<03:21,  1.58it/s]\u001b[A\n","Iteration:  83% 1533/1851 [16:10<03:20,  1.59it/s]\u001b[A\n","Iteration:  83% 1534/1851 [16:11<03:19,  1.59it/s]\u001b[A\n","Iteration:  83% 1535/1851 [16:11<03:19,  1.58it/s]\u001b[A\n","Iteration:  83% 1536/1851 [16:12<03:19,  1.58it/s]\u001b[A\n","Iteration:  83% 1537/1851 [16:13<03:18,  1.58it/s]\u001b[A\n","Iteration:  83% 1538/1851 [16:13<03:18,  1.58it/s]\u001b[A\n","Iteration:  83% 1539/1851 [16:14<03:17,  1.58it/s]\u001b[A\n","Iteration:  83% 1540/1851 [16:14<03:16,  1.58it/s]\u001b[A\n","Iteration:  83% 1541/1851 [16:15<03:16,  1.58it/s]\u001b[A\n","Iteration:  83% 1542/1851 [16:16<03:15,  1.58it/s]\u001b[A\n","Iteration:  83% 1543/1851 [16:16<03:14,  1.58it/s]\u001b[A\n","Iteration:  83% 1544/1851 [16:17<03:14,  1.58it/s]\u001b[A\n","Iteration:  83% 1545/1851 [16:18<03:13,  1.58it/s]\u001b[A\n","Iteration:  84% 1546/1851 [16:18<03:12,  1.58it/s]\u001b[A\n","Iteration:  84% 1547/1851 [16:19<03:12,  1.58it/s]\u001b[A\n","Iteration:  84% 1548/1851 [16:20<03:11,  1.58it/s]\u001b[A\n","Iteration:  84% 1549/1851 [16:20<03:11,  1.58it/s]\u001b[A\n","Iteration:  84% 1550/1851 [16:21<03:10,  1.58it/s]\u001b[A\n","Iteration:  84% 1551/1851 [16:21<03:09,  1.58it/s]\u001b[A\n","Iteration:  84% 1552/1851 [16:22<03:09,  1.58it/s]\u001b[A\n","Iteration:  84% 1553/1851 [16:23<03:08,  1.58it/s]\u001b[A\n","Iteration:  84% 1554/1851 [16:23<03:07,  1.58it/s]\u001b[A\n","Iteration:  84% 1555/1851 [16:24<03:06,  1.58it/s]\u001b[A\n","Iteration:  84% 1556/1851 [16:25<03:06,  1.58it/s]\u001b[A\n","Iteration:  84% 1557/1851 [16:25<03:06,  1.58it/s]\u001b[A\n","Iteration:  84% 1558/1851 [16:26<03:05,  1.58it/s]\u001b[A\n","Iteration:  84% 1559/1851 [16:27<03:04,  1.58it/s]\u001b[A\n","Iteration:  84% 1560/1851 [16:27<03:03,  1.58it/s]\u001b[A\n","Iteration:  84% 1561/1851 [16:28<03:03,  1.58it/s]\u001b[A\n","Iteration:  84% 1562/1851 [16:28<03:02,  1.58it/s]\u001b[A\n","Iteration:  84% 1563/1851 [16:29<03:02,  1.58it/s]\u001b[A\n","Iteration:  84% 1564/1851 [16:30<03:01,  1.58it/s]\u001b[A\n","Iteration:  85% 1565/1851 [16:30<03:00,  1.58it/s]\u001b[A\n","Iteration:  85% 1566/1851 [16:31<03:00,  1.58it/s]\u001b[A\n","Iteration:  85% 1567/1851 [16:32<02:59,  1.58it/s]\u001b[A\n","Iteration:  85% 1568/1851 [16:32<02:59,  1.58it/s]\u001b[A\n","Iteration:  85% 1569/1851 [16:33<02:58,  1.58it/s]\u001b[A\n","Iteration:  85% 1570/1851 [16:33<02:58,  1.58it/s]\u001b[A\n","Iteration:  85% 1571/1851 [16:34<02:57,  1.58it/s]\u001b[A\n","Iteration:  85% 1572/1851 [16:35<02:56,  1.58it/s]\u001b[A\n","Iteration:  85% 1573/1851 [16:35<02:55,  1.58it/s]\u001b[A\n","Iteration:  85% 1574/1851 [16:36<02:54,  1.58it/s]\u001b[A\n","Iteration:  85% 1575/1851 [16:37<02:54,  1.58it/s]\u001b[A\n","Iteration:  85% 1576/1851 [16:37<02:53,  1.58it/s]\u001b[A\n","Iteration:  85% 1577/1851 [16:38<02:53,  1.58it/s]\u001b[A\n","Iteration:  85% 1578/1851 [16:39<02:52,  1.58it/s]\u001b[A\n","Iteration:  85% 1579/1851 [16:39<02:51,  1.58it/s]\u001b[A\n","Iteration:  85% 1580/1851 [16:40<02:51,  1.58it/s]\u001b[A\n","Iteration:  85% 1581/1851 [16:40<02:50,  1.58it/s]\u001b[A\n","Iteration:  85% 1582/1851 [16:41<02:49,  1.58it/s]\u001b[A\n","Iteration:  86% 1583/1851 [16:42<02:49,  1.58it/s]\u001b[A\n","Iteration:  86% 1584/1851 [16:42<02:48,  1.58it/s]\u001b[A\n","Iteration:  86% 1585/1851 [16:43<02:48,  1.58it/s]\u001b[A\n","Iteration:  86% 1586/1851 [16:44<02:47,  1.58it/s]\u001b[A\n","Iteration:  86% 1587/1851 [16:44<02:46,  1.58it/s]\u001b[A\n","Iteration:  86% 1588/1851 [16:45<02:46,  1.58it/s]\u001b[A\n","Iteration:  86% 1589/1851 [16:45<02:45,  1.58it/s]\u001b[A\n","Iteration:  86% 1590/1851 [16:46<02:44,  1.58it/s]\u001b[A\n","Iteration:  86% 1591/1851 [16:47<02:44,  1.58it/s]\u001b[A\n","Iteration:  86% 1592/1851 [16:47<02:43,  1.58it/s]\u001b[A\n","Iteration:  86% 1593/1851 [16:48<02:42,  1.58it/s]\u001b[A\n","Iteration:  86% 1594/1851 [16:49<02:42,  1.58it/s]\u001b[A\n","Iteration:  86% 1595/1851 [16:49<02:41,  1.58it/s]\u001b[A\n","Iteration:  86% 1596/1851 [16:50<02:41,  1.58it/s]\u001b[A\n","Iteration:  86% 1597/1851 [16:51<02:40,  1.58it/s]\u001b[A\n","Iteration:  86% 1598/1851 [16:51<02:39,  1.58it/s]\u001b[A\n","Iteration:  86% 1599/1851 [16:52<02:39,  1.58it/s]\u001b[A\n","Iteration:  86% 1600/1851 [16:52<02:38,  1.58it/s]\u001b[A\n","Iteration:  86% 1601/1851 [16:53<02:38,  1.58it/s]\u001b[A\n","Iteration:  87% 1602/1851 [16:54<02:37,  1.58it/s]\u001b[A\n","Iteration:  87% 1603/1851 [16:54<02:37,  1.58it/s]\u001b[A\n","Iteration:  87% 1604/1851 [16:55<02:36,  1.58it/s]\u001b[A\n","Iteration:  87% 1605/1851 [16:56<02:35,  1.58it/s]\u001b[A\n","Iteration:  87% 1606/1851 [16:56<02:34,  1.58it/s]\u001b[A\n","Iteration:  87% 1607/1851 [16:57<02:34,  1.58it/s]\u001b[A\n","Iteration:  87% 1608/1851 [16:57<02:33,  1.58it/s]\u001b[A\n","Iteration:  87% 1609/1851 [16:58<02:32,  1.58it/s]\u001b[A\n","Iteration:  87% 1610/1851 [16:59<02:32,  1.58it/s]\u001b[A\n","Iteration:  87% 1611/1851 [16:59<02:31,  1.58it/s]\u001b[A\n","Iteration:  87% 1612/1851 [17:00<02:31,  1.58it/s]\u001b[A\n","Iteration:  87% 1613/1851 [17:01<02:30,  1.58it/s]\u001b[A\n","Iteration:  87% 1614/1851 [17:01<02:29,  1.58it/s]\u001b[A\n","Iteration:  87% 1615/1851 [17:02<02:29,  1.58it/s]\u001b[A\n","Iteration:  87% 1616/1851 [17:03<02:28,  1.58it/s]\u001b[A\n","Iteration:  87% 1617/1851 [17:03<02:27,  1.58it/s]\u001b[A\n","Iteration:  87% 1618/1851 [17:04<02:27,  1.58it/s]\u001b[A\n","Iteration:  87% 1619/1851 [17:04<02:27,  1.58it/s]\u001b[A\n","Iteration:  88% 1620/1851 [17:05<02:26,  1.58it/s]\u001b[A\n","Iteration:  88% 1621/1851 [17:06<02:25,  1.58it/s]\u001b[A\n","Iteration:  88% 1622/1851 [17:06<02:24,  1.58it/s]\u001b[A\n","Iteration:  88% 1623/1851 [17:07<02:24,  1.58it/s]\u001b[A\n","Iteration:  88% 1624/1851 [17:08<02:23,  1.58it/s]\u001b[A\n","Iteration:  88% 1625/1851 [17:08<02:23,  1.58it/s]\u001b[A\n","Iteration:  88% 1626/1851 [17:09<02:22,  1.58it/s]\u001b[A\n","Iteration:  88% 1627/1851 [17:10<02:21,  1.58it/s]\u001b[A\n","Iteration:  88% 1628/1851 [17:10<02:21,  1.58it/s]\u001b[A\n","Iteration:  88% 1629/1851 [17:11<02:20,  1.58it/s]\u001b[A\n","Iteration:  88% 1630/1851 [17:11<02:19,  1.58it/s]\u001b[A\n","Iteration:  88% 1631/1851 [17:12<02:19,  1.58it/s]\u001b[A\n","Iteration:  88% 1632/1851 [17:13<02:18,  1.58it/s]\u001b[A\n","Iteration:  88% 1633/1851 [17:13<02:18,  1.58it/s]\u001b[A\n","Iteration:  88% 1634/1851 [17:14<02:17,  1.58it/s]\u001b[A\n","Iteration:  88% 1635/1851 [17:15<02:16,  1.58it/s]\u001b[A\n","Iteration:  88% 1636/1851 [17:15<02:16,  1.58it/s]\u001b[A\n","Iteration:  88% 1637/1851 [17:16<02:14,  1.59it/s]\u001b[A\n","Iteration:  88% 1638/1851 [17:16<02:15,  1.58it/s]\u001b[A\n","Iteration:  89% 1639/1851 [17:17<02:14,  1.58it/s]\u001b[A\n","Iteration:  89% 1640/1851 [17:18<02:13,  1.58it/s]\u001b[A\n","Iteration:  89% 1641/1851 [17:18<02:12,  1.58it/s]\u001b[A\n","Iteration:  89% 1642/1851 [17:19<02:11,  1.58it/s]\u001b[A\n","Iteration:  89% 1643/1851 [17:20<02:11,  1.58it/s]\u001b[A\n","Iteration:  89% 1644/1851 [17:20<02:10,  1.58it/s]\u001b[A\n","Iteration:  89% 1645/1851 [17:21<02:10,  1.58it/s]\u001b[A\n","Iteration:  89% 1646/1851 [17:22<02:09,  1.58it/s]\u001b[A\n","Iteration:  89% 1647/1851 [17:22<02:09,  1.58it/s]\u001b[A\n","Iteration:  89% 1648/1851 [17:23<02:09,  1.57it/s]\u001b[A\n","Iteration:  89% 1649/1851 [17:23<02:08,  1.57it/s]\u001b[A\n","Iteration:  89% 1650/1851 [17:24<02:07,  1.58it/s]\u001b[A\n","Iteration:  89% 1651/1851 [17:25<02:06,  1.58it/s]\u001b[A\n","Iteration:  89% 1652/1851 [17:25<02:06,  1.58it/s]\u001b[A\n","Iteration:  89% 1653/1851 [17:26<02:05,  1.58it/s]\u001b[A\n","Iteration:  89% 1654/1851 [17:27<02:04,  1.58it/s]\u001b[A\n","Iteration:  89% 1655/1851 [17:27<02:03,  1.58it/s]\u001b[A\n","Iteration:  89% 1656/1851 [17:28<02:03,  1.58it/s]\u001b[A\n","Iteration:  90% 1657/1851 [17:29<02:02,  1.58it/s]\u001b[A\n","Iteration:  90% 1658/1851 [17:29<02:02,  1.58it/s]\u001b[A\n","Iteration:  90% 1659/1851 [17:30<02:01,  1.58it/s]\u001b[A\n","Iteration:  90% 1660/1851 [17:30<02:00,  1.58it/s]\u001b[A\n","Iteration:  90% 1661/1851 [17:31<01:59,  1.58it/s]\u001b[A\n","Iteration:  90% 1662/1851 [17:32<01:59,  1.58it/s]\u001b[A\n","Iteration:  90% 1663/1851 [17:32<01:58,  1.58it/s]\u001b[A\n","Iteration:  90% 1664/1851 [17:33<01:58,  1.58it/s]\u001b[A\n","Iteration:  90% 1665/1851 [17:34<01:57,  1.58it/s]\u001b[A\n","Iteration:  90% 1666/1851 [17:34<01:57,  1.58it/s]\u001b[A\n","Iteration:  90% 1667/1851 [17:35<01:56,  1.58it/s]\u001b[A\n","Iteration:  90% 1668/1851 [17:35<01:55,  1.58it/s]\u001b[A\n","Iteration:  90% 1669/1851 [17:36<01:55,  1.58it/s]\u001b[A\n","Iteration:  90% 1670/1851 [17:37<01:54,  1.58it/s]\u001b[A\n","Iteration:  90% 1671/1851 [17:37<01:54,  1.58it/s]\u001b[A\n","Iteration:  90% 1672/1851 [17:38<01:53,  1.58it/s]\u001b[A\n","Iteration:  90% 1673/1851 [17:39<01:52,  1.58it/s]\u001b[A\n","Iteration:  90% 1674/1851 [17:39<01:52,  1.58it/s]\u001b[A\n","Iteration:  90% 1675/1851 [17:40<01:51,  1.58it/s]\u001b[A\n","Iteration:  91% 1676/1851 [17:41<01:50,  1.58it/s]\u001b[A\n","Iteration:  91% 1677/1851 [17:41<01:50,  1.58it/s]\u001b[A\n","Iteration:  91% 1678/1851 [17:42<01:49,  1.58it/s]\u001b[A\n","Iteration:  91% 1679/1851 [17:42<01:48,  1.58it/s]\u001b[A\n","Iteration:  91% 1680/1851 [17:43<01:48,  1.58it/s]\u001b[A\n","Iteration:  91% 1681/1851 [17:44<01:47,  1.58it/s]\u001b[A\n","Iteration:  91% 1682/1851 [17:44<01:46,  1.58it/s]\u001b[A\n","Iteration:  91% 1683/1851 [17:45<01:46,  1.58it/s]\u001b[A\n","Iteration:  91% 1684/1851 [17:46<01:45,  1.58it/s]\u001b[A\n","Iteration:  91% 1685/1851 [17:46<01:45,  1.58it/s]\u001b[A\n","Iteration:  91% 1686/1851 [17:47<01:44,  1.58it/s]\u001b[A\n","Iteration:  91% 1687/1851 [17:47<01:43,  1.58it/s]\u001b[A\n","Iteration:  91% 1688/1851 [17:48<01:43,  1.58it/s]\u001b[A\n","Iteration:  91% 1689/1851 [17:49<01:42,  1.58it/s]\u001b[A\n","Iteration:  91% 1690/1851 [17:49<01:42,  1.58it/s]\u001b[A\n","Iteration:  91% 1691/1851 [17:50<01:41,  1.58it/s]\u001b[A\n","Iteration:  91% 1692/1851 [17:51<01:40,  1.58it/s]\u001b[A\n","Iteration:  91% 1693/1851 [17:51<01:40,  1.58it/s]\u001b[A\n","Iteration:  92% 1694/1851 [17:52<01:39,  1.57it/s]\u001b[A\n","Iteration:  92% 1695/1851 [17:53<01:39,  1.58it/s]\u001b[A\n","Iteration:  92% 1696/1851 [17:53<01:38,  1.58it/s]\u001b[A\n","Iteration:  92% 1697/1851 [17:54<01:37,  1.58it/s]\u001b[A\n","Iteration:  92% 1698/1851 [17:54<01:36,  1.58it/s]\u001b[A\n","Iteration:  92% 1699/1851 [17:55<01:36,  1.58it/s]\u001b[A\n","Iteration:  92% 1700/1851 [17:56<01:35,  1.58it/s]\u001b[A\n","Iteration:  92% 1701/1851 [17:56<01:34,  1.58it/s]\u001b[A\n","Iteration:  92% 1702/1851 [17:57<01:34,  1.58it/s]\u001b[A\n","Iteration:  92% 1703/1851 [17:58<01:33,  1.58it/s]\u001b[A\n","Iteration:  92% 1704/1851 [17:58<01:32,  1.58it/s]\u001b[A\n","Iteration:  92% 1705/1851 [17:59<01:32,  1.58it/s]\u001b[A\n","Iteration:  92% 1706/1851 [18:00<01:31,  1.58it/s]\u001b[A\n","Iteration:  92% 1707/1851 [18:00<01:31,  1.58it/s]\u001b[A\n","Iteration:  92% 1708/1851 [18:01<01:30,  1.58it/s]\u001b[A\n","Iteration:  92% 1709/1851 [18:01<01:30,  1.57it/s]\u001b[A\n","Iteration:  92% 1710/1851 [18:02<01:29,  1.58it/s]\u001b[A\n","Iteration:  92% 1711/1851 [18:03<01:28,  1.58it/s]\u001b[A\n","Iteration:  92% 1712/1851 [18:03<01:28,  1.58it/s]\u001b[A\n","Iteration:  93% 1713/1851 [18:04<01:27,  1.57it/s]\u001b[A\n","Iteration:  93% 1714/1851 [18:05<01:27,  1.57it/s]\u001b[A\n","Iteration:  93% 1715/1851 [18:05<01:26,  1.58it/s]\u001b[A\n","Iteration:  93% 1716/1851 [18:06<01:25,  1.58it/s]\u001b[A\n","Iteration:  93% 1717/1851 [18:07<01:25,  1.58it/s]\u001b[A\n","Iteration:  93% 1718/1851 [18:07<01:24,  1.58it/s]\u001b[A\n","Iteration:  93% 1719/1851 [18:08<01:23,  1.58it/s]\u001b[A\n","Iteration:  93% 1720/1851 [18:08<01:23,  1.58it/s]\u001b[A\n","Iteration:  93% 1721/1851 [18:09<01:22,  1.58it/s]\u001b[A\n","Iteration:  93% 1722/1851 [18:10<01:21,  1.58it/s]\u001b[A\n","Iteration:  93% 1723/1851 [18:10<01:21,  1.58it/s]\u001b[A\n","Iteration:  93% 1724/1851 [18:11<01:20,  1.58it/s]\u001b[A\n","Iteration:  93% 1725/1851 [18:12<01:19,  1.58it/s]\u001b[A\n","Iteration:  93% 1726/1851 [18:12<01:19,  1.58it/s]\u001b[A\n","Iteration:  93% 1727/1851 [18:13<01:18,  1.58it/s]\u001b[A\n","Iteration:  93% 1728/1851 [18:13<01:17,  1.58it/s]\u001b[A\n","Iteration:  93% 1729/1851 [18:14<01:17,  1.58it/s]\u001b[A\n","Iteration:  93% 1730/1851 [18:15<01:16,  1.58it/s]\u001b[A\n","Iteration:  94% 1731/1851 [18:15<01:16,  1.57it/s]\u001b[A\n","Iteration:  94% 1732/1851 [18:16<01:15,  1.57it/s]\u001b[A\n","Iteration:  94% 1733/1851 [18:17<01:14,  1.57it/s]\u001b[A\n","Iteration:  94% 1734/1851 [18:17<01:14,  1.58it/s]\u001b[A\n","Iteration:  94% 1735/1851 [18:18<01:13,  1.58it/s]\u001b[A\n","Iteration:  94% 1736/1851 [18:19<01:12,  1.58it/s]\u001b[A\n","Iteration:  94% 1737/1851 [18:19<01:12,  1.58it/s]\u001b[A\n","Iteration:  94% 1738/1851 [18:20<01:11,  1.58it/s]\u001b[A\n","Iteration:  94% 1739/1851 [18:20<01:10,  1.58it/s]\u001b[A\n","Iteration:  94% 1740/1851 [18:21<01:10,  1.58it/s]\u001b[A\n","Iteration:  94% 1741/1851 [18:22<01:09,  1.58it/s]\u001b[A\n","Iteration:  94% 1742/1851 [18:22<01:09,  1.58it/s]\u001b[A\n","Iteration:  94% 1743/1851 [18:23<01:08,  1.58it/s]\u001b[A\n","Iteration:  94% 1744/1851 [18:24<01:07,  1.58it/s]\u001b[A\n","Iteration:  94% 1745/1851 [18:24<01:07,  1.58it/s]\u001b[A\n","Iteration:  94% 1746/1851 [18:25<01:06,  1.58it/s]\u001b[A\n","Iteration:  94% 1747/1851 [18:26<01:05,  1.58it/s]\u001b[A\n","Iteration:  94% 1748/1851 [18:26<01:05,  1.58it/s]\u001b[A\n","Iteration:  94% 1749/1851 [18:27<01:04,  1.58it/s]\u001b[A\n","Iteration:  95% 1750/1851 [18:27<01:03,  1.58it/s]\u001b[A\n","Iteration:  95% 1751/1851 [18:28<01:03,  1.58it/s]\u001b[A\n","Iteration:  95% 1752/1851 [18:29<01:02,  1.58it/s]\u001b[A\n","Iteration:  95% 1753/1851 [18:29<01:01,  1.58it/s]\u001b[A\n","Iteration:  95% 1754/1851 [18:30<01:01,  1.58it/s]\u001b[A\n","Iteration:  95% 1755/1851 [18:31<01:00,  1.58it/s]\u001b[A\n","Iteration:  95% 1756/1851 [18:31<01:00,  1.58it/s]\u001b[A\n","Iteration:  95% 1757/1851 [18:32<00:59,  1.57it/s]\u001b[A\n","Iteration:  95% 1758/1851 [18:32<00:59,  1.58it/s]\u001b[A\n","Iteration:  95% 1759/1851 [18:33<00:58,  1.58it/s]\u001b[A\n","Iteration:  95% 1760/1851 [18:34<00:57,  1.58it/s]\u001b[A\n","Iteration:  95% 1761/1851 [18:34<00:56,  1.58it/s]\u001b[A\n","Iteration:  95% 1762/1851 [18:35<00:56,  1.58it/s]\u001b[A\n","Iteration:  95% 1763/1851 [18:36<00:55,  1.58it/s]\u001b[A\n","Iteration:  95% 1764/1851 [18:36<00:55,  1.58it/s]\u001b[A\n","Iteration:  95% 1765/1851 [18:37<00:54,  1.58it/s]\u001b[A\n","Iteration:  95% 1766/1851 [18:38<00:53,  1.59it/s]\u001b[A\n","Iteration:  95% 1767/1851 [18:38<00:53,  1.58it/s]\u001b[A\n","Iteration:  96% 1768/1851 [18:39<00:52,  1.58it/s]\u001b[A\n","Iteration:  96% 1769/1851 [18:39<00:51,  1.58it/s]\u001b[A\n","Iteration:  96% 1770/1851 [18:40<00:51,  1.58it/s]\u001b[A\n","Iteration:  96% 1771/1851 [18:41<00:50,  1.58it/s]\u001b[A\n","Iteration:  96% 1772/1851 [18:41<00:49,  1.58it/s]\u001b[A\n","Iteration:  96% 1773/1851 [18:42<00:49,  1.58it/s]\u001b[A\n","Iteration:  96% 1774/1851 [18:43<00:48,  1.58it/s]\u001b[A\n","Iteration:  96% 1775/1851 [18:43<00:48,  1.57it/s]\u001b[A\n","Iteration:  96% 1776/1851 [18:44<00:47,  1.58it/s]\u001b[A\n","Iteration:  96% 1777/1851 [18:45<00:46,  1.58it/s]\u001b[A\n","Iteration:  96% 1778/1851 [18:45<00:46,  1.58it/s]\u001b[A\n","Iteration:  96% 1779/1851 [18:46<00:45,  1.58it/s]\u001b[A\n","Iteration:  96% 1780/1851 [18:46<00:44,  1.58it/s]\u001b[A\n","Iteration:  96% 1781/1851 [18:47<00:44,  1.58it/s]\u001b[A\n","Iteration:  96% 1782/1851 [18:48<00:43,  1.58it/s]\u001b[A\n","Iteration:  96% 1783/1851 [18:48<00:42,  1.58it/s]\u001b[A\n","Iteration:  96% 1784/1851 [18:49<00:42,  1.58it/s]\u001b[A\n","Iteration:  96% 1785/1851 [18:50<00:41,  1.58it/s]\u001b[A\n","Iteration:  96% 1786/1851 [18:50<00:40,  1.59it/s]\u001b[A\n","Iteration:  97% 1787/1851 [18:51<00:40,  1.59it/s]\u001b[A\n","Iteration:  97% 1788/1851 [18:51<00:39,  1.58it/s]\u001b[A\n","Iteration:  97% 1789/1851 [18:52<00:39,  1.58it/s]\u001b[A\n","Iteration:  97% 1790/1851 [18:53<00:38,  1.58it/s]\u001b[A\n","Iteration:  97% 1791/1851 [18:53<00:37,  1.58it/s]\u001b[A\n","Iteration:  97% 1792/1851 [18:54<00:37,  1.58it/s]\u001b[A\n","Iteration:  97% 1793/1851 [18:55<00:36,  1.58it/s]\u001b[A\n","Iteration:  97% 1794/1851 [18:55<00:36,  1.58it/s]\u001b[A\n","Iteration:  97% 1795/1851 [18:56<00:35,  1.58it/s]\u001b[A\n","Iteration:  97% 1796/1851 [18:57<00:34,  1.58it/s]\u001b[A\n","Iteration:  97% 1797/1851 [18:57<00:34,  1.58it/s]\u001b[A\n","Iteration:  97% 1798/1851 [18:58<00:33,  1.58it/s]\u001b[A\n","Iteration:  97% 1799/1851 [18:58<00:32,  1.58it/s]\u001b[A\n","Iteration:  97% 1800/1851 [18:59<00:32,  1.58it/s]\u001b[A\n","Iteration:  97% 1801/1851 [19:00<00:31,  1.59it/s]\u001b[A\n","Iteration:  97% 1802/1851 [19:00<00:30,  1.59it/s]\u001b[A\n","Iteration:  97% 1803/1851 [19:01<00:30,  1.59it/s]\u001b[A\n","Iteration:  97% 1804/1851 [19:02<00:29,  1.59it/s]\u001b[A\n","Iteration:  98% 1805/1851 [19:02<00:29,  1.58it/s]\u001b[A\n","Iteration:  98% 1806/1851 [19:03<00:28,  1.58it/s]\u001b[A\n","Iteration:  98% 1807/1851 [19:03<00:27,  1.58it/s]\u001b[A\n","Iteration:  98% 1808/1851 [19:04<00:27,  1.59it/s]\u001b[A\n","Iteration:  98% 1809/1851 [19:05<00:26,  1.58it/s]\u001b[A\n","Iteration:  98% 1810/1851 [19:05<00:25,  1.58it/s]\u001b[A\n","Iteration:  98% 1811/1851 [19:06<00:25,  1.58it/s]\u001b[A\n","Iteration:  98% 1812/1851 [19:07<00:24,  1.58it/s]\u001b[A\n","Iteration:  98% 1813/1851 [19:07<00:24,  1.58it/s]\u001b[A\n","Iteration:  98% 1814/1851 [19:08<00:23,  1.58it/s]\u001b[A\n","Iteration:  98% 1815/1851 [19:08<00:22,  1.58it/s]\u001b[A\n","Iteration:  98% 1816/1851 [19:09<00:22,  1.58it/s]\u001b[A\n","Iteration:  98% 1817/1851 [19:10<00:21,  1.59it/s]\u001b[A\n","Iteration:  98% 1818/1851 [19:10<00:20,  1.59it/s]\u001b[A\n","Iteration:  98% 1819/1851 [19:11<00:20,  1.59it/s]\u001b[A\n","Iteration:  98% 1820/1851 [19:12<00:19,  1.59it/s]\u001b[A\n","Iteration:  98% 1821/1851 [19:12<00:18,  1.59it/s]\u001b[A\n","Iteration:  98% 1822/1851 [19:13<00:18,  1.59it/s]\u001b[A\n","Iteration:  98% 1823/1851 [19:14<00:17,  1.58it/s]\u001b[A\n","Iteration:  99% 1824/1851 [19:14<00:17,  1.58it/s]\u001b[A\n","Iteration:  99% 1825/1851 [19:15<00:16,  1.58it/s]\u001b[A\n","Iteration:  99% 1826/1851 [19:15<00:15,  1.59it/s]\u001b[A\n","Iteration:  99% 1827/1851 [19:16<00:15,  1.58it/s]\u001b[A\n","Iteration:  99% 1828/1851 [19:17<00:14,  1.59it/s]\u001b[A\n","Iteration:  99% 1829/1851 [19:17<00:13,  1.59it/s]\u001b[A\n","Iteration:  99% 1830/1851 [19:18<00:13,  1.59it/s]\u001b[A\n","Iteration:  99% 1831/1851 [19:19<00:12,  1.59it/s]\u001b[A\n","Iteration:  99% 1832/1851 [19:19<00:11,  1.59it/s]\u001b[A\n","Iteration:  99% 1833/1851 [19:20<00:11,  1.59it/s]\u001b[A\n","Iteration:  99% 1834/1851 [19:20<00:10,  1.59it/s]\u001b[A\n","Iteration:  99% 1835/1851 [19:21<00:10,  1.59it/s]\u001b[A\n","Iteration:  99% 1836/1851 [19:22<00:09,  1.59it/s]\u001b[A\n","Iteration:  99% 1837/1851 [19:22<00:08,  1.59it/s]\u001b[A\n","Iteration:  99% 1838/1851 [19:23<00:08,  1.58it/s]\u001b[A\n","Iteration:  99% 1839/1851 [19:24<00:07,  1.58it/s]\u001b[A\n","Iteration:  99% 1840/1851 [19:24<00:06,  1.58it/s]\u001b[A\n","Iteration:  99% 1841/1851 [19:25<00:06,  1.58it/s]\u001b[A\n","Iteration: 100% 1842/1851 [19:26<00:05,  1.59it/s]\u001b[A\n","Iteration: 100% 1843/1851 [19:26<00:05,  1.59it/s]\u001b[A\n","Iteration: 100% 1844/1851 [19:27<00:04,  1.59it/s]\u001b[A\n","Iteration: 100% 1845/1851 [19:27<00:03,  1.59it/s]\u001b[A\n","Iteration: 100% 1846/1851 [19:28<00:03,  1.59it/s]\u001b[A\n","Iteration: 100% 1847/1851 [19:29<00:02,  1.59it/s]\u001b[A\n","Iteration: 100% 1848/1851 [19:29<00:01,  1.59it/s]\u001b[A\n","Iteration: 100% 1849/1851 [19:30<00:01,  1.59it/s]\u001b[A\n","Iteration: 100% 1850/1851 [19:31<00:00,  1.59it/s]\u001b[A\n","Iteration: 100% 1851/1851 [19:31<00:00,  1.58it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-16 08:10:59,687][__main__][DEBUG] - early stop\n","Epoch:   1% 1/100 [46:47<77:12:54, 2807.83s/it]\n"]}],"source":["!HYDRA_FULL_ERROR=1 python run.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"w7sdHHb0uFV-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660644019183,"user_tz":-540,"elapsed":6419274,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"b13e5b36-b05a-40ee-c061-ca9ec0bd27e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","eval.py:21: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-16 08:11:05,650][HYDRA] Hydra 1.2.0\n","[2022-08-16 08:11:05,651][HYDRA] ===========\n","[2022-08-16 08:11:05,651][HYDRA] Installed Hydra Plugins\n","[2022-08-16 08:11:05,651][HYDRA] ***********************\n","[2022-08-16 08:11:05,651][HYDRA] \tConfigSource:\n","[2022-08-16 08:11:05,651][HYDRA] \t-------------\n","[2022-08-16 08:11:05,651][HYDRA] \t\tFileConfigSource\n","[2022-08-16 08:11:05,651][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-16 08:11:05,651][HYDRA] \t\tStructuredConfigSource\n","[2022-08-16 08:11:05,651][HYDRA] \tCompletionPlugin:\n","[2022-08-16 08:11:05,651][HYDRA] \t-----------------\n","[2022-08-16 08:11:05,651][HYDRA] \t\tBashCompletion\n","[2022-08-16 08:11:05,651][HYDRA] \t\tFishCompletion\n","[2022-08-16 08:11:05,651][HYDRA] \t\tZshCompletion\n","[2022-08-16 08:11:05,651][HYDRA] \tLauncher:\n","[2022-08-16 08:11:05,651][HYDRA] \t---------\n","[2022-08-16 08:11:05,651][HYDRA] \t\tBasicLauncher\n","[2022-08-16 08:11:05,651][HYDRA] \tSweeper:\n","[2022-08-16 08:11:05,651][HYDRA] \t--------\n","[2022-08-16 08:11:05,651][HYDRA] \t\tBasicSweeper\n","[2022-08-16 08:11:05,651][HYDRA] \n","[2022-08-16 08:11:05,651][HYDRA] Config search path\n","[2022-08-16 08:11:05,651][HYDRA] ******************\n","[2022-08-16 08:11:05,936][HYDRA] | Provider | Search path                                                           |\n","[2022-08-16 08:11:05,936][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-16 08:11:05,936][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-16 08:11:05,936][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-16 08:11:05,936][HYDRA] | schema   | structured://                                                         |\n","[2022-08-16 08:11:05,936][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-16 08:11:06,007][HYDRA] \n","[2022-08-16 08:11:06,007][HYDRA] Defaults Tree\n","[2022-08-16 08:11:06,007][HYDRA] *************\n","[2022-08-16 08:11:06,007][HYDRA] <root>:\n","[2022-08-16 08:11:06,007][HYDRA]   hydra/config:\n","[2022-08-16 08:11:06,008][HYDRA]     hydra/output: default\n","[2022-08-16 08:11:06,008][HYDRA]     hydra/launcher: basic\n","[2022-08-16 08:11:06,008][HYDRA]     hydra/sweeper: basic\n","[2022-08-16 08:11:06,008][HYDRA]     hydra/help: default\n","[2022-08-16 08:11:06,008][HYDRA]     hydra/hydra_help: default\n","[2022-08-16 08:11:06,008][HYDRA]     hydra/hydra_logging: default\n","[2022-08-16 08:11:06,008][HYDRA]     hydra/job_logging: default\n","[2022-08-16 08:11:06,008][HYDRA]     hydra/callbacks: null\n","[2022-08-16 08:11:06,008][HYDRA]     hydra/env: default\n","[2022-08-16 08:11:06,008][HYDRA]     _self_\n","[2022-08-16 08:11:06,009][HYDRA]   config:\n","[2022-08-16 08:11:06,009][HYDRA]     data/FB15kET\n","[2022-08-16 08:11:06,009][HYDRA]     model/Bart\n","[2022-08-16 08:11:06,009][HYDRA]     _self_\n","[2022-08-16 08:11:06,077][HYDRA] \n","[2022-08-16 08:11:06,077][HYDRA] Defaults List\n","[2022-08-16 08:11:06,077][HYDRA] *************\n","[2022-08-16 08:11:06,077][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-16 08:11:06,077][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-16 08:11:06,077][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-16 08:11:06,077][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-16 08:11:06,077][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-16 08:11:06,077][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-16 08:11:06,077][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-16 08:11:06,077][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-16 08:11:06,077][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-16 08:11:06,077][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-16 08:11:06,077][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-16 08:11:06,077][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-08-16 08:11:06,077][HYDRA] | model/Bart                  | model               | False  | config       |\n","[2022-08-16 08:11:06,077][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-16 08:11:06,077][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-16 08:11:06,207][HYDRA] Config\n","[2022-08-16 08:11:06,207][HYDRA] ******\n","[2022-08-16 08:11:06,211][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: false\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: Bart\n","  train_dataset: ET_train.txt\n","  pretrained_model: facebook/bart-base\n","  append_another_bos: false\n","  append_sep_token: true\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 256\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 256\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_test.txt\n","    save_outputs: true\n","    max_output_length: 128\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: save/FB15kET/ET_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-16 08:11:06,294][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 08:11:06,294 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 08:11:07,062][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","2022-08-16 08:11:07,062 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-16 08:11:07,066][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 08:11:07,066 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 08:11:07,831][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","2022-08-16 08:11:07,831 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-16 08:11:07,833][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-16 08:11:07,833 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-16 08:11:07,834][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-16 08:11:07,834 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-16 08:11:15,531][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 08:11:15,531 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 08:11:16,300][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 0\n","2022-08-16 08:11:16,300 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 0\n","[2022-08-16 08:11:16,302][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","2022-08-16 08:11:16,302 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","[2022-08-16 08:11:16,303][transformers.configuration_utils][INFO] - Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\",\n","    \"BartForConditionalGeneration\",\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-16 08:11:16,303 INFO     Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\",\n","    \"BartForConditionalGeneration\",\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-16 08:11:16,305][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-16 08:11:16,305 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-16 08:11:17,249][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-16 08:11:17,249 DEBUG    https://cdn.huggingface.co:443 \"HEAD /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-16 08:11:17,251][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","2022-08-16 08:11:17,251 INFO     loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","[2022-08-16 08:11:20,373][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","2022-08-16 08:11:20,373 INFO     All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","[2022-08-16 08:11:20,373][transformers.modeling_utils][INFO] - All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","2022-08-16 08:11:20,373 INFO     All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","[2022-08-16 08:11:25,329][root][DEBUG] - Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","2022-08-16 08:11:25,329 DEBUG    Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","[2022-08-16 08:11:25,329][root][DEBUG] - Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","2022-08-16 08:11:25,329 DEBUG    Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-16 08:11:25,329][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,329 DEBUG    Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,330][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,330 DEBUG    Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,330][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,330 DEBUG    Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,330][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,330 DEBUG    Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,330][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,330 DEBUG    Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,330][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,330 DEBUG    Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,331][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,331 DEBUG    Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,331][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,331 DEBUG    Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,331][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,331 DEBUG    Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,331][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,331 DEBUG    Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,332][root][DEBUG] - Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,332 DEBUG    Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,332][root][DEBUG] - Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,332 DEBUG    Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,332][root][DEBUG] - Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,332 DEBUG    Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,332][root][DEBUG] - Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,332 DEBUG    Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,332][root][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,332 DEBUG    Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,333][root][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,333 DEBUG    Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,333][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,333 DEBUG    Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,333][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,333 DEBUG    Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,333][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,333 DEBUG    Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,333][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,333 DEBUG    Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,334][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,334 DEBUG    Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,334][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,334 DEBUG    Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,334][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,334 DEBUG    Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,334][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,334 DEBUG    Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,334][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,334 DEBUG    Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,334][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,334 DEBUG    Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,335][root][DEBUG] - Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,335 DEBUG    Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,335][root][DEBUG] - Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,335 DEBUG    Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,335][root][DEBUG] - Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,335 DEBUG    Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,335][root][DEBUG] - Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,335 DEBUG    Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,335][root][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,335 DEBUG    Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,336][root][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,336 DEBUG    Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,336][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,336 DEBUG    Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,336][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,336 DEBUG    Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,336][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,336 DEBUG    Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,336][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,336 DEBUG    Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,336][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,336 DEBUG    Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,337][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,337 DEBUG    Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,337][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,337 DEBUG    Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,337][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,337 DEBUG    Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,337][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,337 DEBUG    Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,337][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,337 DEBUG    Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,337][root][DEBUG] - Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,337 DEBUG    Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,338][root][DEBUG] - Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,338 DEBUG    Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,338][root][DEBUG] - Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,338 DEBUG    Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,338][root][DEBUG] - Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,338 DEBUG    Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,338][root][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,338 DEBUG    Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,338][root][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,338 DEBUG    Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,339][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,339 DEBUG    Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,339][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,339 DEBUG    Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,339][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,339 DEBUG    Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,339][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,339 DEBUG    Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,339][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,339 DEBUG    Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,339][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,339 DEBUG    Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,340][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,340 DEBUG    Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,340][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,340 DEBUG    Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,340][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,340 DEBUG    Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,340][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,340 DEBUG    Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,340][root][DEBUG] - Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,340 DEBUG    Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,341][root][DEBUG] - Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,341 DEBUG    Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,341][root][DEBUG] - Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,341 DEBUG    Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,341][root][DEBUG] - Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,341 DEBUG    Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,341][root][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,341 DEBUG    Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,341][root][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,341 DEBUG    Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,341][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,341 DEBUG    Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,342][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,342 DEBUG    Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,342][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,342 DEBUG    Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,342][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,342 DEBUG    Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,342][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,342 DEBUG    Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,342][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,342 DEBUG    Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,343][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,343 DEBUG    Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,343][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,343 DEBUG    Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,343][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,343 DEBUG    Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,343][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,343 DEBUG    Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,343][root][DEBUG] - Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,343 DEBUG    Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,343][root][DEBUG] - Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,343 DEBUG    Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,344][root][DEBUG] - Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,344 DEBUG    Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,344][root][DEBUG] - Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,344 DEBUG    Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,344][root][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,344 DEBUG    Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,344][root][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,344 DEBUG    Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,344][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,344 DEBUG    Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,345][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,345 DEBUG    Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,345][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,345 DEBUG    Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,345][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,345 DEBUG    Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,345][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,345 DEBUG    Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,345][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,345 DEBUG    Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,345][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,345 DEBUG    Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,346][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,346 DEBUG    Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,346][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,346 DEBUG    Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,346][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,346 DEBUG    Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,346][root][DEBUG] - Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,346 DEBUG    Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,346][root][DEBUG] - Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,346 DEBUG    Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,347][root][DEBUG] - Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,347 DEBUG    Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,347][root][DEBUG] - Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,347 DEBUG    Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,347][root][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,347 DEBUG    Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,347][root][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,347 DEBUG    Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,347][root][DEBUG] - Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,347 DEBUG    Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,347][root][DEBUG] - Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,347 DEBUG    Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,348][root][DEBUG] - Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","2022-08-16 08:11:25,348 DEBUG    Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-16 08:11:25,348][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,348 DEBUG    Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,348][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,348 DEBUG    Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,348][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,348 DEBUG    Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,348][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,348 DEBUG    Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,348][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,348 DEBUG    Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,349][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,349 DEBUG    Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,349][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,349 DEBUG    Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,349][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,349 DEBUG    Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,349][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,349 DEBUG    Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,349][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,349 DEBUG    Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,350][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,350 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,350][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,350 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,350][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,350 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,350][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,350 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,350][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,350 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,350][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,350 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,351][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,351 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,351][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,351 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,351][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,351 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,351][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,351 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,351][root][DEBUG] - Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,351 DEBUG    Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,352][root][DEBUG] - Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,352 DEBUG    Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,352][root][DEBUG] - Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,352 DEBUG    Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,352][root][DEBUG] - Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,352 DEBUG    Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,352][root][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,352 DEBUG    Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,352][root][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,352 DEBUG    Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,353][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,353 DEBUG    Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,353][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,353 DEBUG    Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,353][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,353 DEBUG    Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,353][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,353 DEBUG    Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,353][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,353 DEBUG    Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,353][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,353 DEBUG    Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,354][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,354 DEBUG    Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,354][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,354 DEBUG    Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,354][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,354 DEBUG    Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,354][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,354 DEBUG    Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,354][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,354 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,355][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,355 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,355][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,355 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,355][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,355 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,355][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,355 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,355][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,355 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,355][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,355 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,356][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,356 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,356][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,356 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,356][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,356 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,356][root][DEBUG] - Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,356 DEBUG    Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,356][root][DEBUG] - Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,356 DEBUG    Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,357][root][DEBUG] - Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,357 DEBUG    Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,357][root][DEBUG] - Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,357 DEBUG    Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,357][root][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,357 DEBUG    Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,357][root][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,357 DEBUG    Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,357][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,357 DEBUG    Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,357][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,357 DEBUG    Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,358][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,358 DEBUG    Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,358][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,358 DEBUG    Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,358][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,358 DEBUG    Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,358][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,358 DEBUG    Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,358][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,358 DEBUG    Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,359][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,359 DEBUG    Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,359][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,359 DEBUG    Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,359][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,359 DEBUG    Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,359][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,359 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,359][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,359 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,360][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,360 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,360][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,360 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,360][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,360 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,360][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,360 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,360][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,360 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,361][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,361 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,361][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,361 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,361][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,361 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,361][root][DEBUG] - Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,361 DEBUG    Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,361][root][DEBUG] - Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,361 DEBUG    Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,361][root][DEBUG] - Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,361 DEBUG    Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,362][root][DEBUG] - Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,362 DEBUG    Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,362][root][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,362 DEBUG    Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,362][root][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,362 DEBUG    Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,362][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,362 DEBUG    Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,362][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,362 DEBUG    Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,363][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,363 DEBUG    Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,363][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,363 DEBUG    Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,363][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,363 DEBUG    Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,363][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,363 DEBUG    Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,363][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,363 DEBUG    Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,363][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,363 DEBUG    Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,364][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,364 DEBUG    Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,364][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,364 DEBUG    Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,364][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,364 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,364][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,364 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,364][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,364 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,365][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,365 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,365][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,365 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,365][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,365 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,365][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,365 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,365][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,365 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,365][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,365 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,366][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,366 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,366][root][DEBUG] - Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,366 DEBUG    Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,366][root][DEBUG] - Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,366 DEBUG    Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,366][root][DEBUG] - Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,366 DEBUG    Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,366][root][DEBUG] - Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,366 DEBUG    Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,366][root][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,366 DEBUG    Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,367][root][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,367 DEBUG    Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,367][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,367 DEBUG    Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,367][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,367 DEBUG    Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,367][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,367 DEBUG    Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,367][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,367 DEBUG    Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,368][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,368 DEBUG    Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,368][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,368 DEBUG    Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,368][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,368 DEBUG    Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,458][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,458 DEBUG    Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,458][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,458 DEBUG    Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,459][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,459 DEBUG    Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,459][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,459 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,459][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,459 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,459][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,459 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,459][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,459 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,460][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,460 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,460][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,460 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,460][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,460 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,460][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,460 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,460][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,460 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,461][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,461 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,461][root][DEBUG] - Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,461 DEBUG    Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,461][root][DEBUG] - Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,461 DEBUG    Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,461][root][DEBUG] - Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,461 DEBUG    Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,461][root][DEBUG] - Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,461 DEBUG    Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,462][root][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,462 DEBUG    Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,462][root][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,462 DEBUG    Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,462][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,462 DEBUG    Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,462][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,462 DEBUG    Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,463][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,463 DEBUG    Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,463][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,463 DEBUG    Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,463][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,463 DEBUG    Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,463][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,463 DEBUG    Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,463][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,463 DEBUG    Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,463][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,463 DEBUG    Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,464][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,464 DEBUG    Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,464][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,464 DEBUG    Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,464][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,464 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,464][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,464 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,464][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,464 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,465][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,465 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,465][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,465 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,465][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,465 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,465][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 08:11:25,465 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 08:11:25,465][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,465 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,466][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,466 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,466][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,466 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,466][root][DEBUG] - Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 08:11:25,466 DEBUG    Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 08:11:25,466][root][DEBUG] - Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-16 08:11:25,466 DEBUG    Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-16 08:11:25,467][root][DEBUG] - Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 08:11:25,467 DEBUG    Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 08:11:25,467][root][DEBUG] - Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,467 DEBUG    Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,467][root][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,467 DEBUG    Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,467][root][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,467 DEBUG    Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,468][root][DEBUG] - Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,468 DEBUG    Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 08:11:25,468][root][DEBUG] - Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","2022-08-16 08:11:25,468 DEBUG    Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","Iteration:   0% 0/1082 [00:00<?, ?it/s]The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","Iteration: 100% 1082/1082 [1:43:32<00:00,  5.74s/it]\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","[2022-08-16 09:55:03,961][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 09:55:03,961 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 09:55:04,731][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-16 09:55:04,731 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-16 09:55:04,733][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-16 09:55:04,733 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-16 09:55:04,733][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-16 09:55:04,733 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-16 09:55:04,735][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 09:55:04,735 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 09:55:05,500][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","2022-08-16 09:55:05,500 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-16 09:55:05,503][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 09:55:05,503 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 09:55:06,270][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","2022-08-16 09:55:06,270 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-16 09:55:06,272][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-16 09:55:06,272 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-16 09:55:06,272][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-16 09:55:06,272 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-16 09:55:06,360][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 09:55:06,360 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 09:55:07,129][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-16 09:55:07,129 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-16 09:55:07,131][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-16 09:55:07,131 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-16 09:55:07,132][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-16 09:55:07,132 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-16 09:55:07,134][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-16 09:55:07,134 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-16 09:55:07,221][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-16 09:55:07,221 DEBUG    https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-16 09:55:07,223][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","2022-08-16 09:55:07,223 INFO     loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","[2022-08-16 09:55:15,933][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing RobertaModel.\n","\n","2022-08-16 09:55:15,933 INFO     All model checkpoint weights were used when initializing RobertaModel.\n","\n","[2022-08-16 09:55:15,933][transformers.modeling_utils][INFO] - All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","2022-08-16 09:55:15,933 INFO     All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","calculating scores...\n","computing bert embedding.\n","100% 197/197 [02:42<00:00,  1.21it/s]\n","computing greedy matching.\n","100% 136/136 [00:02<00:00, 58.05it/s]\n","done in 165.41 seconds, 52.33 sentences/sec\n","[2022-08-16 09:58:01,772][root][INFO] - test data set : ET_test.txt\n","2022-08-16 09:58:01,772 INFO     test data set : ET_test.txt\n","[2022-08-16 09:58:01,773][root][INFO] - N-grams: 1-0.006470443185711816, 2-0.0003973836199947962, 3-9.25695530593867e-06, 4-2.561120520753045e-309\n","2022-08-16 09:58:01,773 INFO     N-grams: 1-0.006470443185711816, 2-0.0003973836199947962, 3-9.25695530593867e-06, 4-2.561120520753045e-309\n","[2022-08-16 09:58:01,773][root][INFO] - BERT-P:0.760229, BERT-R:0.820034, BERT-F1:0.788846\n","2022-08-16 09:58:01,773 INFO     BERT-P:0.760229, BERT-R:0.820034, BERT-F1:0.788846\n"]}],"source":["!HYDRA_FULL_ERROR=1 python eval.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiRHm4nruPw9"},"outputs":[],"source":["!kill $(ps aux | awk '{print $2}')"]},{"cell_type":"code","source":[""],"metadata":{"id":"WPTZiAzwc_WZ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"cmd_train.ipynb","provenance":[],"mount_file_id":"1Mrwlgkjv2G7LOLpOtCehzWxaTRu9sXPA","authorship_tag":"ABX9TyM2dd7XQjK7MtzbhdCWkdas"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}