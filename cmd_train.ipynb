{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cmd_train.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1Mrwlgkjv2G7LOLpOtCehzWxaTRu9sXPA","authorship_tag":"ABX9TyMEs/DfhGRTESZkd/lhX3ai"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"dymDs0Po0aES","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658717845086,"user_tz":-540,"elapsed":930,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"6d07deaf-991a-41ac-c132-55c50adbe7d4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jul 25 02:55:12 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"],"metadata":{"id":"EfCxDoEXuzgg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658717845660,"user_tz":-540,"elapsed":582,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"ddc01197-5249-46fb-f91b-38d23d914bd2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}]},{"cell_type":"code","source":["!python -m pip install -r requirements.txt"],"metadata":{"id":"mshVPsrku0kd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658718298720,"user_tz":-540,"elapsed":453067,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"5cfa50c1-1f48-42d1-d561-341a28c12d3e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 13 kB/s \n","\u001b[?25hCollecting transformers==3.0.0\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[K     |████████████████████████████████| 754 kB 81.0 MB/s \n","\u001b[?25hCollecting torch_scatter==2.0.4\n","  Downloading torch_scatter-2.0.4.tar.gz (20 kB)\n","Collecting dgl==0.5.3\n","  Downloading dgl-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 74.8 MB/s \n","\u001b[?25hCollecting hydra==2.4\n","  Downloading Hydra-2.4.tar.gz (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 10.7 MB/s \n","\u001b[?25hCollecting omegaconf==2.2.2\n","  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (4.64.0)\n","Collecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 56.9 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 66.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (3.7.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2.23.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 75.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (2.6.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (1.7.3)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 91.0 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 65.9 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.1.0)\n","Building wheels for collected packages: torch-scatter, hydra, antlr4-python3-runtime, sacremoses\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-scatter: filename=torch_scatter-2.0.4-cp37-cp37m-linux_x86_64.whl size=14800530 sha256=e56a107a747ac7dca781758a78583e3cce6a24c01df716b5d406c4cabae0dcb9\n","  Stored in directory: /root/.cache/pip/wheels/4a/3d/01/e408ecc11389070cbacee91b70c978bf3557130e9aaa18a95b\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.4-cp37-cp37m-linux_x86_64.whl size=219212 sha256=25720d4648c458a210c0462f00e7be12a68f48b477f39bb9768fa49fc9f3285e\n","  Stored in directory: /root/.cache/pip/wheels/f5/65/98/3603b340344bd22dfe1c809365013fc4d425d83d89c3e2cd17\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=e5a8e1f5eddae08cfe020c13f8445b1ad5ba4ae134e05c060533b291b0d09b3e\n","  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=7fd6883506e82a73cad13974729f43ee3e7f17d15526d2b93315211176b21ab0\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built torch-scatter hydra antlr4-python3-runtime sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, PyYAML, antlr4-python3-runtime, transformers, torch-scatter, torch, omegaconf, hydra, dgl\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.8.0 which is incompatible.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.9.3 dgl-0.5.3 hydra-2.4 omegaconf-2.2.2 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.8.0rc4 torch-1.8.0 torch-scatter-2.0.4 transformers-3.0.0\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"G8LmQt_jcvSZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658718438883,"user_tz":-540,"elapsed":140179,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"15974a72-54a5-4e50-9f37-66e32e22b17f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 121 kB/s eta 2:45:40tcmalloc: large alloc 1147494400 bytes == 0x394a4000 @  0x7fa311acf615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:44tcmalloc: large alloc 1434370048 bytes == 0x7dafa000 @  0x7fa311acf615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.3 MB/s eta 0:09:24tcmalloc: large alloc 1792966656 bytes == 0x292c000 @  0x7fa311acf615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 74.1 MB/s eta 0:00:05tcmalloc: large alloc 2241208320 bytes == 0x6d714000 @  0x7fa311acf615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf3076000 @  0x7fa311ace1e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2551685120 bytes == 0x1e0ffe000 @  0x7fa311acf615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 2041.3 MB 7.0 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 64.8 MB/s \n","\u001b[?25hCollecting torchaudio===0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 15.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.8.0\n","    Uninstalling torch-1.8.0:\n","      Successfully uninstalled torch-1.8.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.0+cu113\n","    Uninstalling torchvision-0.13.0+cu113:\n","      Successfully uninstalled torchvision-0.13.0+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.0+cu113\n","    Uninstalling torchaudio-0.12.0+cu113:\n","      Successfully uninstalled torchaudio-0.12.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}],"source":["!python -m pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","source":["!python -m pip uninstall torch-scatter -y"],"metadata":{"id":"JJqgY88ou7Qp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658718439526,"user_tz":-540,"elapsed":653,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"e3c35424-e019-405d-c4ce-80754b12e218"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch-scatter 2.0.4\n","Uninstalling torch-scatter-2.0.4:\n","  Successfully uninstalled torch-scatter-2.0.4\n"]}]},{"cell_type":"code","source":["!python -m pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html"],"metadata":{"id":"7c7V5B7yc9Cc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658718445023,"user_tz":-540,"elapsed":5502,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"78f0983c-7563-4143-b699-889f1bfc5e60"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 26.2 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.9\n"]}]},{"cell_type":"code","source":["!python -c \"import torch_scatter; print(torch_scatter.__version__)\""],"metadata":{"id":"l2wm30u-c-i0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658718445630,"user_tz":-540,"elapsed":614,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"045a0d7c-e317-4efc-add8-2f22054c374d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.9\n"]}]},{"cell_type":"code","source":["!pip install hydra-core --upgrade"],"metadata":{"id":"GgPMOQSL4HVZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658718449696,"user_tz":-540,"elapsed":4071,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"aafa114e-0152-40d6-d34f-ab9f0c30a3b6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 32.5 MB/s \n","\u001b[?25hRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core) (21.3)\n","Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.2.2)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.8.0)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core) (3.0.9)\n","Installing collected packages: hydra-core\n","Successfully installed hydra-core-1.2.0\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FT5vluqcNpey","executionInfo":{"status":"ok","timestamp":1658391076700,"user_tz":-540,"elapsed":430,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"509c51db-1dbe-4933-9f2e-c92aba3546bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data\n"]}]},{"cell_type":"code","source":["!python preprocess.py --dataset FB15kET"],"metadata":{"id":"PZROa2w4NUfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python preprocess.py --dataset YAGO43kET"],"metadata":{"id":"mDB7erFzN4St"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"],"metadata":{"id":"hsnRA4_pUSzk","executionInfo":{"status":"ok","timestamp":1658748059941,"user_tz":-540,"elapsed":10,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"391692eb-9dd6-4bb8-de62-81f3877a7a9d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}]},{"cell_type":"code","source":["!HYDRA_FULL_ERROR=1 python run.py hydra.job.chdir=False hydra.verbose=True"],"metadata":{"id":"586hjT34u-VB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"299ecd21-30c0-4861-b64c-aaa1efc1fcd5","executionInfo":{"status":"ok","timestamp":1658751335957,"user_tz":-540,"elapsed":3276022,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","run.py:16: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-07-25 11:18:53,564][HYDRA] Hydra 1.2.0\n","[2022-07-25 11:18:53,565][HYDRA] ===========\n","[2022-07-25 11:18:53,565][HYDRA] Installed Hydra Plugins\n","[2022-07-25 11:18:53,565][HYDRA] ***********************\n","[2022-07-25 11:18:53,565][HYDRA] \tConfigSource:\n","[2022-07-25 11:18:53,565][HYDRA] \t-------------\n","[2022-07-25 11:18:53,565][HYDRA] \t\tFileConfigSource\n","[2022-07-25 11:18:53,565][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-07-25 11:18:53,565][HYDRA] \t\tStructuredConfigSource\n","[2022-07-25 11:18:53,565][HYDRA] \tCompletionPlugin:\n","[2022-07-25 11:18:53,565][HYDRA] \t-----------------\n","[2022-07-25 11:18:53,565][HYDRA] \t\tBashCompletion\n","[2022-07-25 11:18:53,565][HYDRA] \t\tFishCompletion\n","[2022-07-25 11:18:53,565][HYDRA] \t\tZshCompletion\n","[2022-07-25 11:18:53,565][HYDRA] \tLauncher:\n","[2022-07-25 11:18:53,565][HYDRA] \t---------\n","[2022-07-25 11:18:53,565][HYDRA] \t\tBasicLauncher\n","[2022-07-25 11:18:53,565][HYDRA] \tSweeper:\n","[2022-07-25 11:18:53,565][HYDRA] \t--------\n","[2022-07-25 11:18:53,565][HYDRA] \t\tBasicSweeper\n","[2022-07-25 11:18:53,566][HYDRA] \n","[2022-07-25 11:18:53,566][HYDRA] Config search path\n","[2022-07-25 11:18:53,566][HYDRA] ******************\n","[2022-07-25 11:18:53,692][HYDRA] | Provider | Search path                                                           |\n","[2022-07-25 11:18:53,692][HYDRA] ------------------------------------------------------------------------------------\n","[2022-07-25 11:18:53,693][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-07-25 11:18:53,693][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-07-25 11:18:53,693][HYDRA] | schema   | structured://                                                         |\n","[2022-07-25 11:18:53,693][HYDRA] ------------------------------------------------------------------------------------\n","[2022-07-25 11:18:53,764][HYDRA] \n","[2022-07-25 11:18:53,764][HYDRA] Defaults Tree\n","[2022-07-25 11:18:53,764][HYDRA] *************\n","[2022-07-25 11:18:53,764][HYDRA] <root>:\n","[2022-07-25 11:18:53,764][HYDRA]   hydra/config:\n","[2022-07-25 11:18:53,764][HYDRA]     hydra/output: default\n","[2022-07-25 11:18:53,764][HYDRA]     hydra/launcher: basic\n","[2022-07-25 11:18:53,764][HYDRA]     hydra/sweeper: basic\n","[2022-07-25 11:18:53,765][HYDRA]     hydra/help: default\n","[2022-07-25 11:18:53,765][HYDRA]     hydra/hydra_help: default\n","[2022-07-25 11:18:53,765][HYDRA]     hydra/hydra_logging: default\n","[2022-07-25 11:18:53,765][HYDRA]     hydra/job_logging: default\n","[2022-07-25 11:18:53,765][HYDRA]     hydra/callbacks: null\n","[2022-07-25 11:18:53,765][HYDRA]     hydra/env: default\n","[2022-07-25 11:18:53,765][HYDRA]     _self_\n","[2022-07-25 11:18:53,765][HYDRA]   config:\n","[2022-07-25 11:18:53,765][HYDRA]     data/FB15kET\n","[2022-07-25 11:18:53,765][HYDRA]     model/JointGT\n","[2022-07-25 11:18:53,765][HYDRA]     _self_\n","[2022-07-25 11:18:53,834][HYDRA] \n","[2022-07-25 11:18:53,834][HYDRA] Defaults List\n","[2022-07-25 11:18:53,834][HYDRA] *************\n","[2022-07-25 11:18:53,834][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-07-25 11:18:53,834][HYDRA] ------------------------------------------------------------------------------\n","[2022-07-25 11:18:53,834][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-07-25 11:18:53,834][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-07-25 11:18:53,834][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-07-25 11:18:53,834][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-07-25 11:18:53,834][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-07-25 11:18:53,835][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-07-25 11:18:53,835][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-07-25 11:18:53,835][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-07-25 11:18:53,835][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-07-25 11:18:53,835][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-07-25 11:18:53,835][HYDRA] | model/JointGT               | model               | False  | config       |\n","[2022-07-25 11:18:53,835][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-07-25 11:18:53,835][HYDRA] ------------------------------------------------------------------------------\n","[2022-07-25 11:18:53,957][HYDRA] Config\n","[2022-07-25 11:18:53,957][HYDRA] ******\n","[2022-07-25 11:18:53,961][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: false\n","  remove_under_score: false\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: JointGT\n","  tokenizer_path: pretrain_model/jointgt_bart\n","  model_path: pretrain_model/jointgt_bart\n","  train_dataset: ET_train.txt\n","  pretrained_model: Bart\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_node_length: 50\n","  max_edge_length: 60\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 128\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 1.0e-05\n","  valid:\n","    valid_dataset: ET_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 128\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_test.txt\n","    save_outputs: true\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-07-25 11:18:54,027][transformers.tokenization_utils_base][INFO] - Model name 'pretrain_model/jointgt_bart' not found in model shortcut name list (facebook/bart-base, facebook/bart-large, facebook/bart-large-mnli, facebook/bart-large-cnn, facebook/bart-large-xsum, yjernite/bart_eli5). Assuming 'pretrain_model/jointgt_bart' is a path, a model identifier, or url to a directory containing tokenizer files.\n","[2022-07-25 11:18:54,029][transformers.tokenization_utils_base][INFO] - Didn't find file pretrain_model/jointgt_bart/added_tokens.json. We won't load it.\n","[2022-07-25 11:18:54,029][transformers.tokenization_utils_base][INFO] - Didn't find file pretrain_model/jointgt_bart/special_tokens_map.json. We won't load it.\n","[2022-07-25 11:18:54,030][transformers.tokenization_utils_base][INFO] - Didn't find file pretrain_model/jointgt_bart/tokenizer_config.json. We won't load it.\n","[2022-07-25 11:18:54,030][transformers.tokenization_utils_base][INFO] - Didn't find file pretrain_model/jointgt_bart/tokenizer.json. We won't load it.\n","[2022-07-25 11:18:54,031][transformers.tokenization_utils_base][INFO] - loading file pretrain_model/jointgt_bart/vocab.json\n","[2022-07-25 11:18:54,031][transformers.tokenization_utils_base][INFO] - loading file pretrain_model/jointgt_bart/merges.txt\n","[2022-07-25 11:18:54,031][transformers.tokenization_utils_base][INFO] - loading file None\n","[2022-07-25 11:18:54,031][transformers.tokenization_utils_base][INFO] - loading file None\n","[2022-07-25 11:18:54,031][transformers.tokenization_utils_base][INFO] - loading file None\n","[2022-07-25 11:18:54,031][transformers.tokenization_utils_base][INFO] - loading file None\n","[2022-07-25 11:19:09,841][transformers.configuration_utils][INFO] - loading configuration file pretrain_model/jointgt_bart/config.json\n","[2022-07-25 11:19:09,842][transformers.configuration_utils][INFO] - Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"MyBartPretrain\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-07-25 11:19:09,843][transformers.modeling_utils][INFO] - loading weights file pretrain_model/jointgt_bart/pytorch_model.bin\n","[2022-07-25 11:19:16,345][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing MyBartForConditionalGeneration.\n","\n","[2022-07-25 11:19:16,345][transformers.modeling_utils][INFO] - All the weights of MyBartForConditionalGeneration were initialized from the model checkpoint at pretrain_model/jointgt_bart.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use MyBartForConditionalGeneration for predictions without further training.\n","[2022-07-25 11:19:21,336][__main__][DEBUG] - Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","[2022-07-25 11:19:21,337][__main__][DEBUG] - Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-07-25 11:19:21,337][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,337][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,337][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,337][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,337][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,337][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,338][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,338][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,338][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,338][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,338][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,338][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,338][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,338][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,338][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,339][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,340][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,340][__main__][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,340][__main__][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,340][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,340][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,340][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,340][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,340][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,340][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,341][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,341][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,341][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,341][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,341][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,341][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,341][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,341][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,341][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,342][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,343][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,343][__main__][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,343][__main__][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,343][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,343][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,343][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,343][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,343][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,343][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,344][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,344][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,344][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,344][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,344][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,344][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,344][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,344][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,344][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,345][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,345][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,345][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,345][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,345][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,345][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,345][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,345][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,346][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,346][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,346][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,346][__main__][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,346][__main__][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,346][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,346][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,346][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,346][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,347][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,348][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,348][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,348][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,348][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,348][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,348][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,348][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,348][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,348][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,349][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,349][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,349][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,349][__main__][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,349][__main__][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,349][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,349][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,349][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,349][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,350][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,350][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,350][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,396][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,396][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,396][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,396][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,397][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,397][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,397][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,397][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,398][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,398][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,398][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,398][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,398][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,398][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,399][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,399][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,399][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,399][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,399][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,400][__main__][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,400][__main__][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,400][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,400][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,400][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,400][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,401][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,402][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,403][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,404][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,405][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,406][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,407][__main__][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,408][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,409][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,410][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,410][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,410][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,410][__main__][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,410][__main__][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,410][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,411][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,411][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,411][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,411][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,411][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,411][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,412][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,412][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,412][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,412][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,412][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,413][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,413][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,501][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,501][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,502][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,502][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,502][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,502][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,502][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,502][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,503][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,503][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,503][__main__][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,503][__main__][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,504][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,504][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,504][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,504][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,504][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,505][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,505][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,505][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,505][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,505][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,505][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,506][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,506][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,506][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,506][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,506][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,507][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,507][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,507][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,507][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,507][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,507][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,508][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,508][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,508][__main__][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,508][__main__][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,508][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,508][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,509][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,509][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,509][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,509][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,509][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,510][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,510][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,510][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,510][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,510][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,510][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,511][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,511][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,511][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,511][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 11:19:21,511][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,511][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,512][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,512][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 11:19:21,512][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 11:19:21,512][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 11:19:21,512][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,512][__main__][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,513][__main__][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,513][__main__][DEBUG] - Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 11:19:21,513][__main__][DEBUG] - Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","Epoch:   0% 0/100 [00:00<?, ?it/s][2022-07-25 11:19:21,515][__main__][DEBUG] - Starting training!\n","\n","Iteration:   0% 0/1851 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-07-25 11:19:22,625][__main__][DEBUG] - batch 0: tensor([[    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        ...,\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2]], device='cuda:0') \n","[2022-07-25 11:19:22,637][__main__][DEBUG] - batch 1: tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') \n","[2022-07-25 11:19:22,639][__main__][DEBUG] - batch 2: tensor([[    0,  1589, 11070,  ...,     1,     1,     1],\n","        [    0,  1589, 28400,  ...,     1,     1,     1],\n","        [    0,  1589, 28030,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  1589,  1584,  ...,     1,     1,     1],\n","        [    0,  1589, 41829,  ...,     1,     1,     1],\n","        [    0,  1589, 12105,  ..., 10750,    73,     2]], device='cuda:0') \n","[2022-07-25 11:19:22,641][__main__][DEBUG] - batch 3: tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') \n","[2022-07-25 11:19:22,643][__main__][DEBUG] - batch 4: tensor([[50, 50, 50,  ..., 50, 50, 50],\n","        [50, 50, 50,  ..., 50, 50, 50],\n","        [50, 50, 50,  ..., 50, 50, 50],\n","        ...,\n","        [50, 50, 50,  ..., 50, 50, 50],\n","        [50, 50, 50,  ..., 50, 50, 50],\n","        [50, 50, 50,  ..., 50, 50, 50]], device='cuda:0') \n","[2022-07-25 11:19:22,648][__main__][DEBUG] - batch 5: tensor([[60, 60, 60,  ..., 60, 60, 60],\n","        [60, 60, 60,  ..., 60, 60, 60],\n","        [60, 60, 60,  ..., 60, 60, 60],\n","        ...,\n","        [60, 60, 60,  ..., 60, 60, 60],\n","        [60, 60, 60,  ..., 60, 60, 60],\n","        [60, 60, 60,  ..., 60, 60, 60]], device='cuda:0') \n","[2022-07-25 11:19:22,651][__main__][DEBUG] - batch 6: tensor([[183],\n","        [ 11],\n","        [  7],\n","        [ 47],\n","        [  7],\n","        [ 36],\n","        [ 19],\n","        [ 44]], device='cuda:0') \n","[2022-07-25 11:19:22,659][__main__][DEBUG] - batch 7: tensor([[10],\n","        [ 2],\n","        [ 9],\n","        [27],\n","        [ 6],\n","        [23],\n","        [13],\n","        [17]], device='cuda:0') \n","[2022-07-25 11:19:22,668][__main__][DEBUG] - batch 8: tensor([[[60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         ...,\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60]],\n","\n","        [[60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         ...,\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60]],\n","\n","        [[60, 60,  4,  ..., 60, 60, 60],\n","         [60, 60,  0,  ..., 60, 60, 60],\n","         [11,  5, 60,  ..., 60, 60, 60],\n","         ...,\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60]],\n","\n","        ...,\n","\n","        [[60, 60,  9,  ..., 60, 60, 60],\n","         [60, 60,  0,  ..., 60, 60, 60],\n","         [36, 28, 60,  ..., 60, 60, 60],\n","         ...,\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60]],\n","\n","        [[60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         ...,\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60]],\n","\n","        [[60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         ...,\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60],\n","         [60, 60, 60,  ..., 60, 60, 60]]], device='cuda:0') \n","\n","Iteration:   0% 1/1851 [00:01<1:00:04,  1.95s/it]\u001b[A\n","Iteration:   0% 2/1851 [00:02<37:10,  1.21s/it]  \u001b[A\n","Iteration:   0% 3/1851 [00:03<29:56,  1.03it/s]\u001b[A\n","Iteration:   0% 4/1851 [00:04<26:29,  1.16it/s]\u001b[A\n","Iteration:   0% 5/1851 [00:04<24:37,  1.25it/s]\u001b[A\n","Iteration:   0% 6/1851 [00:05<23:28,  1.31it/s]\u001b[A\n","Iteration:   0% 7/1851 [00:06<22:41,  1.35it/s]\u001b[A\n","Iteration:   0% 8/1851 [00:06<22:15,  1.38it/s]\u001b[A\n","Iteration:   0% 9/1851 [00:07<21:55,  1.40it/s]\u001b[A\n","Iteration:   1% 10/1851 [00:08<21:43,  1.41it/s]\u001b[A\n","Iteration:   1% 11/1851 [00:08<21:34,  1.42it/s]\u001b[A\n","Iteration:   1% 12/1851 [00:09<21:27,  1.43it/s]\u001b[A\n","Iteration:   1% 13/1851 [00:10<21:22,  1.43it/s]\u001b[A\n","Iteration:   1% 14/1851 [00:10<21:18,  1.44it/s]\u001b[A\n","Iteration:   1% 15/1851 [00:11<21:17,  1.44it/s]\u001b[A\n","Iteration:   1% 16/1851 [00:12<21:13,  1.44it/s]\u001b[A\n","Iteration:   1% 17/1851 [00:13<21:11,  1.44it/s]\u001b[A\n","Iteration:   1% 18/1851 [00:13<21:14,  1.44it/s]\u001b[A\n","Iteration:   1% 19/1851 [00:14<21:14,  1.44it/s]\u001b[A\n","Iteration:   1% 20/1851 [00:15<21:13,  1.44it/s]\u001b[A\n","Iteration:   1% 21/1851 [00:15<21:12,  1.44it/s]\u001b[A\n","Iteration:   1% 22/1851 [00:16<21:09,  1.44it/s]\u001b[A\n","Iteration:   1% 23/1851 [00:17<21:15,  1.43it/s]\u001b[A\n","Iteration:   1% 24/1851 [00:17<21:13,  1.43it/s]\u001b[A\n","Iteration:   1% 25/1851 [00:18<21:12,  1.44it/s]\u001b[A\n","Iteration:   1% 26/1851 [00:19<21:13,  1.43it/s]\u001b[A\n","Iteration:   1% 27/1851 [00:19<21:13,  1.43it/s]\u001b[A\n","Iteration:   2% 28/1851 [00:20<21:10,  1.43it/s]\u001b[A\n","Iteration:   2% 29/1851 [00:21<21:14,  1.43it/s]\u001b[A\n","Iteration:   2% 30/1851 [00:22<21:10,  1.43it/s]\u001b[A\n","Iteration:   2% 31/1851 [00:22<21:09,  1.43it/s]\u001b[A\n","Iteration:   2% 32/1851 [00:23<21:12,  1.43it/s]\u001b[A\n","Iteration:   2% 33/1851 [00:24<21:15,  1.43it/s]\u001b[A\n","Iteration:   2% 34/1851 [00:24<21:12,  1.43it/s]\u001b[A\n","Iteration:   2% 35/1851 [00:25<21:14,  1.42it/s]\u001b[A\n","Iteration:   2% 36/1851 [00:26<21:10,  1.43it/s]\u001b[A\n","Iteration:   2% 37/1851 [00:26<21:13,  1.42it/s]\u001b[A\n","Iteration:   2% 38/1851 [00:27<21:08,  1.43it/s]\u001b[A\n","Iteration:   2% 39/1851 [00:28<21:11,  1.42it/s]\u001b[A\n","Iteration:   2% 40/1851 [00:29<21:13,  1.42it/s]\u001b[A\n","Iteration:   2% 41/1851 [00:29<21:18,  1.42it/s]\u001b[A\n","Iteration:   2% 42/1851 [00:30<21:20,  1.41it/s]\u001b[A\n","Iteration:   2% 43/1851 [00:31<21:15,  1.42it/s]\u001b[A\n","Iteration:   2% 44/1851 [00:31<21:12,  1.42it/s]\u001b[A\n","Iteration:   2% 45/1851 [00:32<21:14,  1.42it/s]\u001b[A\n","Iteration:   2% 46/1851 [00:33<21:15,  1.42it/s]\u001b[A\n","Iteration:   3% 47/1851 [00:34<21:16,  1.41it/s]\u001b[A\n","Iteration:   3% 48/1851 [00:34<21:16,  1.41it/s]\u001b[A\n","Iteration:   3% 49/1851 [00:35<21:17,  1.41it/s]\u001b[A\n","Iteration:   3% 50/1851 [00:36<21:17,  1.41it/s]\u001b[A\n","Iteration:   3% 51/1851 [00:36<21:16,  1.41it/s]\u001b[A\n","Iteration:   3% 52/1851 [00:37<21:17,  1.41it/s]\u001b[A\n","Iteration:   3% 53/1851 [00:38<21:16,  1.41it/s]\u001b[A\n","Iteration:   3% 54/1851 [00:39<21:14,  1.41it/s]\u001b[A\n","Iteration:   3% 55/1851 [00:39<21:15,  1.41it/s]\u001b[A\n","Iteration:   3% 56/1851 [00:40<21:15,  1.41it/s]\u001b[A\n","Iteration:   3% 57/1851 [00:41<21:15,  1.41it/s]\u001b[A\n","Iteration:   3% 58/1851 [00:41<21:14,  1.41it/s]\u001b[A\n","Iteration:   3% 59/1851 [00:42<21:12,  1.41it/s]\u001b[A\n","Iteration:   3% 60/1851 [00:43<21:10,  1.41it/s]\u001b[A\n","Iteration:   3% 61/1851 [00:44<21:10,  1.41it/s]\u001b[A\n","Iteration:   3% 62/1851 [00:44<21:09,  1.41it/s]\u001b[A\n","Iteration:   3% 63/1851 [00:45<21:10,  1.41it/s]\u001b[A\n","Iteration:   3% 64/1851 [00:46<21:10,  1.41it/s]\u001b[A\n","Iteration:   4% 65/1851 [00:46<21:08,  1.41it/s]\u001b[A\n","Iteration:   4% 66/1851 [00:47<21:08,  1.41it/s]\u001b[A\n","Iteration:   4% 67/1851 [00:48<21:08,  1.41it/s]\u001b[A\n","Iteration:   4% 68/1851 [00:48<21:06,  1.41it/s]\u001b[A\n","Iteration:   4% 69/1851 [00:49<21:06,  1.41it/s]\u001b[A\n","Iteration:   4% 70/1851 [00:50<21:06,  1.41it/s]\u001b[A\n","Iteration:   4% 71/1851 [00:51<21:15,  1.40it/s]\u001b[A\n","Iteration:   4% 72/1851 [00:51<21:12,  1.40it/s]\u001b[A\n","Iteration:   4% 73/1851 [00:52<21:09,  1.40it/s]\u001b[A\n","Iteration:   4% 74/1851 [00:53<21:06,  1.40it/s]\u001b[A\n","Iteration:   4% 75/1851 [00:53<21:07,  1.40it/s]\u001b[A\n","Iteration:   4% 76/1851 [00:54<21:02,  1.41it/s]\u001b[A\n","Iteration:   4% 77/1851 [00:55<21:03,  1.40it/s]\u001b[A\n","Iteration:   4% 78/1851 [00:56<21:08,  1.40it/s]\u001b[A\n","Iteration:   4% 79/1851 [00:56<21:05,  1.40it/s]\u001b[A\n","Iteration:   4% 80/1851 [00:57<21:05,  1.40it/s]\u001b[A\n","Iteration:   4% 81/1851 [00:58<21:08,  1.39it/s]\u001b[A\n","Iteration:   4% 82/1851 [00:58<21:07,  1.40it/s]\u001b[A\n","Iteration:   4% 83/1851 [00:59<21:06,  1.40it/s]\u001b[A\n","Iteration:   5% 84/1851 [01:00<21:08,  1.39it/s]\u001b[A\n","Iteration:   5% 85/1851 [01:01<21:05,  1.40it/s]\u001b[A\n","Iteration:   5% 86/1851 [01:01<21:07,  1.39it/s]\u001b[A\n","Iteration:   5% 87/1851 [01:02<21:06,  1.39it/s]\u001b[A\n","Iteration:   5% 88/1851 [01:03<21:06,  1.39it/s]\u001b[A\n","Iteration:   5% 89/1851 [01:04<21:09,  1.39it/s]\u001b[A\n","Iteration:   5% 90/1851 [01:04<21:08,  1.39it/s]\u001b[A\n","Iteration:   5% 91/1851 [01:05<21:08,  1.39it/s]\u001b[A\n","Iteration:   5% 92/1851 [01:06<21:06,  1.39it/s]\u001b[A\n","Iteration:   5% 93/1851 [01:06<21:07,  1.39it/s]\u001b[A\n","Iteration:   5% 94/1851 [01:07<21:10,  1.38it/s]\u001b[A\n","Iteration:   5% 95/1851 [01:08<21:07,  1.39it/s]\u001b[A\n","Iteration:   5% 96/1851 [01:09<21:08,  1.38it/s]\u001b[A\n","Iteration:   5% 97/1851 [01:09<21:10,  1.38it/s]\u001b[A\n","Iteration:   5% 98/1851 [01:10<21:13,  1.38it/s]\u001b[A\n","Iteration:   5% 99/1851 [01:11<21:15,  1.37it/s]\u001b[A\n","Iteration:   5% 100/1851 [01:11<21:11,  1.38it/s]\u001b[A\n","Iteration:   5% 101/1851 [01:12<21:09,  1.38it/s]\u001b[A\n","Iteration:   6% 102/1851 [01:13<21:09,  1.38it/s]\u001b[A\n","Iteration:   6% 103/1851 [01:14<21:10,  1.38it/s]\u001b[A\n","Iteration:   6% 104/1851 [01:14<21:11,  1.37it/s]\u001b[A\n","Iteration:   6% 105/1851 [01:15<21:08,  1.38it/s]\u001b[A\n","Iteration:   6% 106/1851 [01:16<21:08,  1.38it/s]\u001b[A\n","Iteration:   6% 107/1851 [01:17<21:09,  1.37it/s]\u001b[A\n","Iteration:   6% 108/1851 [01:17<21:10,  1.37it/s]\u001b[A\n","Iteration:   6% 109/1851 [01:18<21:09,  1.37it/s]\u001b[A\n","Iteration:   6% 110/1851 [01:19<21:11,  1.37it/s]\u001b[A\n","Iteration:   6% 111/1851 [01:20<21:12,  1.37it/s]\u001b[A\n","Iteration:   6% 112/1851 [01:20<21:12,  1.37it/s]\u001b[A\n","Iteration:   6% 113/1851 [01:21<21:12,  1.37it/s]\u001b[A\n","Iteration:   6% 114/1851 [01:22<21:11,  1.37it/s]\u001b[A\n","Iteration:   6% 115/1851 [01:22<21:11,  1.37it/s]\u001b[A\n","Iteration:   6% 116/1851 [01:23<21:10,  1.37it/s]\u001b[A\n","Iteration:   6% 117/1851 [01:24<21:11,  1.36it/s]\u001b[A\n","Iteration:   6% 118/1851 [01:25<21:08,  1.37it/s]\u001b[A\n","Iteration:   6% 119/1851 [01:25<21:08,  1.37it/s]\u001b[A\n","Iteration:   6% 120/1851 [01:26<21:08,  1.36it/s]\u001b[A\n","Iteration:   7% 121/1851 [01:27<21:08,  1.36it/s]\u001b[A\n","Iteration:   7% 122/1851 [01:28<21:06,  1.37it/s]\u001b[A\n","Iteration:   7% 123/1851 [01:28<21:05,  1.37it/s]\u001b[A\n","Iteration:   7% 124/1851 [01:29<21:04,  1.37it/s]\u001b[A\n","Iteration:   7% 125/1851 [01:30<21:04,  1.36it/s]\u001b[A\n","Iteration:   7% 126/1851 [01:30<21:02,  1.37it/s]\u001b[A\n","Iteration:   7% 127/1851 [01:31<21:04,  1.36it/s]\u001b[A\n","Iteration:   7% 128/1851 [01:32<21:03,  1.36it/s]\u001b[A\n","Iteration:   7% 129/1851 [01:33<21:05,  1.36it/s]\u001b[A\n","Iteration:   7% 130/1851 [01:33<21:06,  1.36it/s]\u001b[A\n","Iteration:   7% 131/1851 [01:34<21:02,  1.36it/s]\u001b[A\n","Iteration:   7% 132/1851 [01:35<21:06,  1.36it/s]\u001b[A\n","Iteration:   7% 133/1851 [01:36<21:03,  1.36it/s]\u001b[A\n","Iteration:   7% 134/1851 [01:36<21:00,  1.36it/s]\u001b[A\n","Iteration:   7% 135/1851 [01:37<20:59,  1.36it/s]\u001b[A\n","Iteration:   7% 136/1851 [01:38<21:01,  1.36it/s]\u001b[A\n","Iteration:   7% 137/1851 [01:39<21:03,  1.36it/s]\u001b[A\n","Iteration:   7% 138/1851 [01:39<21:02,  1.36it/s]\u001b[A\n","Iteration:   8% 139/1851 [01:40<21:04,  1.35it/s]\u001b[A\n","Iteration:   8% 140/1851 [01:41<21:02,  1.35it/s]\u001b[A\n","Iteration:   8% 141/1851 [01:42<21:06,  1.35it/s]\u001b[A\n","Iteration:   8% 142/1851 [01:42<21:08,  1.35it/s]\u001b[A\n","Iteration:   8% 143/1851 [01:43<21:05,  1.35it/s]\u001b[A\n","Iteration:   8% 144/1851 [01:44<21:07,  1.35it/s]\u001b[A\n","Iteration:   8% 145/1851 [01:45<21:03,  1.35it/s]\u001b[A\n","Iteration:   8% 146/1851 [01:45<21:06,  1.35it/s]\u001b[A\n","Iteration:   8% 147/1851 [01:46<21:04,  1.35it/s]\u001b[A\n","Iteration:   8% 148/1851 [01:47<21:05,  1.35it/s]\u001b[A\n","Iteration:   8% 149/1851 [01:48<21:07,  1.34it/s]\u001b[A\n","Iteration:   8% 150/1851 [01:48<21:05,  1.34it/s]\u001b[A\n","Iteration:   8% 151/1851 [01:49<21:05,  1.34it/s]\u001b[A\n","Iteration:   8% 152/1851 [01:50<21:06,  1.34it/s]\u001b[A\n","Iteration:   8% 153/1851 [01:50<21:06,  1.34it/s]\u001b[A\n","Iteration:   8% 154/1851 [01:51<21:07,  1.34it/s]\u001b[A\n","Iteration:   8% 155/1851 [01:52<21:07,  1.34it/s]\u001b[A\n","Iteration:   8% 156/1851 [01:53<21:02,  1.34it/s]\u001b[A\n","Iteration:   8% 157/1851 [01:53<21:03,  1.34it/s]\u001b[A\n","Iteration:   9% 158/1851 [01:54<21:02,  1.34it/s]\u001b[A\n","Iteration:   9% 159/1851 [01:55<21:02,  1.34it/s]\u001b[A\n","Iteration:   9% 160/1851 [01:56<21:01,  1.34it/s]\u001b[A\n","Iteration:   9% 161/1851 [01:56<21:00,  1.34it/s]\u001b[A\n","Iteration:   9% 162/1851 [01:57<20:56,  1.34it/s]\u001b[A\n","Iteration:   9% 163/1851 [01:58<20:58,  1.34it/s]\u001b[A\n","Iteration:   9% 164/1851 [01:59<20:55,  1.34it/s]\u001b[A\n","Iteration:   9% 165/1851 [01:59<20:54,  1.34it/s]\u001b[A\n","Iteration:   9% 166/1851 [02:00<20:53,  1.34it/s]\u001b[A\n","Iteration:   9% 167/1851 [02:01<20:55,  1.34it/s]\u001b[A\n","Iteration:   9% 168/1851 [02:02<20:55,  1.34it/s]\u001b[A\n","Iteration:   9% 169/1851 [02:02<20:54,  1.34it/s]\u001b[A\n","Iteration:   9% 170/1851 [02:03<20:50,  1.34it/s]\u001b[A\n","Iteration:   9% 171/1851 [02:04<20:52,  1.34it/s]\u001b[A\n","Iteration:   9% 172/1851 [02:05<20:47,  1.35it/s]\u001b[A\n","Iteration:   9% 173/1851 [02:05<20:45,  1.35it/s]\u001b[A\n","Iteration:   9% 174/1851 [02:06<20:42,  1.35it/s]\u001b[A\n","Iteration:   9% 175/1851 [02:07<20:44,  1.35it/s]\u001b[A\n","Iteration:  10% 176/1851 [02:08<20:44,  1.35it/s]\u001b[A\n","Iteration:  10% 177/1851 [02:08<20:42,  1.35it/s]\u001b[A\n","Iteration:  10% 178/1851 [02:09<20:42,  1.35it/s]\u001b[A\n","Iteration:  10% 179/1851 [02:10<20:41,  1.35it/s]\u001b[A\n","Iteration:  10% 180/1851 [02:11<20:39,  1.35it/s]\u001b[A\n","Iteration:  10% 181/1851 [02:11<20:39,  1.35it/s]\u001b[A\n","Iteration:  10% 182/1851 [02:12<20:36,  1.35it/s]\u001b[A\n","Iteration:  10% 183/1851 [02:13<20:33,  1.35it/s]\u001b[A\n","Iteration:  10% 184/1851 [02:14<20:33,  1.35it/s]\u001b[A\n","Iteration:  10% 185/1851 [02:14<20:31,  1.35it/s]\u001b[A\n","Iteration:  10% 186/1851 [02:15<20:30,  1.35it/s]\u001b[A\n","Iteration:  10% 187/1851 [02:16<20:30,  1.35it/s]\u001b[A\n","Iteration:  10% 188/1851 [02:16<20:29,  1.35it/s]\u001b[A\n","Iteration:  10% 189/1851 [02:17<20:29,  1.35it/s]\u001b[A\n","Iteration:  10% 190/1851 [02:18<20:26,  1.35it/s]\u001b[A\n","Iteration:  10% 191/1851 [02:19<20:22,  1.36it/s]\u001b[A\n","Iteration:  10% 192/1851 [02:19<20:21,  1.36it/s]\u001b[A\n","Iteration:  10% 193/1851 [02:20<20:18,  1.36it/s]\u001b[A\n","Iteration:  10% 194/1851 [02:21<20:16,  1.36it/s]\u001b[A\n","Iteration:  11% 195/1851 [02:22<20:12,  1.37it/s]\u001b[A\n","Iteration:  11% 196/1851 [02:22<20:11,  1.37it/s]\u001b[A\n","Iteration:  11% 197/1851 [02:23<20:12,  1.36it/s]\u001b[A\n","Iteration:  11% 198/1851 [02:24<20:13,  1.36it/s]\u001b[A\n","Iteration:  11% 199/1851 [02:25<20:12,  1.36it/s]\u001b[A\n","Iteration:  11% 200/1851 [02:25<20:15,  1.36it/s]\u001b[A\n","Iteration:  11% 201/1851 [02:26<20:13,  1.36it/s]\u001b[A\n","Iteration:  11% 202/1851 [02:27<20:11,  1.36it/s]\u001b[A\n","Iteration:  11% 203/1851 [02:28<20:09,  1.36it/s]\u001b[A\n","Iteration:  11% 204/1851 [02:28<20:09,  1.36it/s]\u001b[A\n","Iteration:  11% 205/1851 [02:29<20:06,  1.36it/s]\u001b[A\n","Iteration:  11% 206/1851 [02:30<20:03,  1.37it/s]\u001b[A\n","Iteration:  11% 207/1851 [02:30<20:02,  1.37it/s]\u001b[A\n","Iteration:  11% 208/1851 [02:31<20:03,  1.36it/s]\u001b[A\n","Iteration:  11% 209/1851 [02:32<20:02,  1.37it/s]\u001b[A\n","Iteration:  11% 210/1851 [02:33<20:00,  1.37it/s]\u001b[A\n","Iteration:  11% 211/1851 [02:33<20:00,  1.37it/s]\u001b[A\n","Iteration:  11% 212/1851 [02:34<19:58,  1.37it/s]\u001b[A\n","Iteration:  12% 213/1851 [02:35<20:00,  1.36it/s]\u001b[A\n","Iteration:  12% 214/1851 [02:36<20:00,  1.36it/s]\u001b[A\n","Iteration:  12% 215/1851 [02:36<19:58,  1.37it/s]\u001b[A\n","Iteration:  12% 216/1851 [02:37<19:59,  1.36it/s]\u001b[A\n","Iteration:  12% 217/1851 [02:38<20:01,  1.36it/s]\u001b[A\n","Iteration:  12% 218/1851 [02:38<19:59,  1.36it/s]\u001b[A\n","Iteration:  12% 219/1851 [02:39<19:56,  1.36it/s]\u001b[A\n","Iteration:  12% 220/1851 [02:40<19:55,  1.36it/s]\u001b[A\n","Iteration:  12% 221/1851 [02:41<19:52,  1.37it/s]\u001b[A\n","Iteration:  12% 222/1851 [02:41<19:54,  1.36it/s]\u001b[A\n","Iteration:  12% 223/1851 [02:42<19:50,  1.37it/s]\u001b[A\n","Iteration:  12% 224/1851 [02:43<19:49,  1.37it/s]\u001b[A\n","Iteration:  12% 225/1851 [02:44<19:45,  1.37it/s]\u001b[A\n","Iteration:  12% 226/1851 [02:44<19:50,  1.37it/s]\u001b[A\n","Iteration:  12% 227/1851 [02:45<19:49,  1.37it/s]\u001b[A\n","Iteration:  12% 228/1851 [02:46<19:49,  1.36it/s]\u001b[A\n","Iteration:  12% 229/1851 [02:47<19:48,  1.36it/s]\u001b[A\n","Iteration:  12% 230/1851 [02:47<19:49,  1.36it/s]\u001b[A\n","Iteration:  12% 231/1851 [02:48<19:47,  1.36it/s]\u001b[A\n","Iteration:  13% 232/1851 [02:49<19:47,  1.36it/s]\u001b[A\n","Iteration:  13% 233/1851 [02:49<19:44,  1.37it/s]\u001b[A\n","Iteration:  13% 234/1851 [02:50<19:43,  1.37it/s]\u001b[A\n","Iteration:  13% 235/1851 [02:51<19:42,  1.37it/s]\u001b[A\n","Iteration:  13% 236/1851 [02:52<19:46,  1.36it/s]\u001b[A\n","Iteration:  13% 237/1851 [02:52<19:45,  1.36it/s]\u001b[A\n","Iteration:  13% 238/1851 [02:53<19:44,  1.36it/s]\u001b[A\n","Iteration:  13% 239/1851 [02:54<19:43,  1.36it/s]\u001b[A\n","Iteration:  13% 240/1851 [02:55<19:44,  1.36it/s]\u001b[A\n","Iteration:  13% 241/1851 [02:55<19:43,  1.36it/s]\u001b[A\n","Iteration:  13% 242/1851 [02:56<19:42,  1.36it/s]\u001b[A\n","Iteration:  13% 243/1851 [02:57<19:40,  1.36it/s]\u001b[A\n","Iteration:  13% 244/1851 [02:58<19:36,  1.37it/s]\u001b[A\n","Iteration:  13% 245/1851 [02:58<19:38,  1.36it/s]\u001b[A\n","Iteration:  13% 246/1851 [02:59<19:39,  1.36it/s]\u001b[A\n","Iteration:  13% 247/1851 [03:00<19:39,  1.36it/s]\u001b[A\n","Iteration:  13% 248/1851 [03:00<19:39,  1.36it/s]\u001b[A\n","Iteration:  13% 249/1851 [03:01<19:39,  1.36it/s]\u001b[A\n","Iteration:  14% 250/1851 [03:02<19:40,  1.36it/s]\u001b[A\n","Iteration:  14% 251/1851 [03:03<19:36,  1.36it/s]\u001b[A\n","Iteration:  14% 252/1851 [03:03<19:38,  1.36it/s]\u001b[A\n","Iteration:  14% 253/1851 [03:04<19:38,  1.36it/s]\u001b[A\n","Iteration:  14% 254/1851 [03:05<19:36,  1.36it/s]\u001b[A\n","Iteration:  14% 255/1851 [03:06<19:32,  1.36it/s]\u001b[A\n","Iteration:  14% 256/1851 [03:06<19:36,  1.36it/s]\u001b[A\n","Iteration:  14% 257/1851 [03:07<19:34,  1.36it/s]\u001b[A\n","Iteration:  14% 258/1851 [03:08<19:30,  1.36it/s]\u001b[A\n","Iteration:  14% 259/1851 [03:09<19:30,  1.36it/s]\u001b[A\n","Iteration:  14% 260/1851 [03:09<19:34,  1.35it/s]\u001b[A\n","Iteration:  14% 261/1851 [03:10<19:31,  1.36it/s]\u001b[A\n","Iteration:  14% 262/1851 [03:11<19:34,  1.35it/s]\u001b[A\n","Iteration:  14% 263/1851 [03:12<19:32,  1.35it/s]\u001b[A\n","Iteration:  14% 264/1851 [03:12<19:29,  1.36it/s]\u001b[A\n","Iteration:  14% 265/1851 [03:13<19:31,  1.35it/s]\u001b[A\n","Iteration:  14% 266/1851 [03:14<19:30,  1.35it/s]\u001b[A\n","Iteration:  14% 267/1851 [03:15<19:31,  1.35it/s]\u001b[A\n","Iteration:  14% 268/1851 [03:15<19:30,  1.35it/s]\u001b[A\n","Iteration:  15% 269/1851 [03:16<19:31,  1.35it/s]\u001b[A\n","Iteration:  15% 270/1851 [03:17<19:29,  1.35it/s]\u001b[A\n","Iteration:  15% 271/1851 [03:17<19:28,  1.35it/s]\u001b[A\n","Iteration:  15% 272/1851 [03:18<19:29,  1.35it/s]\u001b[A\n","Iteration:  15% 273/1851 [03:19<19:26,  1.35it/s]\u001b[A\n","Iteration:  15% 274/1851 [03:20<19:26,  1.35it/s]\u001b[A\n","Iteration:  15% 275/1851 [03:20<19:24,  1.35it/s]\u001b[A\n","Iteration:  15% 276/1851 [03:21<19:23,  1.35it/s]\u001b[A\n","Iteration:  15% 277/1851 [03:22<19:23,  1.35it/s]\u001b[A\n","Iteration:  15% 278/1851 [03:23<19:22,  1.35it/s]\u001b[A\n","Iteration:  15% 279/1851 [03:23<19:23,  1.35it/s]\u001b[A\n","Iteration:  15% 280/1851 [03:24<19:22,  1.35it/s]\u001b[A\n","Iteration:  15% 281/1851 [03:25<19:22,  1.35it/s]\u001b[A\n","Iteration:  15% 282/1851 [03:26<19:19,  1.35it/s]\u001b[A\n","Iteration:  15% 283/1851 [03:26<19:15,  1.36it/s]\u001b[A\n","Iteration:  15% 284/1851 [03:27<19:17,  1.35it/s]\u001b[A\n","Iteration:  15% 285/1851 [03:28<19:16,  1.35it/s]\u001b[A\n","Iteration:  15% 286/1851 [03:29<19:14,  1.36it/s]\u001b[A\n","Iteration:  16% 287/1851 [03:29<19:15,  1.35it/s]\u001b[A\n","Iteration:  16% 288/1851 [03:30<19:13,  1.35it/s]\u001b[A\n","Iteration:  16% 289/1851 [03:31<19:12,  1.36it/s]\u001b[A\n","Iteration:  16% 290/1851 [03:32<19:14,  1.35it/s]\u001b[A\n","Iteration:  16% 291/1851 [03:32<19:11,  1.35it/s]\u001b[A\n","Iteration:  16% 292/1851 [03:33<19:10,  1.36it/s]\u001b[A\n","Iteration:  16% 293/1851 [03:34<19:07,  1.36it/s]\u001b[A\n","Iteration:  16% 294/1851 [03:34<19:08,  1.36it/s]\u001b[A\n","Iteration:  16% 295/1851 [03:35<19:07,  1.36it/s]\u001b[A\n","Iteration:  16% 296/1851 [03:36<19:07,  1.36it/s]\u001b[A\n","Iteration:  16% 297/1851 [03:37<19:08,  1.35it/s]\u001b[A\n","Iteration:  16% 298/1851 [03:37<19:09,  1.35it/s]\u001b[A\n","Iteration:  16% 299/1851 [03:38<19:06,  1.35it/s]\u001b[A\n","Iteration:  16% 300/1851 [03:39<19:04,  1.36it/s]\u001b[A\n","Iteration:  16% 301/1851 [03:40<19:05,  1.35it/s]\u001b[A\n","Iteration:  16% 302/1851 [03:40<19:07,  1.35it/s]\u001b[A\n","Iteration:  16% 303/1851 [03:41<19:05,  1.35it/s]\u001b[A\n","Iteration:  16% 304/1851 [03:42<19:04,  1.35it/s]\u001b[A\n","Iteration:  16% 305/1851 [03:43<19:03,  1.35it/s]\u001b[A\n","Iteration:  17% 306/1851 [03:43<19:03,  1.35it/s]\u001b[A\n","Iteration:  17% 307/1851 [03:44<19:00,  1.35it/s]\u001b[A\n","Iteration:  17% 308/1851 [03:45<19:00,  1.35it/s]\u001b[A\n","Iteration:  17% 309/1851 [03:46<18:59,  1.35it/s]\u001b[A\n","Iteration:  17% 310/1851 [03:46<19:00,  1.35it/s]\u001b[A\n","Iteration:  17% 311/1851 [03:47<18:57,  1.35it/s]\u001b[A\n","Iteration:  17% 312/1851 [03:48<18:56,  1.35it/s]\u001b[A\n","Iteration:  17% 313/1851 [03:49<18:56,  1.35it/s]\u001b[A\n","Iteration:  17% 314/1851 [03:49<18:53,  1.36it/s]\u001b[A\n","Iteration:  17% 315/1851 [03:50<18:50,  1.36it/s]\u001b[A\n","Iteration:  17% 316/1851 [03:51<18:52,  1.36it/s]\u001b[A\n","Iteration:  17% 317/1851 [03:51<18:51,  1.36it/s]\u001b[A\n","Iteration:  17% 318/1851 [03:52<18:48,  1.36it/s]\u001b[A\n","Iteration:  17% 319/1851 [03:53<18:47,  1.36it/s]\u001b[A\n","Iteration:  17% 320/1851 [03:54<18:48,  1.36it/s]\u001b[A\n","Iteration:  17% 321/1851 [03:54<18:47,  1.36it/s]\u001b[A\n","Iteration:  17% 322/1851 [03:55<18:48,  1.36it/s]\u001b[A\n","Iteration:  17% 323/1851 [03:56<18:44,  1.36it/s]\u001b[A\n","Iteration:  18% 324/1851 [03:57<18:44,  1.36it/s]\u001b[A\n","Iteration:  18% 325/1851 [03:57<18:43,  1.36it/s]\u001b[A\n","Iteration:  18% 326/1851 [03:58<18:45,  1.35it/s]\u001b[A\n","Iteration:  18% 327/1851 [03:59<18:45,  1.35it/s]\u001b[A\n","Iteration:  18% 328/1851 [04:00<18:42,  1.36it/s]\u001b[A\n","Iteration:  18% 329/1851 [04:00<18:45,  1.35it/s]\u001b[A\n","Iteration:  18% 330/1851 [04:01<18:42,  1.36it/s]\u001b[A\n","Iteration:  18% 331/1851 [04:02<18:43,  1.35it/s]\u001b[A\n","Iteration:  18% 332/1851 [04:03<18:43,  1.35it/s]\u001b[A\n","Iteration:  18% 333/1851 [04:03<18:40,  1.35it/s]\u001b[A\n","Iteration:  18% 334/1851 [04:04<18:41,  1.35it/s]\u001b[A\n","Iteration:  18% 335/1851 [04:05<18:38,  1.36it/s]\u001b[A\n","Iteration:  18% 336/1851 [04:05<18:39,  1.35it/s]\u001b[A\n","Iteration:  18% 337/1851 [04:06<18:38,  1.35it/s]\u001b[A\n","Iteration:  18% 338/1851 [04:07<18:38,  1.35it/s]\u001b[A\n","Iteration:  18% 339/1851 [04:08<18:38,  1.35it/s]\u001b[A\n","Iteration:  18% 340/1851 [04:08<18:37,  1.35it/s]\u001b[A\n","Iteration:  18% 341/1851 [04:09<18:36,  1.35it/s]\u001b[A\n","Iteration:  18% 342/1851 [04:10<18:36,  1.35it/s]\u001b[A\n","Iteration:  19% 343/1851 [04:11<18:32,  1.36it/s]\u001b[A\n","Iteration:  19% 344/1851 [04:11<18:33,  1.35it/s]\u001b[A\n","Iteration:  19% 345/1851 [04:12<18:30,  1.36it/s]\u001b[A\n","Iteration:  19% 346/1851 [04:13<18:28,  1.36it/s]\u001b[A\n","Iteration:  19% 347/1851 [04:14<18:24,  1.36it/s]\u001b[A\n","Iteration:  19% 348/1851 [04:14<18:27,  1.36it/s]\u001b[A\n","Iteration:  19% 349/1851 [04:15<18:25,  1.36it/s]\u001b[A\n","Iteration:  19% 350/1851 [04:16<18:23,  1.36it/s]\u001b[A\n","Iteration:  19% 351/1851 [04:17<18:21,  1.36it/s]\u001b[A\n","Iteration:  19% 352/1851 [04:17<18:23,  1.36it/s]\u001b[A\n","Iteration:  19% 353/1851 [04:18<18:23,  1.36it/s]\u001b[A\n","Iteration:  19% 354/1851 [04:19<18:21,  1.36it/s]\u001b[A\n","Iteration:  19% 355/1851 [04:19<18:18,  1.36it/s]\u001b[A\n","Iteration:  19% 356/1851 [04:20<18:16,  1.36it/s]\u001b[A\n","Iteration:  19% 357/1851 [04:21<18:16,  1.36it/s]\u001b[A\n","Iteration:  19% 358/1851 [04:22<18:17,  1.36it/s]\u001b[A\n","Iteration:  19% 359/1851 [04:22<18:15,  1.36it/s]\u001b[A\n","Iteration:  19% 360/1851 [04:23<18:14,  1.36it/s]\u001b[A\n","Iteration:  20% 361/1851 [04:24<18:13,  1.36it/s]\u001b[A\n","Iteration:  20% 362/1851 [04:25<18:12,  1.36it/s]\u001b[A\n","Iteration:  20% 363/1851 [04:25<18:14,  1.36it/s]\u001b[A\n","Iteration:  20% 364/1851 [04:26<18:12,  1.36it/s]\u001b[A\n","Iteration:  20% 365/1851 [04:27<18:12,  1.36it/s]\u001b[A\n","Iteration:  20% 366/1851 [04:28<18:14,  1.36it/s]\u001b[A\n","Iteration:  20% 367/1851 [04:28<18:12,  1.36it/s]\u001b[A\n","Iteration:  20% 368/1851 [04:29<18:12,  1.36it/s]\u001b[A\n","Iteration:  20% 369/1851 [04:30<18:08,  1.36it/s]\u001b[A\n","Iteration:  20% 370/1851 [04:30<18:08,  1.36it/s]\u001b[A\n","Iteration:  20% 371/1851 [04:31<18:10,  1.36it/s]\u001b[A\n","Iteration:  20% 372/1851 [04:32<18:07,  1.36it/s]\u001b[A\n","Iteration:  20% 373/1851 [04:33<18:07,  1.36it/s]\u001b[A\n","Iteration:  20% 374/1851 [04:33<18:04,  1.36it/s]\u001b[A\n","Iteration:  20% 375/1851 [04:34<18:06,  1.36it/s]\u001b[A\n","Iteration:  20% 376/1851 [04:35<18:06,  1.36it/s]\u001b[A\n","Iteration:  20% 377/1851 [04:36<18:04,  1.36it/s]\u001b[A\n","Iteration:  20% 378/1851 [04:36<18:01,  1.36it/s]\u001b[A\n","Iteration:  20% 379/1851 [04:37<18:00,  1.36it/s]\u001b[A\n","Iteration:  21% 380/1851 [04:38<18:00,  1.36it/s]\u001b[A\n","Iteration:  21% 381/1851 [04:39<18:03,  1.36it/s]\u001b[A\n","Iteration:  21% 382/1851 [04:39<18:02,  1.36it/s]\u001b[A\n","Iteration:  21% 383/1851 [04:40<18:00,  1.36it/s]\u001b[A\n","Iteration:  21% 384/1851 [04:41<18:03,  1.35it/s]\u001b[A\n","Iteration:  21% 385/1851 [04:42<18:00,  1.36it/s]\u001b[A\n","Iteration:  21% 386/1851 [04:42<17:59,  1.36it/s]\u001b[A\n","Iteration:  21% 387/1851 [04:43<18:00,  1.35it/s]\u001b[A\n","Iteration:  21% 388/1851 [04:44<17:56,  1.36it/s]\u001b[A\n","Iteration:  21% 389/1851 [04:44<17:57,  1.36it/s]\u001b[A\n","Iteration:  21% 390/1851 [04:45<17:57,  1.36it/s]\u001b[A\n","Iteration:  21% 391/1851 [04:46<17:57,  1.35it/s]\u001b[A\n","Iteration:  21% 392/1851 [04:47<17:55,  1.36it/s]\u001b[A\n","Iteration:  21% 393/1851 [04:47<17:53,  1.36it/s]\u001b[A\n","Iteration:  21% 394/1851 [04:48<17:54,  1.36it/s]\u001b[A\n","Iteration:  21% 395/1851 [04:49<17:52,  1.36it/s]\u001b[A\n","Iteration:  21% 396/1851 [04:50<17:50,  1.36it/s]\u001b[A\n","Iteration:  21% 397/1851 [04:50<17:50,  1.36it/s]\u001b[A\n","Iteration:  22% 398/1851 [04:51<17:50,  1.36it/s]\u001b[A\n","Iteration:  22% 399/1851 [04:52<17:50,  1.36it/s]\u001b[A\n","Iteration:  22% 400/1851 [04:53<17:48,  1.36it/s]\u001b[A\n","Iteration:  22% 401/1851 [04:53<17:48,  1.36it/s]\u001b[A\n","Iteration:  22% 402/1851 [04:54<17:48,  1.36it/s]\u001b[A\n","Iteration:  22% 403/1851 [04:55<17:46,  1.36it/s]\u001b[A\n","Iteration:  22% 404/1851 [04:56<17:47,  1.36it/s]\u001b[A\n","Iteration:  22% 405/1851 [04:56<17:47,  1.35it/s]\u001b[A\n","Iteration:  22% 406/1851 [04:57<17:45,  1.36it/s]\u001b[A\n","Iteration:  22% 407/1851 [04:58<17:47,  1.35it/s]\u001b[A\n","Iteration:  22% 408/1851 [04:58<17:46,  1.35it/s]\u001b[A\n","Iteration:  22% 409/1851 [04:59<17:46,  1.35it/s]\u001b[A\n","Iteration:  22% 410/1851 [05:00<17:43,  1.35it/s]\u001b[A\n","Iteration:  22% 411/1851 [05:01<17:42,  1.35it/s]\u001b[A\n","Iteration:  22% 412/1851 [05:01<17:44,  1.35it/s]\u001b[A\n","Iteration:  22% 413/1851 [05:02<17:42,  1.35it/s]\u001b[A\n","Iteration:  22% 414/1851 [05:03<17:39,  1.36it/s]\u001b[A\n","Iteration:  22% 415/1851 [05:04<17:41,  1.35it/s]\u001b[A\n","Iteration:  22% 416/1851 [05:04<17:38,  1.36it/s]\u001b[A\n","Iteration:  23% 417/1851 [05:05<17:36,  1.36it/s]\u001b[A\n","Iteration:  23% 418/1851 [05:06<17:38,  1.35it/s]\u001b[A\n","Iteration:  23% 419/1851 [05:07<17:37,  1.35it/s]\u001b[A\n","Iteration:  23% 420/1851 [05:07<17:38,  1.35it/s]\u001b[A\n","Iteration:  23% 421/1851 [05:08<17:34,  1.36it/s]\u001b[A\n","Iteration:  23% 422/1851 [05:09<17:32,  1.36it/s]\u001b[A\n","Iteration:  23% 423/1851 [05:10<17:28,  1.36it/s]\u001b[A\n","Iteration:  23% 424/1851 [05:10<17:28,  1.36it/s]\u001b[A\n","Iteration:  23% 425/1851 [05:11<17:30,  1.36it/s]\u001b[A\n","Iteration:  23% 426/1851 [05:12<17:27,  1.36it/s]\u001b[A\n","Iteration:  23% 427/1851 [05:12<17:26,  1.36it/s]\u001b[A\n","Iteration:  23% 428/1851 [05:13<17:28,  1.36it/s]\u001b[A\n","Iteration:  23% 429/1851 [05:14<17:28,  1.36it/s]\u001b[A\n","Iteration:  23% 430/1851 [05:15<17:25,  1.36it/s]\u001b[A\n","Iteration:  23% 431/1851 [05:15<17:23,  1.36it/s]\u001b[A\n","Iteration:  23% 432/1851 [05:16<17:21,  1.36it/s]\u001b[A\n","Iteration:  23% 433/1851 [05:17<17:18,  1.36it/s]\u001b[A\n","Iteration:  23% 434/1851 [05:18<17:20,  1.36it/s]\u001b[A\n","Iteration:  24% 435/1851 [05:18<17:21,  1.36it/s]\u001b[A\n","Iteration:  24% 436/1851 [05:19<17:20,  1.36it/s]\u001b[A\n","Iteration:  24% 437/1851 [05:20<17:18,  1.36it/s]\u001b[A\n","Iteration:  24% 438/1851 [05:21<17:21,  1.36it/s]\u001b[A\n","Iteration:  24% 439/1851 [05:21<17:17,  1.36it/s]\u001b[A\n","Iteration:  24% 440/1851 [05:22<17:17,  1.36it/s]\u001b[A\n","Iteration:  24% 441/1851 [05:23<17:14,  1.36it/s]\u001b[A\n","Iteration:  24% 442/1851 [05:24<17:14,  1.36it/s]\u001b[A\n","Iteration:  24% 443/1851 [05:24<17:15,  1.36it/s]\u001b[A\n","Iteration:  24% 444/1851 [05:25<17:16,  1.36it/s]\u001b[A\n","Iteration:  24% 445/1851 [05:26<17:13,  1.36it/s]\u001b[A\n","Iteration:  24% 446/1851 [05:26<17:13,  1.36it/s]\u001b[A\n","Iteration:  24% 447/1851 [05:27<17:14,  1.36it/s]\u001b[A\n","Iteration:  24% 448/1851 [05:28<17:16,  1.35it/s]\u001b[A\n","Iteration:  24% 449/1851 [05:29<17:16,  1.35it/s]\u001b[A\n","Iteration:  24% 450/1851 [05:29<17:12,  1.36it/s]\u001b[A\n","Iteration:  24% 451/1851 [05:30<17:15,  1.35it/s]\u001b[A\n","Iteration:  24% 452/1851 [05:31<17:14,  1.35it/s]\u001b[A\n","Iteration:  24% 453/1851 [05:32<17:11,  1.36it/s]\u001b[A\n","Iteration:  25% 454/1851 [05:32<17:08,  1.36it/s]\u001b[A\n","Iteration:  25% 455/1851 [05:33<17:09,  1.36it/s]\u001b[A\n","Iteration:  25% 456/1851 [05:34<17:05,  1.36it/s]\u001b[A\n","Iteration:  25% 457/1851 [05:35<17:05,  1.36it/s]\u001b[A\n","Iteration:  25% 458/1851 [05:35<17:07,  1.36it/s]\u001b[A\n","Iteration:  25% 459/1851 [05:36<17:07,  1.35it/s]\u001b[A\n","Iteration:  25% 460/1851 [05:37<17:07,  1.35it/s]\u001b[A\n","Iteration:  25% 461/1851 [05:38<17:07,  1.35it/s]\u001b[A\n","Iteration:  25% 462/1851 [05:38<17:07,  1.35it/s]\u001b[A\n","Iteration:  25% 463/1851 [05:39<17:07,  1.35it/s]\u001b[A\n","Iteration:  25% 464/1851 [05:40<17:04,  1.35it/s]\u001b[A\n","Iteration:  25% 465/1851 [05:40<17:05,  1.35it/s]\u001b[A\n","Iteration:  25% 466/1851 [05:41<17:03,  1.35it/s]\u001b[A\n","Iteration:  25% 467/1851 [05:42<17:06,  1.35it/s]\u001b[A\n","Iteration:  25% 468/1851 [05:43<17:02,  1.35it/s]\u001b[A\n","Iteration:  25% 469/1851 [05:43<17:01,  1.35it/s]\u001b[A\n","Iteration:  25% 470/1851 [05:44<17:00,  1.35it/s]\u001b[A\n","Iteration:  25% 471/1851 [05:45<16:59,  1.35it/s]\u001b[A\n","Iteration:  25% 472/1851 [05:46<16:55,  1.36it/s]\u001b[A\n","Iteration:  26% 473/1851 [05:46<16:54,  1.36it/s]\u001b[A\n","Iteration:  26% 474/1851 [05:47<16:53,  1.36it/s]\u001b[A\n","Iteration:  26% 475/1851 [05:48<16:55,  1.36it/s]\u001b[A\n","Iteration:  26% 476/1851 [05:49<16:53,  1.36it/s]\u001b[A\n","Iteration:  26% 477/1851 [05:49<16:50,  1.36it/s]\u001b[A\n","Iteration:  26% 478/1851 [05:50<16:49,  1.36it/s]\u001b[A\n","Iteration:  26% 479/1851 [05:51<16:51,  1.36it/s]\u001b[A\n","Iteration:  26% 480/1851 [05:52<16:51,  1.36it/s]\u001b[A\n","Iteration:  26% 481/1851 [05:52<16:47,  1.36it/s]\u001b[A\n","Iteration:  26% 482/1851 [05:53<16:46,  1.36it/s]\u001b[A\n","Iteration:  26% 483/1851 [05:54<16:49,  1.36it/s]\u001b[A\n","Iteration:  26% 484/1851 [05:55<16:48,  1.36it/s]\u001b[A\n","Iteration:  26% 485/1851 [05:55<16:45,  1.36it/s]\u001b[A\n","Iteration:  26% 486/1851 [05:56<16:43,  1.36it/s]\u001b[A\n","Iteration:  26% 487/1851 [05:57<16:41,  1.36it/s]\u001b[A\n","Iteration:  26% 488/1851 [05:57<16:41,  1.36it/s]\u001b[A\n","Iteration:  26% 489/1851 [05:58<16:42,  1.36it/s]\u001b[A\n","Iteration:  26% 490/1851 [05:59<16:43,  1.36it/s]\u001b[A\n","Iteration:  27% 491/1851 [06:00<16:43,  1.35it/s]\u001b[A\n","Iteration:  27% 492/1851 [06:00<16:43,  1.35it/s]\u001b[A\n","Iteration:  27% 493/1851 [06:01<16:41,  1.36it/s]\u001b[A\n","Iteration:  27% 494/1851 [06:02<16:39,  1.36it/s]\u001b[A\n","Iteration:  27% 495/1851 [06:03<16:40,  1.35it/s]\u001b[A\n","Iteration:  27% 496/1851 [06:03<16:40,  1.35it/s]\u001b[A\n","Iteration:  27% 497/1851 [06:04<16:39,  1.36it/s]\u001b[A\n","Iteration:  27% 498/1851 [06:05<16:38,  1.35it/s]\u001b[A\n","Iteration:  27% 499/1851 [06:06<16:38,  1.35it/s]\u001b[A\n","Iteration:  27% 500/1851 [06:06<16:34,  1.36it/s]\u001b[A\n","Iteration:  27% 501/1851 [06:07<16:35,  1.36it/s]\u001b[A\n","Iteration:  27% 502/1851 [06:08<16:35,  1.36it/s]\u001b[A\n","Iteration:  27% 503/1851 [06:09<16:33,  1.36it/s]\u001b[A\n","Iteration:  27% 504/1851 [06:09<16:31,  1.36it/s]\u001b[A\n","Iteration:  27% 505/1851 [06:10<16:32,  1.36it/s]\u001b[A\n","Iteration:  27% 506/1851 [06:11<16:30,  1.36it/s]\u001b[A\n","Iteration:  27% 507/1851 [06:11<16:30,  1.36it/s]\u001b[A\n","Iteration:  27% 508/1851 [06:12<16:32,  1.35it/s]\u001b[A\n","Iteration:  27% 509/1851 [06:13<16:30,  1.35it/s]\u001b[A\n","Iteration:  28% 510/1851 [06:14<16:31,  1.35it/s]\u001b[A\n","Iteration:  28% 511/1851 [06:14<16:29,  1.35it/s]\u001b[A\n","Iteration:  28% 512/1851 [06:15<16:25,  1.36it/s]\u001b[A\n","Iteration:  28% 513/1851 [06:16<16:25,  1.36it/s]\u001b[A\n","Iteration:  28% 514/1851 [06:17<16:26,  1.36it/s]\u001b[A\n","Iteration:  28% 515/1851 [06:17<16:24,  1.36it/s]\u001b[A\n","Iteration:  28% 516/1851 [06:18<16:23,  1.36it/s]\u001b[A\n","Iteration:  28% 517/1851 [06:19<16:23,  1.36it/s]\u001b[A\n","Iteration:  28% 518/1851 [06:20<16:22,  1.36it/s]\u001b[A\n","Iteration:  28% 519/1851 [06:20<16:19,  1.36it/s]\u001b[A\n","Iteration:  28% 520/1851 [06:21<16:22,  1.35it/s]\u001b[A\n","Iteration:  28% 521/1851 [06:22<16:21,  1.36it/s]\u001b[A\n","Iteration:  28% 522/1851 [06:23<16:23,  1.35it/s]\u001b[A\n","Iteration:  28% 523/1851 [06:23<16:21,  1.35it/s]\u001b[A\n","Iteration:  28% 524/1851 [06:24<16:19,  1.35it/s]\u001b[A\n","Iteration:  28% 525/1851 [06:25<16:19,  1.35it/s]\u001b[A\n","Iteration:  28% 526/1851 [06:25<16:17,  1.36it/s]\u001b[A\n","Iteration:  28% 527/1851 [06:26<16:15,  1.36it/s]\u001b[A\n","Iteration:  29% 528/1851 [06:27<16:14,  1.36it/s]\u001b[A\n","Iteration:  29% 529/1851 [06:28<16:16,  1.35it/s]\u001b[A\n","Iteration:  29% 530/1851 [06:28<16:14,  1.36it/s]\u001b[A\n","Iteration:  29% 531/1851 [06:29<16:13,  1.36it/s]\u001b[A\n","Iteration:  29% 532/1851 [06:30<16:13,  1.35it/s]\u001b[A\n","Iteration:  29% 533/1851 [06:31<16:13,  1.35it/s]\u001b[A\n","Iteration:  29% 534/1851 [06:31<16:12,  1.35it/s]\u001b[A\n","Iteration:  29% 535/1851 [06:32<16:10,  1.36it/s]\u001b[A\n","Iteration:  29% 536/1851 [06:33<16:11,  1.35it/s]\u001b[A\n","Iteration:  29% 537/1851 [06:34<16:09,  1.36it/s]\u001b[A\n","Iteration:  29% 538/1851 [06:34<16:08,  1.36it/s]\u001b[A\n","Iteration:  29% 539/1851 [06:35<16:10,  1.35it/s]\u001b[A\n","Iteration:  29% 540/1851 [06:36<16:07,  1.36it/s]\u001b[A\n","Iteration:  29% 541/1851 [06:37<16:07,  1.35it/s]\u001b[A\n","Iteration:  29% 542/1851 [06:37<16:06,  1.36it/s]\u001b[A\n","Iteration:  29% 543/1851 [06:38<16:07,  1.35it/s]\u001b[A\n","Iteration:  29% 544/1851 [06:39<16:05,  1.35it/s]\u001b[A\n","Iteration:  29% 545/1851 [06:40<16:04,  1.35it/s]\u001b[A\n","Iteration:  29% 546/1851 [06:40<16:03,  1.35it/s]\u001b[A\n","Iteration:  30% 547/1851 [06:41<16:02,  1.36it/s]\u001b[A\n","Iteration:  30% 548/1851 [06:42<16:00,  1.36it/s]\u001b[A\n","Iteration:  30% 549/1851 [06:42<16:00,  1.36it/s]\u001b[A\n","Iteration:  30% 550/1851 [06:43<16:01,  1.35it/s]\u001b[A\n","Iteration:  30% 551/1851 [06:44<16:02,  1.35it/s]\u001b[A\n","Iteration:  30% 552/1851 [06:45<15:59,  1.35it/s]\u001b[A\n","Iteration:  30% 553/1851 [06:45<15:58,  1.35it/s]\u001b[A\n","Iteration:  30% 554/1851 [06:46<15:58,  1.35it/s]\u001b[A\n","Iteration:  30% 555/1851 [06:47<15:55,  1.36it/s]\u001b[A\n","Iteration:  30% 556/1851 [06:48<15:55,  1.35it/s]\u001b[A\n","Iteration:  30% 557/1851 [06:48<15:54,  1.36it/s]\u001b[A\n","Iteration:  30% 558/1851 [06:49<15:54,  1.35it/s]\u001b[A\n","Iteration:  30% 559/1851 [06:50<15:53,  1.35it/s]\u001b[A\n","Iteration:  30% 560/1851 [06:51<15:53,  1.35it/s]\u001b[A\n","Iteration:  30% 561/1851 [06:51<15:51,  1.36it/s]\u001b[A\n","Iteration:  30% 562/1851 [06:52<15:53,  1.35it/s]\u001b[A\n","Iteration:  30% 563/1851 [06:53<15:53,  1.35it/s]\u001b[A\n","Iteration:  30% 564/1851 [06:54<15:50,  1.35it/s]\u001b[A\n","Iteration:  31% 565/1851 [06:54<15:49,  1.35it/s]\u001b[A\n","Iteration:  31% 566/1851 [06:55<15:50,  1.35it/s]\u001b[A\n","Iteration:  31% 567/1851 [06:56<15:48,  1.35it/s]\u001b[A\n","Iteration:  31% 568/1851 [06:56<15:45,  1.36it/s]\u001b[A\n","Iteration:  31% 569/1851 [06:57<15:46,  1.35it/s]\u001b[A\n","Iteration:  31% 570/1851 [06:58<15:45,  1.35it/s]\u001b[A\n","Iteration:  31% 571/1851 [06:59<15:44,  1.36it/s]\u001b[A\n","Iteration:  31% 572/1851 [06:59<15:46,  1.35it/s]\u001b[A\n","Iteration:  31% 573/1851 [07:00<15:46,  1.35it/s]\u001b[A\n","Iteration:  31% 574/1851 [07:01<15:43,  1.35it/s]\u001b[A\n","Iteration:  31% 575/1851 [07:02<15:42,  1.35it/s]\u001b[A\n","Iteration:  31% 576/1851 [07:02<15:41,  1.35it/s]\u001b[A\n","Iteration:  31% 577/1851 [07:03<15:40,  1.36it/s]\u001b[A\n","Iteration:  31% 578/1851 [07:04<15:37,  1.36it/s]\u001b[A\n","Iteration:  31% 579/1851 [07:05<15:39,  1.35it/s]\u001b[A\n","Iteration:  31% 580/1851 [07:05<15:36,  1.36it/s]\u001b[A\n","Iteration:  31% 581/1851 [07:06<15:37,  1.35it/s]\u001b[A\n","Iteration:  31% 582/1851 [07:07<15:35,  1.36it/s]\u001b[A\n","Iteration:  31% 583/1851 [07:08<15:35,  1.35it/s]\u001b[A\n","Iteration:  32% 584/1851 [07:08<15:37,  1.35it/s]\u001b[A\n","Iteration:  32% 585/1851 [07:09<15:35,  1.35it/s]\u001b[A\n","Iteration:  32% 586/1851 [07:10<15:32,  1.36it/s]\u001b[A\n","Iteration:  32% 587/1851 [07:11<15:29,  1.36it/s]\u001b[A\n","Iteration:  32% 588/1851 [07:11<15:27,  1.36it/s]\u001b[A\n","Iteration:  32% 589/1851 [07:12<15:30,  1.36it/s]\u001b[A\n","Iteration:  32% 590/1851 [07:13<15:29,  1.36it/s]\u001b[A\n","Iteration:  32% 591/1851 [07:13<15:30,  1.35it/s]\u001b[A\n","Iteration:  32% 592/1851 [07:14<15:29,  1.35it/s]\u001b[A\n","Iteration:  32% 593/1851 [07:15<15:25,  1.36it/s]\u001b[A\n","Iteration:  32% 594/1851 [07:16<15:27,  1.36it/s]\u001b[A\n","Iteration:  32% 595/1851 [07:16<15:26,  1.36it/s]\u001b[A\n","Iteration:  32% 596/1851 [07:17<15:25,  1.36it/s]\u001b[A\n","Iteration:  32% 597/1851 [07:18<15:25,  1.35it/s]\u001b[A\n","Iteration:  32% 598/1851 [07:19<15:25,  1.35it/s]\u001b[A\n","Iteration:  32% 599/1851 [07:19<15:26,  1.35it/s]\u001b[A\n","Iteration:  32% 600/1851 [07:20<15:25,  1.35it/s]\u001b[A\n","Iteration:  32% 601/1851 [07:21<15:24,  1.35it/s]\u001b[A\n","Iteration:  33% 602/1851 [07:22<15:22,  1.35it/s]\u001b[A\n","Iteration:  33% 603/1851 [07:22<15:20,  1.36it/s]\u001b[A\n","Iteration:  33% 604/1851 [07:23<15:22,  1.35it/s]\u001b[A\n","Iteration:  33% 605/1851 [07:24<15:18,  1.36it/s]\u001b[A\n","Iteration:  33% 606/1851 [07:25<15:16,  1.36it/s]\u001b[A\n","Iteration:  33% 607/1851 [07:25<15:15,  1.36it/s]\u001b[A\n","Iteration:  33% 608/1851 [07:26<15:14,  1.36it/s]\u001b[A\n","Iteration:  33% 609/1851 [07:27<15:14,  1.36it/s]\u001b[A\n","Iteration:  33% 610/1851 [07:27<15:14,  1.36it/s]\u001b[A\n","Iteration:  33% 611/1851 [07:28<15:14,  1.36it/s]\u001b[A\n","Iteration:  33% 612/1851 [07:29<15:14,  1.36it/s]\u001b[A\n","Iteration:  33% 613/1851 [07:30<15:12,  1.36it/s]\u001b[A\n","Iteration:  33% 614/1851 [07:30<15:13,  1.35it/s]\u001b[A\n","Iteration:  33% 615/1851 [07:31<15:10,  1.36it/s]\u001b[A\n","Iteration:  33% 616/1851 [07:32<15:11,  1.36it/s]\u001b[A\n","Iteration:  33% 617/1851 [07:33<15:10,  1.35it/s]\u001b[A\n","Iteration:  33% 618/1851 [07:33<15:08,  1.36it/s]\u001b[A\n","Iteration:  33% 619/1851 [07:34<15:05,  1.36it/s]\u001b[A\n","Iteration:  33% 620/1851 [07:35<15:04,  1.36it/s]\u001b[A\n","Iteration:  34% 621/1851 [07:36<15:02,  1.36it/s]\u001b[A\n","Iteration:  34% 622/1851 [07:36<15:05,  1.36it/s]\u001b[A\n","Iteration:  34% 623/1851 [07:37<15:04,  1.36it/s]\u001b[A\n","Iteration:  34% 624/1851 [07:38<15:01,  1.36it/s]\u001b[A\n","Iteration:  34% 625/1851 [07:39<15:01,  1.36it/s]\u001b[A\n","Iteration:  34% 626/1851 [07:39<15:03,  1.36it/s]\u001b[A\n","Iteration:  34% 627/1851 [07:40<15:00,  1.36it/s]\u001b[A\n","Iteration:  34% 628/1851 [07:41<14:58,  1.36it/s]\u001b[A\n","Iteration:  34% 629/1851 [07:41<15:01,  1.36it/s]\u001b[A\n","Iteration:  34% 630/1851 [07:42<15:00,  1.36it/s]\u001b[A\n","Iteration:  34% 631/1851 [07:43<14:59,  1.36it/s]\u001b[A\n","Iteration:  34% 632/1851 [07:44<15:00,  1.35it/s]\u001b[A\n","Iteration:  34% 633/1851 [07:44<14:58,  1.36it/s]\u001b[A\n","Iteration:  34% 634/1851 [07:45<14:54,  1.36it/s]\u001b[A\n","Iteration:  34% 635/1851 [07:46<14:53,  1.36it/s]\u001b[A\n","Iteration:  34% 636/1851 [07:47<14:53,  1.36it/s]\u001b[A\n","Iteration:  34% 637/1851 [07:47<14:55,  1.36it/s]\u001b[A\n","Iteration:  34% 638/1851 [07:48<14:53,  1.36it/s]\u001b[A\n","Iteration:  35% 639/1851 [07:49<14:51,  1.36it/s]\u001b[A\n","Iteration:  35% 640/1851 [07:50<14:52,  1.36it/s]\u001b[A\n","Iteration:  35% 641/1851 [07:50<14:50,  1.36it/s]\u001b[A\n","Iteration:  35% 642/1851 [07:51<14:51,  1.36it/s]\u001b[A\n","Iteration:  35% 643/1851 [07:52<14:50,  1.36it/s]\u001b[A\n","Iteration:  35% 644/1851 [07:53<14:49,  1.36it/s]\u001b[A\n","Iteration:  35% 645/1851 [07:53<14:48,  1.36it/s]\u001b[A\n","Iteration:  35% 646/1851 [07:54<14:50,  1.35it/s]\u001b[A\n","Iteration:  35% 647/1851 [07:55<14:47,  1.36it/s]\u001b[A\n","Iteration:  35% 648/1851 [07:55<14:45,  1.36it/s]\u001b[A\n","Iteration:  35% 649/1851 [07:56<14:43,  1.36it/s]\u001b[A\n","Iteration:  35% 650/1851 [07:57<14:43,  1.36it/s]\u001b[A\n","Iteration:  35% 651/1851 [07:58<14:45,  1.36it/s]\u001b[A\n","Iteration:  35% 652/1851 [07:58<14:44,  1.36it/s]\u001b[A\n","Iteration:  35% 653/1851 [07:59<14:42,  1.36it/s]\u001b[A\n","Iteration:  35% 654/1851 [08:00<14:42,  1.36it/s]\u001b[A\n","Iteration:  35% 655/1851 [08:01<14:41,  1.36it/s]\u001b[A\n","Iteration:  35% 656/1851 [08:01<14:38,  1.36it/s]\u001b[A\n","Iteration:  35% 657/1851 [08:02<14:40,  1.36it/s]\u001b[A\n","Iteration:  36% 658/1851 [08:03<14:40,  1.35it/s]\u001b[A\n","Iteration:  36% 659/1851 [08:04<14:42,  1.35it/s]\u001b[A\n","Iteration:  36% 660/1851 [08:04<14:41,  1.35it/s]\u001b[A\n","Iteration:  36% 661/1851 [08:05<14:39,  1.35it/s]\u001b[A\n","Iteration:  36% 662/1851 [08:06<14:39,  1.35it/s]\u001b[A\n","Iteration:  36% 663/1851 [08:07<14:39,  1.35it/s]\u001b[A\n","Iteration:  36% 664/1851 [08:07<14:40,  1.35it/s]\u001b[A\n","Iteration:  36% 665/1851 [08:08<14:37,  1.35it/s]\u001b[A\n","Iteration:  36% 666/1851 [08:09<14:36,  1.35it/s]\u001b[A\n","Iteration:  36% 667/1851 [08:09<14:32,  1.36it/s]\u001b[A\n","Iteration:  36% 668/1851 [08:10<14:28,  1.36it/s]\u001b[A\n","Iteration:  36% 669/1851 [08:11<14:29,  1.36it/s]\u001b[A\n","Iteration:  36% 670/1851 [08:12<14:30,  1.36it/s]\u001b[A\n","Iteration:  36% 671/1851 [08:12<14:28,  1.36it/s]\u001b[A\n","Iteration:  36% 672/1851 [08:13<14:27,  1.36it/s]\u001b[A\n","Iteration:  36% 673/1851 [08:14<14:25,  1.36it/s]\u001b[A\n","Iteration:  36% 674/1851 [08:15<14:24,  1.36it/s]\u001b[A\n","Iteration:  36% 675/1851 [08:15<14:25,  1.36it/s]\u001b[A\n","Iteration:  37% 676/1851 [08:16<14:26,  1.36it/s]\u001b[A\n","Iteration:  37% 677/1851 [08:17<14:26,  1.35it/s]\u001b[A\n","Iteration:  37% 678/1851 [08:18<14:26,  1.35it/s]\u001b[A\n","Iteration:  37% 679/1851 [08:18<14:23,  1.36it/s]\u001b[A\n","Iteration:  37% 680/1851 [08:19<14:23,  1.36it/s]\u001b[A\n","Iteration:  37% 681/1851 [08:20<14:22,  1.36it/s]\u001b[A\n","Iteration:  37% 682/1851 [08:21<14:22,  1.36it/s]\u001b[A\n","Iteration:  37% 683/1851 [08:21<14:19,  1.36it/s]\u001b[A\n","Iteration:  37% 684/1851 [08:22<14:20,  1.36it/s]\u001b[A\n","Iteration:  37% 685/1851 [08:23<14:20,  1.36it/s]\u001b[A\n","Iteration:  37% 686/1851 [08:23<14:17,  1.36it/s]\u001b[A\n","Iteration:  37% 687/1851 [08:24<14:18,  1.36it/s]\u001b[A\n","Iteration:  37% 688/1851 [08:25<14:18,  1.35it/s]\u001b[A\n","Iteration:  37% 689/1851 [08:26<14:15,  1.36it/s]\u001b[A\n","Iteration:  37% 690/1851 [08:26<14:14,  1.36it/s]\u001b[A\n","Iteration:  37% 691/1851 [08:27<14:11,  1.36it/s]\u001b[A\n","Iteration:  37% 692/1851 [08:28<14:12,  1.36it/s]\u001b[A\n","Iteration:  37% 693/1851 [08:29<14:11,  1.36it/s]\u001b[A\n","Iteration:  37% 694/1851 [08:29<14:10,  1.36it/s]\u001b[A\n","Iteration:  38% 695/1851 [08:30<14:11,  1.36it/s]\u001b[A\n","Iteration:  38% 696/1851 [08:31<14:11,  1.36it/s]\u001b[A\n","Iteration:  38% 697/1851 [08:32<14:11,  1.36it/s]\u001b[A\n","Iteration:  38% 698/1851 [08:32<14:10,  1.36it/s]\u001b[A\n","Iteration:  38% 699/1851 [08:33<14:10,  1.36it/s]\u001b[A\n","Iteration:  38% 700/1851 [08:34<14:07,  1.36it/s]\u001b[A\n","Iteration:  38% 701/1851 [08:35<14:07,  1.36it/s]\u001b[A\n","Iteration:  38% 702/1851 [08:35<14:08,  1.35it/s]\u001b[A\n","Iteration:  38% 703/1851 [08:36<14:07,  1.35it/s]\u001b[A\n","Iteration:  38% 704/1851 [08:37<14:07,  1.35it/s]\u001b[A\n","Iteration:  38% 705/1851 [08:37<14:06,  1.35it/s]\u001b[A\n","Iteration:  38% 706/1851 [08:38<14:03,  1.36it/s]\u001b[A\n","Iteration:  38% 707/1851 [08:39<14:01,  1.36it/s]\u001b[A\n","Iteration:  38% 708/1851 [08:40<14:00,  1.36it/s]\u001b[A\n","Iteration:  38% 709/1851 [08:40<14:00,  1.36it/s]\u001b[A\n","Iteration:  38% 710/1851 [08:41<14:00,  1.36it/s]\u001b[A\n","Iteration:  38% 711/1851 [08:42<13:59,  1.36it/s]\u001b[A\n","Iteration:  38% 712/1851 [08:43<13:58,  1.36it/s]\u001b[A\n","Iteration:  39% 713/1851 [08:43<13:57,  1.36it/s]\u001b[A\n","Iteration:  39% 714/1851 [08:44<13:55,  1.36it/s]\u001b[A\n","Iteration:  39% 715/1851 [08:45<13:54,  1.36it/s]\u001b[A\n","Iteration:  39% 716/1851 [08:46<13:54,  1.36it/s]\u001b[A\n","Iteration:  39% 717/1851 [08:46<13:54,  1.36it/s]\u001b[A\n","Iteration:  39% 718/1851 [08:47<13:52,  1.36it/s]\u001b[A\n","Iteration:  39% 719/1851 [08:48<13:54,  1.36it/s]\u001b[A\n","Iteration:  39% 720/1851 [08:49<13:53,  1.36it/s]\u001b[A\n","Iteration:  39% 721/1851 [08:49<13:53,  1.36it/s]\u001b[A\n","Iteration:  39% 722/1851 [08:50<13:54,  1.35it/s]\u001b[A\n","Iteration:  39% 723/1851 [08:51<13:52,  1.36it/s]\u001b[A\n","Iteration:  39% 724/1851 [08:51<13:49,  1.36it/s]\u001b[A\n","Iteration:  39% 725/1851 [08:52<13:47,  1.36it/s]\u001b[A\n","Iteration:  39% 726/1851 [08:53<13:47,  1.36it/s]\u001b[A\n","Iteration:  39% 727/1851 [08:54<13:47,  1.36it/s]\u001b[A\n","Iteration:  39% 728/1851 [08:54<13:45,  1.36it/s]\u001b[A\n","Iteration:  39% 729/1851 [08:55<13:46,  1.36it/s]\u001b[A\n","Iteration:  39% 730/1851 [08:56<13:46,  1.36it/s]\u001b[A\n","Iteration:  39% 731/1851 [08:57<13:42,  1.36it/s]\u001b[A\n","Iteration:  40% 732/1851 [08:57<13:41,  1.36it/s]\u001b[A\n","Iteration:  40% 733/1851 [08:58<13:39,  1.36it/s]\u001b[A\n","Iteration:  40% 734/1851 [08:59<13:38,  1.36it/s]\u001b[A\n","Iteration:  40% 735/1851 [09:00<13:40,  1.36it/s]\u001b[A\n","Iteration:  40% 736/1851 [09:00<13:40,  1.36it/s]\u001b[A\n","Iteration:  40% 737/1851 [09:01<13:38,  1.36it/s]\u001b[A\n","Iteration:  40% 738/1851 [09:02<13:36,  1.36it/s]\u001b[A\n","Iteration:  40% 739/1851 [09:02<13:35,  1.36it/s]\u001b[A\n","Iteration:  40% 740/1851 [09:03<13:33,  1.36it/s]\u001b[A\n","Iteration:  40% 741/1851 [09:04<13:32,  1.37it/s]\u001b[A\n","Iteration:  40% 742/1851 [09:05<13:31,  1.37it/s]\u001b[A\n","Iteration:  40% 743/1851 [09:05<13:32,  1.36it/s]\u001b[A\n","Iteration:  40% 744/1851 [09:06<13:34,  1.36it/s]\u001b[A\n","Iteration:  40% 745/1851 [09:07<13:33,  1.36it/s]\u001b[A\n","Iteration:  40% 746/1851 [09:08<13:32,  1.36it/s]\u001b[A\n","Iteration:  40% 747/1851 [09:08<13:30,  1.36it/s]\u001b[A\n","Iteration:  40% 748/1851 [09:09<13:28,  1.36it/s]\u001b[A\n","Iteration:  40% 749/1851 [09:10<13:27,  1.37it/s]\u001b[A\n","Iteration:  41% 750/1851 [09:11<13:28,  1.36it/s]\u001b[A\n","Iteration:  41% 751/1851 [09:11<13:28,  1.36it/s]\u001b[A\n","Iteration:  41% 752/1851 [09:12<13:29,  1.36it/s]\u001b[A\n","Iteration:  41% 753/1851 [09:13<13:28,  1.36it/s]\u001b[A\n","Iteration:  41% 754/1851 [09:14<13:27,  1.36it/s]\u001b[A\n","Iteration:  41% 755/1851 [09:14<13:28,  1.36it/s]\u001b[A\n","Iteration:  41% 756/1851 [09:15<13:27,  1.36it/s]\u001b[A\n","Iteration:  41% 757/1851 [09:16<13:25,  1.36it/s]\u001b[A\n","Iteration:  41% 758/1851 [09:16<13:24,  1.36it/s]\u001b[A\n","Iteration:  41% 759/1851 [09:17<13:23,  1.36it/s]\u001b[A\n","Iteration:  41% 760/1851 [09:18<13:21,  1.36it/s]\u001b[A\n","Iteration:  41% 761/1851 [09:19<13:23,  1.36it/s]\u001b[A\n","Iteration:  41% 762/1851 [09:19<13:22,  1.36it/s]\u001b[A\n","Iteration:  41% 763/1851 [09:20<13:21,  1.36it/s]\u001b[A\n","Iteration:  41% 764/1851 [09:21<13:19,  1.36it/s]\u001b[A\n","Iteration:  41% 765/1851 [09:22<13:20,  1.36it/s]\u001b[A\n","Iteration:  41% 766/1851 [09:22<13:20,  1.36it/s]\u001b[A\n","Iteration:  41% 767/1851 [09:23<13:19,  1.36it/s]\u001b[A\n","Iteration:  41% 768/1851 [09:24<13:17,  1.36it/s]\u001b[A\n","Iteration:  42% 769/1851 [09:25<13:18,  1.36it/s]\u001b[A\n","Iteration:  42% 770/1851 [09:25<13:14,  1.36it/s]\u001b[A\n","Iteration:  42% 771/1851 [09:26<13:13,  1.36it/s]\u001b[A\n","Iteration:  42% 772/1851 [09:27<13:11,  1.36it/s]\u001b[A\n","Iteration:  42% 773/1851 [09:28<13:10,  1.36it/s]\u001b[A\n","Iteration:  42% 774/1851 [09:28<13:07,  1.37it/s]\u001b[A\n","Iteration:  42% 775/1851 [09:29<13:11,  1.36it/s]\u001b[A\n","Iteration:  42% 776/1851 [09:30<13:10,  1.36it/s]\u001b[A\n","Iteration:  42% 777/1851 [09:30<13:11,  1.36it/s]\u001b[A\n","Iteration:  42% 778/1851 [09:31<13:11,  1.36it/s]\u001b[A\n","Iteration:  42% 779/1851 [09:32<13:09,  1.36it/s]\u001b[A\n","Iteration:  42% 780/1851 [09:33<13:09,  1.36it/s]\u001b[A\n","Iteration:  42% 781/1851 [09:33<13:09,  1.36it/s]\u001b[A\n","Iteration:  42% 782/1851 [09:34<13:08,  1.36it/s]\u001b[A\n","Iteration:  42% 783/1851 [09:35<13:04,  1.36it/s]\u001b[A\n","Iteration:  42% 784/1851 [09:36<13:01,  1.36it/s]\u001b[A\n","Iteration:  42% 785/1851 [09:36<13:01,  1.36it/s]\u001b[A\n","Iteration:  42% 786/1851 [09:37<13:03,  1.36it/s]\u001b[A\n","Iteration:  43% 787/1851 [09:38<13:01,  1.36it/s]\u001b[A\n","Iteration:  43% 788/1851 [09:39<13:00,  1.36it/s]\u001b[A\n","Iteration:  43% 789/1851 [09:39<12:58,  1.36it/s]\u001b[A\n","Iteration:  43% 790/1851 [09:40<13:00,  1.36it/s]\u001b[A\n","Iteration:  43% 791/1851 [09:41<12:59,  1.36it/s]\u001b[A\n","Iteration:  43% 792/1851 [09:41<12:58,  1.36it/s]\u001b[A\n","Iteration:  43% 793/1851 [09:42<12:59,  1.36it/s]\u001b[A\n","Iteration:  43% 794/1851 [09:43<12:58,  1.36it/s]\u001b[A\n","Iteration:  43% 795/1851 [09:44<12:58,  1.36it/s]\u001b[A\n","Iteration:  43% 796/1851 [09:44<12:58,  1.35it/s]\u001b[A\n","Iteration:  43% 797/1851 [09:45<12:56,  1.36it/s]\u001b[A\n","Iteration:  43% 798/1851 [09:46<12:55,  1.36it/s]\u001b[A\n","Iteration:  43% 799/1851 [09:47<12:55,  1.36it/s]\u001b[A\n","Iteration:  43% 800/1851 [09:47<12:55,  1.36it/s]\u001b[A\n","Iteration:  43% 801/1851 [09:48<12:52,  1.36it/s]\u001b[A\n","Iteration:  43% 802/1851 [09:49<12:50,  1.36it/s]\u001b[A\n","Iteration:  43% 803/1851 [09:50<12:52,  1.36it/s]\u001b[A\n","Iteration:  43% 804/1851 [09:50<12:50,  1.36it/s]\u001b[A\n","Iteration:  43% 805/1851 [09:51<12:49,  1.36it/s]\u001b[A\n","Iteration:  44% 806/1851 [09:52<12:47,  1.36it/s]\u001b[A\n","Iteration:  44% 807/1851 [09:53<12:48,  1.36it/s]\u001b[A\n","Iteration:  44% 808/1851 [09:53<12:48,  1.36it/s]\u001b[A\n","Iteration:  44% 809/1851 [09:54<12:49,  1.35it/s]\u001b[A\n","Iteration:  44% 810/1851 [09:55<12:47,  1.36it/s]\u001b[A\n","Iteration:  44% 811/1851 [09:55<12:46,  1.36it/s]\u001b[A\n","Iteration:  44% 812/1851 [09:56<12:47,  1.35it/s]\u001b[A\n","Iteration:  44% 813/1851 [09:57<12:46,  1.35it/s]\u001b[A\n","Iteration:  44% 814/1851 [09:58<12:47,  1.35it/s]\u001b[A\n","Iteration:  44% 815/1851 [09:58<12:46,  1.35it/s]\u001b[A\n","Iteration:  44% 816/1851 [09:59<12:43,  1.36it/s]\u001b[A\n","Iteration:  44% 817/1851 [10:00<12:42,  1.36it/s]\u001b[A\n","Iteration:  44% 818/1851 [10:01<12:43,  1.35it/s]\u001b[A\n","Iteration:  44% 819/1851 [10:01<12:40,  1.36it/s]\u001b[A\n","Iteration:  44% 820/1851 [10:02<12:42,  1.35it/s]\u001b[A\n","Iteration:  44% 821/1851 [10:03<12:41,  1.35it/s]\u001b[A\n","Iteration:  44% 822/1851 [10:04<12:39,  1.35it/s]\u001b[A\n","Iteration:  44% 823/1851 [10:04<12:39,  1.35it/s]\u001b[A\n","Iteration:  45% 824/1851 [10:05<12:38,  1.35it/s]\u001b[A\n","Iteration:  45% 825/1851 [10:06<12:35,  1.36it/s]\u001b[A\n","Iteration:  45% 826/1851 [10:07<12:33,  1.36it/s]\u001b[A\n","Iteration:  45% 827/1851 [10:07<12:33,  1.36it/s]\u001b[A\n","Iteration:  45% 828/1851 [10:08<12:33,  1.36it/s]\u001b[A\n","Iteration:  45% 829/1851 [10:09<12:34,  1.35it/s]\u001b[A\n","Iteration:  45% 830/1851 [10:09<12:32,  1.36it/s]\u001b[A\n","Iteration:  45% 831/1851 [10:10<12:32,  1.35it/s]\u001b[A\n","Iteration:  45% 832/1851 [10:11<12:33,  1.35it/s]\u001b[A\n","Iteration:  45% 833/1851 [10:12<12:31,  1.35it/s]\u001b[A\n","Iteration:  45% 834/1851 [10:12<12:33,  1.35it/s]\u001b[A\n","Iteration:  45% 835/1851 [10:13<12:30,  1.35it/s]\u001b[A\n","Iteration:  45% 836/1851 [10:14<12:27,  1.36it/s]\u001b[A\n","Iteration:  45% 837/1851 [10:15<12:25,  1.36it/s]\u001b[A\n","Iteration:  45% 838/1851 [10:15<12:23,  1.36it/s]\u001b[A\n","Iteration:  45% 839/1851 [10:16<12:25,  1.36it/s]\u001b[A\n","Iteration:  45% 840/1851 [10:17<12:25,  1.36it/s]\u001b[A\n","Iteration:  45% 841/1851 [10:18<12:24,  1.36it/s]\u001b[A\n","Iteration:  45% 842/1851 [10:18<12:23,  1.36it/s]\u001b[A\n","Iteration:  46% 843/1851 [10:19<12:22,  1.36it/s]\u001b[A\n","Iteration:  46% 844/1851 [10:20<12:21,  1.36it/s]\u001b[A\n","Iteration:  46% 845/1851 [10:21<12:20,  1.36it/s]\u001b[A\n","Iteration:  46% 846/1851 [10:21<12:18,  1.36it/s]\u001b[A\n","Iteration:  46% 847/1851 [10:22<12:17,  1.36it/s]\u001b[A\n","Iteration:  46% 848/1851 [10:23<12:17,  1.36it/s]\u001b[A\n","Iteration:  46% 849/1851 [10:24<12:18,  1.36it/s]\u001b[A\n","Iteration:  46% 850/1851 [10:24<12:16,  1.36it/s]\u001b[A\n","Iteration:  46% 851/1851 [10:25<12:15,  1.36it/s]\u001b[A\n","Iteration:  46% 852/1851 [10:26<12:13,  1.36it/s]\u001b[A\n","Iteration:  46% 853/1851 [10:26<12:13,  1.36it/s]\u001b[A\n","Iteration:  46% 854/1851 [10:27<12:14,  1.36it/s]\u001b[A\n","Iteration:  46% 855/1851 [10:28<12:13,  1.36it/s]\u001b[A\n","Iteration:  46% 856/1851 [10:29<12:11,  1.36it/s]\u001b[A\n","Iteration:  46% 857/1851 [10:29<12:10,  1.36it/s]\u001b[A\n","Iteration:  46% 858/1851 [10:30<12:10,  1.36it/s]\u001b[A\n","Iteration:  46% 859/1851 [10:31<12:11,  1.36it/s]\u001b[A\n","Iteration:  46% 860/1851 [10:32<12:10,  1.36it/s]\u001b[A\n","Iteration:  47% 861/1851 [10:32<12:11,  1.35it/s]\u001b[A\n","Iteration:  47% 862/1851 [10:33<12:10,  1.35it/s]\u001b[A\n","Iteration:  47% 863/1851 [10:34<12:10,  1.35it/s]\u001b[A\n","Iteration:  47% 864/1851 [10:35<12:08,  1.35it/s]\u001b[A\n","Iteration:  47% 865/1851 [10:35<12:07,  1.36it/s]\u001b[A\n","Iteration:  47% 866/1851 [10:36<12:05,  1.36it/s]\u001b[A\n","Iteration:  47% 867/1851 [10:37<12:07,  1.35it/s]\u001b[A\n","Iteration:  47% 868/1851 [10:37<12:04,  1.36it/s]\u001b[A\n","Iteration:  47% 869/1851 [10:38<12:02,  1.36it/s]\u001b[A\n","Iteration:  47% 870/1851 [10:39<12:04,  1.35it/s]\u001b[A\n","Iteration:  47% 871/1851 [10:40<12:02,  1.36it/s]\u001b[A\n","Iteration:  47% 872/1851 [10:40<12:04,  1.35it/s]\u001b[A\n","Iteration:  47% 873/1851 [10:41<12:01,  1.36it/s]\u001b[A\n","Iteration:  47% 874/1851 [10:42<11:59,  1.36it/s]\u001b[A\n","Iteration:  47% 875/1851 [10:43<12:00,  1.35it/s]\u001b[A\n","Iteration:  47% 876/1851 [10:43<11:59,  1.35it/s]\u001b[A\n","Iteration:  47% 877/1851 [10:44<11:56,  1.36it/s]\u001b[A\n","Iteration:  47% 878/1851 [10:45<11:55,  1.36it/s]\u001b[A\n","Iteration:  47% 879/1851 [10:46<11:56,  1.36it/s]\u001b[A\n","Iteration:  48% 880/1851 [10:46<11:55,  1.36it/s]\u001b[A\n","Iteration:  48% 881/1851 [10:47<11:53,  1.36it/s]\u001b[A\n","Iteration:  48% 882/1851 [10:48<11:52,  1.36it/s]\u001b[A\n","Iteration:  48% 883/1851 [10:49<11:54,  1.36it/s]\u001b[A\n","Iteration:  48% 884/1851 [10:49<11:51,  1.36it/s]\u001b[A\n","Iteration:  48% 885/1851 [10:50<11:49,  1.36it/s]\u001b[A\n","Iteration:  48% 886/1851 [10:51<11:47,  1.36it/s]\u001b[A\n","Iteration:  48% 887/1851 [10:51<11:49,  1.36it/s]\u001b[A\n","Iteration:  48% 888/1851 [10:52<11:49,  1.36it/s]\u001b[A\n","Iteration:  48% 889/1851 [10:53<11:51,  1.35it/s]\u001b[A\n","Iteration:  48% 890/1851 [10:54<11:49,  1.35it/s]\u001b[A\n","Iteration:  48% 891/1851 [10:54<11:50,  1.35it/s]\u001b[A\n","Iteration:  48% 892/1851 [10:55<11:48,  1.35it/s]\u001b[A\n","Iteration:  48% 893/1851 [10:56<11:47,  1.35it/s]\u001b[A\n","Iteration:  48% 894/1851 [10:57<11:45,  1.36it/s]\u001b[A\n","Iteration:  48% 895/1851 [10:57<11:45,  1.36it/s]\u001b[A\n","Iteration:  48% 896/1851 [10:58<11:43,  1.36it/s]\u001b[A\n","Iteration:  48% 897/1851 [10:59<11:42,  1.36it/s]\u001b[A\n","Iteration:  49% 898/1851 [11:00<11:42,  1.36it/s]\u001b[A\n","Iteration:  49% 899/1851 [11:00<11:42,  1.35it/s]\u001b[A\n","Iteration:  49% 900/1851 [11:01<11:43,  1.35it/s]\u001b[A\n","Iteration:  49% 901/1851 [11:02<11:41,  1.35it/s]\u001b[A\n","Iteration:  49% 902/1851 [11:03<11:41,  1.35it/s]\u001b[A\n","Iteration:  49% 903/1851 [11:03<11:40,  1.35it/s]\u001b[A\n","Iteration:  49% 904/1851 [11:04<11:40,  1.35it/s]\u001b[A\n","Iteration:  49% 905/1851 [11:05<11:40,  1.35it/s]\u001b[A\n","Iteration:  49% 906/1851 [11:06<11:37,  1.35it/s]\u001b[A\n","Iteration:  49% 907/1851 [11:06<11:37,  1.35it/s]\u001b[A\n","Iteration:  49% 908/1851 [11:07<11:35,  1.35it/s]\u001b[A\n","Iteration:  49% 909/1851 [11:08<11:34,  1.36it/s]\u001b[A\n","Iteration:  49% 910/1851 [11:08<11:34,  1.35it/s]\u001b[A\n","Iteration:  49% 911/1851 [11:09<11:34,  1.35it/s]\u001b[A\n","Iteration:  49% 912/1851 [11:10<11:33,  1.35it/s]\u001b[A\n","Iteration:  49% 913/1851 [11:11<11:31,  1.36it/s]\u001b[A\n","Iteration:  49% 914/1851 [11:11<11:30,  1.36it/s]\u001b[A\n","Iteration:  49% 915/1851 [11:12<11:31,  1.35it/s]\u001b[A\n","Iteration:  49% 916/1851 [11:13<11:29,  1.36it/s]\u001b[A\n","Iteration:  50% 917/1851 [11:14<11:28,  1.36it/s]\u001b[A\n","Iteration:  50% 918/1851 [11:14<11:28,  1.35it/s]\u001b[A\n","Iteration:  50% 919/1851 [11:15<11:26,  1.36it/s]\u001b[A\n","Iteration:  50% 920/1851 [11:16<11:26,  1.36it/s]\u001b[A\n","Iteration:  50% 921/1851 [11:17<11:26,  1.35it/s]\u001b[A\n","Iteration:  50% 922/1851 [11:17<11:24,  1.36it/s]\u001b[A\n","Iteration:  50% 923/1851 [11:18<11:22,  1.36it/s]\u001b[A\n","Iteration:  50% 924/1851 [11:19<11:24,  1.36it/s]\u001b[A\n","Iteration:  50% 925/1851 [11:20<11:22,  1.36it/s]\u001b[A\n","Iteration:  50% 926/1851 [11:20<11:20,  1.36it/s]\u001b[A\n","Iteration:  50% 927/1851 [11:21<11:18,  1.36it/s]\u001b[A\n","Iteration:  50% 928/1851 [11:22<11:18,  1.36it/s]\u001b[A\n","Iteration:  50% 929/1851 [11:22<11:17,  1.36it/s]\u001b[A\n","Iteration:  50% 930/1851 [11:23<11:18,  1.36it/s]\u001b[A\n","Iteration:  50% 931/1851 [11:24<11:16,  1.36it/s]\u001b[A\n","Iteration:  50% 932/1851 [11:25<11:17,  1.36it/s]\u001b[A\n","Iteration:  50% 933/1851 [11:25<11:17,  1.36it/s]\u001b[A\n","Iteration:  50% 934/1851 [11:26<11:17,  1.35it/s]\u001b[A\n","Iteration:  51% 935/1851 [11:27<11:15,  1.36it/s]\u001b[A\n","Iteration:  51% 936/1851 [11:28<11:14,  1.36it/s]\u001b[A\n","Iteration:  51% 937/1851 [11:28<11:13,  1.36it/s]\u001b[A\n","Iteration:  51% 938/1851 [11:29<11:12,  1.36it/s]\u001b[A\n","Iteration:  51% 939/1851 [11:30<11:11,  1.36it/s]\u001b[A\n","Iteration:  51% 940/1851 [11:31<11:12,  1.35it/s]\u001b[A\n","Iteration:  51% 941/1851 [11:31<11:11,  1.35it/s]\u001b[A\n","Iteration:  51% 942/1851 [11:32<11:10,  1.36it/s]\u001b[A\n","Iteration:  51% 943/1851 [11:33<11:10,  1.36it/s]\u001b[A\n","Iteration:  51% 944/1851 [11:34<11:08,  1.36it/s]\u001b[A\n","Iteration:  51% 945/1851 [11:34<11:08,  1.36it/s]\u001b[A\n","Iteration:  51% 946/1851 [11:35<11:07,  1.36it/s]\u001b[A\n","Iteration:  51% 947/1851 [11:36<11:04,  1.36it/s]\u001b[A\n","Iteration:  51% 948/1851 [11:36<11:04,  1.36it/s]\u001b[A\n","Iteration:  51% 949/1851 [11:37<11:02,  1.36it/s]\u001b[A\n","Iteration:  51% 950/1851 [11:38<11:04,  1.36it/s]\u001b[A\n","Iteration:  51% 951/1851 [11:39<11:02,  1.36it/s]\u001b[A\n","Iteration:  51% 952/1851 [11:39<11:01,  1.36it/s]\u001b[A\n","Iteration:  51% 953/1851 [11:40<10:59,  1.36it/s]\u001b[A\n","Iteration:  52% 954/1851 [11:41<10:58,  1.36it/s]\u001b[A\n","Iteration:  52% 955/1851 [11:42<10:59,  1.36it/s]\u001b[A\n","Iteration:  52% 956/1851 [11:42<10:58,  1.36it/s]\u001b[A\n","Iteration:  52% 957/1851 [11:43<11:00,  1.35it/s]\u001b[A\n","Iteration:  52% 958/1851 [11:44<10:58,  1.36it/s]\u001b[A\n","Iteration:  52% 959/1851 [11:45<10:56,  1.36it/s]\u001b[A\n","Iteration:  52% 960/1851 [11:45<10:55,  1.36it/s]\u001b[A\n","Iteration:  52% 961/1851 [11:46<10:56,  1.36it/s]\u001b[A\n","Iteration:  52% 962/1851 [11:47<10:55,  1.36it/s]\u001b[A\n","Iteration:  52% 963/1851 [11:48<10:54,  1.36it/s]\u001b[A\n","Iteration:  52% 964/1851 [11:48<10:55,  1.35it/s]\u001b[A\n","Iteration:  52% 965/1851 [11:49<10:52,  1.36it/s]\u001b[A\n","Iteration:  52% 966/1851 [11:50<10:50,  1.36it/s]\u001b[A\n","Iteration:  52% 967/1851 [11:50<10:50,  1.36it/s]\u001b[A\n","Iteration:  52% 968/1851 [11:51<10:47,  1.36it/s]\u001b[A\n","Iteration:  52% 969/1851 [11:52<10:48,  1.36it/s]\u001b[A\n","Iteration:  52% 970/1851 [11:53<10:48,  1.36it/s]\u001b[A\n","Iteration:  52% 971/1851 [11:53<10:47,  1.36it/s]\u001b[A\n","Iteration:  53% 972/1851 [11:54<10:45,  1.36it/s]\u001b[A\n","Iteration:  53% 973/1851 [11:55<10:44,  1.36it/s]\u001b[A\n","Iteration:  53% 974/1851 [11:56<10:44,  1.36it/s]\u001b[A\n","Iteration:  53% 975/1851 [11:56<10:45,  1.36it/s]\u001b[A\n","Iteration:  53% 976/1851 [11:57<10:43,  1.36it/s]\u001b[A\n","Iteration:  53% 977/1851 [11:58<10:44,  1.36it/s]\u001b[A\n","Iteration:  53% 978/1851 [11:59<10:43,  1.36it/s]\u001b[A\n","Iteration:  53% 979/1851 [11:59<10:41,  1.36it/s]\u001b[A\n","Iteration:  53% 980/1851 [12:00<10:41,  1.36it/s]\u001b[A\n","Iteration:  53% 981/1851 [12:01<10:41,  1.36it/s]\u001b[A\n","Iteration:  53% 982/1851 [12:02<10:41,  1.36it/s]\u001b[A\n","Iteration:  53% 983/1851 [12:02<10:39,  1.36it/s]\u001b[A\n","Iteration:  53% 984/1851 [12:03<10:39,  1.36it/s]\u001b[A\n","Iteration:  53% 985/1851 [12:04<10:47,  1.34it/s]\u001b[A\n","Iteration:  53% 986/1851 [12:04<10:44,  1.34it/s]\u001b[A\n","Iteration:  53% 987/1851 [12:05<10:42,  1.35it/s]\u001b[A\n","Iteration:  53% 988/1851 [12:06<10:41,  1.34it/s]\u001b[A\n","Iteration:  53% 989/1851 [12:07<10:41,  1.34it/s]\u001b[A\n","Iteration:  53% 990/1851 [12:07<10:37,  1.35it/s]\u001b[A\n","Iteration:  54% 991/1851 [12:08<10:36,  1.35it/s]\u001b[A\n","Iteration:  54% 992/1851 [12:09<10:35,  1.35it/s]\u001b[A\n","Iteration:  54% 993/1851 [12:10<10:32,  1.36it/s]\u001b[A\n","Iteration:  54% 994/1851 [12:10<10:32,  1.36it/s]\u001b[A\n","Iteration:  54% 995/1851 [12:11<10:32,  1.35it/s]\u001b[A\n","Iteration:  54% 996/1851 [12:12<10:30,  1.36it/s]\u001b[A\n","Iteration:  54% 997/1851 [12:13<10:30,  1.35it/s]\u001b[A\n","Iteration:  54% 998/1851 [12:13<10:30,  1.35it/s]\u001b[A\n","Iteration:  54% 999/1851 [12:14<10:29,  1.35it/s]\u001b[A\n","Iteration:  54% 1000/1851 [12:15<10:29,  1.35it/s]\u001b[A\n","Iteration:  54% 1001/1851 [12:16<10:27,  1.36it/s]\u001b[A\n","Iteration:  54% 1002/1851 [12:16<10:27,  1.35it/s]\u001b[A\n","Iteration:  54% 1003/1851 [12:17<10:26,  1.35it/s]\u001b[A\n","Iteration:  54% 1004/1851 [12:18<10:25,  1.35it/s]\u001b[A\n","Iteration:  54% 1005/1851 [12:19<10:24,  1.35it/s]\u001b[A\n","Iteration:  54% 1006/1851 [12:19<10:24,  1.35it/s]\u001b[A\n","Iteration:  54% 1007/1851 [12:20<10:24,  1.35it/s]\u001b[A\n","Iteration:  54% 1008/1851 [12:21<10:23,  1.35it/s]\u001b[A\n","Iteration:  55% 1009/1851 [12:22<10:23,  1.35it/s]\u001b[A\n","Iteration:  55% 1010/1851 [12:22<10:23,  1.35it/s]\u001b[A\n","Iteration:  55% 1011/1851 [12:23<10:23,  1.35it/s]\u001b[A\n","Iteration:  55% 1012/1851 [12:24<10:21,  1.35it/s]\u001b[A\n","Iteration:  55% 1013/1851 [12:24<10:21,  1.35it/s]\u001b[A\n","Iteration:  55% 1014/1851 [12:25<10:19,  1.35it/s]\u001b[A\n","Iteration:  55% 1015/1851 [12:26<10:19,  1.35it/s]\u001b[A\n","Iteration:  55% 1016/1851 [12:27<10:17,  1.35it/s]\u001b[A\n","Iteration:  55% 1017/1851 [12:27<10:16,  1.35it/s]\u001b[A\n","Iteration:  55% 1018/1851 [12:28<10:16,  1.35it/s]\u001b[A\n","Iteration:  55% 1019/1851 [12:29<10:14,  1.35it/s]\u001b[A\n","Iteration:  55% 1020/1851 [12:30<10:13,  1.35it/s]\u001b[A\n","Iteration:  55% 1021/1851 [12:30<10:14,  1.35it/s]\u001b[A\n","Iteration:  55% 1022/1851 [12:31<10:11,  1.35it/s]\u001b[A\n","Iteration:  55% 1023/1851 [12:32<10:12,  1.35it/s]\u001b[A\n","Iteration:  55% 1024/1851 [12:33<10:12,  1.35it/s]\u001b[A\n","Iteration:  55% 1025/1851 [12:33<10:11,  1.35it/s]\u001b[A\n","Iteration:  55% 1026/1851 [12:34<10:11,  1.35it/s]\u001b[A\n","Iteration:  55% 1027/1851 [12:35<10:09,  1.35it/s]\u001b[A\n","Iteration:  56% 1028/1851 [12:36<10:09,  1.35it/s]\u001b[A\n","Iteration:  56% 1029/1851 [12:36<10:08,  1.35it/s]\u001b[A\n","Iteration:  56% 1030/1851 [12:37<10:07,  1.35it/s]\u001b[A\n","Iteration:  56% 1031/1851 [12:38<10:07,  1.35it/s]\u001b[A\n","Iteration:  56% 1032/1851 [12:39<10:05,  1.35it/s]\u001b[A\n","Iteration:  56% 1033/1851 [12:39<10:04,  1.35it/s]\u001b[A\n","Iteration:  56% 1034/1851 [12:40<10:04,  1.35it/s]\u001b[A\n","Iteration:  56% 1035/1851 [12:41<10:02,  1.35it/s]\u001b[A\n","Iteration:  56% 1036/1851 [12:41<10:02,  1.35it/s]\u001b[A\n","Iteration:  56% 1037/1851 [12:42<10:02,  1.35it/s]\u001b[A\n","Iteration:  56% 1038/1851 [12:43<10:02,  1.35it/s]\u001b[A\n","Iteration:  56% 1039/1851 [12:44<10:01,  1.35it/s]\u001b[A\n","Iteration:  56% 1040/1851 [12:44<09:59,  1.35it/s]\u001b[A\n","Iteration:  56% 1041/1851 [12:45<10:00,  1.35it/s]\u001b[A\n","Iteration:  56% 1042/1851 [12:46<09:58,  1.35it/s]\u001b[A\n","Iteration:  56% 1043/1851 [12:47<09:58,  1.35it/s]\u001b[A\n","Iteration:  56% 1044/1851 [12:47<09:57,  1.35it/s]\u001b[A\n","Iteration:  56% 1045/1851 [12:48<09:58,  1.35it/s]\u001b[A\n","Iteration:  57% 1046/1851 [12:49<09:55,  1.35it/s]\u001b[A\n","Iteration:  57% 1047/1851 [12:50<09:56,  1.35it/s]\u001b[A\n","Iteration:  57% 1048/1851 [12:50<09:54,  1.35it/s]\u001b[A\n","Iteration:  57% 1049/1851 [12:51<09:53,  1.35it/s]\u001b[A\n","Iteration:  57% 1050/1851 [12:52<09:53,  1.35it/s]\u001b[A\n","Iteration:  57% 1051/1851 [12:53<09:52,  1.35it/s]\u001b[A\n","Iteration:  57% 1052/1851 [12:53<09:52,  1.35it/s]\u001b[A\n","Iteration:  57% 1053/1851 [12:54<09:51,  1.35it/s]\u001b[A\n","Iteration:  57% 1054/1851 [12:55<09:50,  1.35it/s]\u001b[A\n","Iteration:  57% 1055/1851 [12:56<09:51,  1.35it/s]\u001b[A\n","Iteration:  57% 1056/1851 [12:56<09:48,  1.35it/s]\u001b[A\n","Iteration:  57% 1057/1851 [12:57<09:47,  1.35it/s]\u001b[A\n","Iteration:  57% 1058/1851 [12:58<09:46,  1.35it/s]\u001b[A\n","Iteration:  57% 1059/1851 [12:59<09:46,  1.35it/s]\u001b[A\n","Iteration:  57% 1060/1851 [12:59<09:44,  1.35it/s]\u001b[A\n","Iteration:  57% 1061/1851 [13:00<09:44,  1.35it/s]\u001b[A\n","Iteration:  57% 1062/1851 [13:01<09:43,  1.35it/s]\u001b[A\n","Iteration:  57% 1063/1851 [13:01<09:43,  1.35it/s]\u001b[A\n","Iteration:  57% 1064/1851 [13:02<09:42,  1.35it/s]\u001b[A\n","Iteration:  58% 1065/1851 [13:03<09:41,  1.35it/s]\u001b[A\n","Iteration:  58% 1066/1851 [13:04<09:39,  1.35it/s]\u001b[A\n","Iteration:  58% 1067/1851 [13:04<09:38,  1.35it/s]\u001b[A\n","Iteration:  58% 1068/1851 [13:05<09:38,  1.35it/s]\u001b[A\n","Iteration:  58% 1069/1851 [13:06<09:36,  1.36it/s]\u001b[A\n","Iteration:  58% 1070/1851 [13:07<09:37,  1.35it/s]\u001b[A\n","Iteration:  58% 1071/1851 [13:07<09:36,  1.35it/s]\u001b[A\n","Iteration:  58% 1072/1851 [13:08<09:34,  1.36it/s]\u001b[A\n","Iteration:  58% 1073/1851 [13:09<09:35,  1.35it/s]\u001b[A\n","Iteration:  58% 1074/1851 [13:10<09:33,  1.36it/s]\u001b[A\n","Iteration:  58% 1075/1851 [13:10<09:34,  1.35it/s]\u001b[A\n","Iteration:  58% 1076/1851 [13:11<09:32,  1.35it/s]\u001b[A\n","Iteration:  58% 1077/1851 [13:12<09:32,  1.35it/s]\u001b[A\n","Iteration:  58% 1078/1851 [13:13<09:31,  1.35it/s]\u001b[A\n","Iteration:  58% 1079/1851 [13:13<09:28,  1.36it/s]\u001b[A\n","Iteration:  58% 1080/1851 [13:14<09:29,  1.35it/s]\u001b[A\n","Iteration:  58% 1081/1851 [13:15<09:29,  1.35it/s]\u001b[A\n","Iteration:  58% 1082/1851 [13:16<09:28,  1.35it/s]\u001b[A\n","Iteration:  59% 1083/1851 [13:16<09:28,  1.35it/s]\u001b[A\n","Iteration:  59% 1084/1851 [13:17<09:27,  1.35it/s]\u001b[A\n","Iteration:  59% 1085/1851 [13:18<09:26,  1.35it/s]\u001b[A\n","Iteration:  59% 1086/1851 [13:18<09:26,  1.35it/s]\u001b[A\n","Iteration:  59% 1087/1851 [13:19<09:25,  1.35it/s]\u001b[A\n","Iteration:  59% 1088/1851 [13:20<09:24,  1.35it/s]\u001b[A\n","Iteration:  59% 1089/1851 [13:21<09:24,  1.35it/s]\u001b[A\n","Iteration:  59% 1090/1851 [13:21<09:21,  1.35it/s]\u001b[A\n","Iteration:  59% 1091/1851 [13:22<09:20,  1.36it/s]\u001b[A\n","Iteration:  59% 1092/1851 [13:23<09:20,  1.35it/s]\u001b[A\n","Iteration:  59% 1093/1851 [13:24<09:19,  1.35it/s]\u001b[A\n","Iteration:  59% 1094/1851 [13:24<09:19,  1.35it/s]\u001b[A\n","Iteration:  59% 1095/1851 [13:25<09:18,  1.35it/s]\u001b[A\n","Iteration:  59% 1096/1851 [13:26<09:17,  1.36it/s]\u001b[A\n","Iteration:  59% 1097/1851 [13:27<09:17,  1.35it/s]\u001b[A\n","Iteration:  59% 1098/1851 [13:27<09:16,  1.35it/s]\u001b[A\n","Iteration:  59% 1099/1851 [13:28<09:16,  1.35it/s]\u001b[A\n","Iteration:  59% 1100/1851 [13:29<09:15,  1.35it/s]\u001b[A\n","Iteration:  59% 1101/1851 [13:30<09:15,  1.35it/s]\u001b[A\n","Iteration:  60% 1102/1851 [13:30<09:12,  1.36it/s]\u001b[A\n","Iteration:  60% 1103/1851 [13:31<09:11,  1.36it/s]\u001b[A\n","Iteration:  60% 1104/1851 [13:32<09:11,  1.35it/s]\u001b[A\n","Iteration:  60% 1105/1851 [13:33<09:10,  1.36it/s]\u001b[A\n","Iteration:  60% 1106/1851 [13:33<09:09,  1.36it/s]\u001b[A\n","Iteration:  60% 1107/1851 [13:34<09:07,  1.36it/s]\u001b[A\n","Iteration:  60% 1108/1851 [13:35<09:07,  1.36it/s]\u001b[A\n","Iteration:  60% 1109/1851 [13:35<09:06,  1.36it/s]\u001b[A\n","Iteration:  60% 1110/1851 [13:36<09:05,  1.36it/s]\u001b[A\n","Iteration:  60% 1111/1851 [13:37<09:03,  1.36it/s]\u001b[A\n","Iteration:  60% 1112/1851 [13:38<09:02,  1.36it/s]\u001b[A\n","Iteration:  60% 1113/1851 [13:38<09:01,  1.36it/s]\u001b[A\n","Iteration:  60% 1114/1851 [13:39<09:01,  1.36it/s]\u001b[A\n","Iteration:  60% 1115/1851 [13:40<09:02,  1.36it/s]\u001b[A\n","Iteration:  60% 1116/1851 [13:41<09:01,  1.36it/s]\u001b[A\n","Iteration:  60% 1117/1851 [13:41<08:59,  1.36it/s]\u001b[A\n","Iteration:  60% 1118/1851 [13:42<08:59,  1.36it/s]\u001b[A\n","Iteration:  60% 1119/1851 [13:43<08:58,  1.36it/s]\u001b[A\n","Iteration:  61% 1120/1851 [13:44<08:56,  1.36it/s]\u001b[A\n","Iteration:  61% 1121/1851 [13:44<08:56,  1.36it/s]\u001b[A\n","Iteration:  61% 1122/1851 [13:45<08:56,  1.36it/s]\u001b[A\n","Iteration:  61% 1123/1851 [13:46<08:55,  1.36it/s]\u001b[A\n","Iteration:  61% 1124/1851 [13:46<08:54,  1.36it/s]\u001b[A\n","Iteration:  61% 1125/1851 [13:47<08:54,  1.36it/s]\u001b[A\n","Iteration:  61% 1126/1851 [13:48<08:52,  1.36it/s]\u001b[A\n","Iteration:  61% 1127/1851 [13:49<08:52,  1.36it/s]\u001b[A\n","Iteration:  61% 1128/1851 [13:49<08:51,  1.36it/s]\u001b[A\n","Iteration:  61% 1129/1851 [13:50<08:51,  1.36it/s]\u001b[A\n","Iteration:  61% 1130/1851 [13:51<08:51,  1.36it/s]\u001b[A\n","Iteration:  61% 1131/1851 [13:52<08:51,  1.36it/s]\u001b[A\n","Iteration:  61% 1132/1851 [13:52<08:50,  1.36it/s]\u001b[A\n","Iteration:  61% 1133/1851 [13:53<08:50,  1.35it/s]\u001b[A\n","Iteration:  61% 1134/1851 [13:54<08:49,  1.35it/s]\u001b[A\n","Iteration:  61% 1135/1851 [13:55<08:48,  1.35it/s]\u001b[A\n","Iteration:  61% 1136/1851 [13:55<08:48,  1.35it/s]\u001b[A\n","Iteration:  61% 1137/1851 [13:56<08:47,  1.35it/s]\u001b[A\n","Iteration:  61% 1138/1851 [13:57<08:47,  1.35it/s]\u001b[A\n","Iteration:  62% 1139/1851 [13:58<08:46,  1.35it/s]\u001b[A\n","Iteration:  62% 1140/1851 [13:58<08:44,  1.36it/s]\u001b[A\n","Iteration:  62% 1141/1851 [13:59<08:41,  1.36it/s]\u001b[A\n","Iteration:  62% 1142/1851 [14:00<08:40,  1.36it/s]\u001b[A\n","Iteration:  62% 1143/1851 [14:00<08:38,  1.36it/s]\u001b[A\n","Iteration:  62% 1144/1851 [14:01<08:39,  1.36it/s]\u001b[A\n","Iteration:  62% 1145/1851 [14:02<08:39,  1.36it/s]\u001b[A\n","Iteration:  62% 1146/1851 [14:03<08:39,  1.36it/s]\u001b[A\n","Iteration:  62% 1147/1851 [14:03<08:39,  1.36it/s]\u001b[A\n","Iteration:  62% 1148/1851 [14:04<08:38,  1.36it/s]\u001b[A\n","Iteration:  62% 1149/1851 [14:05<08:37,  1.36it/s]\u001b[A\n","Iteration:  62% 1150/1851 [14:06<08:35,  1.36it/s]\u001b[A\n","Iteration:  62% 1151/1851 [14:06<08:35,  1.36it/s]\u001b[A\n","Iteration:  62% 1152/1851 [14:07<08:34,  1.36it/s]\u001b[A\n","Iteration:  62% 1153/1851 [14:08<08:32,  1.36it/s]\u001b[A\n","Iteration:  62% 1154/1851 [14:09<08:31,  1.36it/s]\u001b[A\n","Iteration:  62% 1155/1851 [14:09<08:30,  1.36it/s]\u001b[A\n","Iteration:  62% 1156/1851 [14:10<08:31,  1.36it/s]\u001b[A\n","Iteration:  63% 1157/1851 [14:11<08:30,  1.36it/s]\u001b[A\n","Iteration:  63% 1158/1851 [14:12<08:29,  1.36it/s]\u001b[A\n","Iteration:  63% 1159/1851 [14:12<08:30,  1.36it/s]\u001b[A\n","Iteration:  63% 1160/1851 [14:13<08:28,  1.36it/s]\u001b[A\n","Iteration:  63% 1161/1851 [14:14<08:26,  1.36it/s]\u001b[A\n","Iteration:  63% 1162/1851 [14:14<08:25,  1.36it/s]\u001b[A\n","Iteration:  63% 1163/1851 [14:15<08:24,  1.36it/s]\u001b[A\n","Iteration:  63% 1164/1851 [14:16<08:25,  1.36it/s]\u001b[A\n","Iteration:  63% 1165/1851 [14:17<08:24,  1.36it/s]\u001b[A\n","Iteration:  63% 1166/1851 [14:17<08:22,  1.36it/s]\u001b[A\n","Iteration:  63% 1167/1851 [14:18<08:21,  1.36it/s]\u001b[A\n","Iteration:  63% 1168/1851 [14:19<08:21,  1.36it/s]\u001b[A\n","Iteration:  63% 1169/1851 [14:20<08:21,  1.36it/s]\u001b[A\n","Iteration:  63% 1170/1851 [14:20<08:21,  1.36it/s]\u001b[A\n","Iteration:  63% 1171/1851 [14:21<08:19,  1.36it/s]\u001b[A\n","Iteration:  63% 1172/1851 [14:22<08:18,  1.36it/s]\u001b[A\n","Iteration:  63% 1173/1851 [14:23<08:18,  1.36it/s]\u001b[A\n","Iteration:  63% 1174/1851 [14:23<08:18,  1.36it/s]\u001b[A\n","Iteration:  63% 1175/1851 [14:24<08:18,  1.36it/s]\u001b[A\n","Iteration:  64% 1176/1851 [14:25<08:16,  1.36it/s]\u001b[A\n","Iteration:  64% 1177/1851 [14:25<08:14,  1.36it/s]\u001b[A\n","Iteration:  64% 1178/1851 [14:26<08:15,  1.36it/s]\u001b[A\n","Iteration:  64% 1179/1851 [14:27<08:14,  1.36it/s]\u001b[A\n","Iteration:  64% 1180/1851 [14:28<08:14,  1.36it/s]\u001b[A\n","Iteration:  64% 1181/1851 [14:28<08:13,  1.36it/s]\u001b[A\n","Iteration:  64% 1182/1851 [14:29<08:13,  1.36it/s]\u001b[A\n","Iteration:  64% 1183/1851 [14:30<08:11,  1.36it/s]\u001b[A\n","Iteration:  64% 1184/1851 [14:31<08:12,  1.36it/s]\u001b[A\n","Iteration:  64% 1185/1851 [14:31<08:11,  1.36it/s]\u001b[A\n","Iteration:  64% 1186/1851 [14:32<08:10,  1.36it/s]\u001b[A\n","Iteration:  64% 1187/1851 [14:33<08:09,  1.36it/s]\u001b[A\n","Iteration:  64% 1188/1851 [14:34<08:08,  1.36it/s]\u001b[A\n","Iteration:  64% 1189/1851 [14:34<08:07,  1.36it/s]\u001b[A\n","Iteration:  64% 1190/1851 [14:35<08:08,  1.35it/s]\u001b[A\n","Iteration:  64% 1191/1851 [14:36<08:07,  1.35it/s]\u001b[A\n","Iteration:  64% 1192/1851 [14:37<08:06,  1.35it/s]\u001b[A\n","Iteration:  64% 1193/1851 [14:37<08:06,  1.35it/s]\u001b[A\n","Iteration:  65% 1194/1851 [14:38<08:05,  1.35it/s]\u001b[A\n","Iteration:  65% 1195/1851 [14:39<08:05,  1.35it/s]\u001b[A\n","Iteration:  65% 1196/1851 [14:40<08:03,  1.36it/s]\u001b[A\n","Iteration:  65% 1197/1851 [14:40<08:03,  1.35it/s]\u001b[A\n","Iteration:  65% 1198/1851 [14:41<08:02,  1.35it/s]\u001b[A\n","Iteration:  65% 1199/1851 [14:42<08:01,  1.35it/s]\u001b[A\n","Iteration:  65% 1200/1851 [14:42<07:59,  1.36it/s]\u001b[A\n","Iteration:  65% 1201/1851 [14:43<07:59,  1.36it/s]\u001b[A\n","Iteration:  65% 1202/1851 [14:44<07:58,  1.36it/s]\u001b[A\n","Iteration:  65% 1203/1851 [14:45<07:57,  1.36it/s]\u001b[A\n","Iteration:  65% 1204/1851 [14:45<07:56,  1.36it/s]\u001b[A\n","Iteration:  65% 1205/1851 [14:46<07:56,  1.35it/s]\u001b[A\n","Iteration:  65% 1206/1851 [14:47<07:55,  1.36it/s]\u001b[A\n","Iteration:  65% 1207/1851 [14:48<07:54,  1.36it/s]\u001b[A\n","Iteration:  65% 1208/1851 [14:48<07:54,  1.35it/s]\u001b[A\n","Iteration:  65% 1209/1851 [14:49<07:53,  1.36it/s]\u001b[A\n","Iteration:  65% 1210/1851 [14:50<07:53,  1.35it/s]\u001b[A\n","Iteration:  65% 1211/1851 [14:51<07:50,  1.36it/s]\u001b[A\n","Iteration:  65% 1212/1851 [14:51<07:51,  1.36it/s]\u001b[A\n","Iteration:  66% 1213/1851 [14:52<07:50,  1.36it/s]\u001b[A\n","Iteration:  66% 1214/1851 [14:53<07:49,  1.36it/s]\u001b[A\n","Iteration:  66% 1215/1851 [14:54<07:47,  1.36it/s]\u001b[A\n","Iteration:  66% 1216/1851 [14:54<07:46,  1.36it/s]\u001b[A\n","Iteration:  66% 1217/1851 [14:55<07:47,  1.36it/s]\u001b[A\n","Iteration:  66% 1218/1851 [14:56<07:46,  1.36it/s]\u001b[A\n","Iteration:  66% 1219/1851 [14:56<07:45,  1.36it/s]\u001b[A\n","Iteration:  66% 1220/1851 [14:57<07:43,  1.36it/s]\u001b[A\n","Iteration:  66% 1221/1851 [14:58<07:42,  1.36it/s]\u001b[A\n","Iteration:  66% 1222/1851 [14:59<07:43,  1.36it/s]\u001b[A\n","Iteration:  66% 1223/1851 [14:59<07:42,  1.36it/s]\u001b[A\n","Iteration:  66% 1224/1851 [15:00<07:42,  1.36it/s]\u001b[A\n","Iteration:  66% 1225/1851 [15:01<07:40,  1.36it/s]\u001b[A\n","Iteration:  66% 1226/1851 [15:02<07:40,  1.36it/s]\u001b[A\n","Iteration:  66% 1227/1851 [15:02<07:39,  1.36it/s]\u001b[A\n","Iteration:  66% 1228/1851 [15:03<07:39,  1.36it/s]\u001b[A\n","Iteration:  66% 1229/1851 [15:04<07:39,  1.35it/s]\u001b[A\n","Iteration:  66% 1230/1851 [15:05<07:38,  1.35it/s]\u001b[A\n","Iteration:  67% 1231/1851 [15:05<07:39,  1.35it/s]\u001b[A\n","Iteration:  67% 1232/1851 [15:06<07:36,  1.36it/s]\u001b[A\n","Iteration:  67% 1233/1851 [15:07<07:36,  1.35it/s]\u001b[A\n","Iteration:  67% 1234/1851 [15:08<07:36,  1.35it/s]\u001b[A\n","Iteration:  67% 1235/1851 [15:08<07:34,  1.35it/s]\u001b[A\n","Iteration:  67% 1236/1851 [15:09<07:34,  1.35it/s]\u001b[A\n","Iteration:  67% 1237/1851 [15:10<07:33,  1.35it/s]\u001b[A\n","Iteration:  67% 1238/1851 [15:10<07:32,  1.36it/s]\u001b[A\n","Iteration:  67% 1239/1851 [15:11<07:32,  1.35it/s]\u001b[A\n","Iteration:  67% 1240/1851 [15:12<07:30,  1.36it/s]\u001b[A\n","Iteration:  67% 1241/1851 [15:13<07:30,  1.35it/s]\u001b[A\n","Iteration:  67% 1242/1851 [15:13<07:29,  1.35it/s]\u001b[A\n","Iteration:  67% 1243/1851 [15:14<07:28,  1.36it/s]\u001b[A\n","Iteration:  67% 1244/1851 [15:15<07:26,  1.36it/s]\u001b[A\n","Iteration:  67% 1245/1851 [15:16<07:25,  1.36it/s]\u001b[A\n","Iteration:  67% 1246/1851 [15:16<07:24,  1.36it/s]\u001b[A\n","Iteration:  67% 1247/1851 [15:17<07:24,  1.36it/s]\u001b[A\n","Iteration:  67% 1248/1851 [15:18<07:23,  1.36it/s]\u001b[A\n","Iteration:  67% 1249/1851 [15:19<07:22,  1.36it/s]\u001b[A\n","Iteration:  68% 1250/1851 [15:19<07:20,  1.36it/s]\u001b[A\n","Iteration:  68% 1251/1851 [15:20<07:19,  1.36it/s]\u001b[A\n","Iteration:  68% 1252/1851 [15:21<07:19,  1.36it/s]\u001b[A\n","Iteration:  68% 1253/1851 [15:21<07:18,  1.36it/s]\u001b[A\n","Iteration:  68% 1254/1851 [15:22<07:16,  1.37it/s]\u001b[A\n","Iteration:  68% 1255/1851 [15:23<07:16,  1.37it/s]\u001b[A\n","Iteration:  68% 1256/1851 [15:24<07:17,  1.36it/s]\u001b[A\n","Iteration:  68% 1257/1851 [15:24<07:16,  1.36it/s]\u001b[A\n","Iteration:  68% 1258/1851 [15:25<07:17,  1.36it/s]\u001b[A\n","Iteration:  68% 1259/1851 [15:26<07:16,  1.36it/s]\u001b[A\n","Iteration:  68% 1260/1851 [15:27<07:14,  1.36it/s]\u001b[A\n","Iteration:  68% 1261/1851 [15:27<07:13,  1.36it/s]\u001b[A\n","Iteration:  68% 1262/1851 [15:28<07:11,  1.36it/s]\u001b[A\n","Iteration:  68% 1263/1851 [15:29<07:12,  1.36it/s]\u001b[A\n","Iteration:  68% 1264/1851 [15:30<07:12,  1.36it/s]\u001b[A\n","Iteration:  68% 1265/1851 [15:30<07:12,  1.36it/s]\u001b[A\n","Iteration:  68% 1266/1851 [15:31<07:10,  1.36it/s]\u001b[A\n","Iteration:  68% 1267/1851 [15:32<07:10,  1.36it/s]\u001b[A\n","Iteration:  69% 1268/1851 [15:33<07:09,  1.36it/s]\u001b[A\n","Iteration:  69% 1269/1851 [15:33<07:06,  1.36it/s]\u001b[A\n","Iteration:  69% 1270/1851 [15:34<07:06,  1.36it/s]\u001b[A\n","Iteration:  69% 1271/1851 [15:35<07:06,  1.36it/s]\u001b[A\n","Iteration:  69% 1272/1851 [15:35<07:06,  1.36it/s]\u001b[A\n","Iteration:  69% 1273/1851 [15:36<07:06,  1.35it/s]\u001b[A\n","Iteration:  69% 1274/1851 [15:37<07:05,  1.35it/s]\u001b[A\n","Iteration:  69% 1275/1851 [15:38<07:04,  1.36it/s]\u001b[A\n","Iteration:  69% 1276/1851 [15:38<07:02,  1.36it/s]\u001b[A\n","Iteration:  69% 1277/1851 [15:39<07:01,  1.36it/s]\u001b[A\n","Iteration:  69% 1278/1851 [15:40<07:01,  1.36it/s]\u001b[A\n","Iteration:  69% 1279/1851 [15:41<07:00,  1.36it/s]\u001b[A\n","Iteration:  69% 1280/1851 [15:41<07:00,  1.36it/s]\u001b[A\n","Iteration:  69% 1281/1851 [15:42<06:59,  1.36it/s]\u001b[A\n","Iteration:  69% 1282/1851 [15:43<06:59,  1.36it/s]\u001b[A\n","Iteration:  69% 1283/1851 [15:44<06:58,  1.36it/s]\u001b[A\n","Iteration:  69% 1284/1851 [15:44<06:57,  1.36it/s]\u001b[A\n","Iteration:  69% 1285/1851 [15:45<06:57,  1.35it/s]\u001b[A\n","Iteration:  69% 1286/1851 [15:46<06:56,  1.36it/s]\u001b[A\n","Iteration:  70% 1287/1851 [15:47<06:54,  1.36it/s]\u001b[A\n","Iteration:  70% 1288/1851 [15:47<06:53,  1.36it/s]\u001b[A\n","Iteration:  70% 1289/1851 [15:48<06:52,  1.36it/s]\u001b[A\n","Iteration:  70% 1290/1851 [15:49<06:53,  1.36it/s]\u001b[A\n","Iteration:  70% 1291/1851 [15:49<06:52,  1.36it/s]\u001b[A\n","Iteration:  70% 1292/1851 [15:50<06:52,  1.36it/s]\u001b[A\n","Iteration:  70% 1293/1851 [15:51<06:51,  1.36it/s]\u001b[A\n","Iteration:  70% 1294/1851 [15:52<06:50,  1.36it/s]\u001b[A\n","Iteration:  70% 1295/1851 [15:52<06:50,  1.35it/s]\u001b[A\n","Iteration:  70% 1296/1851 [15:53<06:49,  1.36it/s]\u001b[A\n","Iteration:  70% 1297/1851 [15:54<06:47,  1.36it/s]\u001b[A\n","Iteration:  70% 1298/1851 [15:55<06:47,  1.36it/s]\u001b[A\n","Iteration:  70% 1299/1851 [15:55<06:45,  1.36it/s]\u001b[A\n","Iteration:  70% 1300/1851 [15:56<06:46,  1.36it/s]\u001b[A\n","Iteration:  70% 1301/1851 [15:57<06:44,  1.36it/s]\u001b[A\n","Iteration:  70% 1302/1851 [15:58<06:44,  1.36it/s]\u001b[A\n","Iteration:  70% 1303/1851 [15:58<06:43,  1.36it/s]\u001b[A\n","Iteration:  70% 1304/1851 [15:59<06:41,  1.36it/s]\u001b[A\n","Iteration:  71% 1305/1851 [16:00<06:40,  1.36it/s]\u001b[A\n","Iteration:  71% 1306/1851 [16:00<06:39,  1.36it/s]\u001b[A\n","Iteration:  71% 1307/1851 [16:01<06:39,  1.36it/s]\u001b[A\n","Iteration:  71% 1308/1851 [16:02<06:38,  1.36it/s]\u001b[A\n","Iteration:  71% 1309/1851 [16:03<06:38,  1.36it/s]\u001b[A\n","Iteration:  71% 1310/1851 [16:03<06:38,  1.36it/s]\u001b[A\n","Iteration:  71% 1311/1851 [16:04<06:37,  1.36it/s]\u001b[A\n","Iteration:  71% 1312/1851 [16:05<06:36,  1.36it/s]\u001b[A\n","Iteration:  71% 1313/1851 [16:06<06:35,  1.36it/s]\u001b[A\n","Iteration:  71% 1314/1851 [16:06<06:35,  1.36it/s]\u001b[A\n","Iteration:  71% 1315/1851 [16:07<06:34,  1.36it/s]\u001b[A\n","Iteration:  71% 1316/1851 [16:08<06:33,  1.36it/s]\u001b[A\n","Iteration:  71% 1317/1851 [16:09<06:32,  1.36it/s]\u001b[A\n","Iteration:  71% 1318/1851 [16:09<06:32,  1.36it/s]\u001b[A\n","Iteration:  71% 1319/1851 [16:10<06:32,  1.36it/s]\u001b[A\n","Iteration:  71% 1320/1851 [16:11<06:31,  1.36it/s]\u001b[A\n","Iteration:  71% 1321/1851 [16:12<06:29,  1.36it/s]\u001b[A\n","Iteration:  71% 1322/1851 [16:12<06:28,  1.36it/s]\u001b[A\n","Iteration:  71% 1323/1851 [16:13<06:29,  1.36it/s]\u001b[A\n","Iteration:  72% 1324/1851 [16:14<06:27,  1.36it/s]\u001b[A\n","Iteration:  72% 1325/1851 [16:14<06:26,  1.36it/s]\u001b[A\n","Iteration:  72% 1326/1851 [16:15<06:25,  1.36it/s]\u001b[A\n","Iteration:  72% 1327/1851 [16:16<06:25,  1.36it/s]\u001b[A\n","Iteration:  72% 1328/1851 [16:17<06:24,  1.36it/s]\u001b[A\n","Iteration:  72% 1329/1851 [16:17<06:23,  1.36it/s]\u001b[A\n","Iteration:  72% 1330/1851 [16:18<06:24,  1.36it/s]\u001b[A\n","Iteration:  72% 1331/1851 [16:19<06:23,  1.36it/s]\u001b[A\n","Iteration:  72% 1332/1851 [16:20<06:23,  1.35it/s]\u001b[A\n","Iteration:  72% 1333/1851 [16:20<06:22,  1.36it/s]\u001b[A\n","Iteration:  72% 1334/1851 [16:21<06:20,  1.36it/s]\u001b[A\n","Iteration:  72% 1335/1851 [16:22<06:19,  1.36it/s]\u001b[A\n","Iteration:  72% 1336/1851 [16:23<06:19,  1.36it/s]\u001b[A\n","Iteration:  72% 1337/1851 [16:23<06:18,  1.36it/s]\u001b[A\n","Iteration:  72% 1338/1851 [16:24<06:17,  1.36it/s]\u001b[A\n","Iteration:  72% 1339/1851 [16:25<06:16,  1.36it/s]\u001b[A\n","Iteration:  72% 1340/1851 [16:26<06:16,  1.36it/s]\u001b[A\n","Iteration:  72% 1341/1851 [16:26<06:15,  1.36it/s]\u001b[A\n","Iteration:  73% 1342/1851 [16:27<06:14,  1.36it/s]\u001b[A\n","Iteration:  73% 1343/1851 [16:28<06:12,  1.36it/s]\u001b[A\n","Iteration:  73% 1344/1851 [16:28<06:11,  1.37it/s]\u001b[A\n","Iteration:  73% 1345/1851 [16:29<06:11,  1.36it/s]\u001b[A\n","Iteration:  73% 1346/1851 [16:30<06:10,  1.36it/s]\u001b[A\n","Iteration:  73% 1347/1851 [16:31<06:10,  1.36it/s]\u001b[A\n","Iteration:  73% 1348/1851 [16:31<06:09,  1.36it/s]\u001b[A\n","Iteration:  73% 1349/1851 [16:32<06:10,  1.36it/s]\u001b[A\n","Iteration:  73% 1350/1851 [16:33<06:08,  1.36it/s]\u001b[A\n","Iteration:  73% 1351/1851 [16:34<06:08,  1.36it/s]\u001b[A\n","Iteration:  73% 1352/1851 [16:34<06:07,  1.36it/s]\u001b[A\n","Iteration:  73% 1353/1851 [16:35<06:06,  1.36it/s]\u001b[A\n","Iteration:  73% 1354/1851 [16:36<06:06,  1.36it/s]\u001b[A\n","Iteration:  73% 1355/1851 [16:37<06:05,  1.36it/s]\u001b[A\n","Iteration:  73% 1356/1851 [16:37<06:05,  1.36it/s]\u001b[A\n","Iteration:  73% 1357/1851 [16:38<06:04,  1.35it/s]\u001b[A\n","Iteration:  73% 1358/1851 [16:39<06:02,  1.36it/s]\u001b[A\n","Iteration:  73% 1359/1851 [16:40<06:01,  1.36it/s]\u001b[A\n","Iteration:  73% 1360/1851 [16:40<06:01,  1.36it/s]\u001b[A\n","Iteration:  74% 1361/1851 [16:41<06:01,  1.36it/s]\u001b[A\n","Iteration:  74% 1362/1851 [16:42<05:59,  1.36it/s]\u001b[A\n","Iteration:  74% 1363/1851 [16:42<05:59,  1.36it/s]\u001b[A\n","Iteration:  74% 1364/1851 [16:43<05:58,  1.36it/s]\u001b[A\n","Iteration:  74% 1365/1851 [16:44<05:57,  1.36it/s]\u001b[A\n","Iteration:  74% 1366/1851 [16:45<05:56,  1.36it/s]\u001b[A\n","Iteration:  74% 1367/1851 [16:45<05:57,  1.36it/s]\u001b[A\n","Iteration:  74% 1368/1851 [16:46<05:56,  1.36it/s]\u001b[A\n","Iteration:  74% 1369/1851 [16:47<05:54,  1.36it/s]\u001b[A\n","Iteration:  74% 1370/1851 [16:48<05:53,  1.36it/s]\u001b[A\n","Iteration:  74% 1371/1851 [16:48<05:52,  1.36it/s]\u001b[A\n","Iteration:  74% 1372/1851 [16:49<05:52,  1.36it/s]\u001b[A\n","Iteration:  74% 1373/1851 [16:50<05:51,  1.36it/s]\u001b[A\n","Iteration:  74% 1374/1851 [16:51<05:51,  1.36it/s]\u001b[A\n","Iteration:  74% 1375/1851 [16:51<05:50,  1.36it/s]\u001b[A\n","Iteration:  74% 1376/1851 [16:52<05:49,  1.36it/s]\u001b[A\n","Iteration:  74% 1377/1851 [16:53<05:48,  1.36it/s]\u001b[A\n","Iteration:  74% 1378/1851 [16:53<05:47,  1.36it/s]\u001b[A\n","Iteration:  75% 1379/1851 [16:54<05:47,  1.36it/s]\u001b[A\n","Iteration:  75% 1380/1851 [16:55<05:46,  1.36it/s]\u001b[A\n","Iteration:  75% 1381/1851 [16:56<05:45,  1.36it/s]\u001b[A\n","Iteration:  75% 1382/1851 [16:56<05:44,  1.36it/s]\u001b[A\n","Iteration:  75% 1383/1851 [16:57<05:43,  1.36it/s]\u001b[A\n","Iteration:  75% 1384/1851 [16:58<05:42,  1.36it/s]\u001b[A\n","Iteration:  75% 1385/1851 [16:59<05:42,  1.36it/s]\u001b[A\n","Iteration:  75% 1386/1851 [16:59<05:42,  1.36it/s]\u001b[A\n","Iteration:  75% 1387/1851 [17:00<05:41,  1.36it/s]\u001b[A\n","Iteration:  75% 1388/1851 [17:01<05:39,  1.36it/s]\u001b[A\n","Iteration:  75% 1389/1851 [17:02<05:40,  1.36it/s]\u001b[A\n","Iteration:  75% 1390/1851 [17:02<05:39,  1.36it/s]\u001b[A\n","Iteration:  75% 1391/1851 [17:03<05:38,  1.36it/s]\u001b[A\n","Iteration:  75% 1392/1851 [17:04<05:37,  1.36it/s]\u001b[A\n","Iteration:  75% 1393/1851 [17:05<05:37,  1.36it/s]\u001b[A\n","Iteration:  75% 1394/1851 [17:05<05:36,  1.36it/s]\u001b[A\n","Iteration:  75% 1395/1851 [17:06<05:35,  1.36it/s]\u001b[A\n","Iteration:  75% 1396/1851 [17:07<05:34,  1.36it/s]\u001b[A\n","Iteration:  75% 1397/1851 [17:07<05:33,  1.36it/s]\u001b[A\n","Iteration:  76% 1398/1851 [17:08<05:32,  1.36it/s]\u001b[A\n","Iteration:  76% 1399/1851 [17:09<05:30,  1.37it/s]\u001b[A\n","Iteration:  76% 1400/1851 [17:10<05:30,  1.36it/s]\u001b[A\n","Iteration:  76% 1401/1851 [17:10<05:30,  1.36it/s]\u001b[A\n","Iteration:  76% 1402/1851 [17:11<05:29,  1.36it/s]\u001b[A\n","Iteration:  76% 1403/1851 [17:12<05:29,  1.36it/s]\u001b[A\n","Iteration:  76% 1404/1851 [17:13<05:28,  1.36it/s]\u001b[A\n","Iteration:  76% 1405/1851 [17:13<05:27,  1.36it/s]\u001b[A\n","Iteration:  76% 1406/1851 [17:14<05:27,  1.36it/s]\u001b[A\n","Iteration:  76% 1407/1851 [17:15<05:25,  1.36it/s]\u001b[A\n","Iteration:  76% 1408/1851 [17:16<05:24,  1.36it/s]\u001b[A\n","Iteration:  76% 1409/1851 [17:16<05:24,  1.36it/s]\u001b[A\n","Iteration:  76% 1410/1851 [17:17<05:22,  1.37it/s]\u001b[A\n","Iteration:  76% 1411/1851 [17:18<05:21,  1.37it/s]\u001b[A\n","Iteration:  76% 1412/1851 [17:18<05:21,  1.36it/s]\u001b[A\n","Iteration:  76% 1413/1851 [17:19<05:22,  1.36it/s]\u001b[A\n","Iteration:  76% 1414/1851 [17:20<05:21,  1.36it/s]\u001b[A\n","Iteration:  76% 1415/1851 [17:21<05:20,  1.36it/s]\u001b[A\n","Iteration:  76% 1416/1851 [17:21<05:20,  1.36it/s]\u001b[A\n","Iteration:  77% 1417/1851 [17:22<05:19,  1.36it/s]\u001b[A\n","Iteration:  77% 1418/1851 [17:23<05:19,  1.36it/s]\u001b[A\n","Iteration:  77% 1419/1851 [17:24<05:18,  1.36it/s]\u001b[A\n","Iteration:  77% 1420/1851 [17:24<05:17,  1.36it/s]\u001b[A\n","Iteration:  77% 1421/1851 [17:25<05:15,  1.36it/s]\u001b[A\n","Iteration:  77% 1422/1851 [17:26<05:15,  1.36it/s]\u001b[A\n","Iteration:  77% 1423/1851 [17:27<05:15,  1.36it/s]\u001b[A\n","Iteration:  77% 1424/1851 [17:27<05:14,  1.36it/s]\u001b[A\n","Iteration:  77% 1425/1851 [17:28<05:13,  1.36it/s]\u001b[A\n","Iteration:  77% 1426/1851 [17:29<05:12,  1.36it/s]\u001b[A\n","Iteration:  77% 1427/1851 [17:30<05:12,  1.36it/s]\u001b[A\n","Iteration:  77% 1428/1851 [17:30<05:11,  1.36it/s]\u001b[A\n","Iteration:  77% 1429/1851 [17:31<05:09,  1.36it/s]\u001b[A\n","Iteration:  77% 1430/1851 [17:32<05:09,  1.36it/s]\u001b[A\n","Iteration:  77% 1431/1851 [17:32<05:07,  1.37it/s]\u001b[A\n","Iteration:  77% 1432/1851 [17:33<05:06,  1.37it/s]\u001b[A\n","Iteration:  77% 1433/1851 [17:34<05:05,  1.37it/s]\u001b[A\n","Iteration:  77% 1434/1851 [17:35<05:05,  1.37it/s]\u001b[A\n","Iteration:  78% 1435/1851 [17:35<05:05,  1.36it/s]\u001b[A\n","Iteration:  78% 1436/1851 [17:36<05:04,  1.36it/s]\u001b[A\n","Iteration:  78% 1437/1851 [17:37<05:04,  1.36it/s]\u001b[A\n","Iteration:  78% 1438/1851 [17:38<05:03,  1.36it/s]\u001b[A\n","Iteration:  78% 1439/1851 [17:38<05:02,  1.36it/s]\u001b[A\n","Iteration:  78% 1440/1851 [17:39<05:01,  1.36it/s]\u001b[A\n","Iteration:  78% 1441/1851 [17:40<05:01,  1.36it/s]\u001b[A\n","Iteration:  78% 1442/1851 [17:41<05:00,  1.36it/s]\u001b[A\n","Iteration:  78% 1443/1851 [17:41<04:59,  1.36it/s]\u001b[A\n","Iteration:  78% 1444/1851 [17:42<04:59,  1.36it/s]\u001b[A\n","Iteration:  78% 1445/1851 [17:43<04:58,  1.36it/s]\u001b[A\n","Iteration:  78% 1446/1851 [17:43<04:58,  1.36it/s]\u001b[A\n","Iteration:  78% 1447/1851 [17:44<04:57,  1.36it/s]\u001b[A\n","Iteration:  78% 1448/1851 [17:45<04:57,  1.36it/s]\u001b[A\n","Iteration:  78% 1449/1851 [17:46<04:55,  1.36it/s]\u001b[A\n","Iteration:  78% 1450/1851 [17:46<04:55,  1.36it/s]\u001b[A\n","Iteration:  78% 1451/1851 [17:47<04:55,  1.36it/s]\u001b[A\n","Iteration:  78% 1452/1851 [17:48<04:53,  1.36it/s]\u001b[A\n","Iteration:  78% 1453/1851 [17:49<04:53,  1.36it/s]\u001b[A\n","Iteration:  79% 1454/1851 [17:49<04:52,  1.36it/s]\u001b[A\n","Iteration:  79% 1455/1851 [17:50<04:52,  1.36it/s]\u001b[A\n","Iteration:  79% 1456/1851 [17:51<04:52,  1.35it/s]\u001b[A\n","Iteration:  79% 1457/1851 [17:52<04:50,  1.35it/s]\u001b[A\n","Iteration:  79% 1458/1851 [17:52<04:50,  1.35it/s]\u001b[A\n","Iteration:  79% 1459/1851 [17:53<04:49,  1.36it/s]\u001b[A\n","Iteration:  79% 1460/1851 [17:54<04:48,  1.36it/s]\u001b[A\n","Iteration:  79% 1461/1851 [17:55<04:47,  1.36it/s]\u001b[A\n","Iteration:  79% 1462/1851 [17:55<04:46,  1.36it/s]\u001b[A\n","Iteration:  79% 1463/1851 [17:56<04:46,  1.36it/s]\u001b[A\n","Iteration:  79% 1464/1851 [17:57<04:45,  1.36it/s]\u001b[A\n","Iteration:  79% 1465/1851 [17:57<04:45,  1.35it/s]\u001b[A\n","Iteration:  79% 1466/1851 [17:58<04:44,  1.35it/s]\u001b[A\n","Iteration:  79% 1467/1851 [17:59<04:44,  1.35it/s]\u001b[A\n","Iteration:  79% 1468/1851 [18:00<04:42,  1.35it/s]\u001b[A\n","Iteration:  79% 1469/1851 [18:00<04:41,  1.36it/s]\u001b[A\n","Iteration:  79% 1470/1851 [18:01<04:41,  1.35it/s]\u001b[A\n","Iteration:  79% 1471/1851 [18:02<04:41,  1.35it/s]\u001b[A\n","Iteration:  80% 1472/1851 [18:03<04:39,  1.35it/s]\u001b[A\n","Iteration:  80% 1473/1851 [18:03<04:39,  1.35it/s]\u001b[A\n","Iteration:  80% 1474/1851 [18:04<04:38,  1.35it/s]\u001b[A\n","Iteration:  80% 1475/1851 [18:05<04:37,  1.35it/s]\u001b[A\n","Iteration:  80% 1476/1851 [18:06<04:36,  1.35it/s]\u001b[A\n","Iteration:  80% 1477/1851 [18:06<04:35,  1.36it/s]\u001b[A\n","Iteration:  80% 1478/1851 [18:07<04:35,  1.35it/s]\u001b[A\n","Iteration:  80% 1479/1851 [18:08<04:34,  1.35it/s]\u001b[A\n","Iteration:  80% 1480/1851 [18:09<04:33,  1.36it/s]\u001b[A\n","Iteration:  80% 1481/1851 [18:09<04:32,  1.36it/s]\u001b[A\n","Iteration:  80% 1482/1851 [18:10<04:31,  1.36it/s]\u001b[A\n","Iteration:  80% 1483/1851 [18:11<04:30,  1.36it/s]\u001b[A\n","Iteration:  80% 1484/1851 [18:11<04:29,  1.36it/s]\u001b[A\n","Iteration:  80% 1485/1851 [18:12<04:30,  1.36it/s]\u001b[A\n","Iteration:  80% 1486/1851 [18:13<04:29,  1.36it/s]\u001b[A\n","Iteration:  80% 1487/1851 [18:14<04:27,  1.36it/s]\u001b[A\n","Iteration:  80% 1488/1851 [18:14<04:27,  1.36it/s]\u001b[A\n","Iteration:  80% 1489/1851 [18:15<04:26,  1.36it/s]\u001b[A\n","Iteration:  80% 1490/1851 [18:16<04:25,  1.36it/s]\u001b[A\n","Iteration:  81% 1491/1851 [18:17<04:24,  1.36it/s]\u001b[A\n","Iteration:  81% 1492/1851 [18:17<04:24,  1.36it/s]\u001b[A\n","Iteration:  81% 1493/1851 [18:18<04:23,  1.36it/s]\u001b[A\n","Iteration:  81% 1494/1851 [18:19<04:22,  1.36it/s]\u001b[A\n","Iteration:  81% 1495/1851 [18:20<04:21,  1.36it/s]\u001b[A\n","Iteration:  81% 1496/1851 [18:20<04:20,  1.36it/s]\u001b[A\n","Iteration:  81% 1497/1851 [18:21<04:20,  1.36it/s]\u001b[A\n","Iteration:  81% 1498/1851 [18:22<04:20,  1.36it/s]\u001b[A\n","Iteration:  81% 1499/1851 [18:23<04:19,  1.36it/s]\u001b[A\n","Iteration:  81% 1500/1851 [18:23<04:17,  1.36it/s]\u001b[A\n","Iteration:  81% 1501/1851 [18:24<04:16,  1.36it/s]\u001b[A\n","Iteration:  81% 1502/1851 [18:25<04:16,  1.36it/s]\u001b[A\n","Iteration:  81% 1503/1851 [18:25<04:15,  1.36it/s]\u001b[A\n","Iteration:  81% 1504/1851 [18:26<04:15,  1.36it/s]\u001b[A\n","Iteration:  81% 1505/1851 [18:27<04:14,  1.36it/s]\u001b[A\n","Iteration:  81% 1506/1851 [18:28<04:14,  1.36it/s]\u001b[A\n","Iteration:  81% 1507/1851 [18:28<04:13,  1.36it/s]\u001b[A\n","Iteration:  81% 1508/1851 [18:29<04:12,  1.36it/s]\u001b[A\n","Iteration:  82% 1509/1851 [18:30<04:12,  1.35it/s]\u001b[A\n","Iteration:  82% 1510/1851 [18:31<04:11,  1.36it/s]\u001b[A\n","Iteration:  82% 1511/1851 [18:31<04:11,  1.35it/s]\u001b[A\n","Iteration:  82% 1512/1851 [18:32<04:10,  1.36it/s]\u001b[A\n","Iteration:  82% 1513/1851 [18:33<04:09,  1.35it/s]\u001b[A\n","Iteration:  82% 1514/1851 [18:34<04:08,  1.35it/s]\u001b[A\n","Iteration:  82% 1515/1851 [18:34<04:07,  1.36it/s]\u001b[A\n","Iteration:  82% 1516/1851 [18:35<04:06,  1.36it/s]\u001b[A\n","Iteration:  82% 1517/1851 [18:36<04:06,  1.35it/s]\u001b[A\n","Iteration:  82% 1518/1851 [18:37<04:05,  1.35it/s]\u001b[A\n","Iteration:  82% 1519/1851 [18:37<04:05,  1.35it/s]\u001b[A\n","Iteration:  82% 1520/1851 [18:38<04:04,  1.36it/s]\u001b[A\n","Iteration:  82% 1521/1851 [18:39<04:02,  1.36it/s]\u001b[A\n","Iteration:  82% 1522/1851 [18:39<04:02,  1.36it/s]\u001b[A\n","Iteration:  82% 1523/1851 [18:40<04:02,  1.35it/s]\u001b[A\n","Iteration:  82% 1524/1851 [18:41<04:00,  1.36it/s]\u001b[A\n","Iteration:  82% 1525/1851 [18:42<04:00,  1.35it/s]\u001b[A\n","Iteration:  82% 1526/1851 [18:42<03:59,  1.35it/s]\u001b[A\n","Iteration:  82% 1527/1851 [18:43<03:59,  1.35it/s]\u001b[A\n","Iteration:  83% 1528/1851 [18:44<03:58,  1.35it/s]\u001b[A\n","Iteration:  83% 1529/1851 [18:45<03:57,  1.35it/s]\u001b[A\n","Iteration:  83% 1530/1851 [18:45<03:57,  1.35it/s]\u001b[A\n","Iteration:  83% 1531/1851 [18:46<03:56,  1.35it/s]\u001b[A\n","Iteration:  83% 1532/1851 [18:47<03:55,  1.36it/s]\u001b[A\n","Iteration:  83% 1533/1851 [18:48<03:54,  1.35it/s]\u001b[A\n","Iteration:  83% 1534/1851 [18:48<03:54,  1.35it/s]\u001b[A\n","Iteration:  83% 1535/1851 [18:49<03:52,  1.36it/s]\u001b[A\n","Iteration:  83% 1536/1851 [18:50<03:52,  1.36it/s]\u001b[A\n","Iteration:  83% 1537/1851 [18:51<03:51,  1.35it/s]\u001b[A\n","Iteration:  83% 1538/1851 [18:51<03:50,  1.36it/s]\u001b[A\n","Iteration:  83% 1539/1851 [18:52<03:49,  1.36it/s]\u001b[A\n","Iteration:  83% 1540/1851 [18:53<03:49,  1.36it/s]\u001b[A\n","Iteration:  83% 1541/1851 [18:54<03:49,  1.35it/s]\u001b[A\n","Iteration:  83% 1542/1851 [18:54<03:48,  1.35it/s]\u001b[A\n","Iteration:  83% 1543/1851 [18:55<03:47,  1.35it/s]\u001b[A\n","Iteration:  83% 1544/1851 [18:56<03:47,  1.35it/s]\u001b[A\n","Iteration:  83% 1545/1851 [18:56<03:46,  1.35it/s]\u001b[A\n","Iteration:  84% 1546/1851 [18:57<03:45,  1.36it/s]\u001b[A\n","Iteration:  84% 1547/1851 [18:58<03:44,  1.35it/s]\u001b[A\n","Iteration:  84% 1548/1851 [18:59<03:43,  1.36it/s]\u001b[A\n","Iteration:  84% 1549/1851 [18:59<03:42,  1.36it/s]\u001b[A\n","Iteration:  84% 1550/1851 [19:00<03:42,  1.35it/s]\u001b[A\n","Iteration:  84% 1551/1851 [19:01<03:41,  1.36it/s]\u001b[A\n","Iteration:  84% 1552/1851 [19:02<03:40,  1.35it/s]\u001b[A\n","Iteration:  84% 1553/1851 [19:02<03:39,  1.36it/s]\u001b[A\n","Iteration:  84% 1554/1851 [19:03<03:39,  1.35it/s]\u001b[A\n","Iteration:  84% 1555/1851 [19:04<03:38,  1.35it/s]\u001b[A\n","Iteration:  84% 1556/1851 [19:05<03:37,  1.35it/s]\u001b[A\n","Iteration:  84% 1557/1851 [19:05<03:37,  1.35it/s]\u001b[A\n","Iteration:  84% 1558/1851 [19:06<03:36,  1.35it/s]\u001b[A\n","Iteration:  84% 1559/1851 [19:07<03:35,  1.36it/s]\u001b[A\n","Iteration:  84% 1560/1851 [19:08<03:35,  1.35it/s]\u001b[A\n","Iteration:  84% 1561/1851 [19:08<03:34,  1.35it/s]\u001b[A\n","Iteration:  84% 1562/1851 [19:09<03:33,  1.35it/s]\u001b[A\n","Iteration:  84% 1563/1851 [19:10<03:32,  1.35it/s]\u001b[A\n","Iteration:  84% 1564/1851 [19:11<03:32,  1.35it/s]\u001b[A\n","Iteration:  85% 1565/1851 [19:11<03:30,  1.36it/s]\u001b[A\n","Iteration:  85% 1566/1851 [19:12<03:29,  1.36it/s]\u001b[A\n","Iteration:  85% 1567/1851 [19:13<03:29,  1.36it/s]\u001b[A\n","Iteration:  85% 1568/1851 [19:13<03:28,  1.36it/s]\u001b[A\n","Iteration:  85% 1569/1851 [19:14<03:28,  1.35it/s]\u001b[A\n","Iteration:  85% 1570/1851 [19:15<03:27,  1.36it/s]\u001b[A\n","Iteration:  85% 1571/1851 [19:16<03:26,  1.36it/s]\u001b[A\n","Iteration:  85% 1572/1851 [19:16<03:25,  1.36it/s]\u001b[A\n","Iteration:  85% 1573/1851 [19:17<03:24,  1.36it/s]\u001b[A\n","Iteration:  85% 1574/1851 [19:18<03:24,  1.36it/s]\u001b[A\n","Iteration:  85% 1575/1851 [19:19<03:23,  1.36it/s]\u001b[A\n","Iteration:  85% 1576/1851 [19:19<03:22,  1.36it/s]\u001b[A\n","Iteration:  85% 1577/1851 [19:20<03:22,  1.36it/s]\u001b[A\n","Iteration:  85% 1578/1851 [19:21<03:21,  1.36it/s]\u001b[A\n","Iteration:  85% 1579/1851 [19:22<03:21,  1.35it/s]\u001b[A\n","Iteration:  85% 1580/1851 [19:22<03:20,  1.35it/s]\u001b[A\n","Iteration:  85% 1581/1851 [19:23<03:19,  1.35it/s]\u001b[A\n","Iteration:  85% 1582/1851 [19:24<03:18,  1.36it/s]\u001b[A\n","Iteration:  86% 1583/1851 [19:25<03:17,  1.36it/s]\u001b[A\n","Iteration:  86% 1584/1851 [19:25<03:16,  1.36it/s]\u001b[A\n","Iteration:  86% 1585/1851 [19:26<03:16,  1.36it/s]\u001b[A\n","Iteration:  86% 1586/1851 [19:27<03:15,  1.35it/s]\u001b[A\n","Iteration:  86% 1587/1851 [19:27<03:14,  1.35it/s]\u001b[A\n","Iteration:  86% 1588/1851 [19:28<03:14,  1.36it/s]\u001b[A\n","Iteration:  86% 1589/1851 [19:29<03:13,  1.36it/s]\u001b[A\n","Iteration:  86% 1590/1851 [19:30<03:12,  1.36it/s]\u001b[A\n","Iteration:  86% 1591/1851 [19:30<03:11,  1.36it/s]\u001b[A\n","Iteration:  86% 1592/1851 [19:31<03:11,  1.35it/s]\u001b[A\n","Iteration:  86% 1593/1851 [19:32<03:11,  1.35it/s]\u001b[A\n","Iteration:  86% 1594/1851 [19:33<03:10,  1.35it/s]\u001b[A\n","Iteration:  86% 1595/1851 [19:33<03:09,  1.35it/s]\u001b[A\n","Iteration:  86% 1596/1851 [19:34<03:08,  1.35it/s]\u001b[A\n","Iteration:  86% 1597/1851 [19:35<03:07,  1.36it/s]\u001b[A\n","Iteration:  86% 1598/1851 [19:36<03:06,  1.36it/s]\u001b[A\n","Iteration:  86% 1599/1851 [19:36<03:05,  1.36it/s]\u001b[A\n","Iteration:  86% 1600/1851 [19:37<03:05,  1.36it/s]\u001b[A\n","Iteration:  86% 1601/1851 [19:38<03:04,  1.36it/s]\u001b[A\n","Iteration:  87% 1602/1851 [19:39<03:03,  1.36it/s]\u001b[A\n","Iteration:  87% 1603/1851 [19:39<03:02,  1.36it/s]\u001b[A\n","Iteration:  87% 1604/1851 [19:40<03:02,  1.36it/s]\u001b[A\n","Iteration:  87% 1605/1851 [19:41<03:01,  1.36it/s]\u001b[A\n","Iteration:  87% 1606/1851 [19:41<03:00,  1.35it/s]\u001b[A\n","Iteration:  87% 1607/1851 [19:42<03:00,  1.35it/s]\u001b[A\n","Iteration:  87% 1608/1851 [19:43<02:59,  1.35it/s]\u001b[A\n","Iteration:  87% 1609/1851 [19:44<02:58,  1.35it/s]\u001b[A\n","Iteration:  87% 1610/1851 [19:44<02:58,  1.35it/s]\u001b[A\n","Iteration:  87% 1611/1851 [19:45<02:57,  1.35it/s]\u001b[A\n","Iteration:  87% 1612/1851 [19:46<02:56,  1.35it/s]\u001b[A\n","Iteration:  87% 1613/1851 [19:47<02:55,  1.36it/s]\u001b[A\n","Iteration:  87% 1614/1851 [19:47<02:55,  1.35it/s]\u001b[A\n","Iteration:  87% 1615/1851 [19:48<02:54,  1.35it/s]\u001b[A\n","Iteration:  87% 1616/1851 [19:49<02:54,  1.35it/s]\u001b[A\n","Iteration:  87% 1617/1851 [19:50<02:53,  1.35it/s]\u001b[A\n","Iteration:  87% 1618/1851 [19:50<02:52,  1.35it/s]\u001b[A\n","Iteration:  87% 1619/1851 [19:51<02:51,  1.35it/s]\u001b[A\n","Iteration:  88% 1620/1851 [19:52<02:51,  1.35it/s]\u001b[A\n","Iteration:  88% 1621/1851 [19:53<02:50,  1.35it/s]\u001b[A\n","Iteration:  88% 1622/1851 [19:53<02:49,  1.35it/s]\u001b[A\n","Iteration:  88% 1623/1851 [19:54<02:49,  1.35it/s]\u001b[A\n","Iteration:  88% 1624/1851 [19:55<02:48,  1.35it/s]\u001b[A\n","Iteration:  88% 1625/1851 [19:56<02:46,  1.35it/s]\u001b[A\n","Iteration:  88% 1626/1851 [19:56<02:46,  1.35it/s]\u001b[A\n","Iteration:  88% 1627/1851 [19:57<02:45,  1.35it/s]\u001b[A\n","Iteration:  88% 1628/1851 [19:58<02:44,  1.36it/s]\u001b[A\n","Iteration:  88% 1629/1851 [19:58<02:43,  1.36it/s]\u001b[A\n","Iteration:  88% 1630/1851 [19:59<02:43,  1.35it/s]\u001b[A\n","Iteration:  88% 1631/1851 [20:00<02:42,  1.36it/s]\u001b[A\n","Iteration:  88% 1632/1851 [20:01<02:41,  1.36it/s]\u001b[A\n","Iteration:  88% 1633/1851 [20:01<02:40,  1.36it/s]\u001b[A\n","Iteration:  88% 1634/1851 [20:02<02:40,  1.36it/s]\u001b[A\n","Iteration:  88% 1635/1851 [20:03<02:39,  1.35it/s]\u001b[A\n","Iteration:  88% 1636/1851 [20:04<02:38,  1.35it/s]\u001b[A\n","Iteration:  88% 1637/1851 [20:04<02:37,  1.36it/s]\u001b[A\n","Iteration:  88% 1638/1851 [20:05<02:37,  1.35it/s]\u001b[A\n","Iteration:  89% 1639/1851 [20:06<02:36,  1.36it/s]\u001b[A\n","Iteration:  89% 1640/1851 [20:07<02:35,  1.35it/s]\u001b[A\n","Iteration:  89% 1641/1851 [20:07<02:35,  1.35it/s]\u001b[A\n","Iteration:  89% 1642/1851 [20:08<02:33,  1.36it/s]\u001b[A\n","Iteration:  89% 1643/1851 [20:09<02:33,  1.36it/s]\u001b[A\n","Iteration:  89% 1644/1851 [20:10<02:32,  1.36it/s]\u001b[A\n","Iteration:  89% 1645/1851 [20:10<02:32,  1.35it/s]\u001b[A\n","Iteration:  89% 1646/1851 [20:11<02:31,  1.35it/s]\u001b[A\n","Iteration:  89% 1647/1851 [20:12<02:30,  1.35it/s]\u001b[A\n","Iteration:  89% 1648/1851 [20:13<02:29,  1.36it/s]\u001b[A\n","Iteration:  89% 1649/1851 [20:13<02:29,  1.35it/s]\u001b[A\n","Iteration:  89% 1650/1851 [20:14<02:28,  1.36it/s]\u001b[A\n","Iteration:  89% 1651/1851 [20:15<02:27,  1.36it/s]\u001b[A\n","Iteration:  89% 1652/1851 [20:15<02:27,  1.35it/s]\u001b[A\n","Iteration:  89% 1653/1851 [20:16<02:26,  1.35it/s]\u001b[A\n","Iteration:  89% 1654/1851 [20:17<02:25,  1.36it/s]\u001b[A\n","Iteration:  89% 1655/1851 [20:18<02:24,  1.35it/s]\u001b[A\n","Iteration:  89% 1656/1851 [20:18<02:23,  1.36it/s]\u001b[A\n","Iteration:  90% 1657/1851 [20:19<02:23,  1.36it/s]\u001b[A\n","Iteration:  90% 1658/1851 [20:20<02:22,  1.35it/s]\u001b[A\n","Iteration:  90% 1659/1851 [20:21<02:21,  1.36it/s]\u001b[A\n","Iteration:  90% 1660/1851 [20:21<02:21,  1.35it/s]\u001b[A\n","Iteration:  90% 1661/1851 [20:22<02:20,  1.35it/s]\u001b[A\n","Iteration:  90% 1662/1851 [20:23<02:19,  1.36it/s]\u001b[A\n","Iteration:  90% 1663/1851 [20:24<02:18,  1.35it/s]\u001b[A\n","Iteration:  90% 1664/1851 [20:24<02:18,  1.35it/s]\u001b[A\n","Iteration:  90% 1665/1851 [20:25<02:17,  1.35it/s]\u001b[A\n","Iteration:  90% 1666/1851 [20:26<02:16,  1.36it/s]\u001b[A\n","Iteration:  90% 1667/1851 [20:27<02:15,  1.35it/s]\u001b[A\n","Iteration:  90% 1668/1851 [20:27<02:15,  1.35it/s]\u001b[A\n","Iteration:  90% 1669/1851 [20:28<02:14,  1.36it/s]\u001b[A\n","Iteration:  90% 1670/1851 [20:29<02:13,  1.36it/s]\u001b[A\n","Iteration:  90% 1671/1851 [20:29<02:12,  1.36it/s]\u001b[A\n","Iteration:  90% 1672/1851 [20:30<02:11,  1.36it/s]\u001b[A\n","Iteration:  90% 1673/1851 [20:31<02:10,  1.36it/s]\u001b[A\n","Iteration:  90% 1674/1851 [20:32<02:10,  1.36it/s]\u001b[A\n","Iteration:  90% 1675/1851 [20:32<02:09,  1.36it/s]\u001b[A\n","Iteration:  91% 1676/1851 [20:33<02:09,  1.36it/s]\u001b[A\n","Iteration:  91% 1677/1851 [20:34<02:08,  1.35it/s]\u001b[A\n","Iteration:  91% 1678/1851 [20:35<02:07,  1.36it/s]\u001b[A\n","Iteration:  91% 1679/1851 [20:35<02:07,  1.35it/s]\u001b[A\n","Iteration:  91% 1680/1851 [20:36<02:06,  1.35it/s]\u001b[A\n","Iteration:  91% 1681/1851 [20:37<02:05,  1.36it/s]\u001b[A\n","Iteration:  91% 1682/1851 [20:38<02:04,  1.36it/s]\u001b[A\n","Iteration:  91% 1683/1851 [20:38<02:03,  1.36it/s]\u001b[A\n","Iteration:  91% 1684/1851 [20:39<02:02,  1.36it/s]\u001b[A\n","Iteration:  91% 1685/1851 [20:40<02:02,  1.36it/s]\u001b[A\n","Iteration:  91% 1686/1851 [20:41<02:01,  1.36it/s]\u001b[A\n","Iteration:  91% 1687/1851 [20:41<02:00,  1.36it/s]\u001b[A\n","Iteration:  91% 1688/1851 [20:42<02:00,  1.36it/s]\u001b[A\n","Iteration:  91% 1689/1851 [20:43<01:59,  1.36it/s]\u001b[A\n","Iteration:  91% 1690/1851 [20:43<01:58,  1.36it/s]\u001b[A\n","Iteration:  91% 1691/1851 [20:44<01:58,  1.35it/s]\u001b[A\n","Iteration:  91% 1692/1851 [20:45<01:57,  1.36it/s]\u001b[A\n","Iteration:  91% 1693/1851 [20:46<01:56,  1.35it/s]\u001b[A\n","Iteration:  92% 1694/1851 [20:46<01:55,  1.36it/s]\u001b[A\n","Iteration:  92% 1695/1851 [20:47<01:55,  1.35it/s]\u001b[A\n","Iteration:  92% 1696/1851 [20:48<01:54,  1.36it/s]\u001b[A\n","Iteration:  92% 1697/1851 [20:49<01:53,  1.36it/s]\u001b[A\n","Iteration:  92% 1698/1851 [20:49<01:53,  1.35it/s]\u001b[A\n","Iteration:  92% 1699/1851 [20:50<01:52,  1.35it/s]\u001b[A\n","Iteration:  92% 1700/1851 [20:51<01:51,  1.35it/s]\u001b[A\n","Iteration:  92% 1701/1851 [20:52<01:50,  1.35it/s]\u001b[A\n","Iteration:  92% 1702/1851 [20:52<01:49,  1.35it/s]\u001b[A\n","Iteration:  92% 1703/1851 [20:53<01:49,  1.35it/s]\u001b[A\n","Iteration:  92% 1704/1851 [20:54<01:48,  1.35it/s]\u001b[A\n","Iteration:  92% 1705/1851 [20:55<01:47,  1.36it/s]\u001b[A\n","Iteration:  92% 1706/1851 [20:55<01:46,  1.36it/s]\u001b[A\n","Iteration:  92% 1707/1851 [20:56<01:46,  1.35it/s]\u001b[A\n","Iteration:  92% 1708/1851 [20:57<01:45,  1.35it/s]\u001b[A\n","Iteration:  92% 1709/1851 [20:58<01:44,  1.35it/s]\u001b[A\n","Iteration:  92% 1710/1851 [20:58<01:44,  1.35it/s]\u001b[A\n","Iteration:  92% 1711/1851 [20:59<01:43,  1.35it/s]\u001b[A\n","Iteration:  92% 1712/1851 [21:00<01:42,  1.36it/s]\u001b[A\n","Iteration:  93% 1713/1851 [21:00<01:41,  1.35it/s]\u001b[A\n","Iteration:  93% 1714/1851 [21:01<01:41,  1.35it/s]\u001b[A\n","Iteration:  93% 1715/1851 [21:02<01:40,  1.36it/s]\u001b[A\n","Iteration:  93% 1716/1851 [21:03<01:39,  1.35it/s]\u001b[A\n","Iteration:  93% 1717/1851 [21:03<01:39,  1.35it/s]\u001b[A\n","Iteration:  93% 1718/1851 [21:04<01:38,  1.35it/s]\u001b[A\n","Iteration:  93% 1719/1851 [21:05<01:37,  1.35it/s]\u001b[A\n","Iteration:  93% 1720/1851 [21:06<01:36,  1.36it/s]\u001b[A\n","Iteration:  93% 1721/1851 [21:06<01:35,  1.36it/s]\u001b[A\n","Iteration:  93% 1722/1851 [21:07<01:34,  1.36it/s]\u001b[A\n","Iteration:  93% 1723/1851 [21:08<01:34,  1.36it/s]\u001b[A\n","Iteration:  93% 1724/1851 [21:09<01:33,  1.36it/s]\u001b[A\n","Iteration:  93% 1725/1851 [21:09<01:32,  1.36it/s]\u001b[A\n","Iteration:  93% 1726/1851 [21:10<01:32,  1.36it/s]\u001b[A\n","Iteration:  93% 1727/1851 [21:11<01:31,  1.36it/s]\u001b[A\n","Iteration:  93% 1728/1851 [21:12<01:30,  1.36it/s]\u001b[A\n","Iteration:  93% 1729/1851 [21:12<01:29,  1.36it/s]\u001b[A\n","Iteration:  93% 1730/1851 [21:13<01:29,  1.35it/s]\u001b[A\n","Iteration:  94% 1731/1851 [21:14<01:28,  1.35it/s]\u001b[A\n","Iteration:  94% 1732/1851 [21:14<01:27,  1.35it/s]\u001b[A\n","Iteration:  94% 1733/1851 [21:15<01:27,  1.35it/s]\u001b[A\n","Iteration:  94% 1734/1851 [21:16<01:26,  1.35it/s]\u001b[A\n","Iteration:  94% 1735/1851 [21:17<01:25,  1.35it/s]\u001b[A\n","Iteration:  94% 1736/1851 [21:17<01:25,  1.35it/s]\u001b[A\n","Iteration:  94% 1737/1851 [21:18<01:24,  1.35it/s]\u001b[A\n","Iteration:  94% 1738/1851 [21:19<01:23,  1.36it/s]\u001b[A\n","Iteration:  94% 1739/1851 [21:20<01:22,  1.36it/s]\u001b[A\n","Iteration:  94% 1740/1851 [21:20<01:21,  1.35it/s]\u001b[A\n","Iteration:  94% 1741/1851 [21:21<01:21,  1.36it/s]\u001b[A\n","Iteration:  94% 1742/1851 [21:22<01:20,  1.36it/s]\u001b[A\n","Iteration:  94% 1743/1851 [21:23<01:19,  1.36it/s]\u001b[A\n","Iteration:  94% 1744/1851 [21:23<01:18,  1.36it/s]\u001b[A\n","Iteration:  94% 1745/1851 [21:24<01:18,  1.36it/s]\u001b[A\n","Iteration:  94% 1746/1851 [21:25<01:17,  1.35it/s]\u001b[A\n","Iteration:  94% 1747/1851 [21:26<01:16,  1.35it/s]\u001b[A\n","Iteration:  94% 1748/1851 [21:26<01:15,  1.36it/s]\u001b[A\n","Iteration:  94% 1749/1851 [21:27<01:15,  1.36it/s]\u001b[A\n","Iteration:  95% 1750/1851 [21:28<01:14,  1.36it/s]\u001b[A\n","Iteration:  95% 1751/1851 [21:28<01:13,  1.36it/s]\u001b[A\n","Iteration:  95% 1752/1851 [21:29<01:12,  1.36it/s]\u001b[A\n","Iteration:  95% 1753/1851 [21:30<01:12,  1.36it/s]\u001b[A\n","Iteration:  95% 1754/1851 [21:31<01:11,  1.36it/s]\u001b[A\n","Iteration:  95% 1755/1851 [21:31<01:10,  1.36it/s]\u001b[A\n","Iteration:  95% 1756/1851 [21:32<01:09,  1.36it/s]\u001b[A\n","Iteration:  95% 1757/1851 [21:33<01:08,  1.36it/s]\u001b[A\n","Iteration:  95% 1758/1851 [21:34<01:08,  1.36it/s]\u001b[A\n","Iteration:  95% 1759/1851 [21:34<01:07,  1.36it/s]\u001b[A\n","Iteration:  95% 1760/1851 [21:35<01:06,  1.36it/s]\u001b[A\n","Iteration:  95% 1761/1851 [21:36<01:06,  1.36it/s]\u001b[A\n","Iteration:  95% 1762/1851 [21:37<01:05,  1.37it/s]\u001b[A\n","Iteration:  95% 1763/1851 [21:37<01:04,  1.37it/s]\u001b[A\n","Iteration:  95% 1764/1851 [21:38<01:03,  1.37it/s]\u001b[A\n","Iteration:  95% 1765/1851 [21:39<01:02,  1.37it/s]\u001b[A\n","Iteration:  95% 1766/1851 [21:40<01:02,  1.36it/s]\u001b[A\n","Iteration:  95% 1767/1851 [21:40<01:01,  1.36it/s]\u001b[A\n","Iteration:  96% 1768/1851 [21:41<01:01,  1.36it/s]\u001b[A\n","Iteration:  96% 1769/1851 [21:42<01:00,  1.35it/s]\u001b[A\n","Iteration:  96% 1770/1851 [21:42<00:59,  1.36it/s]\u001b[A\n","Iteration:  96% 1771/1851 [21:43<00:58,  1.36it/s]\u001b[A\n","Iteration:  96% 1772/1851 [21:44<00:58,  1.36it/s]\u001b[A\n","Iteration:  96% 1773/1851 [21:45<00:57,  1.35it/s]\u001b[A\n","Iteration:  96% 1774/1851 [21:45<00:56,  1.35it/s]\u001b[A\n","Iteration:  96% 1775/1851 [21:46<00:56,  1.35it/s]\u001b[A\n","Iteration:  96% 1776/1851 [21:47<00:55,  1.36it/s]\u001b[A\n","Iteration:  96% 1777/1851 [21:48<00:54,  1.36it/s]\u001b[A\n","Iteration:  96% 1778/1851 [21:48<00:53,  1.36it/s]\u001b[A\n","Iteration:  96% 1779/1851 [21:49<00:53,  1.36it/s]\u001b[A\n","Iteration:  96% 1780/1851 [21:50<00:52,  1.36it/s]\u001b[A\n","Iteration:  96% 1781/1851 [21:51<00:51,  1.36it/s]\u001b[A\n","Iteration:  96% 1782/1851 [21:51<00:50,  1.36it/s]\u001b[A\n","Iteration:  96% 1783/1851 [21:52<00:50,  1.36it/s]\u001b[A\n","Iteration:  96% 1784/1851 [21:53<00:49,  1.36it/s]\u001b[A\n","Iteration:  96% 1785/1851 [21:54<00:48,  1.35it/s]\u001b[A\n","Iteration:  96% 1786/1851 [21:54<00:47,  1.36it/s]\u001b[A\n","Iteration:  97% 1787/1851 [21:55<00:47,  1.35it/s]\u001b[A\n","Iteration:  97% 1788/1851 [21:56<00:46,  1.36it/s]\u001b[A\n","Iteration:  97% 1789/1851 [21:56<00:45,  1.35it/s]\u001b[A\n","Iteration:  97% 1790/1851 [21:57<00:45,  1.35it/s]\u001b[A\n","Iteration:  97% 1791/1851 [21:58<00:44,  1.36it/s]\u001b[A\n","Iteration:  97% 1792/1851 [21:59<00:43,  1.36it/s]\u001b[A\n","Iteration:  97% 1793/1851 [21:59<00:42,  1.35it/s]\u001b[A\n","Iteration:  97% 1794/1851 [22:00<00:41,  1.36it/s]\u001b[A\n","Iteration:  97% 1795/1851 [22:01<00:41,  1.35it/s]\u001b[A\n","Iteration:  97% 1796/1851 [22:02<00:40,  1.35it/s]\u001b[A\n","Iteration:  97% 1797/1851 [22:02<00:39,  1.36it/s]\u001b[A\n","Iteration:  97% 1798/1851 [22:03<00:39,  1.36it/s]\u001b[A\n","Iteration:  97% 1799/1851 [22:04<00:38,  1.36it/s]\u001b[A\n","Iteration:  97% 1800/1851 [22:05<00:37,  1.36it/s]\u001b[A\n","Iteration:  97% 1801/1851 [22:05<00:36,  1.36it/s]\u001b[A\n","Iteration:  97% 1802/1851 [22:06<00:36,  1.36it/s]\u001b[A\n","Iteration:  97% 1803/1851 [22:07<00:35,  1.36it/s]\u001b[A\n","Iteration:  97% 1804/1851 [22:08<00:34,  1.36it/s]\u001b[A\n","Iteration:  98% 1805/1851 [22:08<00:33,  1.36it/s]\u001b[A\n","Iteration:  98% 1806/1851 [22:09<00:33,  1.35it/s]\u001b[A\n","Iteration:  98% 1807/1851 [22:10<00:32,  1.35it/s]\u001b[A\n","Iteration:  98% 1808/1851 [22:10<00:31,  1.35it/s]\u001b[A\n","Iteration:  98% 1809/1851 [22:11<00:31,  1.35it/s]\u001b[A\n","Iteration:  98% 1810/1851 [22:12<00:30,  1.35it/s]\u001b[A\n","Iteration:  98% 1811/1851 [22:13<00:29,  1.35it/s]\u001b[A\n","Iteration:  98% 1812/1851 [22:13<00:28,  1.35it/s]\u001b[A\n","Iteration:  98% 1813/1851 [22:14<00:28,  1.35it/s]\u001b[A\n","Iteration:  98% 1814/1851 [22:15<00:27,  1.35it/s]\u001b[A\n","Iteration:  98% 1815/1851 [22:16<00:26,  1.35it/s]\u001b[A\n","Iteration:  98% 1816/1851 [22:16<00:25,  1.36it/s]\u001b[A\n","Iteration:  98% 1817/1851 [22:17<00:25,  1.36it/s]\u001b[A\n","Iteration:  98% 1818/1851 [22:18<00:24,  1.36it/s]\u001b[A\n","Iteration:  98% 1819/1851 [22:19<00:23,  1.36it/s]\u001b[A\n","Iteration:  98% 1820/1851 [22:19<00:22,  1.36it/s]\u001b[A\n","Iteration:  98% 1821/1851 [22:20<00:21,  1.37it/s]\u001b[A\n","Iteration:  98% 1822/1851 [22:21<00:21,  1.36it/s]\u001b[A\n","Iteration:  98% 1823/1851 [22:22<00:20,  1.36it/s]\u001b[A\n","Iteration:  99% 1824/1851 [22:22<00:19,  1.36it/s]\u001b[A\n","Iteration:  99% 1825/1851 [22:23<00:19,  1.36it/s]\u001b[A\n","Iteration:  99% 1826/1851 [22:24<00:18,  1.36it/s]\u001b[A\n","Iteration:  99% 1827/1851 [22:24<00:17,  1.36it/s]\u001b[A\n","Iteration:  99% 1828/1851 [22:25<00:16,  1.36it/s]\u001b[A\n","Iteration:  99% 1829/1851 [22:26<00:16,  1.36it/s]\u001b[A\n","Iteration:  99% 1830/1851 [22:27<00:15,  1.36it/s]\u001b[A\n","Iteration:  99% 1831/1851 [22:27<00:14,  1.36it/s]\u001b[A\n","Iteration:  99% 1832/1851 [22:28<00:13,  1.36it/s]\u001b[A\n","Iteration:  99% 1833/1851 [22:29<00:13,  1.36it/s]\u001b[A\n","Iteration:  99% 1834/1851 [22:30<00:12,  1.36it/s]\u001b[A\n","Iteration:  99% 1835/1851 [22:30<00:11,  1.36it/s]\u001b[A\n","Iteration:  99% 1836/1851 [22:31<00:11,  1.36it/s]\u001b[A\n","Iteration:  99% 1837/1851 [22:32<00:10,  1.35it/s]\u001b[A\n","Iteration:  99% 1838/1851 [22:33<00:09,  1.35it/s]\u001b[A\n","Iteration:  99% 1839/1851 [22:33<00:08,  1.35it/s]\u001b[A\n","Iteration:  99% 1840/1851 [22:34<00:08,  1.35it/s]\u001b[A\n","Iteration:  99% 1841/1851 [22:35<00:07,  1.35it/s]\u001b[A\n","Iteration: 100% 1842/1851 [22:36<00:06,  1.36it/s]\u001b[A\n","Iteration: 100% 1843/1851 [22:36<00:05,  1.35it/s]\u001b[A\n","Iteration: 100% 1844/1851 [22:37<00:05,  1.36it/s]\u001b[A\n","Iteration: 100% 1845/1851 [22:38<00:04,  1.35it/s]\u001b[A\n","Iteration: 100% 1846/1851 [22:39<00:03,  1.35it/s]\u001b[A\n","Iteration: 100% 1847/1851 [22:39<00:02,  1.36it/s]\u001b[A\n","Iteration: 100% 1848/1851 [22:40<00:02,  1.36it/s]\u001b[A\n","Iteration: 100% 1849/1851 [22:41<00:01,  1.36it/s]\u001b[A\n","Iteration: 100% 1850/1851 [22:41<00:00,  1.35it/s]\u001b[A\n","Iteration: 100% 1851/1851 [22:42<00:00,  1.36it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","[2022-07-25 11:46:18,379][__main__][DEBUG] - epoch is 0\n","[2022-07-25 11:46:18,380][__main__][DEBUG] - validation loss is tensor(0.9889, device='cuda:0')\n","Epoch:   1% 1/100 [26:58<44:31:09, 1618.88s/it]\n","Iteration:   0% 0/1851 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\n","Iteration:   0% 1/1851 [00:01<56:04,  1.82s/it]\u001b[A\n","Iteration:   0% 2/1851 [00:02<36:21,  1.18s/it]\u001b[A\n","Iteration:   0% 3/1851 [00:03<30:05,  1.02it/s]\u001b[A\n","Iteration:   0% 4/1851 [00:04<27:11,  1.13it/s]\u001b[A\n","Iteration:   0% 5/1851 [00:04<25:32,  1.20it/s]\u001b[A\n","Iteration:   0% 6/1851 [00:05<24:31,  1.25it/s]\u001b[A\n","Iteration:   0% 7/1851 [00:06<23:55,  1.28it/s]\u001b[A\n","Iteration:   0% 8/1851 [00:06<23:30,  1.31it/s]\u001b[A\n","Iteration:   0% 9/1851 [00:07<23:11,  1.32it/s]\u001b[A\n","Iteration:   1% 10/1851 [00:08<23:02,  1.33it/s]\u001b[A\n","Iteration:   1% 11/1851 [00:09<22:55,  1.34it/s]\u001b[A\n","Iteration:   1% 12/1851 [00:09<22:45,  1.35it/s]\u001b[A\n","Iteration:   1% 13/1851 [00:10<22:42,  1.35it/s]\u001b[A\n","Iteration:   1% 14/1851 [00:11<22:39,  1.35it/s]\u001b[A\n","Iteration:   1% 15/1851 [00:12<22:37,  1.35it/s]\u001b[A\n","Iteration:   1% 16/1851 [00:12<22:34,  1.35it/s]\u001b[A\n","Iteration:   1% 17/1851 [00:13<22:28,  1.36it/s]\u001b[A\n","Iteration:   1% 18/1851 [00:14<22:31,  1.36it/s]\u001b[A\n","Iteration:   1% 19/1851 [00:15<22:30,  1.36it/s]\u001b[A\n","Iteration:   1% 20/1851 [00:15<22:30,  1.36it/s]\u001b[A\n","Iteration:   1% 21/1851 [00:16<22:31,  1.35it/s]\u001b[A\n","Iteration:   1% 22/1851 [00:17<22:32,  1.35it/s]\u001b[A\n","Iteration:   1% 23/1851 [00:18<22:30,  1.35it/s]\u001b[A\n","Iteration:   1% 24/1851 [00:18<22:24,  1.36it/s]\u001b[A\n","Iteration:   1% 25/1851 [00:19<22:21,  1.36it/s]\u001b[A\n","Iteration:   1% 26/1851 [00:20<22:22,  1.36it/s]\u001b[A\n","Iteration:   1% 27/1851 [00:20<22:23,  1.36it/s]\u001b[A\n","Iteration:   2% 28/1851 [00:21<22:23,  1.36it/s]\u001b[A\n","Iteration:   2% 29/1851 [00:22<22:24,  1.36it/s]\u001b[A\n","Iteration:   2% 30/1851 [00:23<22:26,  1.35it/s]\u001b[A\n","Iteration:   2% 31/1851 [00:23<22:25,  1.35it/s]\u001b[A\n","Iteration:   2% 32/1851 [00:24<22:27,  1.35it/s]\u001b[A\n","Iteration:   2% 33/1851 [00:25<22:23,  1.35it/s]\u001b[A\n","Iteration:   2% 34/1851 [00:26<22:19,  1.36it/s]\u001b[A\n","Iteration:   2% 35/1851 [00:26<22:23,  1.35it/s]\u001b[A\n","Iteration:   2% 36/1851 [00:27<22:21,  1.35it/s]\u001b[A\n","Iteration:   2% 37/1851 [00:28<22:22,  1.35it/s]\u001b[A\n","Iteration:   2% 38/1851 [00:29<22:21,  1.35it/s]\u001b[A\n","Iteration:   2% 39/1851 [00:29<22:20,  1.35it/s]\u001b[A\n","Iteration:   2% 40/1851 [00:30<22:20,  1.35it/s]\u001b[A\n","Iteration:   2% 41/1851 [00:31<22:17,  1.35it/s]\u001b[A\n","Iteration:   2% 42/1851 [00:32<22:13,  1.36it/s]\u001b[A\n","Iteration:   2% 43/1851 [00:32<22:14,  1.35it/s]\u001b[A\n","Iteration:   2% 44/1851 [00:33<22:14,  1.35it/s]\u001b[A\n","Iteration:   2% 45/1851 [00:34<22:15,  1.35it/s]\u001b[A\n","Iteration:   2% 46/1851 [00:35<22:13,  1.35it/s]\u001b[A\n","Iteration:   3% 47/1851 [00:35<22:14,  1.35it/s]\u001b[A\n","Iteration:   3% 48/1851 [00:36<22:13,  1.35it/s]\u001b[A\n","Iteration:   3% 49/1851 [00:37<22:14,  1.35it/s]\u001b[A\n","Iteration:   3% 50/1851 [00:37<22:09,  1.35it/s]\u001b[A\n","Iteration:   3% 51/1851 [00:38<22:10,  1.35it/s]\u001b[A\n","Iteration:   3% 52/1851 [00:39<22:11,  1.35it/s]\u001b[A\n","Iteration:   3% 53/1851 [00:40<22:11,  1.35it/s]\u001b[A\n","Iteration:   3% 54/1851 [00:40<22:08,  1.35it/s]\u001b[A\n","Iteration:   3% 55/1851 [00:41<22:10,  1.35it/s]\u001b[A\n","Iteration:   3% 56/1851 [00:42<22:07,  1.35it/s]\u001b[A\n","Iteration:   3% 57/1851 [00:43<22:05,  1.35it/s]\u001b[A\n","Iteration:   3% 58/1851 [00:43<22:06,  1.35it/s]\u001b[A\n","Iteration:   3% 59/1851 [00:44<22:04,  1.35it/s]\u001b[A\n","Iteration:   3% 60/1851 [00:45<22:06,  1.35it/s]\u001b[A\n","Iteration:   3% 61/1851 [00:46<22:06,  1.35it/s]\u001b[A\n","Iteration:   3% 62/1851 [00:46<22:05,  1.35it/s]\u001b[A\n","Iteration:   3% 63/1851 [00:47<22:04,  1.35it/s]\u001b[A\n","Iteration:   3% 64/1851 [00:48<22:04,  1.35it/s]\u001b[A\n","Iteration:   4% 65/1851 [00:49<22:03,  1.35it/s]\u001b[A\n","Iteration:   4% 66/1851 [00:49<22:01,  1.35it/s]\u001b[A\n","Iteration:   4% 67/1851 [00:50<21:54,  1.36it/s]\u001b[A\n","Iteration:   4% 68/1851 [00:51<21:54,  1.36it/s]\u001b[A\n","Iteration:   4% 69/1851 [00:52<21:56,  1.35it/s]\u001b[A\n","Iteration:   4% 70/1851 [00:52<21:53,  1.36it/s]\u001b[A\n","Iteration:   4% 71/1851 [00:53<21:53,  1.36it/s]\u001b[A\n","Iteration:   4% 72/1851 [00:54<21:54,  1.35it/s]\u001b[A\n","Iteration:   4% 73/1851 [00:54<21:51,  1.36it/s]\u001b[A\n","Iteration:   4% 74/1851 [00:55<21:52,  1.35it/s]\u001b[A\n","Iteration:   4% 75/1851 [00:56<21:47,  1.36it/s]\u001b[A\n","Iteration:   4% 76/1851 [00:57<21:47,  1.36it/s]\u001b[A\n","Iteration:   4% 77/1851 [00:57<21:47,  1.36it/s]\u001b[A\n","Iteration:   4% 78/1851 [00:58<21:43,  1.36it/s]\u001b[A\n","Iteration:   4% 79/1851 [00:59<21:43,  1.36it/s]\u001b[A\n","Iteration:   4% 80/1851 [01:00<21:44,  1.36it/s]\u001b[A\n","Iteration:   4% 81/1851 [01:00<21:43,  1.36it/s]\u001b[A\n","Iteration:   4% 82/1851 [01:01<21:44,  1.36it/s]\u001b[A\n","Iteration:   4% 83/1851 [01:02<21:42,  1.36it/s]\u001b[A\n","Iteration:   5% 84/1851 [01:03<21:41,  1.36it/s]\u001b[A\n","Iteration:   5% 85/1851 [01:03<21:38,  1.36it/s]\u001b[A\n","Iteration:   5% 86/1851 [01:04<21:38,  1.36it/s]\u001b[A\n","Iteration:   5% 87/1851 [01:05<21:40,  1.36it/s]\u001b[A\n","Iteration:   5% 88/1851 [01:06<21:38,  1.36it/s]\u001b[A\n","Iteration:   5% 89/1851 [01:06<21:40,  1.35it/s]\u001b[A\n","Iteration:   5% 90/1851 [01:07<21:39,  1.36it/s]\u001b[A\n","Iteration:   5% 91/1851 [01:08<21:36,  1.36it/s]\u001b[A\n","Iteration:   5% 92/1851 [01:08<21:37,  1.36it/s]\u001b[A\n","Iteration:   5% 93/1851 [01:09<21:37,  1.35it/s]\u001b[A\n","Iteration:   5% 94/1851 [01:10<21:33,  1.36it/s]\u001b[A\n","Iteration:   5% 95/1851 [01:11<21:31,  1.36it/s]\u001b[A\n","Iteration:   5% 96/1851 [01:11<21:34,  1.36it/s]\u001b[A\n","Iteration:   5% 97/1851 [01:12<21:38,  1.35it/s]\u001b[A\n","Iteration:   5% 98/1851 [01:13<21:37,  1.35it/s]\u001b[A\n","Iteration:   5% 99/1851 [01:14<21:32,  1.36it/s]\u001b[A\n","Iteration:   5% 100/1851 [01:14<21:30,  1.36it/s]\u001b[A\n","Iteration:   5% 101/1851 [01:15<21:29,  1.36it/s]\u001b[A\n","Iteration:   6% 102/1851 [01:16<21:28,  1.36it/s]\u001b[A\n","Iteration:   6% 103/1851 [01:17<21:26,  1.36it/s]\u001b[A\n","Iteration:   6% 104/1851 [01:17<21:28,  1.36it/s]\u001b[A\n","Iteration:   6% 105/1851 [01:18<21:26,  1.36it/s]\u001b[A\n","Iteration:   6% 106/1851 [01:19<21:23,  1.36it/s]\u001b[A\n","Iteration:   6% 107/1851 [01:20<21:21,  1.36it/s]\u001b[A\n","Iteration:   6% 108/1851 [01:20<21:21,  1.36it/s]\u001b[A\n","Iteration:   6% 109/1851 [01:21<21:19,  1.36it/s]\u001b[A\n","Iteration:   6% 110/1851 [01:22<21:21,  1.36it/s]\u001b[A\n","Iteration:   6% 111/1851 [01:22<21:20,  1.36it/s]\u001b[A\n","Iteration:   6% 112/1851 [01:23<21:20,  1.36it/s]\u001b[A\n","Iteration:   6% 113/1851 [01:24<21:18,  1.36it/s]\u001b[A\n","Iteration:   6% 114/1851 [01:25<21:21,  1.36it/s]\u001b[A\n","Iteration:   6% 115/1851 [01:26<21:59,  1.32it/s]\u001b[A\n","Iteration:   6% 116/1851 [01:26<21:47,  1.33it/s]\u001b[A\n","Iteration:   6% 117/1851 [01:27<21:36,  1.34it/s]\u001b[A\n","Iteration:   6% 118/1851 [01:28<21:31,  1.34it/s]\u001b[A\n","Iteration:   6% 119/1851 [01:28<21:28,  1.34it/s]\u001b[A\n","Iteration:   6% 120/1851 [01:29<21:27,  1.34it/s]\u001b[A\n","Iteration:   7% 121/1851 [01:30<21:25,  1.35it/s]\u001b[A\n","Iteration:   7% 122/1851 [01:31<21:21,  1.35it/s]\u001b[A\n","Iteration:   7% 123/1851 [01:31<21:19,  1.35it/s]\u001b[A\n","Iteration:   7% 124/1851 [01:32<21:17,  1.35it/s]\u001b[A\n","Iteration:   7% 125/1851 [01:33<21:15,  1.35it/s]\u001b[A\n","Iteration:   7% 126/1851 [01:34<21:17,  1.35it/s]\u001b[A\n","Iteration:   7% 127/1851 [01:34<21:16,  1.35it/s]\u001b[A\n","Iteration:   7% 128/1851 [01:35<21:17,  1.35it/s]\u001b[A\n","Iteration:   7% 129/1851 [01:36<21:12,  1.35it/s]\u001b[A\n","Iteration:   7% 130/1851 [01:37<21:10,  1.36it/s]\u001b[A\n","Iteration:   7% 131/1851 [01:37<21:07,  1.36it/s]\u001b[A\n","Iteration:   7% 132/1851 [01:38<21:07,  1.36it/s]\u001b[A\n","Iteration:   7% 133/1851 [01:39<21:06,  1.36it/s]\u001b[A\n","Iteration:   7% 134/1851 [01:40<21:07,  1.35it/s]\u001b[A\n","Iteration:   7% 135/1851 [01:40<21:06,  1.35it/s]\u001b[A\n","Iteration:   7% 136/1851 [01:41<21:06,  1.35it/s]\u001b[A\n","Iteration:   7% 137/1851 [01:42<20:59,  1.36it/s]\u001b[A\n","Iteration:   7% 138/1851 [01:42<20:57,  1.36it/s]\u001b[A\n","Iteration:   8% 139/1851 [01:43<20:55,  1.36it/s]\u001b[A\n","Iteration:   8% 140/1851 [01:44<20:59,  1.36it/s]\u001b[A\n","Iteration:   8% 141/1851 [01:45<20:59,  1.36it/s]\u001b[A\n","Iteration:   8% 142/1851 [01:45<21:02,  1.35it/s]\u001b[A\n","Iteration:   8% 143/1851 [01:46<20:59,  1.36it/s]\u001b[A\n","Iteration:   8% 144/1851 [01:47<21:01,  1.35it/s]\u001b[A\n","Iteration:   8% 145/1851 [01:48<21:00,  1.35it/s]\u001b[A\n","Iteration:   8% 146/1851 [01:48<20:59,  1.35it/s]\u001b[A\n","Iteration:   8% 147/1851 [01:49<20:59,  1.35it/s]\u001b[A\n","Iteration:   8% 148/1851 [01:50<20:56,  1.35it/s]\u001b[A\n","Iteration:   8% 149/1851 [01:51<20:55,  1.36it/s]\u001b[A\n","Iteration:   8% 150/1851 [01:51<20:57,  1.35it/s]\u001b[A\n","Iteration:   8% 151/1851 [01:52<20:55,  1.35it/s]\u001b[A\n","Iteration:   8% 152/1851 [01:53<20:56,  1.35it/s]\u001b[A\n","Iteration:   8% 153/1851 [01:54<20:52,  1.36it/s]\u001b[A\n","Iteration:   8% 154/1851 [01:54<20:53,  1.35it/s]\u001b[A\n","Iteration:   8% 155/1851 [01:55<20:53,  1.35it/s]\u001b[A\n","Iteration:   8% 156/1851 [01:56<20:50,  1.36it/s]\u001b[A\n","Iteration:   8% 157/1851 [01:56<20:47,  1.36it/s]\u001b[A\n","Iteration:   9% 158/1851 [01:57<20:49,  1.35it/s]\u001b[A\n","Iteration:   9% 159/1851 [01:58<20:49,  1.35it/s]\u001b[A\n","Iteration:   9% 160/1851 [01:59<20:51,  1.35it/s]\u001b[A\n","Iteration:   9% 161/1851 [01:59<20:51,  1.35it/s]\u001b[A\n","Iteration:   9% 162/1851 [02:00<20:48,  1.35it/s]\u001b[A\n","Iteration:   9% 163/1851 [02:01<20:47,  1.35it/s]\u001b[A\n","Iteration:   9% 164/1851 [02:02<20:43,  1.36it/s]\u001b[A\n","Iteration:   9% 165/1851 [02:02<20:43,  1.36it/s]\u001b[A\n","Iteration:   9% 166/1851 [02:03<20:42,  1.36it/s]\u001b[A\n","Iteration:   9% 167/1851 [02:04<20:40,  1.36it/s]\u001b[A\n","Iteration:   9% 168/1851 [02:05<20:40,  1.36it/s]\u001b[A\n","Iteration:   9% 169/1851 [02:05<20:36,  1.36it/s]\u001b[A\n","Iteration:   9% 170/1851 [02:06<20:38,  1.36it/s]\u001b[A\n","Iteration:   9% 171/1851 [02:07<20:38,  1.36it/s]\u001b[A\n","Iteration:   9% 172/1851 [02:08<20:42,  1.35it/s]\u001b[A\n","Iteration:   9% 173/1851 [02:08<20:40,  1.35it/s]\u001b[A\n","Iteration:   9% 174/1851 [02:09<20:36,  1.36it/s]\u001b[A\n","Iteration:   9% 175/1851 [02:10<20:30,  1.36it/s]\u001b[A\n","Iteration:  10% 176/1851 [02:11<20:31,  1.36it/s]\u001b[A\n","Iteration:  10% 177/1851 [02:11<20:31,  1.36it/s]\u001b[A\n","Iteration:  10% 178/1851 [02:12<20:30,  1.36it/s]\u001b[A\n","Iteration:  10% 179/1851 [02:13<20:30,  1.36it/s]\u001b[A\n","Iteration:  10% 180/1851 [02:13<20:31,  1.36it/s]\u001b[A\n","Iteration:  10% 181/1851 [02:14<20:32,  1.36it/s]\u001b[A\n","Iteration:  10% 182/1851 [02:15<20:32,  1.35it/s]\u001b[A\n","Iteration:  10% 183/1851 [02:16<20:30,  1.36it/s]\u001b[A\n","Iteration:  10% 184/1851 [02:16<20:28,  1.36it/s]\u001b[A\n","Iteration:  10% 185/1851 [02:17<20:29,  1.35it/s]\u001b[A\n","Iteration:  10% 186/1851 [02:18<20:28,  1.36it/s]\u001b[A\n","Iteration:  10% 187/1851 [02:19<20:29,  1.35it/s]\u001b[A\n","Iteration:  10% 188/1851 [02:19<20:28,  1.35it/s]\u001b[A\n","Iteration:  10% 189/1851 [02:20<20:29,  1.35it/s]\u001b[A\n","Iteration:  10% 190/1851 [02:21<20:28,  1.35it/s]\u001b[A\n","Iteration:  10% 191/1851 [02:22<20:25,  1.35it/s]\u001b[A\n","Iteration:  10% 192/1851 [02:22<20:24,  1.35it/s]\u001b[A\n","Iteration:  10% 193/1851 [02:23<20:24,  1.35it/s]\u001b[A\n","Iteration:  10% 194/1851 [02:24<20:21,  1.36it/s]\u001b[A\n","Iteration:  11% 195/1851 [02:25<20:21,  1.36it/s]\u001b[A\n","Iteration:  11% 196/1851 [02:25<20:22,  1.35it/s]\u001b[A\n","Iteration:  11% 197/1851 [02:26<20:20,  1.35it/s]\u001b[A\n","Iteration:  11% 198/1851 [02:27<20:18,  1.36it/s]\u001b[A\n","Iteration:  11% 199/1851 [02:27<20:17,  1.36it/s]\u001b[A\n","Iteration:  11% 200/1851 [02:28<20:18,  1.36it/s]\u001b[A\n","Iteration:  11% 201/1851 [02:29<20:16,  1.36it/s]\u001b[A\n","Iteration:  11% 202/1851 [02:30<20:12,  1.36it/s]\u001b[A\n","Iteration:  11% 203/1851 [02:30<20:11,  1.36it/s]\u001b[A\n","Iteration:  11% 204/1851 [02:31<20:10,  1.36it/s]\u001b[A\n","Iteration:  11% 205/1851 [02:32<20:11,  1.36it/s]\u001b[A\n","Iteration:  11% 206/1851 [02:33<20:12,  1.36it/s]\u001b[A\n","Iteration:  11% 207/1851 [02:33<20:11,  1.36it/s]\u001b[A\n","Iteration:  11% 208/1851 [02:34<20:15,  1.35it/s]\u001b[A\n","Iteration:  11% 209/1851 [02:35<20:11,  1.36it/s]\u001b[A\n","Iteration:  11% 210/1851 [02:36<20:11,  1.35it/s]\u001b[A\n","Iteration:  11% 211/1851 [02:36<20:05,  1.36it/s]\u001b[A\n","Iteration:  11% 212/1851 [02:37<20:05,  1.36it/s]\u001b[A\n","Iteration:  12% 213/1851 [02:38<20:08,  1.35it/s]\u001b[A\n","Iteration:  12% 214/1851 [02:39<20:05,  1.36it/s]\u001b[A\n","Iteration:  12% 215/1851 [02:39<20:06,  1.36it/s]\u001b[A\n","Iteration:  12% 216/1851 [02:40<20:05,  1.36it/s]\u001b[A\n","Iteration:  12% 217/1851 [02:41<20:05,  1.36it/s]\u001b[A\n","Iteration:  12% 218/1851 [02:41<20:02,  1.36it/s]\u001b[A\n","Iteration:  12% 219/1851 [02:42<20:01,  1.36it/s]\u001b[A\n","Iteration:  12% 220/1851 [02:43<20:02,  1.36it/s]\u001b[A\n","Iteration:  12% 221/1851 [02:44<20:03,  1.35it/s]\u001b[A\n","Iteration:  12% 222/1851 [02:44<20:01,  1.36it/s]\u001b[A\n","Iteration:  12% 223/1851 [02:45<20:03,  1.35it/s]\u001b[A\n","Iteration:  12% 224/1851 [02:46<20:04,  1.35it/s]\u001b[A\n","Iteration:  12% 225/1851 [02:47<20:01,  1.35it/s]\u001b[A\n","Iteration:  12% 226/1851 [02:47<20:00,  1.35it/s]\u001b[A\n","Iteration:  12% 227/1851 [02:48<19:57,  1.36it/s]\u001b[A\n","Iteration:  12% 228/1851 [02:49<19:50,  1.36it/s]\u001b[A\n","Iteration:  12% 229/1851 [02:50<19:54,  1.36it/s]\u001b[A\n","Iteration:  12% 230/1851 [02:50<19:53,  1.36it/s]\u001b[A\n","Iteration:  12% 231/1851 [02:51<19:53,  1.36it/s]\u001b[A\n","Iteration:  13% 232/1851 [02:52<19:55,  1.35it/s]\u001b[A\n","Iteration:  13% 233/1851 [02:53<19:52,  1.36it/s]\u001b[A\n","Iteration:  13% 234/1851 [02:53<19:54,  1.35it/s]\u001b[A\n","Iteration:  13% 235/1851 [02:54<19:54,  1.35it/s]\u001b[A\n","Iteration:  13% 236/1851 [02:55<19:54,  1.35it/s]\u001b[A\n","Iteration:  13% 237/1851 [02:56<19:54,  1.35it/s]\u001b[A\n","Iteration:  13% 238/1851 [02:56<19:55,  1.35it/s]\u001b[A\n","Iteration:  13% 239/1851 [02:57<19:51,  1.35it/s]\u001b[A\n","Iteration:  13% 240/1851 [02:58<19:46,  1.36it/s]\u001b[A\n","Iteration:  13% 241/1851 [02:58<19:44,  1.36it/s]\u001b[A\n","Iteration:  13% 242/1851 [02:59<19:44,  1.36it/s]\u001b[A\n","Iteration:  13% 243/1851 [03:00<19:45,  1.36it/s]\u001b[A\n","Iteration:  13% 244/1851 [03:01<19:50,  1.35it/s]\u001b[A\n","Iteration:  13% 245/1851 [03:01<19:46,  1.35it/s]\u001b[A\n","Iteration:  13% 246/1851 [03:02<19:46,  1.35it/s]\u001b[A\n","Iteration:  13% 247/1851 [03:03<19:45,  1.35it/s]\u001b[A\n","Iteration:  13% 248/1851 [03:04<19:47,  1.35it/s]\u001b[A\n","Iteration:  13% 249/1851 [03:04<19:44,  1.35it/s]\u001b[A\n","Iteration:  14% 250/1851 [03:05<19:46,  1.35it/s]\u001b[A\n","Iteration:  14% 251/1851 [03:06<19:45,  1.35it/s]\u001b[A\n","Iteration:  14% 252/1851 [03:07<19:40,  1.35it/s]\u001b[A\n","Iteration:  14% 253/1851 [03:07<19:41,  1.35it/s]\u001b[A\n","Iteration:  14% 254/1851 [03:08<19:38,  1.35it/s]\u001b[A\n","Iteration:  14% 255/1851 [03:09<19:36,  1.36it/s]\u001b[A\n","Iteration:  14% 256/1851 [03:10<19:39,  1.35it/s]\u001b[A\n","Iteration:  14% 257/1851 [03:10<19:37,  1.35it/s]\u001b[A\n","Iteration:  14% 258/1851 [03:11<19:38,  1.35it/s]\u001b[A\n","Iteration:  14% 259/1851 [03:12<19:35,  1.35it/s]\u001b[A\n","Iteration:  14% 260/1851 [03:12<19:32,  1.36it/s]\u001b[A\n","Iteration:  14% 261/1851 [03:13<19:30,  1.36it/s]\u001b[A\n","Iteration:  14% 262/1851 [03:14<19:30,  1.36it/s]\u001b[A\n","Iteration:  14% 263/1851 [03:15<19:32,  1.35it/s]\u001b[A\n","Iteration:  14% 264/1851 [03:15<19:30,  1.36it/s]\u001b[A\n","Iteration:  14% 265/1851 [03:16<19:33,  1.35it/s]\u001b[A\n","Iteration:  14% 266/1851 [03:17<19:28,  1.36it/s]\u001b[A\n","Iteration:  14% 267/1851 [03:18<19:26,  1.36it/s]\u001b[A\n","Iteration:  14% 268/1851 [03:18<19:25,  1.36it/s]\u001b[A\n","Iteration:  15% 269/1851 [03:19<19:27,  1.36it/s]\u001b[A\n","Iteration:  15% 270/1851 [03:20<19:27,  1.35it/s]\u001b[A\n","Iteration:  15% 271/1851 [03:21<19:27,  1.35it/s]\u001b[A\n","Iteration:  15% 272/1851 [03:21<19:25,  1.36it/s]\u001b[A\n","Iteration:  15% 273/1851 [03:22<19:21,  1.36it/s]\u001b[A\n","Iteration:  15% 274/1851 [03:23<19:18,  1.36it/s]\u001b[A\n","Iteration:  15% 275/1851 [03:24<19:21,  1.36it/s]\u001b[A\n","Iteration:  15% 276/1851 [03:24<19:20,  1.36it/s]\u001b[A\n","Iteration:  15% 277/1851 [03:25<19:17,  1.36it/s]\u001b[A\n","Iteration:  15% 278/1851 [03:26<19:18,  1.36it/s]\u001b[A\n","Iteration:  15% 279/1851 [03:27<19:19,  1.36it/s]\u001b[A\n","Iteration:  15% 280/1851 [03:27<19:18,  1.36it/s]\u001b[A\n","Iteration:  15% 281/1851 [03:28<19:16,  1.36it/s]\u001b[A\n","Iteration:  15% 282/1851 [03:29<19:17,  1.36it/s]\u001b[A\n","Iteration:  15% 283/1851 [03:29<19:17,  1.35it/s]\u001b[A\n","Iteration:  15% 284/1851 [03:30<19:17,  1.35it/s]\u001b[A\n","Iteration:  15% 285/1851 [03:31<19:15,  1.36it/s]\u001b[A\n","Iteration:  15% 286/1851 [03:32<19:14,  1.36it/s]\u001b[A\n","Iteration:  16% 287/1851 [03:32<19:14,  1.35it/s]\u001b[A\n","Iteration:  16% 288/1851 [03:33<19:12,  1.36it/s]\u001b[A\n","Iteration:  16% 289/1851 [03:34<19:10,  1.36it/s]\u001b[A\n","Iteration:  16% 290/1851 [03:35<19:06,  1.36it/s]\u001b[A\n","Iteration:  16% 291/1851 [03:35<19:04,  1.36it/s]\u001b[A\n","Iteration:  16% 292/1851 [03:36<19:03,  1.36it/s]\u001b[A\n","Iteration:  16% 293/1851 [03:37<19:00,  1.37it/s]\u001b[A\n","Iteration:  16% 294/1851 [03:38<19:00,  1.37it/s]\u001b[A\n","Iteration:  16% 295/1851 [03:38<19:03,  1.36it/s]\u001b[A\n","Iteration:  16% 296/1851 [03:39<19:05,  1.36it/s]\u001b[A\n","Iteration:  16% 297/1851 [03:40<19:05,  1.36it/s]\u001b[A\n","Iteration:  16% 298/1851 [03:40<19:07,  1.35it/s]\u001b[A\n","Iteration:  16% 299/1851 [03:41<19:04,  1.36it/s]\u001b[A\n","Iteration:  16% 300/1851 [03:42<19:03,  1.36it/s]\u001b[A\n","Iteration:  16% 301/1851 [03:43<19:01,  1.36it/s]\u001b[A\n","Iteration:  16% 302/1851 [03:43<19:03,  1.35it/s]\u001b[A\n","Iteration:  16% 303/1851 [03:44<19:00,  1.36it/s]\u001b[A\n","Iteration:  16% 304/1851 [03:45<18:58,  1.36it/s]\u001b[A\n","Iteration:  16% 305/1851 [03:46<18:58,  1.36it/s]\u001b[A\n","Iteration:  17% 306/1851 [03:46<18:59,  1.36it/s]\u001b[A\n","Iteration:  17% 307/1851 [03:47<18:59,  1.35it/s]\u001b[A\n","Iteration:  17% 308/1851 [03:48<18:55,  1.36it/s]\u001b[A\n","Iteration:  17% 309/1851 [03:49<18:54,  1.36it/s]\u001b[A\n","Iteration:  17% 310/1851 [03:49<18:55,  1.36it/s]\u001b[A\n","Iteration:  17% 311/1851 [03:50<18:54,  1.36it/s]\u001b[A\n","Iteration:  17% 312/1851 [03:51<18:54,  1.36it/s]\u001b[A\n","Iteration:  17% 313/1851 [03:52<18:52,  1.36it/s]\u001b[A\n","Iteration:  17% 314/1851 [03:52<18:52,  1.36it/s]\u001b[A\n","Iteration:  17% 315/1851 [03:53<18:51,  1.36it/s]\u001b[A\n","Iteration:  17% 316/1851 [03:54<18:52,  1.35it/s]\u001b[A\n","Iteration:  17% 317/1851 [03:54<18:51,  1.36it/s]\u001b[A\n","Iteration:  17% 318/1851 [03:55<18:50,  1.36it/s]\u001b[A\n","Iteration:  17% 319/1851 [03:56<18:46,  1.36it/s]\u001b[A\n","Iteration:  17% 320/1851 [03:57<18:43,  1.36it/s]\u001b[A\n","Iteration:  17% 321/1851 [03:57<18:40,  1.37it/s]\u001b[A\n","Iteration:  17% 322/1851 [03:58<18:44,  1.36it/s]\u001b[A\n","Iteration:  17% 323/1851 [03:59<18:44,  1.36it/s]\u001b[A\n","Iteration:  18% 324/1851 [04:00<18:43,  1.36it/s]\u001b[A\n","Iteration:  18% 325/1851 [04:00<18:41,  1.36it/s]\u001b[A\n","Iteration:  18% 326/1851 [04:01<18:38,  1.36it/s]\u001b[A\n","Iteration:  18% 327/1851 [04:02<18:37,  1.36it/s]\u001b[A\n","Iteration:  18% 328/1851 [04:03<18:39,  1.36it/s]\u001b[A\n","Iteration:  18% 329/1851 [04:03<18:40,  1.36it/s]\u001b[A\n","Iteration:  18% 330/1851 [04:04<18:40,  1.36it/s]\u001b[A\n","Iteration:  18% 331/1851 [04:05<18:40,  1.36it/s]\u001b[A\n","Iteration:  18% 332/1851 [04:06<18:37,  1.36it/s]\u001b[A\n","Iteration:  18% 333/1851 [04:06<18:37,  1.36it/s]\u001b[A\n","Iteration:  18% 334/1851 [04:07<18:40,  1.35it/s]\u001b[A\n","Iteration:  18% 335/1851 [04:08<18:38,  1.36it/s]\u001b[A\n","Iteration:  18% 336/1851 [04:08<18:39,  1.35it/s]\u001b[A\n","Iteration:  18% 337/1851 [04:09<18:37,  1.36it/s]\u001b[A\n","Iteration:  18% 338/1851 [04:10<18:34,  1.36it/s]\u001b[A\n","Iteration:  18% 339/1851 [04:11<18:34,  1.36it/s]\u001b[A\n","Iteration:  18% 340/1851 [04:11<18:34,  1.36it/s]\u001b[A\n","Iteration:  18% 341/1851 [04:12<18:32,  1.36it/s]\u001b[A\n","Iteration:  18% 342/1851 [04:13<18:32,  1.36it/s]\u001b[A\n","Iteration:  19% 343/1851 [04:14<18:34,  1.35it/s]\u001b[A\n","Iteration:  19% 344/1851 [04:14<18:31,  1.36it/s]\u001b[A\n","Iteration:  19% 345/1851 [04:15<18:29,  1.36it/s]\u001b[A\n","Iteration:  19% 346/1851 [04:16<18:29,  1.36it/s]\u001b[A\n","Iteration:  19% 347/1851 [04:17<18:31,  1.35it/s]\u001b[A\n","Iteration:  19% 348/1851 [04:17<18:30,  1.35it/s]\u001b[A\n","Iteration:  19% 349/1851 [04:18<18:27,  1.36it/s]\u001b[A\n","Iteration:  19% 350/1851 [04:19<18:25,  1.36it/s]\u001b[A\n","Iteration:  19% 351/1851 [04:20<18:26,  1.36it/s]\u001b[A\n","Iteration:  19% 352/1851 [04:20<18:24,  1.36it/s]\u001b[A\n","Iteration:  19% 353/1851 [04:21<18:23,  1.36it/s]\u001b[A\n","Iteration:  19% 354/1851 [04:22<18:19,  1.36it/s]\u001b[A\n","Iteration:  19% 355/1851 [04:22<18:22,  1.36it/s]\u001b[A\n","Iteration:  19% 356/1851 [04:23<18:20,  1.36it/s]\u001b[A\n","Iteration:  19% 357/1851 [04:24<18:22,  1.35it/s]\u001b[A\n","Iteration:  19% 358/1851 [04:25<18:20,  1.36it/s]\u001b[A\n","Iteration:  19% 359/1851 [04:25<18:18,  1.36it/s]\u001b[A\n","Iteration:  19% 360/1851 [04:26<18:16,  1.36it/s]\u001b[A\n","Iteration:  20% 361/1851 [04:27<18:15,  1.36it/s]\u001b[A\n","Iteration:  20% 362/1851 [04:28<18:17,  1.36it/s]\u001b[A\n","Iteration:  20% 363/1851 [04:28<18:15,  1.36it/s]\u001b[A\n","Iteration:  20% 364/1851 [04:29<18:16,  1.36it/s]\u001b[A\n","Iteration:  20% 365/1851 [04:30<18:16,  1.36it/s]\u001b[A\n","Iteration:  20% 366/1851 [04:31<18:12,  1.36it/s]\u001b[A\n","Iteration:  20% 367/1851 [04:31<18:09,  1.36it/s]\u001b[A\n","Iteration:  20% 368/1851 [04:32<18:09,  1.36it/s]\u001b[A\n","Iteration:  20% 369/1851 [04:33<18:12,  1.36it/s]\u001b[A\n","Iteration:  20% 370/1851 [04:34<18:11,  1.36it/s]\u001b[A\n","Iteration:  20% 371/1851 [04:34<18:07,  1.36it/s]\u001b[A\n","Iteration:  20% 372/1851 [04:35<18:07,  1.36it/s]\u001b[A\n","Iteration:  20% 373/1851 [04:36<18:08,  1.36it/s]\u001b[A\n","Iteration:  20% 374/1851 [04:36<18:07,  1.36it/s]\u001b[A\n","Iteration:  20% 375/1851 [04:37<18:07,  1.36it/s]\u001b[A\n","Iteration:  20% 376/1851 [04:38<18:08,  1.35it/s]\u001b[A\n","Iteration:  20% 377/1851 [04:39<18:07,  1.36it/s]\u001b[A\n","Iteration:  20% 378/1851 [04:39<18:09,  1.35it/s]\u001b[A\n","Iteration:  20% 379/1851 [04:40<18:05,  1.36it/s]\u001b[A\n","Iteration:  21% 380/1851 [04:41<18:04,  1.36it/s]\u001b[A\n","Iteration:  21% 381/1851 [04:42<18:07,  1.35it/s]\u001b[A\n","Iteration:  21% 382/1851 [04:42<18:04,  1.35it/s]\u001b[A\n","Iteration:  21% 383/1851 [04:43<18:06,  1.35it/s]\u001b[A\n","Iteration:  21% 384/1851 [04:44<18:05,  1.35it/s]\u001b[A\n","Iteration:  21% 385/1851 [04:45<18:03,  1.35it/s]\u001b[A\n","Iteration:  21% 386/1851 [04:45<17:58,  1.36it/s]\u001b[A\n","Iteration:  21% 387/1851 [04:46<17:57,  1.36it/s]\u001b[A\n","Iteration:  21% 388/1851 [04:47<17:59,  1.36it/s]\u001b[A\n","Iteration:  21% 389/1851 [04:48<17:58,  1.36it/s]\u001b[A\n","Iteration:  21% 390/1851 [04:48<17:56,  1.36it/s]\u001b[A\n","Iteration:  21% 391/1851 [04:49<17:55,  1.36it/s]\u001b[A\n","Iteration:  21% 392/1851 [04:50<17:56,  1.35it/s]\u001b[A\n","Iteration:  21% 393/1851 [04:50<17:57,  1.35it/s]\u001b[A\n","Iteration:  21% 394/1851 [04:51<17:56,  1.35it/s]\u001b[A\n","Iteration:  21% 395/1851 [04:52<17:57,  1.35it/s]\u001b[A\n","Iteration:  21% 396/1851 [04:53<17:53,  1.36it/s]\u001b[A\n","Iteration:  21% 397/1851 [04:53<17:52,  1.36it/s]\u001b[A\n","Iteration:  22% 398/1851 [04:54<17:51,  1.36it/s]\u001b[A\n","Iteration:  22% 399/1851 [04:55<17:49,  1.36it/s]\u001b[A\n","Iteration:  22% 400/1851 [04:56<17:50,  1.36it/s]\u001b[A\n","Iteration:  22% 401/1851 [04:56<17:47,  1.36it/s]\u001b[A\n","Iteration:  22% 402/1851 [04:57<17:46,  1.36it/s]\u001b[A\n","Iteration:  22% 403/1851 [04:58<17:45,  1.36it/s]\u001b[A\n","Iteration:  22% 404/1851 [04:59<17:48,  1.35it/s]\u001b[A\n","Iteration:  22% 405/1851 [04:59<17:44,  1.36it/s]\u001b[A\n","Iteration:  22% 406/1851 [05:00<17:43,  1.36it/s]\u001b[A\n","Iteration:  22% 407/1851 [05:01<17:45,  1.36it/s]\u001b[A\n","Iteration:  22% 408/1851 [05:02<17:43,  1.36it/s]\u001b[A\n","Iteration:  22% 409/1851 [05:02<17:39,  1.36it/s]\u001b[A\n","Iteration:  22% 410/1851 [05:03<17:38,  1.36it/s]\u001b[A\n","Iteration:  22% 411/1851 [05:04<17:39,  1.36it/s]\u001b[A\n","Iteration:  22% 412/1851 [05:04<17:38,  1.36it/s]\u001b[A\n","Iteration:  22% 413/1851 [05:05<17:38,  1.36it/s]\u001b[A\n","Iteration:  22% 414/1851 [05:06<17:34,  1.36it/s]\u001b[A\n","Iteration:  22% 415/1851 [05:07<17:37,  1.36it/s]\u001b[A\n","Iteration:  22% 416/1851 [05:07<17:36,  1.36it/s]\u001b[A\n","Iteration:  23% 417/1851 [05:08<17:35,  1.36it/s]\u001b[A\n","Iteration:  23% 418/1851 [05:09<17:37,  1.36it/s]\u001b[A\n","Iteration:  23% 419/1851 [05:10<17:37,  1.35it/s]\u001b[A\n","Iteration:  23% 420/1851 [05:10<17:34,  1.36it/s]\u001b[A\n","Iteration:  23% 421/1851 [05:11<17:34,  1.36it/s]\u001b[A\n","Iteration:  23% 422/1851 [05:12<17:33,  1.36it/s]\u001b[A\n","Iteration:  23% 423/1851 [05:13<17:30,  1.36it/s]\u001b[A\n","Iteration:  23% 424/1851 [05:13<17:27,  1.36it/s]\u001b[A\n","Iteration:  23% 425/1851 [05:14<17:24,  1.37it/s]\u001b[A\n","Iteration:  23% 426/1851 [05:15<17:27,  1.36it/s]\u001b[A\n","Iteration:  23% 427/1851 [05:16<17:27,  1.36it/s]\u001b[A\n","Iteration:  23% 428/1851 [05:16<17:26,  1.36it/s]\u001b[A\n","Iteration:  23% 429/1851 [05:17<17:26,  1.36it/s]\u001b[A\n","Iteration:  23% 430/1851 [05:18<17:22,  1.36it/s]\u001b[A\n","Iteration:  23% 431/1851 [05:18<17:24,  1.36it/s]\u001b[A\n","Iteration:  23% 432/1851 [05:19<17:24,  1.36it/s]\u001b[A\n","Iteration:  23% 433/1851 [05:20<17:26,  1.36it/s]\u001b[A\n","Iteration:  23% 434/1851 [05:21<17:26,  1.35it/s]\u001b[A\n","Iteration:  24% 435/1851 [05:21<17:27,  1.35it/s]\u001b[A\n","Iteration:  24% 436/1851 [05:22<17:24,  1.35it/s]\u001b[A\n","Iteration:  24% 437/1851 [05:23<17:22,  1.36it/s]\u001b[A\n","Iteration:  24% 438/1851 [05:24<17:22,  1.36it/s]\u001b[A\n","Iteration:  24% 439/1851 [05:24<17:22,  1.35it/s]\u001b[A\n","Iteration:  24% 440/1851 [05:25<17:20,  1.36it/s]\u001b[A\n","Iteration:  24% 441/1851 [05:26<17:17,  1.36it/s]\u001b[A\n","Iteration:  24% 442/1851 [05:27<17:14,  1.36it/s]\u001b[A\n","Iteration:  24% 443/1851 [05:27<17:13,  1.36it/s]\u001b[A\n","Iteration:  24% 444/1851 [05:28<17:12,  1.36it/s]\u001b[A\n","Iteration:  24% 445/1851 [05:29<17:14,  1.36it/s]\u001b[A\n","Iteration:  24% 446/1851 [05:30<17:13,  1.36it/s]\u001b[A\n","Iteration:  24% 447/1851 [05:30<17:12,  1.36it/s]\u001b[A\n","Iteration:  24% 448/1851 [05:31<17:13,  1.36it/s]\u001b[A\n","Iteration:  24% 449/1851 [05:32<17:13,  1.36it/s]\u001b[A\n","Iteration:  24% 450/1851 [05:32<17:11,  1.36it/s]\u001b[A\n","Iteration:  24% 451/1851 [05:33<17:08,  1.36it/s]\u001b[A\n","Iteration:  24% 452/1851 [05:34<17:05,  1.36it/s]\u001b[A\n","Iteration:  24% 453/1851 [05:35<17:05,  1.36it/s]\u001b[A\n","Iteration:  25% 454/1851 [05:35<17:04,  1.36it/s]\u001b[A\n","Iteration:  25% 455/1851 [05:36<17:06,  1.36it/s]\u001b[A\n","Iteration:  25% 456/1851 [05:37<17:04,  1.36it/s]\u001b[A\n","Iteration:  25% 457/1851 [05:38<17:02,  1.36it/s]\u001b[A\n","Iteration:  25% 458/1851 [05:38<17:01,  1.36it/s]\u001b[A\n","Iteration:  25% 459/1851 [05:39<17:04,  1.36it/s]\u001b[A\n","Iteration:  25% 460/1851 [05:40<17:03,  1.36it/s]\u001b[A\n","Iteration:  25% 461/1851 [05:41<17:02,  1.36it/s]\u001b[A\n","Iteration:  25% 462/1851 [05:41<17:04,  1.36it/s]\u001b[A\n","Iteration:  25% 463/1851 [05:42<17:04,  1.35it/s]\u001b[A\n","Iteration:  25% 464/1851 [05:43<17:04,  1.35it/s]\u001b[A\n","Iteration:  25% 465/1851 [05:44<17:05,  1.35it/s]\u001b[A\n","Iteration:  25% 466/1851 [05:44<17:06,  1.35it/s]\u001b[A\n","Iteration:  25% 467/1851 [05:45<17:02,  1.35it/s]\u001b[A\n","Iteration:  25% 468/1851 [05:46<16:59,  1.36it/s]\u001b[A\n","Iteration:  25% 469/1851 [05:46<16:58,  1.36it/s]\u001b[A\n","Iteration:  25% 470/1851 [05:47<16:58,  1.36it/s]\u001b[A\n","Iteration:  25% 471/1851 [05:48<16:56,  1.36it/s]\u001b[A\n","Iteration:  25% 472/1851 [05:49<16:56,  1.36it/s]\u001b[A\n","Iteration:  26% 473/1851 [05:49<16:56,  1.36it/s]\u001b[A\n","Iteration:  26% 474/1851 [05:50<16:56,  1.35it/s]\u001b[A\n","Iteration:  26% 475/1851 [05:51<16:53,  1.36it/s]\u001b[A\n","Iteration:  26% 476/1851 [05:52<16:54,  1.35it/s]\u001b[A\n","Iteration:  26% 477/1851 [05:52<16:55,  1.35it/s]\u001b[A\n","Iteration:  26% 478/1851 [05:53<16:51,  1.36it/s]\u001b[A\n","Iteration:  26% 479/1851 [05:54<16:52,  1.36it/s]\u001b[A\n","Iteration:  26% 480/1851 [05:55<16:51,  1.36it/s]\u001b[A\n","Iteration:  26% 481/1851 [05:55<16:50,  1.36it/s]\u001b[A\n","Iteration:  26% 482/1851 [05:56<16:47,  1.36it/s]\u001b[A\n","Iteration:  26% 483/1851 [05:57<16:46,  1.36it/s]\u001b[A\n","Iteration:  26% 484/1851 [05:58<16:46,  1.36it/s]\u001b[A\n","Iteration:  26% 485/1851 [05:58<16:44,  1.36it/s]\u001b[A\n","Iteration:  26% 486/1851 [05:59<16:45,  1.36it/s]\u001b[A\n","Iteration:  26% 487/1851 [06:00<16:45,  1.36it/s]\u001b[A\n","Iteration:  26% 488/1851 [06:00<16:43,  1.36it/s]\u001b[A\n","Iteration:  26% 489/1851 [06:01<16:44,  1.36it/s]\u001b[A\n","Iteration:  26% 490/1851 [06:02<16:45,  1.35it/s]\u001b[A\n","Iteration:  27% 491/1851 [06:03<16:44,  1.35it/s]\u001b[A\n","Iteration:  27% 492/1851 [06:03<16:45,  1.35it/s]\u001b[A\n","Iteration:  27% 493/1851 [06:04<16:43,  1.35it/s]\u001b[A\n","Iteration:  27% 494/1851 [06:05<16:43,  1.35it/s]\u001b[A\n","Iteration:  27% 495/1851 [06:06<16:43,  1.35it/s]\u001b[A\n","Iteration:  27% 496/1851 [06:06<16:42,  1.35it/s]\u001b[A\n","Iteration:  27% 497/1851 [06:07<16:40,  1.35it/s]\u001b[A\n","Iteration:  27% 498/1851 [06:08<16:38,  1.35it/s]\u001b[A\n","Iteration:  27% 499/1851 [06:09<16:38,  1.35it/s]\u001b[A\n","Iteration:  27% 500/1851 [06:09<16:37,  1.35it/s]\u001b[A\n","Iteration:  27% 501/1851 [06:10<16:36,  1.35it/s]\u001b[A\n","Iteration:  27% 502/1851 [06:11<16:37,  1.35it/s]\u001b[A\n","Iteration:  27% 503/1851 [06:12<16:33,  1.36it/s]\u001b[A\n","Iteration:  27% 504/1851 [06:12<16:34,  1.35it/s]\u001b[A\n","Iteration:  27% 505/1851 [06:13<16:33,  1.35it/s]\u001b[A\n","Iteration:  27% 506/1851 [06:14<16:31,  1.36it/s]\u001b[A\n","Iteration:  27% 507/1851 [06:14<16:28,  1.36it/s]\u001b[A\n","Iteration:  27% 508/1851 [06:15<16:31,  1.35it/s]\u001b[A\n","Iteration:  27% 509/1851 [06:16<16:29,  1.36it/s]\u001b[A\n","Iteration:  28% 510/1851 [06:17<16:26,  1.36it/s]\u001b[A\n","Iteration:  28% 511/1851 [06:17<16:26,  1.36it/s]\u001b[A\n","Iteration:  28% 512/1851 [06:18<16:28,  1.36it/s]\u001b[A\n","Iteration:  28% 513/1851 [06:19<16:26,  1.36it/s]\u001b[A\n","Iteration:  28% 514/1851 [06:20<16:23,  1.36it/s]\u001b[A\n","Iteration:  28% 515/1851 [06:20<16:25,  1.36it/s]\u001b[A\n","Iteration:  28% 516/1851 [06:21<16:23,  1.36it/s]\u001b[A\n","Iteration:  28% 517/1851 [06:22<16:25,  1.35it/s]\u001b[A\n","Iteration:  28% 518/1851 [06:23<16:24,  1.35it/s]\u001b[A\n","Iteration:  28% 519/1851 [06:23<16:21,  1.36it/s]\u001b[A\n","Iteration:  28% 520/1851 [06:24<16:18,  1.36it/s]\u001b[A\n","Iteration:  28% 521/1851 [06:25<16:19,  1.36it/s]\u001b[A\n","Iteration:  28% 522/1851 [06:26<16:21,  1.35it/s]\u001b[A\n","Iteration:  28% 523/1851 [06:26<16:17,  1.36it/s]\u001b[A\n","Iteration:  28% 524/1851 [06:27<16:14,  1.36it/s]\u001b[A\n","Iteration:  28% 525/1851 [06:28<16:13,  1.36it/s]\u001b[A\n","Iteration:  28% 526/1851 [06:28<16:13,  1.36it/s]\u001b[A\n","Iteration:  28% 527/1851 [06:29<16:14,  1.36it/s]\u001b[A\n","Iteration:  29% 528/1851 [06:30<16:14,  1.36it/s]\u001b[A\n","Iteration:  29% 529/1851 [06:31<16:15,  1.36it/s]\u001b[A\n","Iteration:  29% 530/1851 [06:31<16:13,  1.36it/s]\u001b[A\n","Iteration:  29% 531/1851 [06:32<16:12,  1.36it/s]\u001b[A\n","Iteration:  29% 532/1851 [06:33<16:12,  1.36it/s]\u001b[A\n","Iteration:  29% 533/1851 [06:34<16:13,  1.35it/s]\u001b[A\n","Iteration:  29% 534/1851 [06:34<16:13,  1.35it/s]\u001b[A\n","Iteration:  29% 535/1851 [06:35<16:14,  1.35it/s]\u001b[A\n","Iteration:  29% 536/1851 [06:36<16:14,  1.35it/s]\u001b[A\n","Iteration:  29% 537/1851 [06:37<16:10,  1.35it/s]\u001b[A\n","Iteration:  29% 538/1851 [06:37<16:11,  1.35it/s]\u001b[A\n","Iteration:  29% 539/1851 [06:38<16:08,  1.35it/s]\u001b[A\n","Iteration:  29% 540/1851 [06:39<16:07,  1.36it/s]\u001b[A\n","Iteration:  29% 541/1851 [06:40<16:05,  1.36it/s]\u001b[A\n","Iteration:  29% 542/1851 [06:40<16:06,  1.35it/s]\u001b[A\n","Iteration:  29% 543/1851 [06:41<16:05,  1.35it/s]\u001b[A\n","Iteration:  29% 544/1851 [06:42<16:06,  1.35it/s]\u001b[A\n","Iteration:  29% 545/1851 [06:43<16:04,  1.35it/s]\u001b[A\n","Iteration:  29% 546/1851 [06:43<16:02,  1.36it/s]\u001b[A\n","Iteration:  30% 547/1851 [06:44<15:56,  1.36it/s]\u001b[A\n","Iteration:  30% 548/1851 [06:45<15:55,  1.36it/s]\u001b[A\n","Iteration:  30% 549/1851 [06:45<15:54,  1.36it/s]\u001b[A\n","Iteration:  30% 550/1851 [06:46<15:55,  1.36it/s]\u001b[A\n","Iteration:  30% 551/1851 [06:47<15:56,  1.36it/s]\u001b[A\n","Iteration:  30% 552/1851 [06:48<15:56,  1.36it/s]\u001b[A\n","Iteration:  30% 553/1851 [06:48<15:53,  1.36it/s]\u001b[A\n","Iteration:  30% 554/1851 [06:49<15:55,  1.36it/s]\u001b[A\n","Iteration:  30% 555/1851 [06:50<15:54,  1.36it/s]\u001b[A\n","Iteration:  30% 556/1851 [06:51<15:55,  1.36it/s]\u001b[A\n","Iteration:  30% 557/1851 [06:51<15:54,  1.36it/s]\u001b[A\n","Iteration:  30% 558/1851 [06:52<15:52,  1.36it/s]\u001b[A\n","Iteration:  30% 559/1851 [06:53<15:51,  1.36it/s]\u001b[A\n","Iteration:  30% 560/1851 [06:54<15:52,  1.36it/s]\u001b[A\n","Iteration:  30% 561/1851 [06:54<15:51,  1.36it/s]\u001b[A\n","Iteration:  30% 562/1851 [06:55<15:53,  1.35it/s]\u001b[A\n","Iteration:  30% 563/1851 [06:56<15:50,  1.35it/s]\u001b[A\n","Iteration:  30% 564/1851 [06:57<15:47,  1.36it/s]\u001b[A\n","Iteration:  31% 565/1851 [06:57<15:44,  1.36it/s]\u001b[A\n","Iteration:  31% 566/1851 [06:58<15:46,  1.36it/s]\u001b[A\n","Iteration:  31% 567/1851 [06:59<15:48,  1.35it/s]\u001b[A\n","Iteration:  31% 568/1851 [06:59<15:45,  1.36it/s]\u001b[A\n","Iteration:  31% 569/1851 [07:00<15:43,  1.36it/s]\u001b[A\n","Iteration:  31% 570/1851 [07:01<15:42,  1.36it/s]\u001b[A\n","Iteration:  31% 571/1851 [07:02<15:45,  1.35it/s]\u001b[A\n","Iteration:  31% 572/1851 [07:02<15:42,  1.36it/s]\u001b[A\n","Iteration:  31% 573/1851 [07:03<15:42,  1.36it/s]\u001b[A\n","Iteration:  31% 574/1851 [07:04<15:38,  1.36it/s]\u001b[A\n","Iteration:  31% 575/1851 [07:05<15:37,  1.36it/s]\u001b[A\n","Iteration:  31% 576/1851 [07:05<15:37,  1.36it/s]\u001b[A\n","Iteration:  31% 577/1851 [07:06<15:39,  1.36it/s]\u001b[A\n","Iteration:  31% 578/1851 [07:07<15:37,  1.36it/s]\u001b[A\n","Iteration:  31% 579/1851 [07:08<15:37,  1.36it/s]\u001b[A\n","Iteration:  31% 580/1851 [07:08<15:37,  1.36it/s]\u001b[A\n","Iteration:  31% 581/1851 [07:09<15:37,  1.35it/s]\u001b[A\n","Iteration:  31% 582/1851 [07:10<15:34,  1.36it/s]\u001b[A\n","Iteration:  31% 583/1851 [07:11<15:34,  1.36it/s]\u001b[A\n","Iteration:  32% 584/1851 [07:11<15:34,  1.36it/s]\u001b[A\n","Iteration:  32% 585/1851 [07:12<15:33,  1.36it/s]\u001b[A\n","Iteration:  32% 586/1851 [07:13<15:33,  1.36it/s]\u001b[A\n","Iteration:  32% 587/1851 [07:13<15:34,  1.35it/s]\u001b[A\n","Iteration:  32% 588/1851 [07:14<15:31,  1.36it/s]\u001b[A\n","Iteration:  32% 589/1851 [07:15<15:34,  1.35it/s]\u001b[A\n","Iteration:  32% 590/1851 [07:16<15:30,  1.36it/s]\u001b[A\n","Iteration:  32% 591/1851 [07:16<15:31,  1.35it/s]\u001b[A\n","Iteration:  32% 592/1851 [07:17<15:29,  1.35it/s]\u001b[A\n","Iteration:  32% 593/1851 [07:18<15:28,  1.35it/s]\u001b[A\n","Iteration:  32% 594/1851 [07:19<15:29,  1.35it/s]\u001b[A\n","Iteration:  32% 595/1851 [07:19<15:27,  1.35it/s]\u001b[A\n","Iteration:  32% 596/1851 [07:20<15:27,  1.35it/s]\u001b[A\n","Iteration:  32% 597/1851 [07:21<15:26,  1.35it/s]\u001b[A\n","Iteration:  32% 598/1851 [07:22<15:23,  1.36it/s]\u001b[A\n","Iteration:  32% 599/1851 [07:22<15:21,  1.36it/s]\u001b[A\n","Iteration:  32% 600/1851 [07:23<15:23,  1.36it/s]\u001b[A\n","Iteration:  32% 601/1851 [07:24<15:20,  1.36it/s]\u001b[A\n","Iteration:  33% 602/1851 [07:25<15:23,  1.35it/s]\u001b[A\n","Iteration:  33% 603/1851 [07:25<15:22,  1.35it/s]\u001b[A\n","Iteration:  33% 604/1851 [07:26<15:24,  1.35it/s]\u001b[A\n","Iteration:  33% 605/1851 [07:27<15:20,  1.35it/s]\u001b[A\n","Iteration:  33% 606/1851 [07:27<15:21,  1.35it/s]\u001b[A\n","Iteration:  33% 607/1851 [07:28<15:18,  1.35it/s]\u001b[A\n","Iteration:  33% 608/1851 [07:29<15:17,  1.35it/s]\u001b[A\n","Iteration:  33% 609/1851 [07:30<15:17,  1.35it/s]\u001b[A\n","Iteration:  33% 610/1851 [07:30<15:16,  1.35it/s]\u001b[A\n","Iteration:  33% 611/1851 [07:31<15:16,  1.35it/s]\u001b[A\n","Iteration:  33% 612/1851 [07:32<15:16,  1.35it/s]\u001b[A\n","Iteration:  33% 613/1851 [07:33<15:13,  1.36it/s]\u001b[A\n","Iteration:  33% 614/1851 [07:33<15:15,  1.35it/s]\u001b[A\n","Iteration:  33% 615/1851 [07:34<15:16,  1.35it/s]\u001b[A\n","Iteration:  33% 616/1851 [07:35<15:13,  1.35it/s]\u001b[A\n","Iteration:  33% 617/1851 [07:36<15:11,  1.35it/s]\u001b[A\n","Iteration:  33% 618/1851 [07:36<15:12,  1.35it/s]\u001b[A\n","Iteration:  33% 619/1851 [07:37<15:09,  1.35it/s]\u001b[A\n","Iteration:  33% 620/1851 [07:38<15:10,  1.35it/s]\u001b[A\n","Iteration:  34% 621/1851 [07:39<15:09,  1.35it/s]\u001b[A\n","Iteration:  34% 622/1851 [07:39<15:06,  1.36it/s]\u001b[A\n","Iteration:  34% 623/1851 [07:40<15:05,  1.36it/s]\u001b[A\n","Iteration:  34% 624/1851 [07:41<15:03,  1.36it/s]\u001b[A\n","Iteration:  34% 625/1851 [07:42<15:05,  1.35it/s]\u001b[A\n","Iteration:  34% 626/1851 [07:42<15:07,  1.35it/s]\u001b[A\n","Iteration:  34% 627/1851 [07:43<15:05,  1.35it/s]\u001b[A\n","Iteration:  34% 628/1851 [07:44<15:04,  1.35it/s]\u001b[A\n","Iteration:  34% 629/1851 [07:44<15:03,  1.35it/s]\u001b[A\n","Iteration:  34% 630/1851 [07:45<14:59,  1.36it/s]\u001b[A\n","Iteration:  34% 631/1851 [07:46<14:58,  1.36it/s]\u001b[A\n","Iteration:  34% 632/1851 [07:47<15:00,  1.35it/s]\u001b[A\n","Iteration:  34% 633/1851 [07:47<14:59,  1.35it/s]\u001b[A\n","Iteration:  34% 634/1851 [07:48<14:57,  1.36it/s]\u001b[A\n","Iteration:  34% 635/1851 [07:49<14:58,  1.35it/s]\u001b[A\n","Iteration:  34% 636/1851 [07:50<14:56,  1.36it/s]\u001b[A\n","Iteration:  34% 637/1851 [07:50<14:55,  1.36it/s]\u001b[A\n","Iteration:  34% 638/1851 [07:51<14:55,  1.36it/s]\u001b[A\n","Iteration:  35% 639/1851 [07:52<14:52,  1.36it/s]\u001b[A\n","Iteration:  35% 640/1851 [07:53<14:50,  1.36it/s]\u001b[A\n","Iteration:  35% 641/1851 [07:53<14:51,  1.36it/s]\u001b[A\n","Iteration:  35% 642/1851 [07:54<14:51,  1.36it/s]\u001b[A\n","Iteration:  35% 643/1851 [07:55<14:50,  1.36it/s]\u001b[A\n","Iteration:  35% 644/1851 [07:56<14:49,  1.36it/s]\u001b[A\n","Iteration:  35% 645/1851 [07:56<14:50,  1.35it/s]\u001b[A\n","Iteration:  35% 646/1851 [07:57<14:46,  1.36it/s]\u001b[A\n","Iteration:  35% 647/1851 [07:58<14:48,  1.36it/s]\u001b[A\n","Iteration:  35% 648/1851 [07:58<14:48,  1.35it/s]\u001b[A\n","Iteration:  35% 649/1851 [07:59<14:49,  1.35it/s]\u001b[A\n","Iteration:  35% 650/1851 [08:00<14:48,  1.35it/s]\u001b[A\n","Iteration:  35% 651/1851 [08:01<14:48,  1.35it/s]\u001b[A\n","Iteration:  35% 652/1851 [08:01<14:46,  1.35it/s]\u001b[A\n","Iteration:  35% 653/1851 [08:02<14:42,  1.36it/s]\u001b[A\n","Iteration:  35% 654/1851 [08:03<14:42,  1.36it/s]\u001b[A\n","Iteration:  35% 655/1851 [08:04<14:38,  1.36it/s]\u001b[A\n","Iteration:  35% 656/1851 [08:04<14:38,  1.36it/s]\u001b[A\n","Iteration:  35% 657/1851 [08:05<14:37,  1.36it/s]\u001b[A\n","Iteration:  36% 658/1851 [08:06<14:38,  1.36it/s]\u001b[A\n","Iteration:  36% 659/1851 [08:07<14:36,  1.36it/s]\u001b[A\n","Iteration:  36% 660/1851 [08:07<14:34,  1.36it/s]\u001b[A\n","Iteration:  36% 661/1851 [08:08<14:33,  1.36it/s]\u001b[A\n","Iteration:  36% 662/1851 [08:09<14:31,  1.36it/s]\u001b[A\n","Iteration:  36% 663/1851 [08:10<14:29,  1.37it/s]\u001b[A\n","Iteration:  36% 664/1851 [08:10<14:32,  1.36it/s]\u001b[A\n","Iteration:  36% 665/1851 [08:11<14:32,  1.36it/s]\u001b[A\n","Iteration:  36% 666/1851 [08:12<14:32,  1.36it/s]\u001b[A\n","Iteration:  36% 667/1851 [08:12<14:30,  1.36it/s]\u001b[A\n","Iteration:  36% 668/1851 [08:13<14:33,  1.35it/s]\u001b[A\n","Iteration:  36% 669/1851 [08:14<14:32,  1.36it/s]\u001b[A\n","Iteration:  36% 670/1851 [08:15<14:31,  1.36it/s]\u001b[A\n","Iteration:  36% 671/1851 [08:15<14:27,  1.36it/s]\u001b[A\n","Iteration:  36% 672/1851 [08:16<14:29,  1.36it/s]\u001b[A\n","Iteration:  36% 673/1851 [08:17<14:27,  1.36it/s]\u001b[A\n","Iteration:  36% 674/1851 [08:18<14:26,  1.36it/s]\u001b[A\n","Iteration:  36% 675/1851 [08:18<14:26,  1.36it/s]\u001b[A\n","Iteration:  37% 676/1851 [08:19<14:26,  1.36it/s]\u001b[A\n","Iteration:  37% 677/1851 [08:20<14:26,  1.35it/s]\u001b[A\n","Iteration:  37% 678/1851 [08:21<14:25,  1.35it/s]\u001b[A\n","Iteration:  37% 679/1851 [08:21<14:25,  1.35it/s]\u001b[A\n","Iteration:  37% 680/1851 [08:22<14:23,  1.36it/s]\u001b[A\n","Iteration:  37% 681/1851 [08:23<14:22,  1.36it/s]\u001b[A\n","Iteration:  37% 682/1851 [08:24<14:22,  1.35it/s]\u001b[A\n","Iteration:  37% 683/1851 [08:24<14:20,  1.36it/s]\u001b[A\n","Iteration:  37% 684/1851 [08:25<14:19,  1.36it/s]\u001b[A\n","Iteration:  37% 685/1851 [08:26<14:19,  1.36it/s]\u001b[A\n","Iteration:  37% 686/1851 [08:26<14:18,  1.36it/s]\u001b[A\n","Iteration:  37% 687/1851 [08:27<14:16,  1.36it/s]\u001b[A\n","Iteration:  37% 688/1851 [08:28<14:15,  1.36it/s]\u001b[A\n","Iteration:  37% 689/1851 [08:29<14:13,  1.36it/s]\u001b[A\n","Iteration:  37% 690/1851 [08:29<14:12,  1.36it/s]\u001b[A\n","Iteration:  37% 691/1851 [08:30<14:15,  1.36it/s]\u001b[A\n","Iteration:  37% 692/1851 [08:31<14:13,  1.36it/s]\u001b[A\n","Iteration:  37% 693/1851 [08:32<14:14,  1.35it/s]\u001b[A\n","Iteration:  37% 694/1851 [08:32<14:14,  1.35it/s]\u001b[A\n","Iteration:  38% 695/1851 [08:33<14:15,  1.35it/s]\u001b[A\n","Iteration:  38% 696/1851 [08:34<14:14,  1.35it/s]\u001b[A\n","Iteration:  38% 697/1851 [08:35<14:15,  1.35it/s]\u001b[A\n","Iteration:  38% 698/1851 [08:35<14:14,  1.35it/s]\u001b[A\n","Iteration:  38% 699/1851 [08:36<14:13,  1.35it/s]\u001b[A\n","Iteration:  38% 700/1851 [08:37<14:11,  1.35it/s]\u001b[A\n","Iteration:  38% 701/1851 [08:38<14:08,  1.36it/s]\u001b[A\n","Iteration:  38% 702/1851 [08:38<14:05,  1.36it/s]\u001b[A\n","Iteration:  38% 703/1851 [08:39<14:06,  1.36it/s]\u001b[A\n","Iteration:  38% 704/1851 [08:40<14:04,  1.36it/s]\u001b[A\n","Iteration:  38% 705/1851 [08:41<14:03,  1.36it/s]\u001b[A\n","Iteration:  38% 706/1851 [08:41<14:01,  1.36it/s]\u001b[A\n","Iteration:  38% 707/1851 [08:42<14:02,  1.36it/s]\u001b[A\n","Iteration:  38% 708/1851 [08:43<14:03,  1.36it/s]\u001b[A\n","Iteration:  38% 709/1851 [08:43<14:00,  1.36it/s]\u001b[A\n","Iteration:  38% 710/1851 [08:44<14:01,  1.36it/s]\u001b[A\n","Iteration:  38% 711/1851 [08:45<13:59,  1.36it/s]\u001b[A\n","Iteration:  38% 712/1851 [08:46<13:58,  1.36it/s]\u001b[A\n","Iteration:  39% 713/1851 [08:46<13:57,  1.36it/s]\u001b[A\n","Iteration:  39% 714/1851 [08:47<13:59,  1.36it/s]\u001b[A\n","Iteration:  39% 715/1851 [08:48<13:59,  1.35it/s]\u001b[A\n","Iteration:  39% 716/1851 [08:49<13:58,  1.35it/s]\u001b[A\n","Iteration:  39% 717/1851 [08:49<13:54,  1.36it/s]\u001b[A\n","Iteration:  39% 718/1851 [08:50<13:53,  1.36it/s]\u001b[A\n","Iteration:  39% 719/1851 [08:51<13:49,  1.36it/s]\u001b[A\n","Iteration:  39% 720/1851 [08:52<13:50,  1.36it/s]\u001b[A\n","Iteration:  39% 721/1851 [08:52<13:49,  1.36it/s]\u001b[A\n","Iteration:  39% 722/1851 [08:53<13:49,  1.36it/s]\u001b[A\n","Iteration:  39% 723/1851 [08:54<13:49,  1.36it/s]\u001b[A\n","Iteration:  39% 724/1851 [08:54<13:49,  1.36it/s]\u001b[A\n","Iteration:  39% 725/1851 [08:55<13:51,  1.35it/s]\u001b[A\n","Iteration:  39% 726/1851 [08:56<13:50,  1.36it/s]\u001b[A\n","Iteration:  39% 727/1851 [08:57<13:49,  1.35it/s]\u001b[A\n","Iteration:  39% 728/1851 [08:57<13:48,  1.36it/s]\u001b[A\n","Iteration:  39% 729/1851 [08:58<13:49,  1.35it/s]\u001b[A\n","Iteration:  39% 730/1851 [08:59<13:46,  1.36it/s]\u001b[A\n","Iteration:  39% 731/1851 [09:00<13:47,  1.35it/s]\u001b[A\n","Iteration:  40% 732/1851 [09:00<13:47,  1.35it/s]\u001b[A\n","Iteration:  40% 733/1851 [09:01<13:43,  1.36it/s]\u001b[A\n","Iteration:  40% 734/1851 [09:02<13:43,  1.36it/s]\u001b[A\n","Iteration:  40% 735/1851 [09:03<13:43,  1.36it/s]\u001b[A\n","Iteration:  40% 736/1851 [09:03<13:41,  1.36it/s]\u001b[A\n","Iteration:  40% 737/1851 [09:04<13:40,  1.36it/s]\u001b[A\n","Iteration:  40% 738/1851 [09:05<13:39,  1.36it/s]\u001b[A\n","Iteration:  40% 739/1851 [09:06<13:39,  1.36it/s]\u001b[A\n","Iteration:  40% 740/1851 [09:06<13:38,  1.36it/s]\u001b[A\n","Iteration:  40% 741/1851 [09:07<13:35,  1.36it/s]\u001b[A\n","Iteration:  40% 742/1851 [09:08<13:36,  1.36it/s]\u001b[A\n","Iteration:  40% 743/1851 [09:09<13:36,  1.36it/s]\u001b[A\n","Iteration:  40% 744/1851 [09:09<13:33,  1.36it/s]\u001b[A\n","Iteration:  40% 745/1851 [09:10<13:33,  1.36it/s]\u001b[A\n","Iteration:  40% 746/1851 [09:11<13:34,  1.36it/s]\u001b[A\n","Iteration:  40% 747/1851 [09:11<13:32,  1.36it/s]\u001b[A\n","Iteration:  40% 748/1851 [09:12<13:30,  1.36it/s]\u001b[A\n","Iteration:  40% 749/1851 [09:13<13:29,  1.36it/s]\u001b[A\n","Iteration:  41% 750/1851 [09:14<13:28,  1.36it/s]\u001b[A\n","Iteration:  41% 751/1851 [09:14<13:29,  1.36it/s]\u001b[A\n","Iteration:  41% 752/1851 [09:15<13:29,  1.36it/s]\u001b[A\n","Iteration:  41% 753/1851 [09:16<13:27,  1.36it/s]\u001b[A\n","Iteration:  41% 754/1851 [09:17<13:28,  1.36it/s]\u001b[A\n","Iteration:  41% 755/1851 [09:17<13:24,  1.36it/s]\u001b[A\n","Iteration:  41% 756/1851 [09:18<13:23,  1.36it/s]\u001b[A\n","Iteration:  41% 757/1851 [09:19<13:22,  1.36it/s]\u001b[A\n","Iteration:  41% 758/1851 [09:20<13:20,  1.36it/s]\u001b[A\n","Iteration:  41% 759/1851 [09:20<13:20,  1.36it/s]\u001b[A\n","Iteration:  41% 760/1851 [09:21<13:22,  1.36it/s]\u001b[A\n","Iteration:  41% 761/1851 [09:22<13:21,  1.36it/s]\u001b[A\n","Iteration:  41% 762/1851 [09:22<13:21,  1.36it/s]\u001b[A\n","Iteration:  41% 763/1851 [09:23<13:19,  1.36it/s]\u001b[A\n","Iteration:  41% 764/1851 [09:24<13:17,  1.36it/s]\u001b[A\n","Iteration:  41% 765/1851 [09:25<13:16,  1.36it/s]\u001b[A\n","Iteration:  41% 766/1851 [09:25<13:16,  1.36it/s]\u001b[A\n","Iteration:  41% 767/1851 [09:26<13:13,  1.37it/s]\u001b[A\n","Iteration:  41% 768/1851 [09:27<13:14,  1.36it/s]\u001b[A\n","Iteration:  42% 769/1851 [09:28<13:12,  1.37it/s]\u001b[A\n","Iteration:  42% 770/1851 [09:28<13:13,  1.36it/s]\u001b[A\n","Iteration:  42% 771/1851 [09:29<13:14,  1.36it/s]\u001b[A\n","Iteration:  42% 772/1851 [09:30<13:13,  1.36it/s]\u001b[A\n","Iteration:  42% 773/1851 [09:31<13:11,  1.36it/s]\u001b[A\n","Iteration:  42% 774/1851 [09:31<13:13,  1.36it/s]\u001b[A\n","Iteration:  42% 775/1851 [09:32<13:11,  1.36it/s]\u001b[A\n","Iteration:  42% 776/1851 [09:33<13:10,  1.36it/s]\u001b[A\n","Iteration:  42% 777/1851 [09:33<13:09,  1.36it/s]\u001b[A\n","Iteration:  42% 778/1851 [09:34<13:11,  1.36it/s]\u001b[A\n","Iteration:  42% 779/1851 [09:35<13:08,  1.36it/s]\u001b[A\n","Iteration:  42% 780/1851 [09:36<13:07,  1.36it/s]\u001b[A\n","Iteration:  42% 781/1851 [09:36<13:06,  1.36it/s]\u001b[A\n","Iteration:  42% 782/1851 [09:37<13:05,  1.36it/s]\u001b[A\n","Iteration:  42% 783/1851 [09:38<13:06,  1.36it/s]\u001b[A\n","Iteration:  42% 784/1851 [09:39<13:04,  1.36it/s]\u001b[A\n","Iteration:  42% 785/1851 [09:39<13:02,  1.36it/s]\u001b[A\n","Iteration:  42% 786/1851 [09:40<13:02,  1.36it/s]\u001b[A\n","Iteration:  43% 787/1851 [09:41<13:02,  1.36it/s]\u001b[A\n","Iteration:  43% 788/1851 [09:42<13:02,  1.36it/s]\u001b[A\n","Iteration:  43% 789/1851 [09:42<13:01,  1.36it/s]\u001b[A\n","Iteration:  43% 790/1851 [09:43<13:00,  1.36it/s]\u001b[A\n","Iteration:  43% 791/1851 [09:44<13:01,  1.36it/s]\u001b[A\n","Iteration:  43% 792/1851 [09:45<12:59,  1.36it/s]\u001b[A\n","Iteration:  43% 793/1851 [09:45<12:59,  1.36it/s]\u001b[A\n","Iteration:  43% 794/1851 [09:46<12:59,  1.36it/s]\u001b[A\n","Iteration:  43% 795/1851 [09:47<12:56,  1.36it/s]\u001b[A\n","Iteration:  43% 796/1851 [09:47<12:55,  1.36it/s]\u001b[A\n","Iteration:  43% 797/1851 [09:48<12:52,  1.36it/s]\u001b[A\n","Iteration:  43% 798/1851 [09:49<12:55,  1.36it/s]\u001b[A\n","Iteration:  43% 799/1851 [09:50<12:54,  1.36it/s]\u001b[A\n","Iteration:  43% 800/1851 [09:50<12:53,  1.36it/s]\u001b[A\n","Iteration:  43% 801/1851 [09:51<12:52,  1.36it/s]\u001b[A\n","Iteration:  43% 802/1851 [09:52<12:52,  1.36it/s]\u001b[A\n","Iteration:  43% 803/1851 [09:53<12:52,  1.36it/s]\u001b[A\n","Iteration:  43% 804/1851 [09:53<12:52,  1.36it/s]\u001b[A\n","Iteration:  43% 805/1851 [09:54<12:51,  1.36it/s]\u001b[A\n","Iteration:  44% 806/1851 [09:55<12:50,  1.36it/s]\u001b[A\n","Iteration:  44% 807/1851 [09:56<12:50,  1.35it/s]\u001b[A\n","Iteration:  44% 808/1851 [09:56<12:50,  1.35it/s]\u001b[A\n","Iteration:  44% 809/1851 [09:57<12:48,  1.36it/s]\u001b[A\n","Iteration:  44% 810/1851 [09:58<12:47,  1.36it/s]\u001b[A\n","Iteration:  44% 811/1851 [09:59<12:47,  1.36it/s]\u001b[A\n","Iteration:  44% 812/1851 [09:59<12:45,  1.36it/s]\u001b[A\n","Iteration:  44% 813/1851 [10:00<12:44,  1.36it/s]\u001b[A\n","Iteration:  44% 814/1851 [10:01<12:44,  1.36it/s]\u001b[A\n","Iteration:  44% 815/1851 [10:01<12:41,  1.36it/s]\u001b[A\n","Iteration:  44% 816/1851 [10:02<12:40,  1.36it/s]\u001b[A\n","Iteration:  44% 817/1851 [10:03<12:41,  1.36it/s]\u001b[A\n","Iteration:  44% 818/1851 [10:04<12:41,  1.36it/s]\u001b[A\n","Iteration:  44% 819/1851 [10:04<12:39,  1.36it/s]\u001b[A\n","Iteration:  44% 820/1851 [10:05<12:36,  1.36it/s]\u001b[A\n","Iteration:  44% 821/1851 [10:06<12:36,  1.36it/s]\u001b[A\n","Iteration:  44% 822/1851 [10:07<12:34,  1.36it/s]\u001b[A\n","Iteration:  44% 823/1851 [10:07<12:36,  1.36it/s]\u001b[A\n","Iteration:  45% 824/1851 [10:08<12:35,  1.36it/s]\u001b[A\n","Iteration:  45% 825/1851 [10:09<12:33,  1.36it/s]\u001b[A\n","Iteration:  45% 826/1851 [10:10<12:34,  1.36it/s]\u001b[A\n","Iteration:  45% 827/1851 [10:10<12:34,  1.36it/s]\u001b[A\n","Iteration:  45% 828/1851 [10:11<12:32,  1.36it/s]\u001b[A\n","Iteration:  45% 829/1851 [10:12<12:31,  1.36it/s]\u001b[A\n","Iteration:  45% 830/1851 [10:12<12:32,  1.36it/s]\u001b[A\n","Iteration:  45% 831/1851 [10:13<12:30,  1.36it/s]\u001b[A\n","Iteration:  45% 832/1851 [10:14<12:28,  1.36it/s]\u001b[A\n","Iteration:  45% 833/1851 [10:15<12:27,  1.36it/s]\u001b[A\n","Iteration:  45% 834/1851 [10:15<12:29,  1.36it/s]\u001b[A\n","Iteration:  45% 835/1851 [10:16<12:28,  1.36it/s]\u001b[A\n","Iteration:  45% 836/1851 [10:17<12:26,  1.36it/s]\u001b[A\n","Iteration:  45% 837/1851 [10:18<12:27,  1.36it/s]\u001b[A\n","Iteration:  45% 838/1851 [10:18<12:26,  1.36it/s]\u001b[A\n","Iteration:  45% 839/1851 [10:19<12:25,  1.36it/s]\u001b[A\n","Iteration:  45% 840/1851 [10:20<12:23,  1.36it/s]\u001b[A\n","Iteration:  45% 841/1851 [10:21<12:23,  1.36it/s]\u001b[A\n","Iteration:  45% 842/1851 [10:21<12:24,  1.36it/s]\u001b[A\n","Iteration:  46% 843/1851 [10:22<12:23,  1.36it/s]\u001b[A\n","Iteration:  46% 844/1851 [10:23<12:20,  1.36it/s]\u001b[A\n","Iteration:  46% 845/1851 [10:24<12:22,  1.36it/s]\u001b[A\n","Iteration:  46% 846/1851 [10:24<12:20,  1.36it/s]\u001b[A\n","Iteration:  46% 847/1851 [10:25<12:20,  1.36it/s]\u001b[A\n","Iteration:  46% 848/1851 [10:26<12:16,  1.36it/s]\u001b[A\n","Iteration:  46% 849/1851 [10:26<12:14,  1.36it/s]\u001b[A\n","Iteration:  46% 850/1851 [10:27<12:15,  1.36it/s]\u001b[A\n","Iteration:  46% 851/1851 [10:28<12:16,  1.36it/s]\u001b[A\n","Iteration:  46% 852/1851 [10:29<12:15,  1.36it/s]\u001b[A\n","Iteration:  46% 853/1851 [10:29<12:14,  1.36it/s]\u001b[A\n","Iteration:  46% 854/1851 [10:30<12:13,  1.36it/s]\u001b[A\n","Iteration:  46% 855/1851 [10:31<12:14,  1.36it/s]\u001b[A\n","Iteration:  46% 856/1851 [10:32<12:14,  1.36it/s]\u001b[A\n","Iteration:  46% 857/1851 [10:32<12:12,  1.36it/s]\u001b[A\n","Iteration:  46% 858/1851 [10:33<12:08,  1.36it/s]\u001b[A\n","Iteration:  46% 859/1851 [10:34<12:07,  1.36it/s]\u001b[A\n","Iteration:  46% 860/1851 [10:35<12:06,  1.36it/s]\u001b[A\n","Iteration:  47% 861/1851 [10:35<12:07,  1.36it/s]\u001b[A\n","Iteration:  47% 862/1851 [10:36<12:07,  1.36it/s]\u001b[A\n","Iteration:  47% 863/1851 [10:37<12:06,  1.36it/s]\u001b[A\n","Iteration:  47% 864/1851 [10:38<12:06,  1.36it/s]\u001b[A\n","Iteration:  47% 865/1851 [10:38<12:04,  1.36it/s]\u001b[A\n","Iteration:  47% 866/1851 [10:39<12:05,  1.36it/s]\u001b[A\n","Iteration:  47% 867/1851 [10:40<12:04,  1.36it/s]\u001b[A\n","Iteration:  47% 868/1851 [10:40<12:04,  1.36it/s]\u001b[A\n","Iteration:  47% 869/1851 [10:41<12:04,  1.35it/s]\u001b[A\n","Iteration:  47% 870/1851 [10:42<12:03,  1.36it/s]\u001b[A\n","Iteration:  47% 871/1851 [10:43<12:01,  1.36it/s]\u001b[A\n","Iteration:  47% 872/1851 [10:43<11:59,  1.36it/s]\u001b[A\n","Iteration:  47% 873/1851 [10:44<11:58,  1.36it/s]\u001b[A\n","Iteration:  47% 874/1851 [10:45<11:59,  1.36it/s]\u001b[A\n","Iteration:  47% 875/1851 [10:46<11:58,  1.36it/s]\u001b[A\n","Iteration:  47% 876/1851 [10:46<11:57,  1.36it/s]\u001b[A\n","Iteration:  47% 877/1851 [10:47<11:54,  1.36it/s]\u001b[A\n","Iteration:  47% 878/1851 [10:48<11:55,  1.36it/s]\u001b[A\n","Iteration:  47% 879/1851 [10:49<11:56,  1.36it/s]\u001b[A\n","Iteration:  48% 880/1851 [10:49<11:53,  1.36it/s]\u001b[A\n","Iteration:  48% 881/1851 [10:50<11:52,  1.36it/s]\u001b[A\n","Iteration:  48% 882/1851 [10:51<11:54,  1.36it/s]\u001b[A\n","Iteration:  48% 883/1851 [10:51<11:53,  1.36it/s]\u001b[A\n","Iteration:  48% 884/1851 [10:52<11:51,  1.36it/s]\u001b[A\n","Iteration:  48% 885/1851 [10:53<11:50,  1.36it/s]\u001b[A\n","Iteration:  48% 886/1851 [10:54<11:47,  1.36it/s]\u001b[A\n","Iteration:  48% 887/1851 [10:54<11:46,  1.36it/s]\u001b[A\n","Iteration:  48% 888/1851 [10:55<11:48,  1.36it/s]\u001b[A\n","Iteration:  48% 889/1851 [10:56<11:47,  1.36it/s]\u001b[A\n","Iteration:  48% 890/1851 [10:57<11:46,  1.36it/s]\u001b[A\n","Iteration:  48% 891/1851 [10:57<11:45,  1.36it/s]\u001b[A\n","Iteration:  48% 892/1851 [10:58<11:46,  1.36it/s]\u001b[A\n","Iteration:  48% 893/1851 [10:59<11:44,  1.36it/s]\u001b[A\n","Iteration:  48% 894/1851 [11:00<11:42,  1.36it/s]\u001b[A\n","Iteration:  48% 895/1851 [11:00<11:41,  1.36it/s]\u001b[A\n","Iteration:  48% 896/1851 [11:01<11:39,  1.37it/s]\u001b[A\n","Iteration:  48% 897/1851 [11:02<11:38,  1.37it/s]\u001b[A\n","Iteration:  49% 898/1851 [11:03<11:39,  1.36it/s]\u001b[A\n","Iteration:  49% 899/1851 [11:03<11:39,  1.36it/s]\u001b[A\n","Iteration:  49% 900/1851 [11:04<11:41,  1.36it/s]\u001b[A\n","Iteration:  49% 901/1851 [11:05<11:40,  1.36it/s]\u001b[A\n","Iteration:  49% 902/1851 [11:05<11:39,  1.36it/s]\u001b[A\n","Iteration:  49% 903/1851 [11:06<11:36,  1.36it/s]\u001b[A\n","Iteration:  49% 904/1851 [11:07<11:36,  1.36it/s]\u001b[A\n","Iteration:  49% 905/1851 [11:08<11:36,  1.36it/s]\u001b[A\n","Iteration:  49% 906/1851 [11:08<11:36,  1.36it/s]\u001b[A\n","Iteration:  49% 907/1851 [11:09<11:37,  1.35it/s]\u001b[A\n","Iteration:  49% 908/1851 [11:10<11:36,  1.35it/s]\u001b[A\n","Iteration:  49% 909/1851 [11:11<11:33,  1.36it/s]\u001b[A\n","Iteration:  49% 910/1851 [11:11<11:33,  1.36it/s]\u001b[A\n","Iteration:  49% 911/1851 [11:12<11:34,  1.35it/s]\u001b[A\n","Iteration:  49% 912/1851 [11:13<11:34,  1.35it/s]\u001b[A\n","Iteration:  49% 913/1851 [11:14<11:33,  1.35it/s]\u001b[A\n","Iteration:  49% 914/1851 [11:14<11:29,  1.36it/s]\u001b[A\n","Iteration:  49% 915/1851 [11:15<11:29,  1.36it/s]\u001b[A\n","Iteration:  49% 916/1851 [11:16<11:30,  1.35it/s]\u001b[A\n","Iteration:  50% 917/1851 [11:17<11:28,  1.36it/s]\u001b[A\n","Iteration:  50% 918/1851 [11:17<11:27,  1.36it/s]\u001b[A\n","Iteration:  50% 919/1851 [11:18<11:27,  1.36it/s]\u001b[A\n","Iteration:  50% 920/1851 [11:19<11:27,  1.36it/s]\u001b[A\n","Iteration:  50% 921/1851 [11:19<11:26,  1.35it/s]\u001b[A\n","Iteration:  50% 922/1851 [11:20<11:26,  1.35it/s]\u001b[A\n","Iteration:  50% 923/1851 [11:21<11:24,  1.36it/s]\u001b[A\n","Iteration:  50% 924/1851 [11:22<11:23,  1.36it/s]\u001b[A\n","Iteration:  50% 925/1851 [11:22<11:23,  1.35it/s]\u001b[A\n","Iteration:  50% 926/1851 [11:23<11:21,  1.36it/s]\u001b[A\n","Iteration:  50% 927/1851 [11:24<11:21,  1.36it/s]\u001b[A\n","Iteration:  50% 928/1851 [11:25<11:21,  1.35it/s]\u001b[A\n","Iteration:  50% 929/1851 [11:25<11:20,  1.35it/s]\u001b[A\n","Iteration:  50% 930/1851 [11:26<11:21,  1.35it/s]\u001b[A\n","Iteration:  50% 931/1851 [11:27<11:18,  1.36it/s]\u001b[A\n","Iteration:  50% 932/1851 [11:28<11:16,  1.36it/s]\u001b[A\n","Iteration:  50% 933/1851 [11:28<11:15,  1.36it/s]\u001b[A\n","Iteration:  50% 934/1851 [11:29<11:14,  1.36it/s]\u001b[A\n","Iteration:  51% 935/1851 [11:30<11:15,  1.36it/s]\u001b[A\n","Iteration:  51% 936/1851 [11:31<11:14,  1.36it/s]\u001b[A\n","Iteration:  51% 937/1851 [11:31<11:12,  1.36it/s]\u001b[A\n","Iteration:  51% 938/1851 [11:32<11:11,  1.36it/s]\u001b[A\n","Iteration:  51% 939/1851 [11:33<11:10,  1.36it/s]\u001b[A\n","Iteration:  51% 940/1851 [11:33<11:10,  1.36it/s]\u001b[A\n","Iteration:  51% 941/1851 [11:34<11:10,  1.36it/s]\u001b[A\n","Iteration:  51% 942/1851 [11:35<11:10,  1.36it/s]\u001b[A\n","Iteration:  51% 943/1851 [11:36<11:08,  1.36it/s]\u001b[A\n","Iteration:  51% 944/1851 [11:36<11:05,  1.36it/s]\u001b[A\n","Iteration:  51% 945/1851 [11:37<11:04,  1.36it/s]\u001b[A\n","Iteration:  51% 946/1851 [11:38<11:05,  1.36it/s]\u001b[A\n","Iteration:  51% 947/1851 [11:39<11:05,  1.36it/s]\u001b[A\n","Iteration:  51% 948/1851 [11:39<11:05,  1.36it/s]\u001b[A\n","Iteration:  51% 949/1851 [11:40<11:06,  1.35it/s]\u001b[A\n","Iteration:  51% 950/1851 [11:41<11:05,  1.35it/s]\u001b[A\n","Iteration:  51% 951/1851 [11:42<11:03,  1.36it/s]\u001b[A\n","Iteration:  51% 952/1851 [11:42<11:02,  1.36it/s]\u001b[A\n","Iteration:  51% 953/1851 [11:43<10:59,  1.36it/s]\u001b[A\n","Iteration:  52% 954/1851 [11:44<11:02,  1.35it/s]\u001b[A\n","Iteration:  52% 955/1851 [11:45<11:01,  1.35it/s]\u001b[A\n","Iteration:  52% 956/1851 [11:45<11:00,  1.35it/s]\u001b[A\n","Iteration:  52% 957/1851 [11:46<11:01,  1.35it/s]\u001b[A\n","Iteration:  52% 958/1851 [11:47<10:58,  1.36it/s]\u001b[A\n","Iteration:  52% 959/1851 [11:47<10:59,  1.35it/s]\u001b[A\n","Iteration:  52% 960/1851 [11:48<10:57,  1.36it/s]\u001b[A\n","Iteration:  52% 961/1851 [11:49<10:58,  1.35it/s]\u001b[A\n","Iteration:  52% 962/1851 [11:50<10:58,  1.35it/s]\u001b[A\n","Iteration:  52% 963/1851 [11:50<10:58,  1.35it/s]\u001b[A\n","Iteration:  52% 964/1851 [11:51<10:56,  1.35it/s]\u001b[A\n","Iteration:  52% 965/1851 [11:52<10:56,  1.35it/s]\u001b[A\n","Iteration:  52% 966/1851 [11:53<10:54,  1.35it/s]\u001b[A\n","Iteration:  52% 967/1851 [11:53<10:53,  1.35it/s]\u001b[A\n","Iteration:  52% 968/1851 [11:54<10:52,  1.35it/s]\u001b[A\n","Iteration:  52% 969/1851 [11:55<10:51,  1.35it/s]\u001b[A\n","Iteration:  52% 970/1851 [11:56<10:50,  1.35it/s]\u001b[A\n","Iteration:  52% 971/1851 [11:56<10:49,  1.35it/s]\u001b[A\n","Iteration:  53% 972/1851 [11:57<10:48,  1.36it/s]\u001b[A\n","Iteration:  53% 973/1851 [11:58<10:47,  1.36it/s]\u001b[A\n","Iteration:  53% 974/1851 [11:59<10:46,  1.36it/s]\u001b[A\n","Iteration:  53% 975/1851 [11:59<10:44,  1.36it/s]\u001b[A\n","Iteration:  53% 976/1851 [12:00<10:43,  1.36it/s]\u001b[A\n","Iteration:  53% 977/1851 [12:01<10:44,  1.36it/s]\u001b[A\n","Iteration:  53% 978/1851 [12:02<10:42,  1.36it/s]\u001b[A\n","Iteration:  53% 979/1851 [12:02<10:43,  1.36it/s]\u001b[A\n","Iteration:  53% 980/1851 [12:03<10:43,  1.35it/s]\u001b[A\n","Iteration:  53% 981/1851 [12:04<10:42,  1.35it/s]\u001b[A\n","Iteration:  53% 982/1851 [12:04<10:42,  1.35it/s]\u001b[A\n","Iteration:  53% 983/1851 [12:05<10:40,  1.35it/s]\u001b[A\n","Iteration:  53% 984/1851 [12:06<10:39,  1.36it/s]\u001b[A\n","Iteration:  53% 985/1851 [12:07<10:38,  1.36it/s]\u001b[A\n","Iteration:  53% 986/1851 [12:07<10:38,  1.36it/s]\u001b[A\n","Iteration:  53% 987/1851 [12:08<10:36,  1.36it/s]\u001b[A\n","Iteration:  53% 988/1851 [12:09<10:37,  1.35it/s]\u001b[A\n","Iteration:  53% 989/1851 [12:10<10:36,  1.35it/s]\u001b[A\n","Iteration:  53% 990/1851 [12:10<10:37,  1.35it/s]\u001b[A\n","Iteration:  54% 991/1851 [12:11<10:34,  1.36it/s]\u001b[A\n","Iteration:  54% 992/1851 [12:12<10:33,  1.36it/s]\u001b[A\n","Iteration:  54% 993/1851 [12:13<10:32,  1.36it/s]\u001b[A\n","Iteration:  54% 994/1851 [12:13<10:32,  1.35it/s]\u001b[A\n","Iteration:  54% 995/1851 [12:14<10:33,  1.35it/s]\u001b[A\n","Iteration:  54% 996/1851 [12:15<10:32,  1.35it/s]\u001b[A\n","Iteration:  54% 997/1851 [12:16<10:31,  1.35it/s]\u001b[A\n","Iteration:  54% 998/1851 [12:16<10:30,  1.35it/s]\u001b[A\n","Iteration:  54% 999/1851 [12:17<10:28,  1.36it/s]\u001b[A\n","Iteration:  54% 1000/1851 [12:18<10:27,  1.36it/s]\u001b[A\n","Iteration:  54% 1001/1851 [12:18<10:25,  1.36it/s]\u001b[A\n","Iteration:  54% 1002/1851 [12:19<10:25,  1.36it/s]\u001b[A\n","Iteration:  54% 1003/1851 [12:20<10:24,  1.36it/s]\u001b[A\n","Iteration:  54% 1004/1851 [12:21<10:25,  1.35it/s]\u001b[A\n","Iteration:  54% 1005/1851 [12:21<10:24,  1.35it/s]\u001b[A\n","Iteration:  54% 1006/1851 [12:22<10:25,  1.35it/s]\u001b[A\n","Iteration:  54% 1007/1851 [12:23<10:23,  1.35it/s]\u001b[A\n","Iteration:  54% 1008/1851 [12:24<10:23,  1.35it/s]\u001b[A\n","Iteration:  55% 1009/1851 [12:24<10:22,  1.35it/s]\u001b[A\n","Iteration:  55% 1010/1851 [12:25<10:20,  1.36it/s]\u001b[A\n","Iteration:  55% 1011/1851 [12:26<10:19,  1.36it/s]\u001b[A\n","Iteration:  55% 1012/1851 [12:27<10:19,  1.35it/s]\u001b[A\n","Iteration:  55% 1013/1851 [12:27<10:18,  1.35it/s]\u001b[A\n","Iteration:  55% 1014/1851 [12:28<10:17,  1.36it/s]\u001b[A\n","Iteration:  55% 1015/1851 [12:29<10:17,  1.35it/s]\u001b[A\n","Iteration:  55% 1016/1851 [12:30<10:15,  1.36it/s]\u001b[A\n","Iteration:  55% 1017/1851 [12:30<10:15,  1.36it/s]\u001b[A\n","Iteration:  55% 1018/1851 [12:31<10:14,  1.35it/s]\u001b[A\n","Iteration:  55% 1019/1851 [12:32<10:14,  1.35it/s]\u001b[A\n","Iteration:  55% 1020/1851 [12:33<10:12,  1.36it/s]\u001b[A\n","Iteration:  55% 1021/1851 [12:33<10:12,  1.36it/s]\u001b[A\n","Iteration:  55% 1022/1851 [12:34<10:11,  1.36it/s]\u001b[A\n","Iteration:  55% 1023/1851 [12:35<10:10,  1.36it/s]\u001b[A\n","Iteration:  55% 1024/1851 [12:35<10:10,  1.36it/s]\u001b[A\n","Iteration:  55% 1025/1851 [12:36<10:08,  1.36it/s]\u001b[A\n","Iteration:  55% 1026/1851 [12:37<10:07,  1.36it/s]\u001b[A\n","Iteration:  55% 1027/1851 [12:38<10:08,  1.35it/s]\u001b[A\n","Iteration:  56% 1028/1851 [12:38<10:07,  1.36it/s]\u001b[A\n","Iteration:  56% 1029/1851 [12:39<10:05,  1.36it/s]\u001b[A\n","Iteration:  56% 1030/1851 [12:40<10:06,  1.35it/s]\u001b[A\n","Iteration:  56% 1031/1851 [12:41<10:05,  1.35it/s]\u001b[A\n","Iteration:  56% 1032/1851 [12:41<10:03,  1.36it/s]\u001b[A\n","Iteration:  56% 1033/1851 [12:42<10:01,  1.36it/s]\u001b[A\n","Iteration:  56% 1034/1851 [12:43<10:03,  1.35it/s]\u001b[A\n","Iteration:  56% 1035/1851 [12:44<10:02,  1.35it/s]\u001b[A\n","Iteration:  56% 1036/1851 [12:44<10:01,  1.35it/s]\u001b[A\n","Iteration:  56% 1037/1851 [12:45<10:00,  1.36it/s]\u001b[A\n","Iteration:  56% 1038/1851 [12:46<09:59,  1.36it/s]\u001b[A\n","Iteration:  56% 1039/1851 [12:47<09:58,  1.36it/s]\u001b[A\n","Iteration:  56% 1040/1851 [12:47<09:57,  1.36it/s]\u001b[A\n","Iteration:  56% 1041/1851 [12:48<09:56,  1.36it/s]\u001b[A\n","Iteration:  56% 1042/1851 [12:49<09:55,  1.36it/s]\u001b[A\n","Iteration:  56% 1043/1851 [12:49<09:55,  1.36it/s]\u001b[A\n","Iteration:  56% 1044/1851 [12:50<09:54,  1.36it/s]\u001b[A\n","Iteration:  56% 1045/1851 [12:51<09:53,  1.36it/s]\u001b[A\n","Iteration:  57% 1046/1851 [12:52<09:52,  1.36it/s]\u001b[A\n","Iteration:  57% 1047/1851 [12:52<09:52,  1.36it/s]\u001b[A\n","Iteration:  57% 1048/1851 [12:53<09:51,  1.36it/s]\u001b[A\n","Iteration:  57% 1049/1851 [12:54<09:51,  1.36it/s]\u001b[A\n","Iteration:  57% 1050/1851 [12:55<09:50,  1.36it/s]\u001b[A\n","Iteration:  57% 1051/1851 [12:55<09:50,  1.36it/s]\u001b[A\n","Iteration:  57% 1052/1851 [12:56<09:48,  1.36it/s]\u001b[A\n","Iteration:  57% 1053/1851 [12:57<09:48,  1.36it/s]\u001b[A\n","Iteration:  57% 1054/1851 [12:58<09:48,  1.36it/s]\u001b[A\n","Iteration:  57% 1055/1851 [12:58<09:46,  1.36it/s]\u001b[A\n","Iteration:  57% 1056/1851 [12:59<09:45,  1.36it/s]\u001b[A\n","Iteration:  57% 1057/1851 [13:00<09:45,  1.36it/s]\u001b[A\n","Iteration:  57% 1058/1851 [13:01<09:44,  1.36it/s]\u001b[A\n","Iteration:  57% 1059/1851 [13:01<09:42,  1.36it/s]\u001b[A\n","Iteration:  57% 1060/1851 [13:02<09:42,  1.36it/s]\u001b[A\n","Iteration:  57% 1061/1851 [13:03<09:38,  1.37it/s]\u001b[A\n","Iteration:  57% 1062/1851 [13:03<09:39,  1.36it/s]\u001b[A\n","Iteration:  57% 1063/1851 [13:04<09:39,  1.36it/s]\u001b[A\n","Iteration:  57% 1064/1851 [13:05<09:39,  1.36it/s]\u001b[A\n","Iteration:  58% 1065/1851 [13:06<09:40,  1.35it/s]\u001b[A\n","Iteration:  58% 1066/1851 [13:06<09:38,  1.36it/s]\u001b[A\n","Iteration:  58% 1067/1851 [13:07<09:38,  1.36it/s]\u001b[A\n","Iteration:  58% 1068/1851 [13:08<09:36,  1.36it/s]\u001b[A\n","Iteration:  58% 1069/1851 [13:09<09:36,  1.36it/s]\u001b[A\n","Iteration:  58% 1070/1851 [13:09<09:35,  1.36it/s]\u001b[A\n","Iteration:  58% 1071/1851 [13:10<09:35,  1.35it/s]\u001b[A\n","Iteration:  58% 1072/1851 [13:11<09:35,  1.35it/s]\u001b[A\n","Iteration:  58% 1073/1851 [13:12<09:32,  1.36it/s]\u001b[A\n","Iteration:  58% 1074/1851 [13:12<09:33,  1.36it/s]\u001b[A\n","Iteration:  58% 1075/1851 [13:13<09:31,  1.36it/s]\u001b[A\n","Iteration:  58% 1076/1851 [13:14<09:30,  1.36it/s]\u001b[A\n","Iteration:  58% 1077/1851 [13:15<09:30,  1.36it/s]\u001b[A\n","Iteration:  58% 1078/1851 [13:15<09:30,  1.36it/s]\u001b[A\n","Iteration:  58% 1079/1851 [13:16<09:28,  1.36it/s]\u001b[A\n","Iteration:  58% 1080/1851 [13:17<09:26,  1.36it/s]\u001b[A\n","Iteration:  58% 1081/1851 [13:17<09:25,  1.36it/s]\u001b[A\n","Iteration:  58% 1082/1851 [13:18<09:23,  1.36it/s]\u001b[A\n","Iteration:  59% 1083/1851 [13:19<09:23,  1.36it/s]\u001b[A\n","Iteration:  59% 1084/1851 [13:20<09:24,  1.36it/s]\u001b[A\n","Iteration:  59% 1085/1851 [13:20<09:23,  1.36it/s]\u001b[A\n","Iteration:  59% 1086/1851 [13:21<09:24,  1.36it/s]\u001b[A\n","Iteration:  59% 1087/1851 [13:22<09:22,  1.36it/s]\u001b[A\n","Iteration:  59% 1088/1851 [13:23<09:21,  1.36it/s]\u001b[A\n","Iteration:  59% 1089/1851 [13:23<09:20,  1.36it/s]\u001b[A\n","Iteration:  59% 1090/1851 [13:24<09:20,  1.36it/s]\u001b[A\n","Iteration:  59% 1091/1851 [13:25<09:19,  1.36it/s]\u001b[A\n","Iteration:  59% 1092/1851 [13:26<09:20,  1.35it/s]\u001b[A\n","Iteration:  59% 1093/1851 [13:26<09:19,  1.35it/s]\u001b[A\n","Iteration:  59% 1094/1851 [13:27<09:17,  1.36it/s]\u001b[A\n","Iteration:  59% 1095/1851 [13:28<09:18,  1.35it/s]\u001b[A\n","Iteration:  59% 1096/1851 [13:29<09:17,  1.35it/s]\u001b[A\n","Iteration:  59% 1097/1851 [13:29<09:16,  1.36it/s]\u001b[A\n","Iteration:  59% 1098/1851 [13:30<09:14,  1.36it/s]\u001b[A\n","Iteration:  59% 1099/1851 [13:31<09:14,  1.36it/s]\u001b[A\n","Iteration:  59% 1100/1851 [13:31<09:13,  1.36it/s]\u001b[A\n","Iteration:  59% 1101/1851 [13:32<09:13,  1.35it/s]\u001b[A\n","Iteration:  60% 1102/1851 [13:33<09:11,  1.36it/s]\u001b[A\n","Iteration:  60% 1103/1851 [13:34<09:11,  1.36it/s]\u001b[A\n","Iteration:  60% 1104/1851 [13:34<09:12,  1.35it/s]\u001b[A\n","Iteration:  60% 1105/1851 [13:35<09:10,  1.36it/s]\u001b[A\n","Iteration:  60% 1106/1851 [13:36<09:08,  1.36it/s]\u001b[A\n","Iteration:  60% 1107/1851 [13:37<09:07,  1.36it/s]\u001b[A\n","Iteration:  60% 1108/1851 [13:37<09:07,  1.36it/s]\u001b[A\n","Iteration:  60% 1109/1851 [13:38<09:07,  1.36it/s]\u001b[A\n","Iteration:  60% 1110/1851 [13:39<09:08,  1.35it/s]\u001b[A\n","Iteration:  60% 1111/1851 [13:40<09:06,  1.35it/s]\u001b[A\n","Iteration:  60% 1112/1851 [13:40<09:06,  1.35it/s]\u001b[A\n","Iteration:  60% 1113/1851 [13:41<09:05,  1.35it/s]\u001b[A\n","Iteration:  60% 1114/1851 [13:42<09:03,  1.36it/s]\u001b[A\n","Iteration:  60% 1115/1851 [13:43<09:02,  1.36it/s]\u001b[A\n","Iteration:  60% 1116/1851 [13:43<09:01,  1.36it/s]\u001b[A\n","Iteration:  60% 1117/1851 [13:44<09:01,  1.36it/s]\u001b[A\n","Iteration:  60% 1118/1851 [13:45<09:00,  1.36it/s]\u001b[A\n","Iteration:  60% 1119/1851 [13:45<09:00,  1.35it/s]\u001b[A\n","Iteration:  61% 1120/1851 [13:46<09:00,  1.35it/s]\u001b[A\n","Iteration:  61% 1121/1851 [13:47<08:57,  1.36it/s]\u001b[A\n","Iteration:  61% 1122/1851 [13:48<08:57,  1.36it/s]\u001b[A\n","Iteration:  61% 1123/1851 [13:48<08:54,  1.36it/s]\u001b[A\n","Iteration:  61% 1124/1851 [13:49<08:53,  1.36it/s]\u001b[A\n","Iteration:  61% 1125/1851 [13:50<08:53,  1.36it/s]\u001b[A\n","Iteration:  61% 1126/1851 [13:51<08:51,  1.36it/s]\u001b[A\n","Iteration:  61% 1127/1851 [13:51<08:51,  1.36it/s]\u001b[A\n","Iteration:  61% 1128/1851 [13:52<08:49,  1.37it/s]\u001b[A\n","Iteration:  61% 1129/1851 [13:53<08:48,  1.37it/s]\u001b[A\n","Iteration:  61% 1130/1851 [13:54<08:47,  1.37it/s]\u001b[A\n","Iteration:  61% 1131/1851 [13:54<08:47,  1.37it/s]\u001b[A\n","Iteration:  61% 1132/1851 [13:55<08:46,  1.37it/s]\u001b[A\n","Iteration:  61% 1133/1851 [13:56<08:45,  1.37it/s]\u001b[A\n","Iteration:  61% 1134/1851 [13:56<08:44,  1.37it/s]\u001b[A\n","Iteration:  61% 1135/1851 [13:57<08:46,  1.36it/s]\u001b[A\n","Iteration:  61% 1136/1851 [13:58<08:46,  1.36it/s]\u001b[A\n","Iteration:  61% 1137/1851 [13:59<08:46,  1.36it/s]\u001b[A\n","Iteration:  61% 1138/1851 [13:59<08:44,  1.36it/s]\u001b[A\n","Iteration:  62% 1139/1851 [14:00<08:42,  1.36it/s]\u001b[A\n","Iteration:  62% 1140/1851 [14:01<08:41,  1.36it/s]\u001b[A\n","Iteration:  62% 1141/1851 [14:02<08:42,  1.36it/s]\u001b[A\n","Iteration:  62% 1142/1851 [14:02<08:41,  1.36it/s]\u001b[A\n","Iteration:  62% 1143/1851 [14:03<08:42,  1.35it/s]\u001b[A\n","Iteration:  62% 1144/1851 [14:04<08:41,  1.35it/s]\u001b[A\n","Iteration:  62% 1145/1851 [14:05<08:38,  1.36it/s]\u001b[A\n","Iteration:  62% 1146/1851 [14:05<08:38,  1.36it/s]\u001b[A\n","Iteration:  62% 1147/1851 [14:06<08:39,  1.36it/s]\u001b[A\n","Iteration:  62% 1148/1851 [14:07<08:38,  1.35it/s]\u001b[A\n","Iteration:  62% 1149/1851 [14:08<08:39,  1.35it/s]\u001b[A\n","Iteration:  62% 1150/1851 [14:08<08:38,  1.35it/s]\u001b[A\n","Iteration:  62% 1151/1851 [14:09<08:37,  1.35it/s]\u001b[A\n","Iteration:  62% 1152/1851 [14:10<08:35,  1.35it/s]\u001b[A\n","Iteration:  62% 1153/1851 [14:10<08:35,  1.35it/s]\u001b[A\n","Iteration:  62% 1154/1851 [14:11<08:34,  1.36it/s]\u001b[A\n","Iteration:  62% 1155/1851 [14:12<08:33,  1.36it/s]\u001b[A\n","Iteration:  62% 1156/1851 [14:13<08:32,  1.36it/s]\u001b[A\n","Iteration:  63% 1157/1851 [14:13<08:31,  1.36it/s]\u001b[A\n","Iteration:  63% 1158/1851 [14:14<08:30,  1.36it/s]\u001b[A\n","Iteration:  63% 1159/1851 [14:15<08:28,  1.36it/s]\u001b[A\n","Iteration:  63% 1160/1851 [14:16<08:27,  1.36it/s]\u001b[A\n","Iteration:  63% 1161/1851 [14:16<08:28,  1.36it/s]\u001b[A\n","Iteration:  63% 1162/1851 [14:17<08:28,  1.36it/s]\u001b[A\n","Iteration:  63% 1163/1851 [14:18<08:28,  1.35it/s]\u001b[A\n","Iteration:  63% 1164/1851 [14:19<08:26,  1.36it/s]\u001b[A\n","Iteration:  63% 1165/1851 [14:19<08:26,  1.36it/s]\u001b[A\n","Iteration:  63% 1166/1851 [14:20<08:25,  1.35it/s]\u001b[A\n","Iteration:  63% 1167/1851 [14:21<08:24,  1.36it/s]\u001b[A\n","Iteration:  63% 1168/1851 [14:22<08:24,  1.35it/s]\u001b[A\n","Iteration:  63% 1169/1851 [14:22<08:23,  1.35it/s]\u001b[A\n","Iteration:  63% 1170/1851 [14:23<08:24,  1.35it/s]\u001b[A\n","Iteration:  63% 1171/1851 [14:24<08:23,  1.35it/s]\u001b[A\n","Iteration:  63% 1172/1851 [14:25<08:21,  1.35it/s]\u001b[A\n","Iteration:  63% 1173/1851 [14:25<08:18,  1.36it/s]\u001b[A\n","Iteration:  63% 1174/1851 [14:26<08:17,  1.36it/s]\u001b[A\n","Iteration:  63% 1175/1851 [14:27<08:18,  1.36it/s]\u001b[A\n","Iteration:  64% 1176/1851 [14:27<08:17,  1.36it/s]\u001b[A\n","Iteration:  64% 1177/1851 [14:28<08:17,  1.36it/s]\u001b[A\n","Iteration:  64% 1178/1851 [14:29<08:16,  1.36it/s]\u001b[A\n","Iteration:  64% 1179/1851 [14:30<08:14,  1.36it/s]\u001b[A\n","Iteration:  64% 1180/1851 [14:30<08:16,  1.35it/s]\u001b[A\n","Iteration:  64% 1181/1851 [14:31<08:14,  1.35it/s]\u001b[A\n","Iteration:  64% 1182/1851 [14:32<08:14,  1.35it/s]\u001b[A\n","Iteration:  64% 1183/1851 [14:33<08:13,  1.35it/s]\u001b[A\n","Iteration:  64% 1184/1851 [14:33<08:13,  1.35it/s]\u001b[A\n","Iteration:  64% 1185/1851 [14:34<08:11,  1.35it/s]\u001b[A\n","Iteration:  64% 1186/1851 [14:35<08:11,  1.35it/s]\u001b[A\n","Iteration:  64% 1187/1851 [14:36<08:10,  1.35it/s]\u001b[A\n","Iteration:  64% 1188/1851 [14:36<08:09,  1.35it/s]\u001b[A\n","Iteration:  64% 1189/1851 [14:37<08:10,  1.35it/s]\u001b[A\n","Iteration:  64% 1190/1851 [14:38<08:09,  1.35it/s]\u001b[A\n","Iteration:  64% 1191/1851 [14:39<08:06,  1.36it/s]\u001b[A\n","Iteration:  64% 1192/1851 [14:39<08:04,  1.36it/s]\u001b[A\n","Iteration:  64% 1193/1851 [14:40<08:03,  1.36it/s]\u001b[A\n","Iteration:  65% 1194/1851 [14:41<08:03,  1.36it/s]\u001b[A\n","Iteration:  65% 1195/1851 [14:41<08:04,  1.35it/s]\u001b[A\n","Iteration:  65% 1196/1851 [14:42<08:02,  1.36it/s]\u001b[A\n","Iteration:  65% 1197/1851 [14:43<08:02,  1.35it/s]\u001b[A\n","Iteration:  65% 1198/1851 [14:44<08:01,  1.36it/s]\u001b[A\n","Iteration:  65% 1199/1851 [14:44<08:01,  1.35it/s]\u001b[A\n","Iteration:  65% 1200/1851 [14:45<08:00,  1.35it/s]\u001b[A\n","Iteration:  65% 1201/1851 [14:46<07:59,  1.36it/s]\u001b[A\n","Iteration:  65% 1202/1851 [14:47<07:56,  1.36it/s]\u001b[A\n","Iteration:  65% 1203/1851 [14:47<07:55,  1.36it/s]\u001b[A\n","Iteration:  65% 1204/1851 [14:48<07:55,  1.36it/s]\u001b[A\n","Iteration:  65% 1205/1851 [14:49<07:55,  1.36it/s]\u001b[A\n","Iteration:  65% 1206/1851 [14:50<07:54,  1.36it/s]\u001b[A\n","Iteration:  65% 1207/1851 [14:50<07:54,  1.36it/s]\u001b[A\n","Iteration:  65% 1208/1851 [14:51<07:54,  1.36it/s]\u001b[A\n","Iteration:  65% 1209/1851 [14:52<07:53,  1.36it/s]\u001b[A\n","Iteration:  65% 1210/1851 [14:53<07:52,  1.36it/s]\u001b[A\n","Iteration:  65% 1211/1851 [14:53<07:52,  1.36it/s]\u001b[A\n","Iteration:  65% 1212/1851 [14:54<07:51,  1.36it/s]\u001b[A\n","Iteration:  66% 1213/1851 [14:55<07:49,  1.36it/s]\u001b[A\n","Iteration:  66% 1214/1851 [14:55<07:49,  1.36it/s]\u001b[A\n","Iteration:  66% 1215/1851 [14:56<07:48,  1.36it/s]\u001b[A\n","Iteration:  66% 1216/1851 [14:57<07:48,  1.36it/s]\u001b[A\n","Iteration:  66% 1217/1851 [14:58<07:46,  1.36it/s]\u001b[A\n","Iteration:  66% 1218/1851 [14:58<07:46,  1.36it/s]\u001b[A\n","Iteration:  66% 1219/1851 [14:59<07:46,  1.36it/s]\u001b[A\n","Iteration:  66% 1220/1851 [15:00<07:45,  1.36it/s]\u001b[A\n","Iteration:  66% 1221/1851 [15:01<07:43,  1.36it/s]\u001b[A\n","Iteration:  66% 1222/1851 [15:01<07:43,  1.36it/s]\u001b[A\n","Iteration:  66% 1223/1851 [15:02<07:43,  1.35it/s]\u001b[A\n","Iteration:  66% 1224/1851 [15:03<07:43,  1.35it/s]\u001b[A\n","Iteration:  66% 1225/1851 [15:04<07:43,  1.35it/s]\u001b[A\n","Iteration:  66% 1226/1851 [15:04<07:41,  1.35it/s]\u001b[A\n","Iteration:  66% 1227/1851 [15:05<07:40,  1.36it/s]\u001b[A\n","Iteration:  66% 1228/1851 [15:06<07:38,  1.36it/s]\u001b[A\n","Iteration:  66% 1229/1851 [15:07<07:37,  1.36it/s]\u001b[A\n","Iteration:  66% 1230/1851 [15:07<07:36,  1.36it/s]\u001b[A\n","Iteration:  67% 1231/1851 [15:08<07:36,  1.36it/s]\u001b[A\n","Iteration:  67% 1232/1851 [15:09<07:35,  1.36it/s]\u001b[A\n","Iteration:  67% 1233/1851 [15:09<07:35,  1.36it/s]\u001b[A\n","Iteration:  67% 1234/1851 [15:10<07:35,  1.35it/s]\u001b[A\n","Iteration:  67% 1235/1851 [15:11<07:33,  1.36it/s]\u001b[A\n","Iteration:  67% 1236/1851 [15:12<07:32,  1.36it/s]\u001b[A\n","Iteration:  67% 1237/1851 [15:12<07:33,  1.35it/s]\u001b[A\n","Iteration:  67% 1238/1851 [15:13<07:31,  1.36it/s]\u001b[A\n","Iteration:  67% 1239/1851 [15:14<07:30,  1.36it/s]\u001b[A\n","Iteration:  67% 1240/1851 [15:15<07:29,  1.36it/s]\u001b[A\n","Iteration:  67% 1241/1851 [15:15<07:29,  1.36it/s]\u001b[A\n","Iteration:  67% 1242/1851 [15:16<07:28,  1.36it/s]\u001b[A\n","Iteration:  67% 1243/1851 [15:17<07:29,  1.35it/s]\u001b[A\n","Iteration:  67% 1244/1851 [15:18<07:27,  1.36it/s]\u001b[A\n","Iteration:  67% 1245/1851 [15:18<07:26,  1.36it/s]\u001b[A\n","Iteration:  67% 1246/1851 [15:19<07:25,  1.36it/s]\u001b[A\n","Iteration:  67% 1247/1851 [15:20<07:25,  1.36it/s]\u001b[A\n","Iteration:  67% 1248/1851 [15:21<07:23,  1.36it/s]\u001b[A\n","Iteration:  67% 1249/1851 [15:21<07:22,  1.36it/s]\u001b[A\n","Iteration:  68% 1250/1851 [15:22<07:21,  1.36it/s]\u001b[A\n","Iteration:  68% 1251/1851 [15:23<07:21,  1.36it/s]\u001b[A\n","Iteration:  68% 1252/1851 [15:23<07:20,  1.36it/s]\u001b[A\n","Iteration:  68% 1253/1851 [15:24<07:19,  1.36it/s]\u001b[A\n","Iteration:  68% 1254/1851 [15:25<07:19,  1.36it/s]\u001b[A\n","Iteration:  68% 1255/1851 [15:26<07:18,  1.36it/s]\u001b[A\n","Iteration:  68% 1256/1851 [15:26<07:18,  1.36it/s]\u001b[A\n","Iteration:  68% 1257/1851 [15:27<07:15,  1.36it/s]\u001b[A\n","Iteration:  68% 1258/1851 [15:28<07:16,  1.36it/s]\u001b[A\n","Iteration:  68% 1259/1851 [15:29<07:16,  1.36it/s]\u001b[A\n","Iteration:  68% 1260/1851 [15:29<07:14,  1.36it/s]\u001b[A\n","Iteration:  68% 1261/1851 [15:30<07:15,  1.36it/s]\u001b[A\n","Iteration:  68% 1262/1851 [15:31<07:14,  1.36it/s]\u001b[A\n","Iteration:  68% 1263/1851 [15:32<07:13,  1.35it/s]\u001b[A\n","Iteration:  68% 1264/1851 [15:32<07:13,  1.35it/s]\u001b[A\n","Iteration:  68% 1265/1851 [15:33<07:12,  1.35it/s]\u001b[A\n","Iteration:  68% 1266/1851 [15:34<07:11,  1.35it/s]\u001b[A\n","Iteration:  68% 1267/1851 [15:35<07:11,  1.35it/s]\u001b[A\n","Iteration:  69% 1268/1851 [15:35<07:09,  1.36it/s]\u001b[A\n","Iteration:  69% 1269/1851 [15:36<07:08,  1.36it/s]\u001b[A\n","Iteration:  69% 1270/1851 [15:37<07:06,  1.36it/s]\u001b[A\n","Iteration:  69% 1271/1851 [15:37<07:05,  1.36it/s]\u001b[A\n","Iteration:  69% 1272/1851 [15:38<07:06,  1.36it/s]\u001b[A\n","Iteration:  69% 1273/1851 [15:39<07:04,  1.36it/s]\u001b[A\n","Iteration:  69% 1274/1851 [15:40<07:03,  1.36it/s]\u001b[A\n","Iteration:  69% 1275/1851 [15:40<07:03,  1.36it/s]\u001b[A\n","Iteration:  69% 1276/1851 [15:41<07:02,  1.36it/s]\u001b[A\n","Iteration:  69% 1277/1851 [15:42<07:02,  1.36it/s]\u001b[A\n","Iteration:  69% 1278/1851 [15:43<07:01,  1.36it/s]\u001b[A\n","Iteration:  69% 1279/1851 [15:43<07:00,  1.36it/s]\u001b[A\n","Iteration:  69% 1280/1851 [15:44<07:00,  1.36it/s]\u001b[A\n","Iteration:  69% 1281/1851 [15:45<06:59,  1.36it/s]\u001b[A\n","Iteration:  69% 1282/1851 [15:46<06:59,  1.36it/s]\u001b[A\n","Iteration:  69% 1283/1851 [15:46<06:59,  1.36it/s]\u001b[A\n","Iteration:  69% 1284/1851 [15:47<06:57,  1.36it/s]\u001b[A\n","Iteration:  69% 1285/1851 [15:48<06:57,  1.36it/s]\u001b[A\n","Iteration:  69% 1286/1851 [15:49<06:56,  1.36it/s]\u001b[A\n","Iteration:  70% 1287/1851 [15:49<06:56,  1.35it/s]\u001b[A\n","Iteration:  70% 1288/1851 [15:50<06:55,  1.36it/s]\u001b[A\n","Iteration:  70% 1289/1851 [15:51<06:54,  1.36it/s]\u001b[A\n","Iteration:  70% 1290/1851 [15:51<06:53,  1.36it/s]\u001b[A\n","Iteration:  70% 1291/1851 [15:52<06:52,  1.36it/s]\u001b[A\n","Iteration:  70% 1292/1851 [15:53<06:52,  1.35it/s]\u001b[A\n","Iteration:  70% 1293/1851 [15:54<06:50,  1.36it/s]\u001b[A\n","Iteration:  70% 1294/1851 [15:54<06:50,  1.36it/s]\u001b[A\n","Iteration:  70% 1295/1851 [15:55<06:50,  1.35it/s]\u001b[A\n","Iteration:  70% 1296/1851 [15:56<06:49,  1.35it/s]\u001b[A\n","Iteration:  70% 1297/1851 [15:57<06:49,  1.35it/s]\u001b[A\n","Iteration:  70% 1298/1851 [15:57<06:48,  1.35it/s]\u001b[A\n","Iteration:  70% 1299/1851 [15:58<06:46,  1.36it/s]\u001b[A\n","Iteration:  70% 1300/1851 [15:59<06:45,  1.36it/s]\u001b[A\n","Iteration:  70% 1301/1851 [16:00<06:44,  1.36it/s]\u001b[A\n","Iteration:  70% 1302/1851 [16:00<06:44,  1.36it/s]\u001b[A\n","Iteration:  70% 1303/1851 [16:01<06:43,  1.36it/s]\u001b[A\n","Iteration:  70% 1304/1851 [16:02<06:43,  1.36it/s]\u001b[A\n","Iteration:  71% 1305/1851 [16:03<06:41,  1.36it/s]\u001b[A\n","Iteration:  71% 1306/1851 [16:03<06:41,  1.36it/s]\u001b[A\n","Iteration:  71% 1307/1851 [16:04<06:39,  1.36it/s]\u001b[A\n","Iteration:  71% 1308/1851 [16:05<06:38,  1.36it/s]\u001b[A\n","Iteration:  71% 1309/1851 [16:05<06:38,  1.36it/s]\u001b[A\n","Iteration:  71% 1310/1851 [16:06<06:37,  1.36it/s]\u001b[A\n","Iteration:  71% 1311/1851 [16:07<06:37,  1.36it/s]\u001b[A\n","Iteration:  71% 1312/1851 [16:08<06:36,  1.36it/s]\u001b[A\n","Iteration:  71% 1313/1851 [16:08<06:35,  1.36it/s]\u001b[A\n","Iteration:  71% 1314/1851 [16:09<06:35,  1.36it/s]\u001b[A\n","Iteration:  71% 1315/1851 [16:10<06:35,  1.36it/s]\u001b[A\n","Iteration:  71% 1316/1851 [16:11<06:34,  1.36it/s]\u001b[A\n","Iteration:  71% 1317/1851 [16:11<06:34,  1.35it/s]\u001b[A\n","Iteration:  71% 1318/1851 [16:12<06:34,  1.35it/s]\u001b[A\n","Iteration:  71% 1319/1851 [16:13<06:32,  1.36it/s]\u001b[A\n","Iteration:  71% 1320/1851 [16:14<06:31,  1.36it/s]\u001b[A\n","Iteration:  71% 1321/1851 [16:14<06:30,  1.36it/s]\u001b[A\n","Iteration:  71% 1322/1851 [16:15<06:29,  1.36it/s]\u001b[A\n","Iteration:  71% 1323/1851 [16:16<06:29,  1.36it/s]\u001b[A\n","Iteration:  72% 1324/1851 [16:17<06:29,  1.35it/s]\u001b[A\n","Iteration:  72% 1325/1851 [16:17<06:28,  1.35it/s]\u001b[A\n","Iteration:  72% 1326/1851 [16:18<06:27,  1.36it/s]\u001b[A\n","Iteration:  72% 1327/1851 [16:19<06:26,  1.36it/s]\u001b[A\n","Iteration:  72% 1328/1851 [16:19<06:26,  1.35it/s]\u001b[A\n","Iteration:  72% 1329/1851 [16:20<06:25,  1.36it/s]\u001b[A\n","Iteration:  72% 1330/1851 [16:21<06:24,  1.36it/s]\u001b[A\n","Iteration:  72% 1331/1851 [16:22<06:23,  1.36it/s]\u001b[A\n","Iteration:  72% 1332/1851 [16:22<06:22,  1.36it/s]\u001b[A\n","Iteration:  72% 1333/1851 [16:23<06:20,  1.36it/s]\u001b[A\n","Iteration:  72% 1334/1851 [16:24<06:19,  1.36it/s]\u001b[A\n","Iteration:  72% 1335/1851 [16:25<06:17,  1.37it/s]\u001b[A\n","Iteration:  72% 1336/1851 [16:25<06:17,  1.37it/s]\u001b[A\n","Iteration:  72% 1337/1851 [16:26<06:16,  1.37it/s]\u001b[A\n","Iteration:  72% 1338/1851 [16:27<06:16,  1.36it/s]\u001b[A\n","Iteration:  72% 1339/1851 [16:28<06:16,  1.36it/s]\u001b[A\n","Iteration:  72% 1340/1851 [16:28<06:15,  1.36it/s]\u001b[A\n","Iteration:  72% 1341/1851 [16:29<06:15,  1.36it/s]\u001b[A\n","Iteration:  73% 1342/1851 [16:30<06:14,  1.36it/s]\u001b[A\n","Iteration:  73% 1343/1851 [16:30<06:14,  1.36it/s]\u001b[A\n","Iteration:  73% 1344/1851 [16:31<06:12,  1.36it/s]\u001b[A\n","Iteration:  73% 1345/1851 [16:32<06:12,  1.36it/s]\u001b[A\n","Iteration:  73% 1346/1851 [16:33<06:11,  1.36it/s]\u001b[A\n","Iteration:  73% 1347/1851 [16:33<06:10,  1.36it/s]\u001b[A\n","Iteration:  73% 1348/1851 [16:34<06:09,  1.36it/s]\u001b[A\n","Iteration:  73% 1349/1851 [16:35<06:09,  1.36it/s]\u001b[A\n","Iteration:  73% 1350/1851 [16:36<06:08,  1.36it/s]\u001b[A\n","Iteration:  73% 1351/1851 [16:36<06:07,  1.36it/s]\u001b[A\n","Iteration:  73% 1352/1851 [16:37<06:07,  1.36it/s]\u001b[A\n","Iteration:  73% 1353/1851 [16:38<06:07,  1.36it/s]\u001b[A\n","Iteration:  73% 1354/1851 [16:39<06:05,  1.36it/s]\u001b[A\n","Iteration:  73% 1355/1851 [16:39<06:04,  1.36it/s]\u001b[A\n","Iteration:  73% 1356/1851 [16:40<06:04,  1.36it/s]\u001b[A\n","Iteration:  73% 1357/1851 [16:41<06:03,  1.36it/s]\u001b[A\n","Iteration:  73% 1358/1851 [16:42<06:02,  1.36it/s]\u001b[A\n","Iteration:  73% 1359/1851 [16:42<06:01,  1.36it/s]\u001b[A\n","Iteration:  73% 1360/1851 [16:43<06:01,  1.36it/s]\u001b[A\n","Iteration:  74% 1361/1851 [16:44<06:00,  1.36it/s]\u001b[A\n","Iteration:  74% 1362/1851 [16:44<06:01,  1.35it/s]\u001b[A\n","Iteration:  74% 1363/1851 [16:45<06:00,  1.35it/s]\u001b[A\n","Iteration:  74% 1364/1851 [16:46<05:59,  1.36it/s]\u001b[A\n","Iteration:  74% 1365/1851 [16:47<05:58,  1.36it/s]\u001b[A\n","Iteration:  74% 1366/1851 [16:47<05:57,  1.36it/s]\u001b[A\n","Iteration:  74% 1367/1851 [16:48<05:56,  1.36it/s]\u001b[A\n","Iteration:  74% 1368/1851 [16:49<05:55,  1.36it/s]\u001b[A\n","Iteration:  74% 1369/1851 [16:50<05:55,  1.36it/s]\u001b[A\n","Iteration:  74% 1370/1851 [16:50<05:54,  1.36it/s]\u001b[A\n","Iteration:  74% 1371/1851 [16:51<05:53,  1.36it/s]\u001b[A\n","Iteration:  74% 1372/1851 [16:52<05:53,  1.36it/s]\u001b[A\n","Iteration:  74% 1373/1851 [16:53<05:52,  1.36it/s]\u001b[A\n","Iteration:  74% 1374/1851 [16:53<05:51,  1.36it/s]\u001b[A\n","Iteration:  74% 1375/1851 [16:54<05:50,  1.36it/s]\u001b[A\n","Iteration:  74% 1376/1851 [16:55<05:48,  1.36it/s]\u001b[A\n","Iteration:  74% 1377/1851 [16:56<05:47,  1.36it/s]\u001b[A\n","Iteration:  74% 1378/1851 [16:56<05:47,  1.36it/s]\u001b[A\n","Iteration:  75% 1379/1851 [16:57<05:47,  1.36it/s]\u001b[A\n","Iteration:  75% 1380/1851 [16:58<05:45,  1.36it/s]\u001b[A\n","Iteration:  75% 1381/1851 [16:58<05:44,  1.36it/s]\u001b[A\n","Iteration:  75% 1382/1851 [16:59<05:44,  1.36it/s]\u001b[A\n","Iteration:  75% 1383/1851 [17:00<05:44,  1.36it/s]\u001b[A\n","Iteration:  75% 1384/1851 [17:01<05:43,  1.36it/s]\u001b[A\n","Iteration:  75% 1385/1851 [17:01<05:42,  1.36it/s]\u001b[A\n","Iteration:  75% 1386/1851 [17:02<05:41,  1.36it/s]\u001b[A\n","Iteration:  75% 1387/1851 [17:03<05:40,  1.36it/s]\u001b[A\n","Iteration:  75% 1388/1851 [17:04<05:39,  1.36it/s]\u001b[A\n","Iteration:  75% 1389/1851 [17:04<05:39,  1.36it/s]\u001b[A\n","Iteration:  75% 1390/1851 [17:05<05:38,  1.36it/s]\u001b[A\n","Iteration:  75% 1391/1851 [17:06<05:38,  1.36it/s]\u001b[A\n","Iteration:  75% 1392/1851 [17:07<05:38,  1.36it/s]\u001b[A\n","Iteration:  75% 1393/1851 [17:07<05:37,  1.36it/s]\u001b[A\n","Iteration:  75% 1394/1851 [17:08<05:37,  1.36it/s]\u001b[A\n","Iteration:  75% 1395/1851 [17:09<05:36,  1.35it/s]\u001b[A\n","Iteration:  75% 1396/1851 [17:09<05:35,  1.36it/s]\u001b[A\n","Iteration:  75% 1397/1851 [17:10<05:34,  1.36it/s]\u001b[A\n","Iteration:  76% 1398/1851 [17:11<05:33,  1.36it/s]\u001b[A\n","Iteration:  76% 1399/1851 [17:12<05:31,  1.36it/s]\u001b[A\n","Iteration:  76% 1400/1851 [17:12<05:31,  1.36it/s]\u001b[A\n","Iteration:  76% 1401/1851 [17:13<05:31,  1.36it/s]\u001b[A\n","Iteration:  76% 1402/1851 [17:14<05:30,  1.36it/s]\u001b[A\n","Iteration:  76% 1403/1851 [17:15<05:29,  1.36it/s]\u001b[A\n","Iteration:  76% 1404/1851 [17:15<05:28,  1.36it/s]\u001b[A\n","Iteration:  76% 1405/1851 [17:16<05:28,  1.36it/s]\u001b[A\n","Iteration:  76% 1406/1851 [17:17<05:26,  1.36it/s]\u001b[A\n","Iteration:  76% 1407/1851 [17:18<05:26,  1.36it/s]\u001b[A\n","Iteration:  76% 1408/1851 [17:18<05:26,  1.36it/s]\u001b[A\n","Iteration:  76% 1409/1851 [17:19<05:24,  1.36it/s]\u001b[A\n","Iteration:  76% 1410/1851 [17:20<05:23,  1.36it/s]\u001b[A\n","Iteration:  76% 1411/1851 [17:21<05:22,  1.36it/s]\u001b[A\n","Iteration:  76% 1412/1851 [17:21<05:21,  1.36it/s]\u001b[A\n","Iteration:  76% 1413/1851 [17:22<05:21,  1.36it/s]\u001b[A\n","Iteration:  76% 1414/1851 [17:23<05:20,  1.36it/s]\u001b[A\n","Iteration:  76% 1415/1851 [17:23<05:19,  1.36it/s]\u001b[A\n","Iteration:  76% 1416/1851 [17:24<05:19,  1.36it/s]\u001b[A\n","Iteration:  77% 1417/1851 [17:25<05:18,  1.36it/s]\u001b[A\n","Iteration:  77% 1418/1851 [17:26<05:18,  1.36it/s]\u001b[A\n","Iteration:  77% 1419/1851 [17:26<05:16,  1.36it/s]\u001b[A\n","Iteration:  77% 1420/1851 [17:27<05:16,  1.36it/s]\u001b[A\n","Iteration:  77% 1421/1851 [17:28<05:15,  1.36it/s]\u001b[A\n","Iteration:  77% 1422/1851 [17:29<05:15,  1.36it/s]\u001b[A\n","Iteration:  77% 1423/1851 [17:29<05:14,  1.36it/s]\u001b[A\n","Iteration:  77% 1424/1851 [17:30<05:13,  1.36it/s]\u001b[A\n","Iteration:  77% 1425/1851 [17:31<05:12,  1.36it/s]\u001b[A\n","Iteration:  77% 1426/1851 [17:32<05:12,  1.36it/s]\u001b[A\n","Iteration:  77% 1427/1851 [17:32<05:11,  1.36it/s]\u001b[A\n","Iteration:  77% 1428/1851 [17:33<05:11,  1.36it/s]\u001b[A\n","Iteration:  77% 1429/1851 [17:34<05:10,  1.36it/s]\u001b[A\n","Iteration:  77% 1430/1851 [17:34<05:10,  1.36it/s]\u001b[A\n","Iteration:  77% 1431/1851 [17:35<05:10,  1.35it/s]\u001b[A\n","Iteration:  77% 1432/1851 [17:36<05:09,  1.36it/s]\u001b[A\n","Iteration:  77% 1433/1851 [17:37<05:08,  1.36it/s]\u001b[A\n","Iteration:  77% 1434/1851 [17:37<05:06,  1.36it/s]\u001b[A\n","Iteration:  78% 1435/1851 [17:38<05:05,  1.36it/s]\u001b[A\n","Iteration:  78% 1436/1851 [17:39<05:04,  1.36it/s]\u001b[A\n","Iteration:  78% 1437/1851 [17:40<05:03,  1.36it/s]\u001b[A\n","Iteration:  78% 1438/1851 [17:40<05:03,  1.36it/s]\u001b[A\n","Iteration:  78% 1439/1851 [17:41<05:03,  1.36it/s]\u001b[A\n","Iteration:  78% 1440/1851 [17:42<05:02,  1.36it/s]\u001b[A\n","Iteration:  78% 1441/1851 [17:43<05:02,  1.36it/s]\u001b[A\n","Iteration:  78% 1442/1851 [17:43<05:01,  1.36it/s]\u001b[A\n","Iteration:  78% 1443/1851 [17:44<05:00,  1.36it/s]\u001b[A\n","Iteration:  78% 1444/1851 [17:45<04:59,  1.36it/s]\u001b[A\n","Iteration:  78% 1445/1851 [17:46<04:58,  1.36it/s]\u001b[A\n","Iteration:  78% 1446/1851 [17:46<04:58,  1.36it/s]\u001b[A\n","Iteration:  78% 1447/1851 [17:47<04:57,  1.36it/s]\u001b[A\n","Iteration:  78% 1448/1851 [17:48<04:57,  1.35it/s]\u001b[A\n","Iteration:  78% 1449/1851 [17:48<04:56,  1.36it/s]\u001b[A\n","Iteration:  78% 1450/1851 [17:49<04:55,  1.36it/s]\u001b[A\n","Iteration:  78% 1451/1851 [17:50<04:55,  1.36it/s]\u001b[A\n","Iteration:  78% 1452/1851 [17:51<04:54,  1.36it/s]\u001b[A\n","Iteration:  78% 1453/1851 [17:51<04:52,  1.36it/s]\u001b[A\n","Iteration:  79% 1454/1851 [17:52<04:51,  1.36it/s]\u001b[A\n","Iteration:  79% 1455/1851 [17:53<04:51,  1.36it/s]\u001b[A\n","Iteration:  79% 1456/1851 [17:54<04:50,  1.36it/s]\u001b[A\n","Iteration:  79% 1457/1851 [17:54<04:49,  1.36it/s]\u001b[A\n","Iteration:  79% 1458/1851 [17:55<04:49,  1.36it/s]\u001b[A\n","Iteration:  79% 1459/1851 [17:56<04:48,  1.36it/s]\u001b[A\n","Iteration:  79% 1460/1851 [17:57<04:48,  1.36it/s]\u001b[A\n","Iteration:  79% 1461/1851 [17:57<04:47,  1.35it/s]\u001b[A\n","Iteration:  79% 1462/1851 [17:58<04:46,  1.36it/s]\u001b[A\n","Iteration:  79% 1463/1851 [17:59<04:45,  1.36it/s]\u001b[A\n","Iteration:  79% 1464/1851 [18:00<04:44,  1.36it/s]\u001b[A\n","Iteration:  79% 1465/1851 [18:00<04:43,  1.36it/s]\u001b[A\n","Iteration:  79% 1466/1851 [18:01<04:43,  1.36it/s]\u001b[A\n","Iteration:  79% 1467/1851 [18:02<04:42,  1.36it/s]\u001b[A\n","Iteration:  79% 1468/1851 [18:02<04:41,  1.36it/s]\u001b[A\n","Iteration:  79% 1469/1851 [18:03<04:40,  1.36it/s]\u001b[A\n","Iteration:  79% 1470/1851 [18:04<04:40,  1.36it/s]\u001b[A\n","Iteration:  79% 1471/1851 [18:05<04:39,  1.36it/s]\u001b[A\n","Iteration:  80% 1472/1851 [18:05<04:39,  1.36it/s]\u001b[A\n","Iteration:  80% 1473/1851 [18:06<04:38,  1.36it/s]\u001b[A\n","Iteration:  80% 1474/1851 [18:07<04:37,  1.36it/s]\u001b[A\n","Iteration:  80% 1475/1851 [18:08<04:36,  1.36it/s]\u001b[A\n","Iteration:  80% 1476/1851 [18:08<04:35,  1.36it/s]\u001b[A\n","Iteration:  80% 1477/1851 [18:09<04:35,  1.36it/s]\u001b[A\n","Iteration:  80% 1478/1851 [18:10<04:35,  1.36it/s]\u001b[A\n","Iteration:  80% 1479/1851 [18:11<04:33,  1.36it/s]\u001b[A\n","Iteration:  80% 1480/1851 [18:11<04:33,  1.36it/s]\u001b[A\n","Iteration:  80% 1481/1851 [18:12<04:32,  1.36it/s]\u001b[A\n","Iteration:  80% 1482/1851 [18:13<04:31,  1.36it/s]\u001b[A\n","Iteration:  80% 1483/1851 [18:14<04:30,  1.36it/s]\u001b[A\n","Iteration:  80% 1484/1851 [18:14<04:29,  1.36it/s]\u001b[A\n","Iteration:  80% 1485/1851 [18:15<04:29,  1.36it/s]\u001b[A\n","Iteration:  80% 1486/1851 [18:16<04:29,  1.36it/s]\u001b[A\n","Iteration:  80% 1487/1851 [18:16<04:28,  1.36it/s]\u001b[A\n","Iteration:  80% 1488/1851 [18:17<04:26,  1.36it/s]\u001b[A\n","Iteration:  80% 1489/1851 [18:18<04:25,  1.36it/s]\u001b[A\n","Iteration:  80% 1490/1851 [18:19<04:24,  1.36it/s]\u001b[A\n","Iteration:  81% 1491/1851 [18:19<04:24,  1.36it/s]\u001b[A\n","Iteration:  81% 1492/1851 [18:20<04:24,  1.36it/s]\u001b[A\n","Iteration:  81% 1493/1851 [18:21<04:23,  1.36it/s]\u001b[A\n","Iteration:  81% 1494/1851 [18:22<04:22,  1.36it/s]\u001b[A\n","Iteration:  81% 1495/1851 [18:22<04:21,  1.36it/s]\u001b[A\n","Iteration:  81% 1496/1851 [18:23<04:20,  1.36it/s]\u001b[A\n","Iteration:  81% 1497/1851 [18:24<04:21,  1.36it/s]\u001b[A\n","Iteration:  81% 1498/1851 [18:25<04:19,  1.36it/s]\u001b[A\n","Iteration:  81% 1499/1851 [18:25<04:19,  1.36it/s]\u001b[A\n","Iteration:  81% 1500/1851 [18:26<04:18,  1.36it/s]\u001b[A\n","Iteration:  81% 1501/1851 [18:27<04:17,  1.36it/s]\u001b[A\n","Iteration:  81% 1502/1851 [18:27<04:17,  1.36it/s]\u001b[A\n","Iteration:  81% 1503/1851 [18:28<04:16,  1.36it/s]\u001b[A\n","Iteration:  81% 1504/1851 [18:29<04:16,  1.36it/s]\u001b[A\n","Iteration:  81% 1505/1851 [18:30<04:15,  1.35it/s]\u001b[A\n","Iteration:  81% 1506/1851 [18:30<04:14,  1.36it/s]\u001b[A\n","Iteration:  81% 1507/1851 [18:31<04:13,  1.36it/s]\u001b[A\n","Iteration:  81% 1508/1851 [18:32<04:13,  1.36it/s]\u001b[A\n","Iteration:  82% 1509/1851 [18:33<04:11,  1.36it/s]\u001b[A\n","Iteration:  82% 1510/1851 [18:33<04:10,  1.36it/s]\u001b[A\n","Iteration:  82% 1511/1851 [18:34<04:09,  1.36it/s]\u001b[A\n","Iteration:  82% 1512/1851 [18:35<04:09,  1.36it/s]\u001b[A\n","Iteration:  82% 1513/1851 [18:36<04:09,  1.36it/s]\u001b[A\n","Iteration:  82% 1514/1851 [18:36<04:08,  1.36it/s]\u001b[A\n","Iteration:  82% 1515/1851 [18:37<04:06,  1.36it/s]\u001b[A\n","Iteration:  82% 1516/1851 [18:38<04:05,  1.36it/s]\u001b[A\n","Iteration:  82% 1517/1851 [18:39<04:04,  1.37it/s]\u001b[A\n","Iteration:  82% 1518/1851 [18:39<04:04,  1.36it/s]\u001b[A\n","Iteration:  82% 1519/1851 [18:40<04:03,  1.36it/s]\u001b[A\n","Iteration:  82% 1520/1851 [18:41<04:03,  1.36it/s]\u001b[A\n","Iteration:  82% 1521/1851 [18:41<04:02,  1.36it/s]\u001b[A\n","Iteration:  82% 1522/1851 [18:42<04:01,  1.36it/s]\u001b[A\n","Iteration:  82% 1523/1851 [18:43<04:01,  1.36it/s]\u001b[A\n","Iteration:  82% 1524/1851 [18:44<04:01,  1.35it/s]\u001b[A\n","Iteration:  82% 1525/1851 [18:44<04:00,  1.35it/s]\u001b[A\n","Iteration:  82% 1526/1851 [18:45<04:00,  1.35it/s]\u001b[A\n","Iteration:  82% 1527/1851 [18:46<03:59,  1.35it/s]\u001b[A\n","Iteration:  83% 1528/1851 [18:47<03:58,  1.36it/s]\u001b[A\n","Iteration:  83% 1529/1851 [18:47<03:58,  1.35it/s]\u001b[A\n","Iteration:  83% 1530/1851 [18:48<03:57,  1.35it/s]\u001b[A\n","Iteration:  83% 1531/1851 [18:49<03:56,  1.35it/s]\u001b[A\n","Iteration:  83% 1532/1851 [18:50<03:55,  1.35it/s]\u001b[A\n","Iteration:  83% 1533/1851 [18:50<03:54,  1.36it/s]\u001b[A\n","Iteration:  83% 1534/1851 [18:51<03:54,  1.35it/s]\u001b[A\n","Iteration:  83% 1535/1851 [18:52<03:53,  1.35it/s]\u001b[A\n","Iteration:  83% 1536/1851 [18:53<03:51,  1.36it/s]\u001b[A\n","Iteration:  83% 1537/1851 [18:53<03:51,  1.36it/s]\u001b[A\n","Iteration:  83% 1538/1851 [18:54<03:50,  1.36it/s]\u001b[A\n","Iteration:  83% 1539/1851 [18:55<03:49,  1.36it/s]\u001b[A\n","Iteration:  83% 1540/1851 [18:55<03:49,  1.36it/s]\u001b[A\n","Iteration:  83% 1541/1851 [18:56<03:48,  1.36it/s]\u001b[A\n","Iteration:  83% 1542/1851 [18:57<03:47,  1.36it/s]\u001b[A\n","Iteration:  83% 1543/1851 [18:58<03:46,  1.36it/s]\u001b[A\n","Iteration:  83% 1544/1851 [18:58<03:46,  1.36it/s]\u001b[A\n","Iteration:  83% 1545/1851 [18:59<03:45,  1.36it/s]\u001b[A\n","Iteration:  84% 1546/1851 [19:00<03:45,  1.35it/s]\u001b[A\n","Iteration:  84% 1547/1851 [19:01<03:44,  1.35it/s]\u001b[A\n","Iteration:  84% 1548/1851 [19:01<03:43,  1.35it/s]\u001b[A\n","Iteration:  84% 1549/1851 [19:02<03:42,  1.36it/s]\u001b[A\n","Iteration:  84% 1550/1851 [19:03<03:41,  1.36it/s]\u001b[A\n","Iteration:  84% 1551/1851 [19:04<03:41,  1.36it/s]\u001b[A\n","Iteration:  84% 1552/1851 [19:04<03:40,  1.36it/s]\u001b[A\n","Iteration:  84% 1553/1851 [19:05<03:39,  1.36it/s]\u001b[A\n","Iteration:  84% 1554/1851 [19:06<03:39,  1.35it/s]\u001b[A\n","Iteration:  84% 1555/1851 [19:07<03:37,  1.36it/s]\u001b[A\n","Iteration:  84% 1556/1851 [19:07<03:37,  1.36it/s]\u001b[A\n","Iteration:  84% 1557/1851 [19:08<03:36,  1.36it/s]\u001b[A\n","Iteration:  84% 1558/1851 [19:09<03:36,  1.36it/s]\u001b[A\n","Iteration:  84% 1559/1851 [19:09<03:35,  1.36it/s]\u001b[A\n","Iteration:  84% 1560/1851 [19:10<03:34,  1.36it/s]\u001b[A\n","Iteration:  84% 1561/1851 [19:11<03:33,  1.36it/s]\u001b[A\n","Iteration:  84% 1562/1851 [19:12<03:32,  1.36it/s]\u001b[A\n","Iteration:  84% 1563/1851 [19:12<03:31,  1.36it/s]\u001b[A\n","Iteration:  84% 1564/1851 [19:13<03:30,  1.36it/s]\u001b[A\n","Iteration:  85% 1565/1851 [19:14<03:30,  1.36it/s]\u001b[A\n","Iteration:  85% 1566/1851 [19:15<03:29,  1.36it/s]\u001b[A\n","Iteration:  85% 1567/1851 [19:15<03:28,  1.36it/s]\u001b[A\n","Iteration:  85% 1568/1851 [19:16<03:28,  1.36it/s]\u001b[A\n","Iteration:  85% 1569/1851 [19:17<03:27,  1.36it/s]\u001b[A\n","Iteration:  85% 1570/1851 [19:18<03:27,  1.36it/s]\u001b[A\n","Iteration:  85% 1571/1851 [19:18<03:26,  1.35it/s]\u001b[A\n","Iteration:  85% 1572/1851 [19:19<03:25,  1.36it/s]\u001b[A\n","Iteration:  85% 1573/1851 [19:20<03:24,  1.36it/s]\u001b[A\n","Iteration:  85% 1574/1851 [19:21<03:23,  1.36it/s]\u001b[A\n","Iteration:  85% 1575/1851 [19:21<03:22,  1.36it/s]\u001b[A\n","Iteration:  85% 1576/1851 [19:22<03:22,  1.36it/s]\u001b[A\n","Iteration:  85% 1577/1851 [19:23<03:21,  1.36it/s]\u001b[A\n","Iteration:  85% 1578/1851 [19:23<03:20,  1.36it/s]\u001b[A\n","Iteration:  85% 1579/1851 [19:24<03:19,  1.36it/s]\u001b[A\n","Iteration:  85% 1580/1851 [19:25<03:19,  1.36it/s]\u001b[A\n","Iteration:  85% 1581/1851 [19:26<03:18,  1.36it/s]\u001b[A\n","Iteration:  85% 1582/1851 [19:26<03:17,  1.36it/s]\u001b[A\n","Iteration:  86% 1583/1851 [19:27<03:17,  1.36it/s]\u001b[A\n","Iteration:  86% 1584/1851 [19:28<03:16,  1.36it/s]\u001b[A\n","Iteration:  86% 1585/1851 [19:29<03:16,  1.36it/s]\u001b[A\n","Iteration:  86% 1586/1851 [19:29<03:15,  1.35it/s]\u001b[A\n","Iteration:  86% 1587/1851 [19:30<03:14,  1.36it/s]\u001b[A\n","Iteration:  86% 1588/1851 [19:31<03:14,  1.35it/s]\u001b[A\n","Iteration:  86% 1589/1851 [19:32<03:13,  1.35it/s]\u001b[A\n","Iteration:  86% 1590/1851 [19:32<03:12,  1.36it/s]\u001b[A\n","Iteration:  86% 1591/1851 [19:33<03:12,  1.35it/s]\u001b[A\n","Iteration:  86% 1592/1851 [19:34<03:11,  1.35it/s]\u001b[A\n","Iteration:  86% 1593/1851 [19:35<03:10,  1.36it/s]\u001b[A\n","Iteration:  86% 1594/1851 [19:35<03:09,  1.36it/s]\u001b[A\n","Iteration:  86% 1595/1851 [19:36<03:08,  1.36it/s]\u001b[A\n","Iteration:  86% 1596/1851 [19:37<03:07,  1.36it/s]\u001b[A\n","Iteration:  86% 1597/1851 [19:37<03:07,  1.36it/s]\u001b[A\n","Iteration:  86% 1598/1851 [19:38<03:06,  1.36it/s]\u001b[A\n","Iteration:  86% 1599/1851 [19:39<03:05,  1.36it/s]\u001b[A\n","Iteration:  86% 1600/1851 [19:40<03:04,  1.36it/s]\u001b[A\n","Iteration:  86% 1601/1851 [19:40<03:04,  1.36it/s]\u001b[A\n","Iteration:  87% 1602/1851 [19:41<03:03,  1.36it/s]\u001b[A\n","Iteration:  87% 1603/1851 [19:42<03:02,  1.36it/s]\u001b[A\n","Iteration:  87% 1604/1851 [19:43<03:01,  1.36it/s]\u001b[A\n","Iteration:  87% 1605/1851 [19:43<03:01,  1.36it/s]\u001b[A\n","Iteration:  87% 1606/1851 [19:44<03:00,  1.36it/s]\u001b[A\n","Iteration:  87% 1607/1851 [19:45<02:59,  1.36it/s]\u001b[A\n","Iteration:  87% 1608/1851 [19:46<02:59,  1.36it/s]\u001b[A\n","Iteration:  87% 1609/1851 [19:46<02:58,  1.36it/s]\u001b[A\n","Iteration:  87% 1610/1851 [19:47<02:57,  1.36it/s]\u001b[A\n","Iteration:  87% 1611/1851 [19:48<02:56,  1.36it/s]\u001b[A\n","Iteration:  87% 1612/1851 [19:49<02:55,  1.37it/s]\u001b[A\n","Iteration:  87% 1613/1851 [19:49<02:55,  1.36it/s]\u001b[A\n","Iteration:  87% 1614/1851 [19:50<02:54,  1.36it/s]\u001b[A\n","Iteration:  87% 1615/1851 [19:51<02:54,  1.35it/s]\u001b[A\n","Iteration:  87% 1616/1851 [19:51<02:53,  1.35it/s]\u001b[A\n","Iteration:  87% 1617/1851 [19:52<02:52,  1.36it/s]\u001b[A\n","Iteration:  87% 1618/1851 [19:53<02:51,  1.36it/s]\u001b[A\n","Iteration:  87% 1619/1851 [19:54<02:50,  1.36it/s]\u001b[A\n","Iteration:  88% 1620/1851 [19:54<02:50,  1.36it/s]\u001b[A\n","Iteration:  88% 1621/1851 [19:55<02:49,  1.36it/s]\u001b[A\n","Iteration:  88% 1622/1851 [19:56<02:48,  1.36it/s]\u001b[A\n","Iteration:  88% 1623/1851 [19:57<02:48,  1.36it/s]\u001b[A\n","Iteration:  88% 1624/1851 [19:57<02:47,  1.36it/s]\u001b[A\n","Iteration:  88% 1625/1851 [19:58<02:46,  1.36it/s]\u001b[A\n","Iteration:  88% 1626/1851 [19:59<02:46,  1.35it/s]\u001b[A\n","Iteration:  88% 1627/1851 [20:00<02:45,  1.36it/s]\u001b[A\n","Iteration:  88% 1628/1851 [20:00<02:44,  1.36it/s]\u001b[A\n","Iteration:  88% 1629/1851 [20:01<02:43,  1.36it/s]\u001b[A\n","Iteration:  88% 1630/1851 [20:02<02:42,  1.36it/s]\u001b[A\n","Iteration:  88% 1631/1851 [20:03<02:42,  1.36it/s]\u001b[A\n","Iteration:  88% 1632/1851 [20:03<02:41,  1.36it/s]\u001b[A\n","Iteration:  88% 1633/1851 [20:04<02:40,  1.36it/s]\u001b[A\n","Iteration:  88% 1634/1851 [20:05<02:39,  1.36it/s]\u001b[A\n","Iteration:  88% 1635/1851 [20:05<02:39,  1.36it/s]\u001b[A\n","Iteration:  88% 1636/1851 [20:06<02:38,  1.36it/s]\u001b[A\n","Iteration:  88% 1637/1851 [20:07<02:37,  1.35it/s]\u001b[A\n","Iteration:  88% 1638/1851 [20:08<02:36,  1.36it/s]\u001b[A\n","Iteration:  89% 1639/1851 [20:08<02:36,  1.36it/s]\u001b[A\n","Iteration:  89% 1640/1851 [20:09<02:35,  1.36it/s]\u001b[A\n","Iteration:  89% 1641/1851 [20:10<02:34,  1.36it/s]\u001b[A\n","Iteration:  89% 1642/1851 [20:11<02:34,  1.35it/s]\u001b[A\n","Iteration:  89% 1643/1851 [20:11<02:33,  1.35it/s]\u001b[A\n","Iteration:  89% 1644/1851 [20:12<02:32,  1.35it/s]\u001b[A\n","Iteration:  89% 1645/1851 [20:13<02:32,  1.35it/s]\u001b[A\n","Iteration:  89% 1646/1851 [20:14<02:31,  1.36it/s]\u001b[A\n","Iteration:  89% 1647/1851 [20:14<02:30,  1.35it/s]\u001b[A\n","Iteration:  89% 1648/1851 [20:15<02:29,  1.35it/s]\u001b[A\n","Iteration:  89% 1649/1851 [20:16<02:28,  1.36it/s]\u001b[A\n","Iteration:  89% 1650/1851 [20:17<02:27,  1.36it/s]\u001b[A\n","Iteration:  89% 1651/1851 [20:17<02:26,  1.36it/s]\u001b[A\n","Iteration:  89% 1652/1851 [20:18<02:26,  1.36it/s]\u001b[A\n","Iteration:  89% 1653/1851 [20:19<02:25,  1.36it/s]\u001b[A\n","Iteration:  89% 1654/1851 [20:19<02:25,  1.36it/s]\u001b[A\n","Iteration:  89% 1655/1851 [20:20<02:24,  1.36it/s]\u001b[A\n","Iteration:  89% 1656/1851 [20:21<02:23,  1.36it/s]\u001b[A\n","Iteration:  90% 1657/1851 [20:22<02:23,  1.35it/s]\u001b[A\n","Iteration:  90% 1658/1851 [20:22<02:22,  1.35it/s]\u001b[A\n","Iteration:  90% 1659/1851 [20:23<02:21,  1.36it/s]\u001b[A\n","Iteration:  90% 1660/1851 [20:24<02:20,  1.36it/s]\u001b[A\n","Iteration:  90% 1661/1851 [20:25<02:19,  1.36it/s]\u001b[A\n","Iteration:  90% 1662/1851 [20:25<02:19,  1.36it/s]\u001b[A\n","Iteration:  90% 1663/1851 [20:26<02:18,  1.36it/s]\u001b[A\n","Iteration:  90% 1664/1851 [20:27<02:17,  1.36it/s]\u001b[A\n","Iteration:  90% 1665/1851 [20:28<02:17,  1.36it/s]\u001b[A\n","Iteration:  90% 1666/1851 [20:28<02:16,  1.35it/s]\u001b[A\n","Iteration:  90% 1667/1851 [20:29<02:15,  1.36it/s]\u001b[A\n","Iteration:  90% 1668/1851 [20:30<02:14,  1.36it/s]\u001b[A\n","Iteration:  90% 1669/1851 [20:31<02:14,  1.35it/s]\u001b[A\n","Iteration:  90% 1670/1851 [20:31<02:13,  1.36it/s]\u001b[A\n","Iteration:  90% 1671/1851 [20:32<02:12,  1.36it/s]\u001b[A\n","Iteration:  90% 1672/1851 [20:33<02:11,  1.36it/s]\u001b[A\n","Iteration:  90% 1673/1851 [20:33<02:11,  1.36it/s]\u001b[A\n","Iteration:  90% 1674/1851 [20:34<02:10,  1.36it/s]\u001b[A\n","Iteration:  90% 1675/1851 [20:35<02:09,  1.36it/s]\u001b[A\n","Iteration:  91% 1676/1851 [20:36<02:08,  1.36it/s]\u001b[A\n","Iteration:  91% 1677/1851 [20:36<02:07,  1.36it/s]\u001b[A\n","Iteration:  91% 1678/1851 [20:37<02:06,  1.36it/s]\u001b[A\n","Iteration:  91% 1679/1851 [20:38<02:06,  1.36it/s]\u001b[A\n","Iteration:  91% 1680/1851 [20:39<02:05,  1.36it/s]\u001b[A\n","Iteration:  91% 1681/1851 [20:39<02:04,  1.37it/s]\u001b[A\n","Iteration:  91% 1682/1851 [20:40<02:04,  1.36it/s]\u001b[A\n","Iteration:  91% 1683/1851 [20:41<02:03,  1.36it/s]\u001b[A\n","Iteration:  91% 1684/1851 [20:42<02:03,  1.36it/s]\u001b[A\n","Iteration:  91% 1685/1851 [20:42<02:02,  1.36it/s]\u001b[A\n","Iteration:  91% 1686/1851 [20:43<02:01,  1.36it/s]\u001b[A\n","Iteration:  91% 1687/1851 [20:44<02:00,  1.36it/s]\u001b[A\n","Iteration:  91% 1688/1851 [20:44<01:59,  1.36it/s]\u001b[A\n","Iteration:  91% 1689/1851 [20:45<01:58,  1.36it/s]\u001b[A\n","Iteration:  91% 1690/1851 [20:46<01:57,  1.37it/s]\u001b[A\n","Iteration:  91% 1691/1851 [20:47<01:57,  1.37it/s]\u001b[A\n","Iteration:  91% 1692/1851 [20:47<01:56,  1.36it/s]\u001b[A\n","Iteration:  91% 1693/1851 [20:48<01:56,  1.36it/s]\u001b[A\n","Iteration:  92% 1694/1851 [20:49<01:55,  1.36it/s]\u001b[A\n","Iteration:  92% 1695/1851 [20:50<01:54,  1.36it/s]\u001b[A\n","Iteration:  92% 1696/1851 [20:50<01:53,  1.36it/s]\u001b[A\n","Iteration:  92% 1697/1851 [20:51<01:53,  1.36it/s]\u001b[A\n","Iteration:  92% 1698/1851 [20:52<01:52,  1.36it/s]\u001b[A\n","Iteration:  92% 1699/1851 [20:53<01:51,  1.36it/s]\u001b[A\n","Iteration:  92% 1700/1851 [20:53<01:50,  1.36it/s]\u001b[A\n","Iteration:  92% 1701/1851 [20:54<01:50,  1.36it/s]\u001b[A\n","Iteration:  92% 1702/1851 [20:55<01:49,  1.36it/s]\u001b[A\n","Iteration:  92% 1703/1851 [20:55<01:48,  1.36it/s]\u001b[A\n","Iteration:  92% 1704/1851 [20:56<01:47,  1.36it/s]\u001b[A\n","Iteration:  92% 1705/1851 [20:57<01:47,  1.36it/s]\u001b[A\n","Iteration:  92% 1706/1851 [20:58<01:46,  1.36it/s]\u001b[A\n","Iteration:  92% 1707/1851 [20:58<01:45,  1.36it/s]\u001b[A\n","Iteration:  92% 1708/1851 [20:59<01:45,  1.36it/s]\u001b[A\n","Iteration:  92% 1709/1851 [21:00<01:44,  1.36it/s]\u001b[A\n","Iteration:  92% 1710/1851 [21:01<01:43,  1.36it/s]\u001b[A\n","Iteration:  92% 1711/1851 [21:01<01:42,  1.36it/s]\u001b[A\n","Iteration:  92% 1712/1851 [21:02<01:42,  1.36it/s]\u001b[A\n","Iteration:  93% 1713/1851 [21:03<01:41,  1.36it/s]\u001b[A\n","Iteration:  93% 1714/1851 [21:04<01:40,  1.36it/s]\u001b[A\n","Iteration:  93% 1715/1851 [21:04<01:40,  1.36it/s]\u001b[A\n","Iteration:  93% 1716/1851 [21:05<01:39,  1.35it/s]\u001b[A\n","Iteration:  93% 1717/1851 [21:06<01:38,  1.36it/s]\u001b[A\n","Iteration:  93% 1718/1851 [21:07<01:38,  1.36it/s]\u001b[A\n","Iteration:  93% 1719/1851 [21:07<01:37,  1.36it/s]\u001b[A\n","Iteration:  93% 1720/1851 [21:08<01:36,  1.36it/s]\u001b[A\n","Iteration:  93% 1721/1851 [21:09<01:35,  1.36it/s]\u001b[A\n","Iteration:  93% 1722/1851 [21:09<01:35,  1.36it/s]\u001b[A\n","Iteration:  93% 1723/1851 [21:10<01:34,  1.36it/s]\u001b[A\n","Iteration:  93% 1724/1851 [21:11<01:33,  1.36it/s]\u001b[A\n","Iteration:  93% 1725/1851 [21:12<01:33,  1.35it/s]\u001b[A\n","Iteration:  93% 1726/1851 [21:12<01:32,  1.36it/s]\u001b[A\n","Iteration:  93% 1727/1851 [21:13<01:31,  1.36it/s]\u001b[A\n","Iteration:  93% 1728/1851 [21:14<01:30,  1.36it/s]\u001b[A\n","Iteration:  93% 1729/1851 [21:15<01:29,  1.36it/s]\u001b[A\n","Iteration:  93% 1730/1851 [21:15<01:28,  1.36it/s]\u001b[A\n","Iteration:  94% 1731/1851 [21:16<01:28,  1.36it/s]\u001b[A\n","Iteration:  94% 1732/1851 [21:17<01:27,  1.36it/s]\u001b[A\n","Iteration:  94% 1733/1851 [21:18<01:26,  1.36it/s]\u001b[A\n","Iteration:  94% 1734/1851 [21:18<01:26,  1.36it/s]\u001b[A\n","Iteration:  94% 1735/1851 [21:19<01:25,  1.36it/s]\u001b[A\n","Iteration:  94% 1736/1851 [21:20<01:24,  1.35it/s]\u001b[A\n","Iteration:  94% 1737/1851 [21:21<01:24,  1.36it/s]\u001b[A\n","Iteration:  94% 1738/1851 [21:21<01:23,  1.36it/s]\u001b[A\n","Iteration:  94% 1739/1851 [21:22<01:22,  1.36it/s]\u001b[A\n","Iteration:  94% 1740/1851 [21:23<01:21,  1.35it/s]\u001b[A\n","Iteration:  94% 1741/1851 [21:23<01:21,  1.35it/s]\u001b[A\n","Iteration:  94% 1742/1851 [21:24<01:20,  1.36it/s]\u001b[A\n","Iteration:  94% 1743/1851 [21:25<01:19,  1.36it/s]\u001b[A\n","Iteration:  94% 1744/1851 [21:26<01:18,  1.36it/s]\u001b[A\n","Iteration:  94% 1745/1851 [21:26<01:18,  1.36it/s]\u001b[A\n","Iteration:  94% 1746/1851 [21:27<01:17,  1.36it/s]\u001b[A\n","Iteration:  94% 1747/1851 [21:28<01:16,  1.36it/s]\u001b[A\n","Iteration:  94% 1748/1851 [21:29<01:15,  1.36it/s]\u001b[A\n","Iteration:  94% 1749/1851 [21:29<01:15,  1.36it/s]\u001b[A\n","Iteration:  95% 1750/1851 [21:30<01:14,  1.35it/s]\u001b[A\n","Iteration:  95% 1751/1851 [21:31<01:13,  1.35it/s]\u001b[A\n","Iteration:  95% 1752/1851 [21:32<01:13,  1.35it/s]\u001b[A\n","Iteration:  95% 1753/1851 [21:32<01:12,  1.35it/s]\u001b[A\n","Iteration:  95% 1754/1851 [21:33<01:11,  1.35it/s]\u001b[A\n","Iteration:  95% 1755/1851 [21:34<01:10,  1.35it/s]\u001b[A\n","Iteration:  95% 1756/1851 [21:35<01:10,  1.35it/s]\u001b[A\n","Iteration:  95% 1757/1851 [21:35<01:09,  1.36it/s]\u001b[A\n","Iteration:  95% 1758/1851 [21:36<01:08,  1.36it/s]\u001b[A\n","Iteration:  95% 1759/1851 [21:37<01:07,  1.36it/s]\u001b[A\n","Iteration:  95% 1760/1851 [21:37<01:07,  1.36it/s]\u001b[A\n","Iteration:  95% 1761/1851 [21:38<01:06,  1.36it/s]\u001b[A\n","Iteration:  95% 1762/1851 [21:39<01:05,  1.36it/s]\u001b[A\n","Iteration:  95% 1763/1851 [21:40<01:04,  1.36it/s]\u001b[A\n","Iteration:  95% 1764/1851 [21:40<01:03,  1.36it/s]\u001b[A\n","Iteration:  95% 1765/1851 [21:41<01:03,  1.36it/s]\u001b[A\n","Iteration:  95% 1766/1851 [21:42<01:02,  1.36it/s]\u001b[A\n","Iteration:  95% 1767/1851 [21:43<01:01,  1.36it/s]\u001b[A\n","Iteration:  96% 1768/1851 [21:43<01:00,  1.36it/s]\u001b[A\n","Iteration:  96% 1769/1851 [21:44<01:00,  1.36it/s]\u001b[A\n","Iteration:  96% 1770/1851 [21:45<00:59,  1.36it/s]\u001b[A\n","Iteration:  96% 1771/1851 [21:46<00:58,  1.36it/s]\u001b[A\n","Iteration:  96% 1772/1851 [21:46<00:58,  1.36it/s]\u001b[A\n","Iteration:  96% 1773/1851 [21:47<00:57,  1.36it/s]\u001b[A\n","Iteration:  96% 1774/1851 [21:48<00:56,  1.36it/s]\u001b[A\n","Iteration:  96% 1775/1851 [21:49<00:56,  1.35it/s]\u001b[A\n","Iteration:  96% 1776/1851 [21:49<00:55,  1.36it/s]\u001b[A\n","Iteration:  96% 1777/1851 [21:50<00:54,  1.36it/s]\u001b[A\n","Iteration:  96% 1778/1851 [21:51<00:53,  1.36it/s]\u001b[A\n","Iteration:  96% 1779/1851 [21:51<00:53,  1.36it/s]\u001b[A\n","Iteration:  96% 1780/1851 [21:52<00:52,  1.36it/s]\u001b[A\n","Iteration:  96% 1781/1851 [21:53<00:51,  1.36it/s]\u001b[A\n","Iteration:  96% 1782/1851 [21:54<00:50,  1.36it/s]\u001b[A\n","Iteration:  96% 1783/1851 [21:54<00:50,  1.36it/s]\u001b[A\n","Iteration:  96% 1784/1851 [21:55<00:49,  1.36it/s]\u001b[A\n","Iteration:  96% 1785/1851 [21:56<00:48,  1.36it/s]\u001b[A\n","Iteration:  96% 1786/1851 [21:57<00:47,  1.36it/s]\u001b[A\n","Iteration:  97% 1787/1851 [21:57<00:46,  1.36it/s]\u001b[A\n","Iteration:  97% 1788/1851 [21:58<00:46,  1.36it/s]\u001b[A\n","Iteration:  97% 1789/1851 [21:59<00:45,  1.36it/s]\u001b[A\n","Iteration:  97% 1790/1851 [22:00<00:44,  1.36it/s]\u001b[A\n","Iteration:  97% 1791/1851 [22:00<00:44,  1.36it/s]\u001b[A\n","Iteration:  97% 1792/1851 [22:01<00:43,  1.36it/s]\u001b[A\n","Iteration:  97% 1793/1851 [22:02<00:42,  1.36it/s]\u001b[A\n","Iteration:  97% 1794/1851 [22:03<00:42,  1.35it/s]\u001b[A\n","Iteration:  97% 1795/1851 [22:03<00:41,  1.36it/s]\u001b[A\n","Iteration:  97% 1796/1851 [22:04<00:40,  1.36it/s]\u001b[A\n","Iteration:  97% 1797/1851 [22:05<00:39,  1.36it/s]\u001b[A\n","Iteration:  97% 1798/1851 [22:05<00:38,  1.36it/s]\u001b[A\n","Iteration:  97% 1799/1851 [22:06<00:38,  1.36it/s]\u001b[A\n","Iteration:  97% 1800/1851 [22:07<00:37,  1.36it/s]\u001b[A\n","Iteration:  97% 1801/1851 [22:08<00:36,  1.36it/s]\u001b[A\n","Iteration:  97% 1802/1851 [22:08<00:36,  1.36it/s]\u001b[A\n","Iteration:  97% 1803/1851 [22:09<00:35,  1.36it/s]\u001b[A\n","Iteration:  97% 1804/1851 [22:10<00:34,  1.36it/s]\u001b[A\n","Iteration:  98% 1805/1851 [22:11<00:33,  1.36it/s]\u001b[A\n","Iteration:  98% 1806/1851 [22:11<00:33,  1.36it/s]\u001b[A\n","Iteration:  98% 1807/1851 [22:12<00:32,  1.36it/s]\u001b[A\n","Iteration:  98% 1808/1851 [22:13<00:31,  1.36it/s]\u001b[A\n","Iteration:  98% 1809/1851 [22:14<00:30,  1.36it/s]\u001b[A\n","Iteration:  98% 1810/1851 [22:14<00:30,  1.35it/s]\u001b[A\n","Iteration:  98% 1811/1851 [22:15<00:29,  1.36it/s]\u001b[A\n","Iteration:  98% 1812/1851 [22:16<00:28,  1.35it/s]\u001b[A\n","Iteration:  98% 1813/1851 [22:17<00:27,  1.36it/s]\u001b[A\n","Iteration:  98% 1814/1851 [22:17<00:27,  1.36it/s]\u001b[A\n","Iteration:  98% 1815/1851 [22:18<00:26,  1.36it/s]\u001b[A\n","Iteration:  98% 1816/1851 [22:19<00:25,  1.36it/s]\u001b[A\n","Iteration:  98% 1817/1851 [22:19<00:25,  1.36it/s]\u001b[A\n","Iteration:  98% 1818/1851 [22:20<00:24,  1.36it/s]\u001b[A\n","Iteration:  98% 1819/1851 [22:21<00:23,  1.36it/s]\u001b[A\n","Iteration:  98% 1820/1851 [22:22<00:22,  1.36it/s]\u001b[A\n","Iteration:  98% 1821/1851 [22:22<00:22,  1.36it/s]\u001b[A\n","Iteration:  98% 1822/1851 [22:23<00:21,  1.35it/s]\u001b[A\n","Iteration:  98% 1823/1851 [22:24<00:20,  1.36it/s]\u001b[A\n","Iteration:  99% 1824/1851 [22:25<00:19,  1.36it/s]\u001b[A\n","Iteration:  99% 1825/1851 [22:25<00:19,  1.36it/s]\u001b[A\n","Iteration:  99% 1826/1851 [22:26<00:18,  1.36it/s]\u001b[A\n","Iteration:  99% 1827/1851 [22:27<00:17,  1.36it/s]\u001b[A\n","Iteration:  99% 1828/1851 [22:28<00:16,  1.36it/s]\u001b[A\n","Iteration:  99% 1829/1851 [22:28<00:16,  1.36it/s]\u001b[A\n","Iteration:  99% 1830/1851 [22:29<00:15,  1.36it/s]\u001b[A\n","Iteration:  99% 1831/1851 [22:30<00:14,  1.36it/s]\u001b[A\n","Iteration:  99% 1832/1851 [22:30<00:13,  1.36it/s]\u001b[A\n","Iteration:  99% 1833/1851 [22:31<00:13,  1.36it/s]\u001b[A\n","Iteration:  99% 1834/1851 [22:32<00:12,  1.36it/s]\u001b[A\n","Iteration:  99% 1835/1851 [22:33<00:11,  1.36it/s]\u001b[A\n","Iteration:  99% 1836/1851 [22:33<00:11,  1.35it/s]\u001b[A\n","Iteration:  99% 1837/1851 [22:34<00:10,  1.35it/s]\u001b[A\n","Iteration:  99% 1838/1851 [22:35<00:09,  1.36it/s]\u001b[A\n","Iteration:  99% 1839/1851 [22:36<00:08,  1.36it/s]\u001b[A\n","Iteration:  99% 1840/1851 [22:36<00:08,  1.36it/s]\u001b[A\n","Iteration:  99% 1841/1851 [22:37<00:07,  1.35it/s]\u001b[A\n","Iteration: 100% 1842/1851 [22:38<00:06,  1.36it/s]\u001b[A\n","Iteration: 100% 1843/1851 [22:39<00:05,  1.36it/s]\u001b[A\n","Iteration: 100% 1844/1851 [22:39<00:05,  1.35it/s]\u001b[A\n","Iteration: 100% 1845/1851 [22:40<00:04,  1.35it/s]\u001b[A\n","Iteration: 100% 1846/1851 [22:41<00:03,  1.36it/s]\u001b[A\n","Iteration: 100% 1847/1851 [22:42<00:02,  1.35it/s]\u001b[A\n","Iteration: 100% 1848/1851 [22:42<00:02,  1.36it/s]\u001b[A\n","Iteration: 100% 1849/1851 [22:43<00:01,  1.35it/s]\u001b[A\n","Iteration: 100% 1850/1851 [22:44<00:00,  1.35it/s]\u001b[A\n","Iteration: 100% 1851/1851 [22:45<00:00,  1.36it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-07-25 12:13:19,733][__main__][DEBUG] - early stop\n","Epoch:   1% 1/100 [53:58<89:03:03, 3238.22s/it]\n"]}]},{"cell_type":"code","source":["!HYDRA_FULL_ERROR=1 python eval.py hydra.job.chdir=False hydra.verbose=True"],"metadata":{"id":"w7sdHHb0uFV-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658753347918,"user_tz":-540,"elapsed":2012010,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"a540d161-7ea7-430c-eeaf-2ef8449f3085"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","eval.py:18: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-07-25 12:13:25,575][HYDRA] Hydra 1.2.0\n","[2022-07-25 12:13:25,575][HYDRA] ===========\n","[2022-07-25 12:13:25,575][HYDRA] Installed Hydra Plugins\n","[2022-07-25 12:13:25,575][HYDRA] ***********************\n","[2022-07-25 12:13:25,575][HYDRA] \tConfigSource:\n","[2022-07-25 12:13:25,575][HYDRA] \t-------------\n","[2022-07-25 12:13:25,575][HYDRA] \t\tFileConfigSource\n","[2022-07-25 12:13:25,575][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-07-25 12:13:25,575][HYDRA] \t\tStructuredConfigSource\n","[2022-07-25 12:13:25,575][HYDRA] \tCompletionPlugin:\n","[2022-07-25 12:13:25,575][HYDRA] \t-----------------\n","[2022-07-25 12:13:25,575][HYDRA] \t\tBashCompletion\n","[2022-07-25 12:13:25,575][HYDRA] \t\tFishCompletion\n","[2022-07-25 12:13:25,575][HYDRA] \t\tZshCompletion\n","[2022-07-25 12:13:25,575][HYDRA] \tLauncher:\n","[2022-07-25 12:13:25,575][HYDRA] \t---------\n","[2022-07-25 12:13:25,575][HYDRA] \t\tBasicLauncher\n","[2022-07-25 12:13:25,575][HYDRA] \tSweeper:\n","[2022-07-25 12:13:25,575][HYDRA] \t--------\n","[2022-07-25 12:13:25,575][HYDRA] \t\tBasicSweeper\n","[2022-07-25 12:13:25,575][HYDRA] \n","[2022-07-25 12:13:25,575][HYDRA] Config search path\n","[2022-07-25 12:13:25,575][HYDRA] ******************\n","[2022-07-25 12:13:25,699][HYDRA] | Provider | Search path                                                           |\n","[2022-07-25 12:13:25,699][HYDRA] ------------------------------------------------------------------------------------\n","[2022-07-25 12:13:25,699][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-07-25 12:13:25,699][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-07-25 12:13:25,699][HYDRA] | schema   | structured://                                                         |\n","[2022-07-25 12:13:25,699][HYDRA] ------------------------------------------------------------------------------------\n","[2022-07-25 12:13:25,768][HYDRA] \n","[2022-07-25 12:13:25,768][HYDRA] Defaults Tree\n","[2022-07-25 12:13:25,768][HYDRA] *************\n","[2022-07-25 12:13:25,768][HYDRA] <root>:\n","[2022-07-25 12:13:25,768][HYDRA]   hydra/config:\n","[2022-07-25 12:13:25,768][HYDRA]     hydra/output: default\n","[2022-07-25 12:13:25,768][HYDRA]     hydra/launcher: basic\n","[2022-07-25 12:13:25,768][HYDRA]     hydra/sweeper: basic\n","[2022-07-25 12:13:25,768][HYDRA]     hydra/help: default\n","[2022-07-25 12:13:25,768][HYDRA]     hydra/hydra_help: default\n","[2022-07-25 12:13:25,768][HYDRA]     hydra/hydra_logging: default\n","[2022-07-25 12:13:25,768][HYDRA]     hydra/job_logging: default\n","[2022-07-25 12:13:25,768][HYDRA]     hydra/callbacks: null\n","[2022-07-25 12:13:25,769][HYDRA]     hydra/env: default\n","[2022-07-25 12:13:25,769][HYDRA]     _self_\n","[2022-07-25 12:13:25,769][HYDRA]   config:\n","[2022-07-25 12:13:25,769][HYDRA]     data/FB15kET\n","[2022-07-25 12:13:25,769][HYDRA]     model/JointGT\n","[2022-07-25 12:13:25,769][HYDRA]     _self_\n","[2022-07-25 12:13:25,838][HYDRA] \n","[2022-07-25 12:13:25,839][HYDRA] Defaults List\n","[2022-07-25 12:13:25,839][HYDRA] *************\n","[2022-07-25 12:13:25,839][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-07-25 12:13:25,839][HYDRA] ------------------------------------------------------------------------------\n","[2022-07-25 12:13:25,839][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-07-25 12:13:25,839][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-07-25 12:13:25,839][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-07-25 12:13:25,839][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-07-25 12:13:25,839][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-07-25 12:13:25,839][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-07-25 12:13:25,839][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-07-25 12:13:25,839][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-07-25 12:13:25,839][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-07-25 12:13:25,839][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-07-25 12:13:25,839][HYDRA] | model/JointGT               | model               | False  | config       |\n","[2022-07-25 12:13:25,839][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-07-25 12:13:25,839][HYDRA] ------------------------------------------------------------------------------\n","[2022-07-25 12:13:25,958][HYDRA] Config\n","[2022-07-25 12:13:25,959][HYDRA] ******\n","[2022-07-25 12:13:25,964][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: false\n","  remove_under_score: false\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: JointGT\n","  tokenizer_path: pretrain_model/jointgt_bart\n","  model_path: pretrain_model/jointgt_bart\n","  train_dataset: ET_train.txt\n","  pretrained_model: Bart\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_node_length: 50\n","  max_edge_length: 60\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 128\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 1.0e-05\n","  valid:\n","    valid_dataset: ET_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 128\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_test.txt\n","    save_outputs: true\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-07-25 12:13:26,025][transformers.tokenization_utils_base][INFO] - Model name 'pretrain_model/jointgt_bart' not found in model shortcut name list (facebook/bart-base, facebook/bart-large, facebook/bart-large-mnli, facebook/bart-large-cnn, facebook/bart-large-xsum, yjernite/bart_eli5). Assuming 'pretrain_model/jointgt_bart' is a path, a model identifier, or url to a directory containing tokenizer files.\n","2022-07-25 12:13:26,025 INFO     Model name 'pretrain_model/jointgt_bart' not found in model shortcut name list (facebook/bart-base, facebook/bart-large, facebook/bart-large-mnli, facebook/bart-large-cnn, facebook/bart-large-xsum, yjernite/bart_eli5). Assuming 'pretrain_model/jointgt_bart' is a path, a model identifier, or url to a directory containing tokenizer files.\n","[2022-07-25 12:13:26,026][transformers.tokenization_utils_base][INFO] - Didn't find file pretrain_model/jointgt_bart/added_tokens.json. We won't load it.\n","2022-07-25 12:13:26,026 INFO     Didn't find file pretrain_model/jointgt_bart/added_tokens.json. We won't load it.\n","[2022-07-25 12:13:26,027][transformers.tokenization_utils_base][INFO] - Didn't find file pretrain_model/jointgt_bart/special_tokens_map.json. We won't load it.\n","2022-07-25 12:13:26,027 INFO     Didn't find file pretrain_model/jointgt_bart/special_tokens_map.json. We won't load it.\n","[2022-07-25 12:13:26,027][transformers.tokenization_utils_base][INFO] - Didn't find file pretrain_model/jointgt_bart/tokenizer_config.json. We won't load it.\n","2022-07-25 12:13:26,027 INFO     Didn't find file pretrain_model/jointgt_bart/tokenizer_config.json. We won't load it.\n","[2022-07-25 12:13:26,028][transformers.tokenization_utils_base][INFO] - Didn't find file pretrain_model/jointgt_bart/tokenizer.json. We won't load it.\n","2022-07-25 12:13:26,028 INFO     Didn't find file pretrain_model/jointgt_bart/tokenizer.json. We won't load it.\n","[2022-07-25 12:13:26,028][transformers.tokenization_utils_base][INFO] - loading file pretrain_model/jointgt_bart/vocab.json\n","2022-07-25 12:13:26,028 INFO     loading file pretrain_model/jointgt_bart/vocab.json\n","[2022-07-25 12:13:26,028][transformers.tokenization_utils_base][INFO] - loading file pretrain_model/jointgt_bart/merges.txt\n","2022-07-25 12:13:26,028 INFO     loading file pretrain_model/jointgt_bart/merges.txt\n","[2022-07-25 12:13:26,028][transformers.tokenization_utils_base][INFO] - loading file None\n","2022-07-25 12:13:26,028 INFO     loading file None\n","[2022-07-25 12:13:26,029][transformers.tokenization_utils_base][INFO] - loading file None\n","2022-07-25 12:13:26,029 INFO     loading file None\n","[2022-07-25 12:13:26,029][transformers.tokenization_utils_base][INFO] - loading file None\n","2022-07-25 12:13:26,029 INFO     loading file None\n","[2022-07-25 12:13:26,029][transformers.tokenization_utils_base][INFO] - loading file None\n","2022-07-25 12:13:26,029 INFO     loading file None\n","[2022-07-25 12:13:33,532][transformers.configuration_utils][INFO] - loading configuration file pretrain_model/jointgt_bart/config.json\n","2022-07-25 12:13:33,532 INFO     loading configuration file pretrain_model/jointgt_bart/config.json\n","[2022-07-25 12:13:33,533][transformers.configuration_utils][INFO] - Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"MyBartPretrain\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","2022-07-25 12:13:33,533 INFO     Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"MyBartPretrain\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-07-25 12:13:33,534][transformers.modeling_utils][INFO] - loading weights file pretrain_model/jointgt_bart/pytorch_model.bin\n","2022-07-25 12:13:33,534 INFO     loading weights file pretrain_model/jointgt_bart/pytorch_model.bin\n","[2022-07-25 12:13:40,091][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing MyBartForConditionalGeneration.\n","\n","2022-07-25 12:13:40,091 INFO     All model checkpoint weights were used when initializing MyBartForConditionalGeneration.\n","\n","[2022-07-25 12:13:40,091][transformers.modeling_utils][INFO] - All the weights of MyBartForConditionalGeneration were initialized from the model checkpoint at pretrain_model/jointgt_bart.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use MyBartForConditionalGeneration for predictions without further training.\n","2022-07-25 12:13:40,091 INFO     All the weights of MyBartForConditionalGeneration were initialized from the model checkpoint at pretrain_model/jointgt_bart.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use MyBartForConditionalGeneration for predictions without further training.\n","[2022-07-25 12:13:44,952][root][DEBUG] - Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","2022-07-25 12:13:44,952 DEBUG    Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","[2022-07-25 12:13:44,953][root][DEBUG] - Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","2022-07-25 12:13:44,953 DEBUG    Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-07-25 12:13:44,953][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,953 DEBUG    Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,953][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,953 DEBUG    Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,953][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,953 DEBUG    Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,953][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,953 DEBUG    Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,954][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,954 DEBUG    Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,954][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,954 DEBUG    Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,954][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,954 DEBUG    Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,954][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,954 DEBUG    Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,954][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,954 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,955][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,955 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,955][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,955 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,955][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,955 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,955][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,955 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,955][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,955 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,956][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,956 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,956][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,956 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,956][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,956 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,956][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,956 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,956][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,956 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,957][root][DEBUG] - Parameter model.model.encoder.layers.0.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,957 DEBUG    Parameter model.model.encoder.layers.0.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,957][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,957 DEBUG    Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,957][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,957 DEBUG    Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,957][root][DEBUG] - Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:44,957 DEBUG    Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:44,957][root][DEBUG] - Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:44,957 DEBUG    Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:44,958][root][DEBUG] - Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:44,958 DEBUG    Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:44,958][root][DEBUG] - Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,958 DEBUG    Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,958][root][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,958 DEBUG    Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,958][root][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,958 DEBUG    Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,958][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,958 DEBUG    Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,959][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,959 DEBUG    Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,959][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,959 DEBUG    Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,959][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,959 DEBUG    Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,959][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,959 DEBUG    Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,959][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,959 DEBUG    Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,959][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,959 DEBUG    Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,960][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,960 DEBUG    Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,960][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,960 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,960][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,960 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,960][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,960 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,961][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,961 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,961][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,961 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,961][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,961 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,961][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,961 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,961][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,961 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,962][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,962 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,962][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,962 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,962][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,962 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,962][root][DEBUG] - Parameter model.model.encoder.layers.1.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,962 DEBUG    Parameter model.model.encoder.layers.1.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,962][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,962 DEBUG    Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,963][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,963 DEBUG    Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,963][root][DEBUG] - Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:44,963 DEBUG    Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:44,963][root][DEBUG] - Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:44,963 DEBUG    Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:44,963][root][DEBUG] - Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:44,963 DEBUG    Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:44,963][root][DEBUG] - Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,963 DEBUG    Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,964][root][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,964 DEBUG    Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,964][root][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,964 DEBUG    Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,964][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,964 DEBUG    Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,964][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,964 DEBUG    Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,964][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,964 DEBUG    Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:44,965][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:44,965 DEBUG    Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:44,965][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:44,965 DEBUG    Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,050][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,050 DEBUG    Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,050][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,050 DEBUG    Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,050][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,050 DEBUG    Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,050][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,050 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,051][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,051 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,051][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,051 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,051][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,051 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,051][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,051 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,052][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,052 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,052][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,052 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,052][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,052 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,052][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,052 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,053][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,053 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,053][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,053 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,053][root][DEBUG] - Parameter model.model.encoder.layers.2.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,053 DEBUG    Parameter model.model.encoder.layers.2.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,053][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,053 DEBUG    Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,053][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,053 DEBUG    Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,054][root][DEBUG] - Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,054 DEBUG    Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,054][root][DEBUG] - Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,054 DEBUG    Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,054][root][DEBUG] - Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,054 DEBUG    Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,054][root][DEBUG] - Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,054 DEBUG    Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,054][root][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,054 DEBUG    Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,055][root][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,055 DEBUG    Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,055][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,055 DEBUG    Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,055][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,055 DEBUG    Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,055][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,055 DEBUG    Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,055][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,055 DEBUG    Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,056][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,056 DEBUG    Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,056][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,056 DEBUG    Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,056][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,056 DEBUG    Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,056][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,056 DEBUG    Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,056][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,056 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,057][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,057 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,057][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,057 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,057][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,057 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,057][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,057 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,057][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,057 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,057][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,057 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,058][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,058 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,058][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,058 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,058][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,058 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,058][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,058 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,058][root][DEBUG] - Parameter model.model.encoder.layers.3.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,058 DEBUG    Parameter model.model.encoder.layers.3.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,058][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,058 DEBUG    Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,058][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,058 DEBUG    Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,058][root][DEBUG] - Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,058 DEBUG    Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,059][root][DEBUG] - Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,059 DEBUG    Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,059][root][DEBUG] - Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,059 DEBUG    Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,059][root][DEBUG] - Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,059 DEBUG    Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,059][root][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,059 DEBUG    Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,059][root][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,059 DEBUG    Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,059][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,059 DEBUG    Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,059][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,059 DEBUG    Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,059][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,059 DEBUG    Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,060][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,060 DEBUG    Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,060][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,060 DEBUG    Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,060][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,060 DEBUG    Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,060][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,060 DEBUG    Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,060][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,060 DEBUG    Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,060][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,060 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,060][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,060 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,060][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,060 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,061][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,061 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,061][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,061 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,061][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,061 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,061][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,061 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,061][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,061 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,061][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,061 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,061][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,061 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,061][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,061 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,061][root][DEBUG] - Parameter model.model.encoder.layers.4.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,061 DEBUG    Parameter model.model.encoder.layers.4.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,062][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,062 DEBUG    Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,062][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,062 DEBUG    Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,062][root][DEBUG] - Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,062 DEBUG    Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,062][root][DEBUG] - Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,062 DEBUG    Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,062][root][DEBUG] - Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,062 DEBUG    Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,062][root][DEBUG] - Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,062 DEBUG    Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,062][root][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,062 DEBUG    Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,062][root][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,062 DEBUG    Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,063][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,063 DEBUG    Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,063][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,063 DEBUG    Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,063][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,063 DEBUG    Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,063][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,063 DEBUG    Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,063][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,063 DEBUG    Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,063][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,063 DEBUG    Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,063][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,063 DEBUG    Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,063][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,063 DEBUG    Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,064][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,064 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,064][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,064 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,064][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,064 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,064][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,064 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,064][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,064 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,157][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,157 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,157][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,157 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.rel_v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,157][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,157 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.rel_v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,157][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,157 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.rel_k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,158][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,158 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.rel_k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,158][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,158 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,158][root][DEBUG] - Parameter model.model.encoder.layers.5.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,158 DEBUG    Parameter model.model.encoder.layers.5.self_struc_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,158][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,158 DEBUG    Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,158][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,158 DEBUG    Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,159][root][DEBUG] - Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,159 DEBUG    Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,159][root][DEBUG] - Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,159 DEBUG    Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,159][root][DEBUG] - Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,159 DEBUG    Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,159][root][DEBUG] - Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,159 DEBUG    Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,160][root][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,160 DEBUG    Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,160][root][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,160 DEBUG    Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,160][root][DEBUG] - Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,160 DEBUG    Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,160][root][DEBUG] - Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,160 DEBUG    Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,160][root][DEBUG] - Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","2022-07-25 12:13:45,160 DEBUG    Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-07-25 12:13:45,161][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,161 DEBUG    Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,161][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,161 DEBUG    Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,161][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,161 DEBUG    Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,161][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,161 DEBUG    Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,161][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,161 DEBUG    Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,162][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,162 DEBUG    Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,162][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,162 DEBUG    Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,162][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,162 DEBUG    Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,162][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,162 DEBUG    Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,162][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,162 DEBUG    Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,163][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,163 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,163][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,163 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,163][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,163 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,163][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,163 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,163][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,163 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,164][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,164 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,164][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,164 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,164][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,164 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,164][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,164 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,164][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,164 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,164][root][DEBUG] - Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,164 DEBUG    Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,165][root][DEBUG] - Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,165 DEBUG    Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,165][root][DEBUG] - Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,165 DEBUG    Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,165][root][DEBUG] - Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,165 DEBUG    Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,165][root][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,165 DEBUG    Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,165][root][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,165 DEBUG    Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,166][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,166 DEBUG    Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,166][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,166 DEBUG    Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,166][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,166 DEBUG    Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,166][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,166 DEBUG    Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,166][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,166 DEBUG    Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,167][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,167 DEBUG    Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,167][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,167 DEBUG    Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,167][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,167 DEBUG    Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,167][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,167 DEBUG    Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,167][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,167 DEBUG    Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,168][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,168 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,168][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,168 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,168][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,168 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,168][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,168 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,168][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,168 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,168][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,168 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,169][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,169 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,169][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,169 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,169][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,169 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,169][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,169 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,169][root][DEBUG] - Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,169 DEBUG    Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,170][root][DEBUG] - Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,170 DEBUG    Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,170][root][DEBUG] - Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,170 DEBUG    Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,170][root][DEBUG] - Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,170 DEBUG    Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,170][root][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,170 DEBUG    Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,170][root][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,170 DEBUG    Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,171][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,171 DEBUG    Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,171][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,171 DEBUG    Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,171][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,171 DEBUG    Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,171][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,171 DEBUG    Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,171][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,171 DEBUG    Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,171][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,171 DEBUG    Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,172][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,172 DEBUG    Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,172][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,172 DEBUG    Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,172][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,172 DEBUG    Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,172][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,172 DEBUG    Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,173][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,173 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,173][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,173 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,173][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,173 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,173][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,173 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,262][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,262 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,262][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,262 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,263][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,263 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,263][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,263 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,264][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,264 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,264][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,264 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,265][root][DEBUG] - Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,265 DEBUG    Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,265][root][DEBUG] - Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,265 DEBUG    Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,265][root][DEBUG] - Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,265 DEBUG    Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,265][root][DEBUG] - Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,265 DEBUG    Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,266][root][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,266 DEBUG    Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,266][root][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,266 DEBUG    Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,266][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,266 DEBUG    Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,266][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,266 DEBUG    Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,266][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,266 DEBUG    Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,266][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,266 DEBUG    Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,266][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,266 DEBUG    Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,266][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,266 DEBUG    Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,266][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,266 DEBUG    Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,267][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,267 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,268][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,268 DEBUG    Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,269][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,269 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,270][root][DEBUG] - Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,270 DEBUG    Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,271][root][DEBUG] - Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,271 DEBUG    Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,271][root][DEBUG] - Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,271 DEBUG    Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,271][root][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,271 DEBUG    Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,271][root][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,271 DEBUG    Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,271][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,271 DEBUG    Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,271][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,271 DEBUG    Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,366][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,366 DEBUG    Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,366][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,366 DEBUG    Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,367][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,367 DEBUG    Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,367][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,367 DEBUG    Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,367][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,367 DEBUG    Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,367][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,367 DEBUG    Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,367][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,367 DEBUG    Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,368][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,368 DEBUG    Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,368][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,368 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,368][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,368 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,368][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,368 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,369][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,369 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,369][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,369 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,369][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,369 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,369][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-07-25 12:13:45,369 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-07-25 12:13:45,369][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,369 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,369][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,369 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,370][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,370 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,370][root][DEBUG] - Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-07-25 12:13:45,370 DEBUG    Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-07-25 12:13:45,370][root][DEBUG] - Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-07-25 12:13:45,370 DEBUG    Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-07-25 12:13:45,370][root][DEBUG] - Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-07-25 12:13:45,370 DEBUG    Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-07-25 12:13:45,370][root][DEBUG] - Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,370 DEBUG    Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,371][root][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,371 DEBUG    Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,371][root][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,371 DEBUG    Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,371][root][DEBUG] - Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,371 DEBUG    Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-07-25 12:13:45,371][root][DEBUG] - Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","2022-07-25 12:13:45,371 DEBUG    Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","Iteration:   0% 0/1082 [00:00<?, ?it/s]The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","Iteration: 100% 1082/1082 [33:04<00:00,  1.83s/it]\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","[2022-07-25 12:46:54,906][root][INFO] - test data set : ET_test.txt\n","2022-07-25 12:46:54,906 INFO     test data set : ET_test.txt\n","[2022-07-25 12:46:54,907][root][INFO] - N-grams: 1-1.0745779847224004e-07, 2-2.552452676e-315, 3-2.552452676e-315, 4-2.552452676e-315\n","2022-07-25 12:46:54,907 INFO     N-grams: 1-1.0745779847224004e-07, 2-2.552452676e-315, 3-2.552452676e-315, 4-2.552452676e-315\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"xiRHm4nruPw9"},"execution_count":null,"outputs":[]}]}