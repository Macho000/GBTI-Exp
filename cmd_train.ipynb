{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1660313965390,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"dymDs0Po0aES","outputId":"974ce289-d7e3-4bc3-b9f7-1f11dcf1037d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Aug 12 14:17:11 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    33W /  70W |      0MiB / 15109MiB |     36%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1660303322333,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"EfCxDoEXuzgg","outputId":"5493d892-9abd-4596-fe43-f019bf40b93b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","source":["!python -m pip install bert-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bOeGCnRF9Cs","executionInfo":{"status":"ok","timestamp":1660303331498,"user_tz":-540,"elapsed":7938,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"b6933d28-7324-49be-a892-3313081c103a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: bert-score in /usr/local/lib/python3.7/dist-packages (0.3.11)\n","Collecting transformers>=3.0.0numpy\n","  Using cached transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert-score) (2.23.0)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (4.64.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert-score) (3.2.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert-score) (21.3)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.3.5)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.9.0+cu111)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert-score) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert-score) (4.1.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (0.8.1)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (3.7.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert-score) (3.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (1.4.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (3.0.4)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.8.0rc4\n","    Uninstalling tokenizers-0.8.0rc4:\n","      Successfully uninstalled tokenizers-0.8.0rc4\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 3.0.0\n","    Uninstalling transformers-3.0.0:\n","      Successfully uninstalled transformers-3.0.0\n","Successfully installed tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31144,"status":"ok","timestamp":1660303362632,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"mshVPsrku0kd","outputId":"fa3a1fb3-67b9-4553-affd-a3863d4359a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.8.0\n","  Using cached torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","Collecting transformers==3.0.0\n","  Using cached transformers-3.0.0-py3-none-any.whl (754 kB)\n","Collecting torch_scatter==2.0.4\n","  Using cached torch_scatter-2.0.4-cp37-cp37m-linux_x86_64.whl\n","Requirement already satisfied: dgl==0.5.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.5.3)\n","Requirement already satisfied: hydra==2.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2.4)\n","Requirement already satisfied: omegaconf==2.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (4.1.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.2)\n","Collecting tokenizers==0.8.0-rc4\n","  Using cached tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (0.0.53)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (4.64.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (0.1.97)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (3.7.1)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (2.6.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (1.7.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.2.2->-r requirements.txt (line 7)) (6.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.2.2->-r requirements.txt (line 7)) (4.9.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.15.0)\n","Installing collected packages: tokenizers, transformers, torch-scatter, torch\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.21.1\n","    Uninstalling transformers-4.21.1:\n","      Successfully uninstalled transformers-4.21.1\n","  Attempting uninstall: torch-scatter\n","    Found existing installation: torch-scatter 2.0.9\n","    Uninstalling torch-scatter-2.0.9:\n","      Successfully uninstalled torch-scatter-2.0.9\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu111\n","    Uninstalling torch-1.9.0+cu111:\n","      Successfully uninstalled torch-1.9.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.8.0 which is incompatible.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.9.0 requires torch==1.9.0, but you have torch 1.8.0 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed tokenizers-0.8.0rc4 torch-1.8.0 torch-scatter-2.0.4 transformers-3.0.0\n"]}],"source":["!python -m pip install -r requirements.txt"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83210,"status":"ok","timestamp":1660303445828,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"G8LmQt_jcvSZ","outputId":"1553d85c-e648-457c-c406-e8a96f4572ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","tcmalloc: large alloc 2041348096 bytes == 0x284c000 @  0x7fb2a10691e7 0x4a3940 0x5b438c 0x5ea94f 0x5939cb 0x594cd3 0x5d0ecb 0x59aeca 0x515655 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x59c019\n","tcmalloc: large alloc 2041348096 bytes == 0x7c314000 @  0x7fb2a10691e7 0x4a3940 0x5b438c 0x64cfe7 0x59b076 0x515655 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576\n","tcmalloc: large alloc 2041348096 bytes == 0xf5ddc000 @  0x7fb2a10691e7 0x4a3940 0x59b5e2 0x63a515 0x63bd66 0x63be16 0x59afff 0x515655 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576\n","tcmalloc: large alloc 2041348096 bytes == 0x16f8a4000 @  0x7fb2a10691e7 0x4a3940 0x59b6f0 0x59f499 0x4d3969 0x512147 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x593dd7 0x511e2c 0x593dd7 0x511e2c\n","tcmalloc: large alloc 2041348096 bytes == 0x1e9c1a000 @  0x7fb2a10691e7 0x4a3940 0x5b438c 0x638cb2 0x59644e 0x5946b8 0x515600 0x549e0e 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6\n","tcmalloc: large alloc 2041348096 bytes == 0x1e9c1a000 @  0x7fb2a10691e7 0x4a3940 0x5b438c 0x5ea94f 0x5939cb 0x594cd3 0x5d0ecb 0x59aeca 0x515655 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x59c019\n","tcmalloc: large alloc 2551685120 bytes == 0x284c000 @  0x7fb2a106a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce\n","  Using cached https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","Requirement already satisfied: torchvision==0.10.0+cu111 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n","Requirement already satisfied: torchaudio===0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.8.0\n","    Uninstalling torch-1.8.0:\n","      Successfully uninstalled torch-1.8.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.9.0+cu111 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111\n"]}],"source":["!python -m pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":904,"status":"ok","timestamp":1660303446706,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"JJqgY88ou7Qp","outputId":"ca5df370-f309-4092-a6a0-f97fe095372a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch-scatter 2.0.4\n","Uninstalling torch-scatter-2.0.4:\n","  Successfully uninstalled torch-scatter-2.0.4\n"]}],"source":["!python -m pip uninstall torch-scatter -y"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4561,"status":"ok","timestamp":1660303451263,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"7c7V5B7yc9Cc","outputId":"d04fea31-d6e9-41c6-ff90-18ce318e2803"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html\n","Collecting torch-scatter\n","  Using cached https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n","Installing collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.9\n"]}],"source":["!python -m pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2077,"status":"ok","timestamp":1660303453327,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"l2wm30u-c-i0","outputId":"b7edd031-3969-4c3d-dff4-43e163aa81ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.9\n"]}],"source":["!python -c \"import torch_scatter; print(torch_scatter.__version__)\""]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2641,"status":"ok","timestamp":1660303455958,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"GgPMOQSL4HVZ","outputId":"67042d15-299a-4fc6-d7a3-a90b40aff89d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (1.2.0)\n","Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.2.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core) (21.3)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.9.0)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core) (3.0.9)\n"]}],"source":["!pip install hydra-core --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1660203016899,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"FT5vluqcNpey","outputId":"fb6b583e-b039-4cef-cbf9-2bf97cee58d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZROa2w4NUfm"},"outputs":[],"source":["!python preprocess.py --dataset FB15kET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDB7erFzN4St"},"outputs":[],"source":["!python preprocess.py --dataset YAGO43kET"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":555,"status":"ok","timestamp":1660312851082,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"hsnRA4_pUSzk","outputId":"6f9619f3-d250-4085-ac82-06e5cd761bdd"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"586hjT34u-VB","outputId":"bb808301-d740-41a7-f8ed-244cbafc7539","executionInfo":{"status":"ok","timestamp":1660313237332,"user_tz":-540,"elapsed":385723,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","run.py:18: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-12 13:58:41,860][HYDRA] Hydra 1.2.0\n","[2022-08-12 13:58:41,860][HYDRA] ===========\n","[2022-08-12 13:58:41,860][HYDRA] Installed Hydra Plugins\n","[2022-08-12 13:58:41,860][HYDRA] ***********************\n","[2022-08-12 13:58:41,860][HYDRA] \tConfigSource:\n","[2022-08-12 13:58:41,860][HYDRA] \t-------------\n","[2022-08-12 13:58:41,860][HYDRA] \t\tFileConfigSource\n","[2022-08-12 13:58:41,860][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-12 13:58:41,860][HYDRA] \t\tStructuredConfigSource\n","[2022-08-12 13:58:41,860][HYDRA] \tCompletionPlugin:\n","[2022-08-12 13:58:41,860][HYDRA] \t-----------------\n","[2022-08-12 13:58:41,860][HYDRA] \t\tBashCompletion\n","[2022-08-12 13:58:41,860][HYDRA] \t\tFishCompletion\n","[2022-08-12 13:58:41,860][HYDRA] \t\tZshCompletion\n","[2022-08-12 13:58:41,861][HYDRA] \tLauncher:\n","[2022-08-12 13:58:41,861][HYDRA] \t---------\n","[2022-08-12 13:58:41,861][HYDRA] \t\tBasicLauncher\n","[2022-08-12 13:58:41,861][HYDRA] \tSweeper:\n","[2022-08-12 13:58:41,861][HYDRA] \t--------\n","[2022-08-12 13:58:41,861][HYDRA] \t\tBasicSweeper\n","[2022-08-12 13:58:41,861][HYDRA] \n","[2022-08-12 13:58:41,861][HYDRA] Config search path\n","[2022-08-12 13:58:41,861][HYDRA] ******************\n","[2022-08-12 13:58:41,984][HYDRA] | Provider | Search path                                                           |\n","[2022-08-12 13:58:41,984][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-12 13:58:41,984][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-12 13:58:41,984][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-12 13:58:41,985][HYDRA] | schema   | structured://                                                         |\n","[2022-08-12 13:58:41,985][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-12 13:58:42,054][HYDRA] \n","[2022-08-12 13:58:42,054][HYDRA] Defaults Tree\n","[2022-08-12 13:58:42,054][HYDRA] *************\n","[2022-08-12 13:58:42,054][HYDRA] <root>:\n","[2022-08-12 13:58:42,054][HYDRA]   hydra/config:\n","[2022-08-12 13:58:42,055][HYDRA]     hydra/output: default\n","[2022-08-12 13:58:42,055][HYDRA]     hydra/launcher: basic\n","[2022-08-12 13:58:42,055][HYDRA]     hydra/sweeper: basic\n","[2022-08-12 13:58:42,055][HYDRA]     hydra/help: default\n","[2022-08-12 13:58:42,055][HYDRA]     hydra/hydra_help: default\n","[2022-08-12 13:58:42,055][HYDRA]     hydra/hydra_logging: default\n","[2022-08-12 13:58:42,055][HYDRA]     hydra/job_logging: default\n","[2022-08-12 13:58:42,055][HYDRA]     hydra/callbacks: null\n","[2022-08-12 13:58:42,055][HYDRA]     hydra/env: default\n","[2022-08-12 13:58:42,055][HYDRA]     _self_\n","[2022-08-12 13:58:42,056][HYDRA]   config:\n","[2022-08-12 13:58:42,056][HYDRA]     data/FB15kET\n","[2022-08-12 13:58:42,056][HYDRA]     model/Bart\n","[2022-08-12 13:58:42,056][HYDRA]     _self_\n","[2022-08-12 13:58:42,125][HYDRA] \n","[2022-08-12 13:58:42,125][HYDRA] Defaults List\n","[2022-08-12 13:58:42,125][HYDRA] *************\n","[2022-08-12 13:58:42,125][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-12 13:58:42,125][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-12 13:58:42,125][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-12 13:58:42,125][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-12 13:58:42,125][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-12 13:58:42,125][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-12 13:58:42,125][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-12 13:58:42,125][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-12 13:58:42,125][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-12 13:58:42,125][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-12 13:58:42,125][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-12 13:58:42,125][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-08-12 13:58:42,125][HYDRA] | model/Bart                  | model               | False  | config       |\n","[2022-08-12 13:58:42,125][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-12 13:58:42,125][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-12 13:58:42,240][HYDRA] Config\n","[2022-08-12 13:58:42,240][HYDRA] ******\n","[2022-08-12 13:58:42,244][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: true\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: Bart\n","  train_dataset: ET_1_1_train.txt\n","  pretrained_model: facebook/bart-base\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 256\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0005\n","  valid:\n","    valid_dataset: ET_1_1_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 256\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_1_1_test.txt\n","    save_outputs: true\n","    max_output_length: 128\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: save/FB15kET/ET_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-12 13:58:42,304][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 13:58:42,686][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-12 13:58:42,690][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 13:58:43,066][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-12 13:58:43,068][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-12 13:58:43,068][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-12 13:58:57,791][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 13:58:58,170][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 0\n","[2022-08-12 13:58:58,172][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","[2022-08-12 13:58:58,173][transformers.configuration_utils][INFO] - Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\",\n","    \"BartForConditionalGeneration\",\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-12 13:58:58,175][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-12 13:58:58,228][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-12 13:58:58,229][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","[2022-08-12 13:59:01,276][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","[2022-08-12 13:59:01,277][transformers.modeling_utils][INFO] - All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","[2022-08-12 13:59:06,145][__main__][DEBUG] - Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","[2022-08-12 13:59:06,145][__main__][DEBUG] - Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-12 13:59:06,145][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,145][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,145][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,146][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,147][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,148][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,149][__main__][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,150][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,151][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,152][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,153][__main__][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,154][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,155][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,156][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,218][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,218][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,218][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,219][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,219][__main__][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,219][__main__][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,219][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,219][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,220][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,220][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,220][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,220][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,220][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,220][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,221][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,221][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,221][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,221][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,221][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,221][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,222][__main__][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,223][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,224][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,225][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,226][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,227][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,228][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,229][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,230][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,231][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 13:59:06,232][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 13:59:06,232][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 13:59:06,232][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,232][__main__][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,232][__main__][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,232][__main__][DEBUG] - Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 13:59:06,232][__main__][DEBUG] - Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","Epoch:   0% 0/100 [00:00<?, ?it/s][2022-08-12 13:59:06,325][__main__][DEBUG] - Starting training!\n","\n","Iteration:   0% 0/106 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-12 13:59:07,121][__main__][DEBUG] - batch 0: tensor([[    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        ...,\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2],\n","        [    0,   646, 44143,  ..., 29015,   742,     2]], device='cuda:0') \n","[2022-08-12 13:59:07,123][__main__][DEBUG] - batch 1: tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') \n","[2022-08-12 13:59:07,127][__main__][DEBUG] - batch 2: tensor([[    0,  2354,  4120,  ...,     1,     1,     1],\n","        [    0,  1612,   165,  ...,     1,     1,     1],\n","        [    0,  2354,  4120,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 10320,     2,  ...,     1,     1,     1],\n","        [    0, 11581,     2,  ...,     1,     1,     1],\n","        [    0,  2354,  4120,  ...,     1,     1,     1]], device='cuda:0') \n","[2022-08-12 13:59:07,137][__main__][DEBUG] - batch 3: tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0') \n","\n","Iteration:   1% 1/106 [00:01<02:30,  1.44s/it]\u001b[A\n","Iteration:   2% 2/106 [00:02<01:36,  1.08it/s]\u001b[A\n","Iteration:   3% 3/106 [00:02<01:18,  1.31it/s]\u001b[A\n","Iteration:   4% 4/106 [00:03<01:09,  1.46it/s]\u001b[A\n","Iteration:   5% 5/106 [00:03<01:04,  1.56it/s]\u001b[A\n","Iteration:   6% 6/106 [00:04<01:01,  1.62it/s]\u001b[A\n","Iteration:   7% 7/106 [00:04<00:59,  1.67it/s]\u001b[A\n","Iteration:   8% 8/106 [00:05<00:57,  1.70it/s]\u001b[A\n","Iteration:   8% 9/106 [00:05<00:56,  1.71it/s]\u001b[A\n","Iteration:   9% 10/106 [00:06<00:55,  1.73it/s]\u001b[A\n","Iteration:  10% 11/106 [00:07<00:54,  1.74it/s]\u001b[A\n","Iteration:  11% 12/106 [00:07<00:53,  1.74it/s]\u001b[A\n","Iteration:  12% 13/106 [00:08<00:53,  1.75it/s]\u001b[A\n","Iteration:  13% 14/106 [00:08<00:52,  1.75it/s]\u001b[A\n","Iteration:  14% 15/106 [00:09<00:51,  1.75it/s]\u001b[A\n","Iteration:  15% 16/106 [00:09<00:51,  1.75it/s]\u001b[A\n","Iteration:  16% 17/106 [00:10<00:50,  1.76it/s]\u001b[A\n","Iteration:  17% 18/106 [00:11<00:50,  1.76it/s]\u001b[A\n","Iteration:  18% 19/106 [00:11<00:49,  1.76it/s]\u001b[A\n","Iteration:  19% 20/106 [00:12<00:48,  1.76it/s]\u001b[A\n","Iteration:  20% 21/106 [00:12<00:48,  1.75it/s]\u001b[A\n","Iteration:  21% 22/106 [00:13<00:48,  1.75it/s]\u001b[A\n","Iteration:  22% 23/106 [00:13<00:47,  1.75it/s]\u001b[A\n","Iteration:  23% 24/106 [00:14<00:46,  1.75it/s]\u001b[A\n","Iteration:  24% 25/106 [00:15<00:46,  1.74it/s]\u001b[A\n","Iteration:  25% 26/106 [00:15<00:45,  1.74it/s]\u001b[A\n","Iteration:  25% 27/106 [00:16<00:45,  1.74it/s]\u001b[A\n","Iteration:  26% 28/106 [00:16<00:44,  1.74it/s]\u001b[A\n","Iteration:  27% 29/106 [00:17<00:44,  1.74it/s]\u001b[A\n","Iteration:  28% 30/106 [00:17<00:43,  1.74it/s]\u001b[A\n","Iteration:  29% 31/106 [00:18<00:43,  1.74it/s]\u001b[A\n","Iteration:  30% 32/106 [00:19<00:42,  1.73it/s]\u001b[A\n","Iteration:  31% 33/106 [00:19<00:42,  1.73it/s]\u001b[A\n","Iteration:  32% 34/106 [00:20<00:41,  1.73it/s]\u001b[A\n","Iteration:  33% 35/106 [00:20<00:41,  1.73it/s]\u001b[A\n","Iteration:  34% 36/106 [00:21<00:40,  1.73it/s]\u001b[A\n","Iteration:  35% 37/106 [00:22<00:39,  1.73it/s]\u001b[A\n","Iteration:  36% 38/106 [00:22<00:39,  1.73it/s]\u001b[A\n","Iteration:  37% 39/106 [00:23<00:38,  1.72it/s]\u001b[A\n","Iteration:  38% 40/106 [00:23<00:38,  1.72it/s]\u001b[A\n","Iteration:  39% 41/106 [00:24<00:37,  1.72it/s]\u001b[A\n","Iteration:  40% 42/106 [00:24<00:37,  1.72it/s]\u001b[A\n","Iteration:  41% 43/106 [00:25<00:36,  1.72it/s]\u001b[A\n","Iteration:  42% 44/106 [00:26<00:36,  1.72it/s]\u001b[A\n","Iteration:  42% 45/106 [00:26<00:35,  1.71it/s]\u001b[A\n","Iteration:  43% 46/106 [00:27<00:35,  1.71it/s]\u001b[A\n","Iteration:  44% 47/106 [00:27<00:34,  1.71it/s]\u001b[A\n","Iteration:  45% 48/106 [00:28<00:33,  1.71it/s]\u001b[A\n","Iteration:  46% 49/106 [00:29<00:33,  1.71it/s]\u001b[A\n","Iteration:  47% 50/106 [00:29<00:32,  1.71it/s]\u001b[A\n","Iteration:  48% 51/106 [00:30<00:32,  1.71it/s]\u001b[A\n","Iteration:  49% 52/106 [00:30<00:31,  1.71it/s]\u001b[A\n","Iteration:  50% 53/106 [00:31<00:30,  1.71it/s]\u001b[A\n","Iteration:  51% 54/106 [00:31<00:30,  1.71it/s]\u001b[A\n","Iteration:  52% 55/106 [00:32<00:29,  1.71it/s]\u001b[A\n","Iteration:  53% 56/106 [00:33<00:29,  1.70it/s]\u001b[A\n","Iteration:  54% 57/106 [00:33<00:28,  1.70it/s]\u001b[A\n","Iteration:  55% 58/106 [00:34<00:28,  1.70it/s]\u001b[A\n","Iteration:  56% 59/106 [00:34<00:27,  1.70it/s]\u001b[A\n","Iteration:  57% 60/106 [00:35<00:27,  1.70it/s]\u001b[A\n","Iteration:  58% 61/106 [00:36<00:26,  1.70it/s]\u001b[A\n","Iteration:  58% 62/106 [00:36<00:25,  1.70it/s]\u001b[A\n","Iteration:  59% 63/106 [00:37<00:25,  1.69it/s]\u001b[A\n","Iteration:  60% 64/106 [00:37<00:24,  1.69it/s]\u001b[A\n","Iteration:  61% 65/106 [00:38<00:24,  1.69it/s]\u001b[A\n","Iteration:  62% 66/106 [00:39<00:23,  1.69it/s]\u001b[A\n","Iteration:  63% 67/106 [00:39<00:23,  1.68it/s]\u001b[A\n","Iteration:  64% 68/106 [00:40<00:22,  1.68it/s]\u001b[A\n","Iteration:  65% 69/106 [00:40<00:21,  1.69it/s]\u001b[A\n","Iteration:  66% 70/106 [00:41<00:21,  1.68it/s]\u001b[A\n","Iteration:  67% 71/106 [00:42<00:20,  1.68it/s]\u001b[A\n","Iteration:  68% 72/106 [00:42<00:20,  1.68it/s]\u001b[A\n","Iteration:  69% 73/106 [00:43<00:19,  1.68it/s]\u001b[A\n","Iteration:  70% 74/106 [00:43<00:19,  1.68it/s]\u001b[A\n","Iteration:  71% 75/106 [00:44<00:18,  1.67it/s]\u001b[A\n","Iteration:  72% 76/106 [00:45<00:17,  1.68it/s]\u001b[A\n","Iteration:  73% 77/106 [00:45<00:17,  1.68it/s]\u001b[A\n","Iteration:  74% 78/106 [00:46<00:16,  1.68it/s]\u001b[A\n","Iteration:  75% 79/106 [00:46<00:16,  1.68it/s]\u001b[A\n","Iteration:  75% 80/106 [00:47<00:15,  1.68it/s]\u001b[A\n","Iteration:  76% 81/106 [00:48<00:14,  1.67it/s]\u001b[A\n","Iteration:  77% 82/106 [00:48<00:14,  1.67it/s]\u001b[A\n","Iteration:  78% 83/106 [00:49<00:13,  1.67it/s]\u001b[A\n","Iteration:  79% 84/106 [00:49<00:13,  1.67it/s]\u001b[A\n","Iteration:  80% 85/106 [00:50<00:12,  1.67it/s]\u001b[A\n","Iteration:  81% 86/106 [00:51<00:12,  1.66it/s]\u001b[A\n","Iteration:  82% 87/106 [00:51<00:11,  1.66it/s]\u001b[A\n","Iteration:  83% 88/106 [00:52<00:10,  1.66it/s]\u001b[A\n","Iteration:  84% 89/106 [00:52<00:10,  1.66it/s]\u001b[A\n","Iteration:  85% 90/106 [00:53<00:09,  1.66it/s]\u001b[A\n","Iteration:  86% 91/106 [00:54<00:09,  1.65it/s]\u001b[A\n","Iteration:  87% 92/106 [00:54<00:08,  1.65it/s]\u001b[A\n","Iteration:  88% 93/106 [00:55<00:07,  1.65it/s]\u001b[A\n","Iteration:  89% 94/106 [00:55<00:07,  1.64it/s]\u001b[A\n","Iteration:  90% 95/106 [00:56<00:06,  1.65it/s]\u001b[A\n","Iteration:  91% 96/106 [00:57<00:06,  1.64it/s]\u001b[A\n","Iteration:  92% 97/106 [00:57<00:05,  1.64it/s]\u001b[A\n","Iteration:  92% 98/106 [00:58<00:04,  1.64it/s]\u001b[A\n","Iteration:  93% 99/106 [00:58<00:04,  1.64it/s]\u001b[A\n","Iteration:  94% 100/106 [00:59<00:03,  1.64it/s]\u001b[A\n","Iteration:  95% 101/106 [01:00<00:03,  1.64it/s]\u001b[A\n","Iteration:  96% 102/106 [01:00<00:02,  1.64it/s]\u001b[A\n","Iteration:  97% 103/106 [01:01<00:01,  1.64it/s]\u001b[A\n","Iteration:  98% 104/106 [01:01<00:01,  1.63it/s]\u001b[A\n","Iteration:  99% 105/106 [01:02<00:00,  1.63it/s]\u001b[A\n","Iteration: 100% 106/106 [01:03<00:00,  1.67it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","[2022-08-12 14:02:01,189][__main__][DEBUG] - epoch is 0\n","[2022-08-12 14:02:01,190][__main__][DEBUG] - validation loss is tensor(0.1729, device='cuda:0')\n","Epoch:   1% 1/100 [02:56<4:51:15, 176.52s/it]\n","Iteration:   0% 0/106 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\n","Iteration:   1% 1/106 [00:01<02:21,  1.35s/it]\u001b[A\n","Iteration:   2% 2/106 [00:01<01:36,  1.08it/s]\u001b[A\n","Iteration:   3% 3/106 [00:02<01:21,  1.26it/s]\u001b[A\n","Iteration:   4% 4/106 [00:03<01:13,  1.39it/s]\u001b[A\n","Iteration:   5% 5/106 [00:03<01:09,  1.45it/s]\u001b[A\n","Iteration:   6% 6/106 [00:04<01:06,  1.51it/s]\u001b[A\n","Iteration:   7% 7/106 [00:05<01:04,  1.53it/s]\u001b[A\n","Iteration:   8% 8/106 [00:05<01:02,  1.56it/s]\u001b[A\n","Iteration:   8% 9/106 [00:06<01:01,  1.57it/s]\u001b[A\n","Iteration:   9% 10/106 [00:06<01:00,  1.58it/s]\u001b[A\n","Iteration:  10% 11/106 [00:07<00:59,  1.58it/s]\u001b[A\n","Iteration:  11% 12/106 [00:08<00:59,  1.59it/s]\u001b[A\n","Iteration:  12% 13/106 [00:08<00:58,  1.60it/s]\u001b[A\n","Iteration:  13% 14/106 [00:09<00:57,  1.61it/s]\u001b[A\n","Iteration:  14% 15/106 [00:10<00:56,  1.60it/s]\u001b[A\n","Iteration:  15% 16/106 [00:10<00:56,  1.61it/s]\u001b[A\n","Iteration:  16% 17/106 [00:11<00:55,  1.60it/s]\u001b[A\n","Iteration:  17% 18/106 [00:11<00:54,  1.61it/s]\u001b[A\n","Iteration:  18% 19/106 [00:12<00:54,  1.60it/s]\u001b[A\n","Iteration:  19% 20/106 [00:13<00:53,  1.60it/s]\u001b[A\n","Iteration:  20% 21/106 [00:13<00:53,  1.60it/s]\u001b[A\n","Iteration:  21% 22/106 [00:14<00:52,  1.60it/s]\u001b[A\n","Iteration:  22% 23/106 [00:15<00:51,  1.60it/s]\u001b[A\n","Iteration:  23% 24/106 [00:15<00:51,  1.60it/s]\u001b[A\n","Iteration:  24% 25/106 [00:16<00:50,  1.60it/s]\u001b[A\n","Iteration:  25% 26/106 [00:16<00:49,  1.60it/s]\u001b[A\n","Iteration:  25% 27/106 [00:17<00:49,  1.61it/s]\u001b[A\n","Iteration:  26% 28/106 [00:18<00:48,  1.60it/s]\u001b[A\n","Iteration:  27% 29/106 [00:18<00:47,  1.61it/s]\u001b[A\n","Iteration:  28% 30/106 [00:19<00:47,  1.60it/s]\u001b[A\n","Iteration:  29% 31/106 [00:20<00:46,  1.61it/s]\u001b[A\n","Iteration:  30% 32/106 [00:20<00:46,  1.60it/s]\u001b[A\n","Iteration:  31% 33/106 [00:21<00:45,  1.60it/s]\u001b[A\n","Iteration:  32% 34/106 [00:21<00:45,  1.60it/s]\u001b[A\n","Iteration:  33% 35/106 [00:22<00:44,  1.61it/s]\u001b[A\n","Iteration:  34% 36/106 [00:23<00:43,  1.60it/s]\u001b[A\n","Iteration:  35% 37/106 [00:23<00:42,  1.61it/s]\u001b[A\n","Iteration:  36% 38/106 [00:24<00:42,  1.60it/s]\u001b[A\n","Iteration:  37% 39/106 [00:25<00:41,  1.60it/s]\u001b[A\n","Iteration:  38% 40/106 [00:25<00:41,  1.60it/s]\u001b[A\n","Iteration:  39% 41/106 [00:26<00:40,  1.60it/s]\u001b[A\n","Iteration:  40% 42/106 [00:26<00:39,  1.60it/s]\u001b[A\n","Iteration:  41% 43/106 [00:27<00:39,  1.60it/s]\u001b[A\n","Iteration:  42% 44/106 [00:28<00:38,  1.60it/s]\u001b[A\n","Iteration:  42% 45/106 [00:28<00:38,  1.60it/s]\u001b[A\n","Iteration:  43% 46/106 [00:29<00:37,  1.60it/s]\u001b[A\n","Iteration:  44% 47/106 [00:30<00:36,  1.60it/s]\u001b[A\n","Iteration:  45% 48/106 [00:30<00:36,  1.60it/s]\u001b[A\n","Iteration:  46% 49/106 [00:31<00:35,  1.60it/s]\u001b[A\n","Iteration:  47% 50/106 [00:31<00:35,  1.60it/s]\u001b[A\n","Iteration:  48% 51/106 [00:32<00:34,  1.60it/s]\u001b[A\n","Iteration:  49% 52/106 [00:33<00:33,  1.60it/s]\u001b[A\n","Iteration:  50% 53/106 [00:33<00:33,  1.60it/s]\u001b[A\n","Iteration:  51% 54/106 [00:34<00:32,  1.60it/s]\u001b[A\n","Iteration:  52% 55/106 [00:35<00:31,  1.60it/s]\u001b[A\n","Iteration:  53% 56/106 [00:35<00:31,  1.60it/s]\u001b[A\n","Iteration:  54% 57/106 [00:36<00:30,  1.60it/s]\u001b[A\n","Iteration:  55% 58/106 [00:36<00:29,  1.60it/s]\u001b[A\n","Iteration:  56% 59/106 [00:37<00:29,  1.60it/s]\u001b[A\n","Iteration:  57% 60/106 [00:38<00:28,  1.60it/s]\u001b[A\n","Iteration:  58% 61/106 [00:38<00:27,  1.61it/s]\u001b[A\n","Iteration:  58% 62/106 [00:39<00:27,  1.61it/s]\u001b[A\n","Iteration:  59% 63/106 [00:40<00:26,  1.60it/s]\u001b[A\n","Iteration:  60% 64/106 [00:40<00:26,  1.60it/s]\u001b[A\n","Iteration:  61% 65/106 [00:41<00:25,  1.60it/s]\u001b[A\n","Iteration:  62% 66/106 [00:41<00:24,  1.61it/s]\u001b[A\n","Iteration:  63% 67/106 [00:42<00:24,  1.61it/s]\u001b[A\n","Iteration:  64% 68/106 [00:43<00:23,  1.61it/s]\u001b[A\n","Iteration:  65% 69/106 [00:43<00:22,  1.61it/s]\u001b[A\n","Iteration:  66% 70/106 [00:44<00:22,  1.61it/s]\u001b[A\n","Iteration:  67% 71/106 [00:45<00:21,  1.61it/s]\u001b[A\n","Iteration:  68% 72/106 [00:45<00:21,  1.60it/s]\u001b[A\n","Iteration:  69% 73/106 [00:46<00:20,  1.60it/s]\u001b[A\n","Iteration:  70% 74/106 [00:46<00:19,  1.61it/s]\u001b[A\n","Iteration:  71% 75/106 [00:47<00:19,  1.60it/s]\u001b[A\n","Iteration:  72% 76/106 [00:48<00:18,  1.61it/s]\u001b[A\n","Iteration:  73% 77/106 [00:48<00:18,  1.60it/s]\u001b[A\n","Iteration:  74% 78/106 [00:49<00:17,  1.60it/s]\u001b[A\n","Iteration:  75% 79/106 [00:49<00:16,  1.60it/s]\u001b[A\n","Iteration:  75% 80/106 [00:50<00:16,  1.60it/s]\u001b[A\n","Iteration:  76% 81/106 [00:51<00:15,  1.61it/s]\u001b[A\n","Iteration:  77% 82/106 [00:51<00:14,  1.60it/s]\u001b[A\n","Iteration:  78% 83/106 [00:52<00:14,  1.61it/s]\u001b[A\n","Iteration:  79% 84/106 [00:53<00:13,  1.60it/s]\u001b[A\n","Iteration:  80% 85/106 [00:53<00:13,  1.61it/s]\u001b[A\n","Iteration:  81% 86/106 [00:54<00:12,  1.61it/s]\u001b[A\n","Iteration:  82% 87/106 [00:54<00:11,  1.61it/s]\u001b[A\n","Iteration:  83% 88/106 [00:55<00:11,  1.60it/s]\u001b[A\n","Iteration:  84% 89/106 [00:56<00:10,  1.61it/s]\u001b[A\n","Iteration:  85% 90/106 [00:56<00:09,  1.60it/s]\u001b[A\n","Iteration:  86% 91/106 [00:57<00:09,  1.60it/s]\u001b[A\n","Iteration:  87% 92/106 [00:58<00:08,  1.60it/s]\u001b[A\n","Iteration:  88% 93/106 [00:58<00:08,  1.60it/s]\u001b[A\n","Iteration:  89% 94/106 [00:59<00:07,  1.61it/s]\u001b[A\n","Iteration:  90% 95/106 [00:59<00:06,  1.60it/s]\u001b[A\n","Iteration:  91% 96/106 [01:00<00:06,  1.60it/s]\u001b[A\n","Iteration:  92% 97/106 [01:01<00:05,  1.60it/s]\u001b[A\n","Iteration:  92% 98/106 [01:01<00:04,  1.61it/s]\u001b[A\n","Iteration:  93% 99/106 [01:02<00:04,  1.60it/s]\u001b[A\n","Iteration:  94% 100/106 [01:03<00:03,  1.60it/s]\u001b[A\n","Iteration:  95% 101/106 [01:03<00:03,  1.60it/s]\u001b[A\n","Iteration:  96% 102/106 [01:04<00:02,  1.60it/s]\u001b[A\n","Iteration:  97% 103/106 [01:04<00:01,  1.60it/s]\u001b[A\n","Iteration:  98% 104/106 [01:05<00:01,  1.61it/s]\u001b[A\n","Iteration:  99% 105/106 [01:06<00:00,  1.60it/s]\u001b[A\n","Iteration: 100% 106/106 [01:06<00:00,  1.58it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-12 14:05:01,347][__main__][DEBUG] - early stop\n","Epoch:   1% 1/100 [05:55<9:45:47, 355.02s/it]\n"]}],"source":["!HYDRA_FULL_ERROR=1 python run.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"w7sdHHb0uFV-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660313965388,"user_tz":-540,"elapsed":728069,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"56a1618a-b556-479b-8c2f-9c5833808793"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","eval.py:21: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-12 14:05:07,506][HYDRA] Hydra 1.2.0\n","[2022-08-12 14:05:07,506][HYDRA] ===========\n","[2022-08-12 14:05:07,506][HYDRA] Installed Hydra Plugins\n","[2022-08-12 14:05:07,506][HYDRA] ***********************\n","[2022-08-12 14:05:07,506][HYDRA] \tConfigSource:\n","[2022-08-12 14:05:07,506][HYDRA] \t-------------\n","[2022-08-12 14:05:07,506][HYDRA] \t\tFileConfigSource\n","[2022-08-12 14:05:07,506][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-12 14:05:07,506][HYDRA] \t\tStructuredConfigSource\n","[2022-08-12 14:05:07,506][HYDRA] \tCompletionPlugin:\n","[2022-08-12 14:05:07,506][HYDRA] \t-----------------\n","[2022-08-12 14:05:07,507][HYDRA] \t\tBashCompletion\n","[2022-08-12 14:05:07,507][HYDRA] \t\tFishCompletion\n","[2022-08-12 14:05:07,507][HYDRA] \t\tZshCompletion\n","[2022-08-12 14:05:07,507][HYDRA] \tLauncher:\n","[2022-08-12 14:05:07,507][HYDRA] \t---------\n","[2022-08-12 14:05:07,507][HYDRA] \t\tBasicLauncher\n","[2022-08-12 14:05:07,507][HYDRA] \tSweeper:\n","[2022-08-12 14:05:07,507][HYDRA] \t--------\n","[2022-08-12 14:05:07,507][HYDRA] \t\tBasicSweeper\n","[2022-08-12 14:05:07,507][HYDRA] \n","[2022-08-12 14:05:07,507][HYDRA] Config search path\n","[2022-08-12 14:05:07,507][HYDRA] ******************\n","[2022-08-12 14:05:07,795][HYDRA] | Provider | Search path                                                           |\n","[2022-08-12 14:05:07,795][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-12 14:05:07,795][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-12 14:05:07,795][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-12 14:05:07,795][HYDRA] | schema   | structured://                                                         |\n","[2022-08-12 14:05:07,795][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-12 14:05:07,866][HYDRA] \n","[2022-08-12 14:05:07,866][HYDRA] Defaults Tree\n","[2022-08-12 14:05:07,866][HYDRA] *************\n","[2022-08-12 14:05:07,866][HYDRA] <root>:\n","[2022-08-12 14:05:07,866][HYDRA]   hydra/config:\n","[2022-08-12 14:05:07,867][HYDRA]     hydra/output: default\n","[2022-08-12 14:05:07,867][HYDRA]     hydra/launcher: basic\n","[2022-08-12 14:05:07,867][HYDRA]     hydra/sweeper: basic\n","[2022-08-12 14:05:07,867][HYDRA]     hydra/help: default\n","[2022-08-12 14:05:07,867][HYDRA]     hydra/hydra_help: default\n","[2022-08-12 14:05:07,867][HYDRA]     hydra/hydra_logging: default\n","[2022-08-12 14:05:07,867][HYDRA]     hydra/job_logging: default\n","[2022-08-12 14:05:07,867][HYDRA]     hydra/callbacks: null\n","[2022-08-12 14:05:07,867][HYDRA]     hydra/env: default\n","[2022-08-12 14:05:07,867][HYDRA]     _self_\n","[2022-08-12 14:05:07,867][HYDRA]   config:\n","[2022-08-12 14:05:07,867][HYDRA]     data/FB15kET\n","[2022-08-12 14:05:07,867][HYDRA]     model/Bart\n","[2022-08-12 14:05:07,867][HYDRA]     _self_\n","[2022-08-12 14:05:07,935][HYDRA] \n","[2022-08-12 14:05:07,935][HYDRA] Defaults List\n","[2022-08-12 14:05:07,935][HYDRA] *************\n","[2022-08-12 14:05:07,935][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-12 14:05:07,935][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-12 14:05:07,935][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-12 14:05:07,935][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-12 14:05:07,935][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-12 14:05:07,935][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-12 14:05:07,935][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-12 14:05:07,935][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-12 14:05:07,935][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-12 14:05:07,935][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-12 14:05:07,935][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-12 14:05:07,935][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-08-12 14:05:07,935][HYDRA] | model/Bart                  | model               | False  | config       |\n","[2022-08-12 14:05:07,935][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-12 14:05:07,935][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-12 14:05:08,050][HYDRA] Config\n","[2022-08-12 14:05:08,050][HYDRA] ******\n","[2022-08-12 14:05:08,054][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: true\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: Bart\n","  train_dataset: ET_1_1_train.txt\n","  pretrained_model: facebook/bart-base\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 256\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0005\n","  valid:\n","    valid_dataset: ET_1_1_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 256\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_1_1_test.txt\n","    save_outputs: true\n","    max_output_length: 128\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: save/FB15kET/ET_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-12 14:05:08,116][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-12 14:05:08,116 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 14:05:08,495][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","2022-08-12 14:05:08,495 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-12 14:05:08,498][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-12 14:05:08,498 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 14:05:08,872][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","2022-08-12 14:05:08,872 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-12 14:05:08,874][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-12 14:05:08,874 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-12 14:05:08,874][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-12 14:05:08,874 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-12 14:05:16,432][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-12 14:05:16,432 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 14:05:16,815][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 0\n","2022-08-12 14:05:16,815 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 0\n","[2022-08-12 14:05:16,817][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","2022-08-12 14:05:16,817 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","[2022-08-12 14:05:16,818][transformers.configuration_utils][INFO] - Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\",\n","    \"BartForConditionalGeneration\",\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-12 14:05:16,818 INFO     Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\",\n","    \"BartForConditionalGeneration\",\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-12 14:05:16,821][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-12 14:05:16,821 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-12 14:05:16,877][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-12 14:05:16,877 DEBUG    https://cdn.huggingface.co:443 \"HEAD /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-12 14:05:16,878][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","2022-08-12 14:05:16,878 INFO     loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","[2022-08-12 14:05:20,026][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","2022-08-12 14:05:20,026 INFO     All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","[2022-08-12 14:05:20,027][transformers.modeling_utils][INFO] - All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","2022-08-12 14:05:20,027 INFO     All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","[2022-08-12 14:05:24,874][root][DEBUG] - Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","2022-08-12 14:05:24,874 DEBUG    Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","[2022-08-12 14:05:24,875][root][DEBUG] - Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","2022-08-12 14:05:24,875 DEBUG    Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-12 14:05:24,875][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,875 DEBUG    Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,875][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,875 DEBUG    Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,875][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,875 DEBUG    Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,875][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,875 DEBUG    Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,876][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,876 DEBUG    Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,876][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,876 DEBUG    Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,876][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,876 DEBUG    Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,876][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,876 DEBUG    Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,876][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,876 DEBUG    Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,876][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,876 DEBUG    Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,876][root][DEBUG] - Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,876 DEBUG    Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,877][root][DEBUG] - Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,877 DEBUG    Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,877][root][DEBUG] - Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,877 DEBUG    Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,877][root][DEBUG] - Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,877 DEBUG    Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,877][root][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,877 DEBUG    Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,877][root][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,877 DEBUG    Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,877][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,877 DEBUG    Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,877][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,877 DEBUG    Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,878][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,878 DEBUG    Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,878][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,878 DEBUG    Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,878][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,878 DEBUG    Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,878][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,878 DEBUG    Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,878][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,878 DEBUG    Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,878][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,878 DEBUG    Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,878][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,878 DEBUG    Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,878][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,878 DEBUG    Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,879][root][DEBUG] - Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,879 DEBUG    Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,879][root][DEBUG] - Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,879 DEBUG    Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,879][root][DEBUG] - Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,879 DEBUG    Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,879][root][DEBUG] - Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,879 DEBUG    Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,879][root][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,879 DEBUG    Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,879][root][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,879 DEBUG    Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,879][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,879 DEBUG    Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,880][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,880 DEBUG    Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,880][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,880 DEBUG    Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,880][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,880 DEBUG    Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,880][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,880 DEBUG    Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,880][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,880 DEBUG    Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,880][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,880 DEBUG    Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,880][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,880 DEBUG    Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,881][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,881 DEBUG    Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,881][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,881 DEBUG    Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,881][root][DEBUG] - Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,881 DEBUG    Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,881][root][DEBUG] - Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,881 DEBUG    Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,881][root][DEBUG] - Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,881 DEBUG    Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,881][root][DEBUG] - Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,881 DEBUG    Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,881][root][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,881 DEBUG    Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,881][root][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,881 DEBUG    Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,882][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,882 DEBUG    Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,882][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,882 DEBUG    Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,882][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,882 DEBUG    Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,882][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,882 DEBUG    Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,882][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,882 DEBUG    Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,882][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,882 DEBUG    Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,882][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,882 DEBUG    Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,883][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,883 DEBUG    Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,883][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,883 DEBUG    Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,883][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,883 DEBUG    Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,883][root][DEBUG] - Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,883 DEBUG    Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,883][root][DEBUG] - Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,883 DEBUG    Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,883][root][DEBUG] - Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,883 DEBUG    Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,883][root][DEBUG] - Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,883 DEBUG    Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,884][root][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,884 DEBUG    Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,918][root][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,918 DEBUG    Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,919][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,919 DEBUG    Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,919][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,919 DEBUG    Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,919][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,919 DEBUG    Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,919][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,919 DEBUG    Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,919][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,919 DEBUG    Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,920][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,920 DEBUG    Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,920][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,920 DEBUG    Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,920][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,920 DEBUG    Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,920][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,920 DEBUG    Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,920][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,920 DEBUG    Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,921][root][DEBUG] - Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,921 DEBUG    Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,921][root][DEBUG] - Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,921 DEBUG    Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,921][root][DEBUG] - Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,921 DEBUG    Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,921][root][DEBUG] - Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,921 DEBUG    Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,921][root][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,921 DEBUG    Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,922][root][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,922 DEBUG    Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,922][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,922 DEBUG    Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,922][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,922 DEBUG    Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,922][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,922 DEBUG    Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,922][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,922 DEBUG    Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,922][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,922 DEBUG    Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,923][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,923 DEBUG    Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,923][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,923 DEBUG    Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,923][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,923 DEBUG    Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,923][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,923 DEBUG    Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,923][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,923 DEBUG    Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,924][root][DEBUG] - Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,924 DEBUG    Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,924][root][DEBUG] - Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,924 DEBUG    Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,924][root][DEBUG] - Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,924 DEBUG    Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,924][root][DEBUG] - Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,924 DEBUG    Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,924][root][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,924 DEBUG    Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,924][root][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,924 DEBUG    Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,925][root][DEBUG] - Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,925 DEBUG    Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,925][root][DEBUG] - Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,925 DEBUG    Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,925][root][DEBUG] - Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","2022-08-12 14:05:24,925 DEBUG    Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-12 14:05:24,925][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,925 DEBUG    Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,925][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,925 DEBUG    Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,925][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,925 DEBUG    Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,926][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,926 DEBUG    Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,926][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,926 DEBUG    Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,926][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,926 DEBUG    Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,926][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,926 DEBUG    Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,926][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,926 DEBUG    Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,926][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,926 DEBUG    Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,927][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,927 DEBUG    Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,927][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,927 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,927][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,927 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,927][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,927 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,927][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,927 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,928][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,928 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,928][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,928 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,928][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,928 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,928][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,928 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,928][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,928 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,928][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,928 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,929][root][DEBUG] - Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,929 DEBUG    Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,929][root][DEBUG] - Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,929 DEBUG    Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,929][root][DEBUG] - Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,929 DEBUG    Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,929][root][DEBUG] - Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,929 DEBUG    Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,929][root][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,929 DEBUG    Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,929][root][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,929 DEBUG    Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,930][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,930 DEBUG    Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,930][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,930 DEBUG    Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,930][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,930 DEBUG    Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,930][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,930 DEBUG    Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,930][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,930 DEBUG    Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,930][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,930 DEBUG    Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,931][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,931 DEBUG    Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,931][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,931 DEBUG    Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,931][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,931 DEBUG    Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,931][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,931 DEBUG    Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,931][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,931 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,931][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,931 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,932][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,932 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,932][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,932 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,932][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,932 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,932][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,932 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,932][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,932 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,933][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,933 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,933][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,933 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,933][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,933 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,933][root][DEBUG] - Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,933 DEBUG    Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,933][root][DEBUG] - Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,933 DEBUG    Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,933][root][DEBUG] - Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,933 DEBUG    Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,934][root][DEBUG] - Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,934 DEBUG    Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,934][root][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,934 DEBUG    Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,934][root][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,934 DEBUG    Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,934][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,934 DEBUG    Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,934][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,934 DEBUG    Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,934][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,934 DEBUG    Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,935][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,935 DEBUG    Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,935][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,935 DEBUG    Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,935][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,935 DEBUG    Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,935][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,935 DEBUG    Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,935][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,935 DEBUG    Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,935][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,935 DEBUG    Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,936][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,936 DEBUG    Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,936][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,936 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,936][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,936 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,936][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,936 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,936][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,936 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,936][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,936 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,937][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,937 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,937][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,937 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,937][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,937 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,937][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,937 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,937][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,937 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,937][root][DEBUG] - Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,937 DEBUG    Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,938][root][DEBUG] - Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,938 DEBUG    Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,938][root][DEBUG] - Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,938 DEBUG    Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,938][root][DEBUG] - Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,938 DEBUG    Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,938][root][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,938 DEBUG    Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,938][root][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,938 DEBUG    Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,939][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,939 DEBUG    Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,939][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,939 DEBUG    Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,939][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,939 DEBUG    Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,939][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,939 DEBUG    Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,939][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,939 DEBUG    Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,939][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,939 DEBUG    Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,940][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,940 DEBUG    Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,940][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,940 DEBUG    Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,940][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,940 DEBUG    Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,940][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,940 DEBUG    Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,940][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,940 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,940][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,940 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,941][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,941 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,941][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,941 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,941][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,941 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,941][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,941 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,941][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,941 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,941][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,941 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,942][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,942 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,942][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,942 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,942][root][DEBUG] - Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,942 DEBUG    Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,942][root][DEBUG] - Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,942 DEBUG    Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,942][root][DEBUG] - Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,942 DEBUG    Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,942][root][DEBUG] - Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,942 DEBUG    Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,943][root][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,943 DEBUG    Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,943][root][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,943 DEBUG    Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,943][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,943 DEBUG    Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,943][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,943 DEBUG    Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,943][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,943 DEBUG    Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,944][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,944 DEBUG    Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,944][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,944 DEBUG    Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,944][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,944 DEBUG    Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,944][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,944 DEBUG    Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,944][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,944 DEBUG    Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,944][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,944 DEBUG    Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,945][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,945 DEBUG    Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,945][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,945 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,945][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,945 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,945][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,945 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,945][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,945 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,945][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,945 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,946][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,946 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,946][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,946 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,946][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,946 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,946][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,946 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,946][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,946 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,947][root][DEBUG] - Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,947 DEBUG    Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,947][root][DEBUG] - Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,947 DEBUG    Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,947][root][DEBUG] - Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,947 DEBUG    Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,947][root][DEBUG] - Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,947 DEBUG    Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,947][root][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,947 DEBUG    Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,947][root][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,947 DEBUG    Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,948][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,948 DEBUG    Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,948][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,948 DEBUG    Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,948][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,948 DEBUG    Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,948][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,948 DEBUG    Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,948][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,948 DEBUG    Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,948][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,948 DEBUG    Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,949][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,949 DEBUG    Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,949][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,949 DEBUG    Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,949][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,949 DEBUG    Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,949][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,949 DEBUG    Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,949][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,949 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,949][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,949 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,950][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,950 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,950][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,950 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,950][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,950 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,950][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,950 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,950][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-12 14:05:24,950 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-12 14:05:24,950][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,950 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,951][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,951 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,951][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,951 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,951][root][DEBUG] - Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-12 14:05:24,951 DEBUG    Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-12 14:05:24,951][root][DEBUG] - Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-12 14:05:24,951 DEBUG    Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-12 14:05:24,951][root][DEBUG] - Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-12 14:05:24,951 DEBUG    Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-12 14:05:24,951][root][DEBUG] - Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,951 DEBUG    Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,952][root][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,952 DEBUG    Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,952][root][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,952 DEBUG    Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,952][root][DEBUG] - Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,952 DEBUG    Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-12 14:05:24,952][root][DEBUG] - Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","2022-08-12 14:05:24,952 DEBUG    Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","Iteration:   0% 0/573 [00:00<?, ?it/s]The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","Iteration: 100% 573/573 [11:30<00:00,  1.20s/it]\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","[2022-08-12 14:16:57,143][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-12 14:16:57,143 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 14:16:57,531][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-12 14:16:57,531 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-12 14:16:57,533][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-12 14:16:57,533 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-12 14:16:57,534][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-12 14:16:57,534 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-12 14:16:57,535][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-12 14:16:57,535 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 14:16:57,901][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","2022-08-12 14:16:57,901 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-12 14:16:57,904][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-12 14:16:57,904 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 14:16:58,280][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","2022-08-12 14:16:58,280 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-12 14:16:58,282][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-12 14:16:58,282 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-12 14:16:58,282][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-12 14:16:58,282 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-12 14:16:58,364][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-12 14:16:58,364 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-12 14:16:58,735][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-12 14:16:58,735 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-12 14:16:58,737][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-12 14:16:58,737 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-12 14:16:58,738][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-12 14:16:58,738 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-12 14:16:58,740][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-12 14:16:58,740 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-12 14:16:58,793][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-12 14:16:58,793 DEBUG    https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-12 14:16:58,794][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","2022-08-12 14:16:58,794 INFO     loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","[2022-08-12 14:17:07,638][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing RobertaModel.\n","\n","2022-08-12 14:17:07,638 INFO     All model checkpoint weights were used when initializing RobertaModel.\n","\n","[2022-08-12 14:17:07,638][transformers.modeling_utils][INFO] - All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","2022-08-12 14:17:07,638 INFO     All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","calculating scores...\n","computing bert embedding.\n","100% 8/8 [00:00<00:00, 13.09it/s]\n","computing greedy matching.\n","100% 72/72 [00:00<00:00, 135.05it/s]\n","done in 1.15 seconds, 3992.54 sentences/sec\n","[2022-08-12 14:17:09,220][root][INFO] - test data set : ET_1_1_test.txt\n","2022-08-12 14:17:09,220 INFO     test data set : ET_1_1_test.txt\n","[2022-08-12 14:17:09,221][root][INFO] - N-grams: 1-0.04171029668411852, 2-0.008289703315881327, 3-3.698748429717506e-309, 4-3.698748429717506e-309\n","2022-08-12 14:17:09,221 INFO     N-grams: 1-0.04171029668411852, 2-0.008289703315881327, 3-3.698748429717506e-309, 4-3.698748429717506e-309\n","[2022-08-12 14:17:09,221][root][INFO] - BERT-P:0.829924, BERT-R:0.878767, BERT-F1:0.853247\n","2022-08-12 14:17:09,221 INFO     BERT-P:0.829924, BERT-R:0.878767, BERT-F1:0.853247\n"]}],"source":["!HYDRA_FULL_ERROR=1 python eval.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiRHm4nruPw9"},"outputs":[],"source":["!kill $(ps aux | awk '{print $2}')"]},{"cell_type":"code","source":[""],"metadata":{"id":"WPTZiAzwc_WZ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"cmd_train.ipynb","provenance":[],"mount_file_id":"1Mrwlgkjv2G7LOLpOtCehzWxaTRu9sXPA","authorship_tag":"ABX9TyM2dd7XQjK7MtzbhdCWkdas"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}