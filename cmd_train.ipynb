{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1660704318122,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"dymDs0Po0aES","outputId":"04722221-47fc-46ff-ea6b-7c6859868df3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Aug 17 02:43:02 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":435,"status":"ok","timestamp":1660704318533,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"EfCxDoEXuzgg","outputId":"e5552d01-a8ab-47ee-b905-7db5122fc281"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","source":["!python -m pip install bert-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bOeGCnRF9Cs","executionInfo":{"status":"ok","timestamp":1660704328152,"user_tz":-540,"elapsed":9626,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"f5ac027b-e719-449c-bd26-b3c4b11f6df1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bert-score\n","  Downloading bert_score-0.3.11-py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.3.5)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert-score) (21.3)\n","Collecting transformers>=3.0.0numpy\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 10.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert-score) (2.23.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.12.1+cu113)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert-score) (3.2.2)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (4.64.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert-score) (3.0.9)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (1.21.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert-score) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.3 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.8 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 52.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert-score) (3.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (0.11.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2022.6.15)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, bert-score\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed bert-score-0.3.11 huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":445547,"status":"ok","timestamp":1660704773679,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"mshVPsrku0kd","outputId":"741f2e3e-66f2-41ef-dfa2-775fb97a9c95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 12 kB/s \n","\u001b[?25hCollecting transformers==3.0.0\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[K     |████████████████████████████████| 754 kB 41.1 MB/s \n","\u001b[?25hCollecting torch_scatter==2.0.4\n","  Downloading torch_scatter-2.0.4.tar.gz (20 kB)\n","Collecting dgl==0.5.3\n","  Downloading dgl-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 50.9 MB/s \n","\u001b[?25hCollecting hydra==2.4\n","  Downloading Hydra-2.4.tar.gz (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 11.1 MB/s \n","\u001b[?25hCollecting omegaconf==2.2.2\n","  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (4.1.1)\n","Collecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 54.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (3.8.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 68.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (4.64.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 59.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (1.7.3)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (2.6.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.2.2->-r requirements.txt (line 7)) (6.0)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 82.5 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.1.0)\n","Building wheels for collected packages: torch-scatter, hydra, antlr4-python3-runtime, sacremoses\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-scatter: filename=torch_scatter-2.0.4-cp37-cp37m-linux_x86_64.whl size=14800665 sha256=d0fc641675297f937a1c62676bbe8461aacb458079212a8e791f9217ea7ddb84\n","  Stored in directory: /root/.cache/pip/wheels/4a/3d/01/e408ecc11389070cbacee91b70c978bf3557130e9aaa18a95b\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.4-cp37-cp37m-linux_x86_64.whl size=219227 sha256=19c1f2d8487ab04622776ed38d27b516246e093d247498c5d48d7dcbd81a8920\n","  Stored in directory: /root/.cache/pip/wheels/f5/65/98/3603b340344bd22dfe1c809365013fc4d425d83d89c3e2cd17\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=c97fe0f3d0eaa9306a37fbe4b80dc4ee4e42f734409bd2e17405c76579cfa5bb\n","  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=68c8a1731fe5c8d01973f7a71ad87c5af6b3a043daa2c4adba46c37fa6e6aaae\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built torch-scatter hydra antlr4-python3-runtime sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, antlr4-python3-runtime, transformers, torch-scatter, torch, omegaconf, hydra, dgl\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.21.1\n","    Uninstalling transformers-4.21.1:\n","      Successfully uninstalled transformers-4.21.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed antlr4-python3-runtime-4.9.3 dgl-0.5.3 hydra-2.4 omegaconf-2.2.2 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.0rc4 torch-1.8.0 torch-scatter-2.0.4 transformers-3.0.0\n"]}],"source":["!python -m pip install -r requirements.txt"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136452,"status":"ok","timestamp":1660704910118,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"G8LmQt_jcvSZ","outputId":"3940ee8b-2fdc-465b-c350-beafd96d5d9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 1.2 MB/s eta 0:16:34tcmalloc: large alloc 1147494400 bytes == 0x39422000 @  0x7f4917d03615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████▌               | 1055.7 MB 60.0 MB/s eta 0:00:17tcmalloc: large alloc 1434370048 bytes == 0x7da78000 @  0x7f4917d03615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:37tcmalloc: large alloc 1792966656 bytes == 0x28aa000 @  0x7f4917d03615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:05:04tcmalloc: large alloc 2241208320 bytes == 0x6d692000 @  0x7f4917d03615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf2ff4000 @  0x7f4917d021e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2551685120 bytes == 0x1e0f62000 @  0x7f4917d03615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 2041.3 MB 7.1 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 1.2 MB/s \n","\u001b[?25hCollecting torchaudio===0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.8.0\n","    Uninstalling torch-1.8.0:\n","      Successfully uninstalled torch-1.8.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}],"source":["!python -m pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":524,"status":"ok","timestamp":1660704910629,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"JJqgY88ou7Qp","outputId":"689001ea-fb37-4954-98ca-57a0d3b56902"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch-scatter 2.0.4\n","Uninstalling torch-scatter-2.0.4:\n","  Successfully uninstalled torch-scatter-2.0.4\n"]}],"source":["!python -m pip uninstall torch-scatter -y"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4917,"status":"ok","timestamp":1660704915540,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"7c7V5B7yc9Cc","outputId":"c7b1abc8-3fd1-4165-d23c-a445364f17f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 2.7 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.9\n"]}],"source":["!python -m pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1244,"status":"ok","timestamp":1660704916776,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"l2wm30u-c-i0","outputId":"5f648b7a-ea38-43ee-dc32-46b5895512e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.9\n"]}],"source":["!python -c \"import torch_scatter; print(torch_scatter.__version__)\""]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3052,"status":"ok","timestamp":1660704919819,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"GgPMOQSL4HVZ","outputId":"bbab9f7d-2f90-4c81-e91f-2ce78c559075"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.2.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core) (21.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.9.0)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core) (3.0.9)\n","Installing collected packages: hydra-core\n","Successfully installed hydra-core-1.2.0\n"]}],"source":["!pip install hydra-core --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1660203016899,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"FT5vluqcNpey","outputId":"fb6b583e-b039-4cef-cbf9-2bf97cee58d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZROa2w4NUfm"},"outputs":[],"source":["!python preprocess.py --dataset FB15kET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDB7erFzN4St"},"outputs":[],"source":["!python preprocess.py --dataset YAGO43kET"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1660712900341,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"hsnRA4_pUSzk","outputId":"6ebea3aa-bf21-42e4-be73-0e5b906583d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"586hjT34u-VB","outputId":"3402fb46-bc51-4f22-c6cf-5135664a58ae","executionInfo":{"status":"ok","timestamp":1660713524981,"user_tz":-540,"elapsed":623396,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","run.py:18: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-17 05:06:11,095][HYDRA] Hydra 1.2.0\n","[2022-08-17 05:06:11,096][HYDRA] ===========\n","[2022-08-17 05:06:11,096][HYDRA] Installed Hydra Plugins\n","[2022-08-17 05:06:11,096][HYDRA] ***********************\n","[2022-08-17 05:06:11,096][HYDRA] \tConfigSource:\n","[2022-08-17 05:06:11,096][HYDRA] \t-------------\n","[2022-08-17 05:06:11,096][HYDRA] \t\tFileConfigSource\n","[2022-08-17 05:06:11,096][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-17 05:06:11,096][HYDRA] \t\tStructuredConfigSource\n","[2022-08-17 05:06:11,096][HYDRA] \tCompletionPlugin:\n","[2022-08-17 05:06:11,096][HYDRA] \t-----------------\n","[2022-08-17 05:06:11,096][HYDRA] \t\tBashCompletion\n","[2022-08-17 05:06:11,096][HYDRA] \t\tFishCompletion\n","[2022-08-17 05:06:11,096][HYDRA] \t\tZshCompletion\n","[2022-08-17 05:06:11,096][HYDRA] \tLauncher:\n","[2022-08-17 05:06:11,096][HYDRA] \t---------\n","[2022-08-17 05:06:11,096][HYDRA] \t\tBasicLauncher\n","[2022-08-17 05:06:11,096][HYDRA] \tSweeper:\n","[2022-08-17 05:06:11,096][HYDRA] \t--------\n","[2022-08-17 05:06:11,096][HYDRA] \t\tBasicSweeper\n","[2022-08-17 05:06:11,096][HYDRA] \n","[2022-08-17 05:06:11,096][HYDRA] Config search path\n","[2022-08-17 05:06:11,096][HYDRA] ******************\n","[2022-08-17 05:06:11,219][HYDRA] | Provider | Search path                                                           |\n","[2022-08-17 05:06:11,219][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-17 05:06:11,219][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-17 05:06:11,219][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-17 05:06:11,219][HYDRA] | schema   | structured://                                                         |\n","[2022-08-17 05:06:11,219][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-17 05:06:11,285][HYDRA] \n","[2022-08-17 05:06:11,285][HYDRA] Defaults Tree\n","[2022-08-17 05:06:11,285][HYDRA] *************\n","[2022-08-17 05:06:11,285][HYDRA] <root>:\n","[2022-08-17 05:06:11,285][HYDRA]   hydra/config:\n","[2022-08-17 05:06:11,285][HYDRA]     hydra/output: default\n","[2022-08-17 05:06:11,285][HYDRA]     hydra/launcher: basic\n","[2022-08-17 05:06:11,285][HYDRA]     hydra/sweeper: basic\n","[2022-08-17 05:06:11,285][HYDRA]     hydra/help: default\n","[2022-08-17 05:06:11,285][HYDRA]     hydra/hydra_help: default\n","[2022-08-17 05:06:11,286][HYDRA]     hydra/hydra_logging: default\n","[2022-08-17 05:06:11,286][HYDRA]     hydra/job_logging: default\n","[2022-08-17 05:06:11,286][HYDRA]     hydra/callbacks: null\n","[2022-08-17 05:06:11,286][HYDRA]     hydra/env: default\n","[2022-08-17 05:06:11,286][HYDRA]     _self_\n","[2022-08-17 05:06:11,286][HYDRA]   config:\n","[2022-08-17 05:06:11,286][HYDRA]     data/YAGO43kET\n","[2022-08-17 05:06:11,286][HYDRA]     model/Bart\n","[2022-08-17 05:06:11,286][HYDRA]     _self_\n","[2022-08-17 05:06:11,353][HYDRA] \n","[2022-08-17 05:06:11,353][HYDRA] Defaults List\n","[2022-08-17 05:06:11,353][HYDRA] *************\n","[2022-08-17 05:06:11,353][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-17 05:06:11,353][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-17 05:06:11,353][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-17 05:06:11,353][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-17 05:06:11,353][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-17 05:06:11,353][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-17 05:06:11,353][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-17 05:06:11,353][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-17 05:06:11,353][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-17 05:06:11,353][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-17 05:06:11,353][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-17 05:06:11,354][HYDRA] | data/YAGO43kET              | data                | False  | config       |\n","[2022-08-17 05:06:11,354][HYDRA] | model/Bart                  | model               | False  | config       |\n","[2022-08-17 05:06:11,354][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-17 05:06:11,354][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-17 05:06:11,465][HYDRA] Config\n","[2022-08-17 05:06:11,465][HYDRA] ******\n","[2022-08-17 05:06:11,469][HYDRA] data:\n","  name: YAGO43kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  lowest_level: false\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: Bart\n","  train_dataset: ET_1_1_train.txt\n","  pretrained_model: facebook/bart-base\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 256\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_1_1_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 256\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_1_1_test.txt\n","    unobserved_test_dataset: ET_1_1_unobserved_test.txt\n","    save_outputs: true\n","    max_output_length: 128\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: save/FB15kET/ET_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-17 05:06:11,530][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-17 05:06:11,655][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-17 05:06:11,658][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-17 05:06:11,775][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-17 05:06:11,776][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-17 05:06:11,776][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","tcmalloc: large alloc 7651123200 bytes == 0xbfc8000 @  0x7f3d0825ab6b 0x7f3d0827a379 0x7f3c510e926e 0x7f3c510ea9e2 0x7f3c52465e19 0x7f3c52466b67 0x7f3c52843059 0x7f3c52fa7e6a 0x7f3c52f8af8e 0x7f3c52b8fcd5 0x7f3c528470c0 0x7f3c53119e64 0x7f3c52f77ec4 0x7f3c52f8e287 0x7f3c52be9441 0x7f3cf5b58d25 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x593fce 0x5118f8 0x4bc98a 0x532c1b 0x594a96 0x515600 0x549e0e 0x593fce 0x5118f8\n","tcmalloc: large alloc 7651123200 bytes == 0x7f39a336e000 @  0x7f3d0825ab6b 0x7f3d0827a379 0x7f3c510e926e 0x7f3c510ea9e2 0x7f3c52465e19 0x7f3c52466b67 0x7f3c52843059 0x7f3c52fa7e6a 0x7f3c52f8af8e 0x7f3c52b8fcd5 0x7f3c528470c0 0x7f3c53119e64 0x7f3c52f77ec4 0x7f3c52f8e287 0x7f3c52be9441 0x7f3cf5b58d25 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x593fce 0x5118f8 0x4bc98a 0x532c1b 0x594a96 0x515600 0x549e0e 0x593fce 0x5118f8\n","[2022-08-17 05:06:16,972][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-17 05:06:17,100][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 0\n","[2022-08-17 05:06:17,101][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","[2022-08-17 05:06:17,102][transformers.configuration_utils][INFO] - Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\",\n","    \"BartForConditionalGeneration\",\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-17 05:06:17,104][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-17 05:06:17,216][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-17 05:06:17,218][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","[2022-08-17 05:06:20,406][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","[2022-08-17 05:06:20,406][transformers.modeling_utils][INFO] - All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","[2022-08-17 05:06:24,201][__main__][DEBUG] - Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","[2022-08-17 05:06:24,202][__main__][DEBUG] - Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-17 05:06:24,202][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,202][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,202][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,203][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,203][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,203][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,203][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,203][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,203][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,203][__main__][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,203][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,204][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,204][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,204][__main__][DEBUG] - Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,204][__main__][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,204][__main__][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,204][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,204][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,205][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,205][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,205][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,205][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,205][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,205][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,206][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,206][__main__][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,206][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,206][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,206][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,206][__main__][DEBUG] - Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,206][__main__][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,206][__main__][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,207][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,207][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,207][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,207][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,207][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,207][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,207][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,207][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,208][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,208][__main__][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,208][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,208][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,208][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,208][__main__][DEBUG] - Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,208][__main__][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,208][__main__][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,209][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,209][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,209][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,209][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,209][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,209][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,209][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,209][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,210][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,210][__main__][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,210][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,210][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,210][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,210][__main__][DEBUG] - Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,210][__main__][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,210][__main__][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,210][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,211][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,211][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,211][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,211][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,211][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,211][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,211][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,211][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,212][__main__][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,212][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,212][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,212][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,212][__main__][DEBUG] - Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,212][__main__][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,212][__main__][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,213][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,213][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,213][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,213][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,213][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,213][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,214][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,214][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,214][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,214][__main__][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,214][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,214][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,215][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,215][__main__][DEBUG] - Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,215][__main__][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,215][__main__][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,215][__main__][DEBUG] - Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,215][__main__][DEBUG] - Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,216][__main__][DEBUG] - Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-17 05:06:24,216][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,216][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,216][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,216][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,216][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,217][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,217][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,217][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,217][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,217][__main__][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,218][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,218][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,218][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,218][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,218][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,218][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,219][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,219][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,219][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,219][__main__][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,288][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,288][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,288][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,288][__main__][DEBUG] - Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,288][__main__][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,289][__main__][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,289][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,289][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,289][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,289][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,289][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,290][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,290][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,290][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,290][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,290][__main__][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,290][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,291][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,291][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,291][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,291][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,291][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,291][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,292][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,292][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,292][__main__][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,292][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,292][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,292][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,293][__main__][DEBUG] - Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,293][__main__][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,293][__main__][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,293][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,293][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,293][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,294][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,294][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,294][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,294][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,294][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,294][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,294][__main__][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,295][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,295][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,295][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,295][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,295][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,295][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,296][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,296][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,296][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,296][__main__][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,296][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,296][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,296][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,296][__main__][DEBUG] - Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,296][__main__][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,297][__main__][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,297][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,297][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,297][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,297][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,297][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,297][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,297][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,297][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,298][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,298][__main__][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,298][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,298][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,298][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,298][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,298][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,298][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,298][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,299][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,299][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,299][__main__][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,299][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,299][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,299][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,299][__main__][DEBUG] - Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,299][__main__][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,299][__main__][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,300][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,300][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,300][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,300][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,300][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,300][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,300][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,300][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,301][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,301][__main__][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,301][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,301][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,301][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,301][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,301][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,301][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,301][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,302][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,302][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,302][__main__][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,302][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,302][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,302][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,302][__main__][DEBUG] - Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,302][__main__][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,303][__main__][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,303][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,303][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,303][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,303][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,303][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,303][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,303][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,304][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,304][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,304][__main__][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,304][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,304][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,304][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,304][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,304][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,304][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,305][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:06:24,305][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,305][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,305][__main__][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,305][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:06:24,305][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:06:24,305][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:06:24,305][__main__][DEBUG] - Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,306][__main__][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,306][__main__][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,306][__main__][DEBUG] - Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:06:24,306][__main__][DEBUG] - Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","Epoch:   0% 0/100 [00:00<?, ?it/s][2022-08-17 05:06:24,308][__main__][DEBUG] - Starting training!\n","\n","Iteration:   0% 0/422 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-17 05:06:25,126][__main__][DEBUG] - batch 0: tensor([[    0,   646, 44143,  ...,     1,     1,     1],\n","        [    0,   646, 44143,  ...,     1,     1,     1],\n","        [    0,   646, 44143,  ...,     1,     1,     1],\n","        ...,\n","        [    0,   646, 44143,  ...,     1,     1,     1],\n","        [    0,   646, 44143,  ...,     1,     1,     1],\n","        [    0,   646, 44143,  ..., 29015,   742,     2]], device='cuda:0') \n","[2022-08-17 05:06:25,128][__main__][DEBUG] - batch 1: tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') \n","[2022-08-17 05:06:25,130][__main__][DEBUG] - batch 2: tensor([[    0,  2136,  4135,  ...,     1,     1,     1],\n","        [    0,  2136,  4135,  ...,     1,     1,     1],\n","        [    0,  2136,  4135,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  2136,  4135,  ...,     1,     1,     1],\n","        [    0, 47764,   636,  ...,     1,     1,     1],\n","        [    0,  2136,  4135,  ...,     1,     1,     1]], device='cuda:0') \n","[2022-08-17 05:06:25,132][__main__][DEBUG] - batch 3: tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0') \n","\n","Iteration:   0% 1/422 [00:01<08:25,  1.20s/it]\u001b[A\n","Iteration:   0% 2/422 [00:01<04:52,  1.43it/s]\u001b[A\n","Iteration:   1% 3/422 [00:01<03:43,  1.87it/s]\u001b[A\n","Iteration:   1% 4/422 [00:02<03:11,  2.18it/s]\u001b[A\n","Iteration:   1% 5/422 [00:02<02:53,  2.41it/s]\u001b[A\n","Iteration:   1% 6/422 [00:02<02:42,  2.56it/s]\u001b[A\n","Iteration:   2% 7/422 [00:03<02:35,  2.68it/s]\u001b[A\n","Iteration:   2% 8/422 [00:03<02:30,  2.76it/s]\u001b[A\n","Iteration:   2% 9/422 [00:03<02:26,  2.81it/s]\u001b[A\n","Iteration:   2% 10/422 [00:04<02:24,  2.85it/s]\u001b[A\n","Iteration:   3% 11/422 [00:04<02:22,  2.88it/s]\u001b[A\n","Iteration:   3% 12/422 [00:04<02:21,  2.90it/s]\u001b[A\n","Iteration:   3% 13/422 [00:05<02:20,  2.91it/s]\u001b[A\n","Iteration:   3% 14/422 [00:05<02:19,  2.92it/s]\u001b[A\n","Iteration:   4% 15/422 [00:05<02:19,  2.92it/s]\u001b[A\n","Iteration:   4% 16/422 [00:06<02:18,  2.93it/s]\u001b[A\n","Iteration:   4% 17/422 [00:06<02:18,  2.93it/s]\u001b[A\n","Iteration:   4% 18/422 [00:06<02:17,  2.93it/s]\u001b[A\n","Iteration:   5% 19/422 [00:07<02:17,  2.94it/s]\u001b[A\n","Iteration:   5% 20/422 [00:07<02:16,  2.94it/s]\u001b[A\n","Iteration:   5% 21/422 [00:08<02:16,  2.93it/s]\u001b[A\n","Iteration:   5% 22/422 [00:08<02:16,  2.94it/s]\u001b[A\n","Iteration:   5% 23/422 [00:08<02:16,  2.93it/s]\u001b[A\n","Iteration:   6% 24/422 [00:09<02:15,  2.94it/s]\u001b[A\n","Iteration:   6% 25/422 [00:09<02:14,  2.94it/s]\u001b[A\n","Iteration:   6% 26/422 [00:09<02:14,  2.94it/s]\u001b[A\n","Iteration:   6% 27/422 [00:10<02:14,  2.94it/s]\u001b[A\n","Iteration:   7% 28/422 [00:10<02:13,  2.94it/s]\u001b[A\n","Iteration:   7% 29/422 [00:10<02:13,  2.94it/s]\u001b[A\n","Iteration:   7% 30/422 [00:11<02:13,  2.94it/s]\u001b[A\n","Iteration:   7% 31/422 [00:11<02:13,  2.94it/s]\u001b[A\n","Iteration:   8% 32/422 [00:11<02:12,  2.94it/s]\u001b[A\n","Iteration:   8% 33/422 [00:12<02:12,  2.94it/s]\u001b[A\n","Iteration:   8% 34/422 [00:12<02:11,  2.94it/s]\u001b[A\n","Iteration:   8% 35/422 [00:12<02:11,  2.94it/s]\u001b[A\n","Iteration:   9% 36/422 [00:13<02:11,  2.94it/s]\u001b[A\n","Iteration:   9% 37/422 [00:13<02:10,  2.94it/s]\u001b[A\n","Iteration:   9% 38/422 [00:13<02:10,  2.94it/s]\u001b[A\n","Iteration:   9% 39/422 [00:14<02:10,  2.94it/s]\u001b[A\n","Iteration:   9% 40/422 [00:14<02:09,  2.94it/s]\u001b[A\n","Iteration:  10% 41/422 [00:14<02:09,  2.94it/s]\u001b[A\n","Iteration:  10% 42/422 [00:15<02:09,  2.94it/s]\u001b[A\n","Iteration:  10% 43/422 [00:15<02:08,  2.94it/s]\u001b[A\n","Iteration:  10% 44/422 [00:15<02:08,  2.94it/s]\u001b[A\n","Iteration:  11% 45/422 [00:16<02:08,  2.94it/s]\u001b[A\n","Iteration:  11% 46/422 [00:16<02:08,  2.94it/s]\u001b[A\n","Iteration:  11% 47/422 [00:16<02:07,  2.94it/s]\u001b[A\n","Iteration:  11% 48/422 [00:17<02:06,  2.95it/s]\u001b[A\n","Iteration:  12% 49/422 [00:17<02:06,  2.95it/s]\u001b[A\n","Iteration:  12% 50/422 [00:17<02:06,  2.94it/s]\u001b[A\n","Iteration:  12% 51/422 [00:18<02:06,  2.94it/s]\u001b[A\n","Iteration:  12% 52/422 [00:18<02:05,  2.94it/s]\u001b[A\n","Iteration:  13% 53/422 [00:18<02:05,  2.94it/s]\u001b[A\n","Iteration:  13% 54/422 [00:19<02:05,  2.94it/s]\u001b[A\n","Iteration:  13% 55/422 [00:19<02:04,  2.94it/s]\u001b[A\n","Iteration:  13% 56/422 [00:19<02:04,  2.94it/s]\u001b[A\n","Iteration:  14% 57/422 [00:20<02:04,  2.94it/s]\u001b[A\n","Iteration:  14% 58/422 [00:20<02:03,  2.94it/s]\u001b[A\n","Iteration:  14% 59/422 [00:20<02:03,  2.94it/s]\u001b[A\n","Iteration:  14% 60/422 [00:21<02:03,  2.94it/s]\u001b[A\n","Iteration:  14% 61/422 [00:21<02:03,  2.93it/s]\u001b[A\n","Iteration:  15% 62/422 [00:21<02:02,  2.94it/s]\u001b[A\n","Iteration:  15% 63/422 [00:22<02:02,  2.94it/s]\u001b[A\n","Iteration:  15% 64/422 [00:22<02:01,  2.94it/s]\u001b[A\n","Iteration:  15% 65/422 [00:22<02:01,  2.94it/s]\u001b[A\n","Iteration:  16% 66/422 [00:23<02:01,  2.94it/s]\u001b[A\n","Iteration:  16% 67/422 [00:23<02:00,  2.94it/s]\u001b[A\n","Iteration:  16% 68/422 [00:23<02:00,  2.94it/s]\u001b[A\n","Iteration:  16% 69/422 [00:24<02:00,  2.94it/s]\u001b[A\n","Iteration:  17% 70/422 [00:24<02:00,  2.93it/s]\u001b[A\n","Iteration:  17% 71/422 [00:25<01:59,  2.94it/s]\u001b[A\n","Iteration:  17% 72/422 [00:25<01:59,  2.94it/s]\u001b[A\n","Iteration:  17% 73/422 [00:25<01:58,  2.94it/s]\u001b[A\n","Iteration:  18% 74/422 [00:26<01:58,  2.94it/s]\u001b[A\n","Iteration:  18% 75/422 [00:26<01:58,  2.94it/s]\u001b[A\n","Iteration:  18% 76/422 [00:26<01:57,  2.94it/s]\u001b[A\n","Iteration:  18% 77/422 [00:27<01:57,  2.94it/s]\u001b[A\n","Iteration:  18% 78/422 [00:27<01:57,  2.94it/s]\u001b[A\n","Iteration:  19% 79/422 [00:27<01:56,  2.93it/s]\u001b[A\n","Iteration:  19% 80/422 [00:28<01:56,  2.93it/s]\u001b[A\n","Iteration:  19% 81/422 [00:28<01:56,  2.94it/s]\u001b[A\n","Iteration:  19% 82/422 [00:28<01:56,  2.93it/s]\u001b[A\n","Iteration:  20% 83/422 [00:29<01:55,  2.93it/s]\u001b[A\n","Iteration:  20% 84/422 [00:29<01:55,  2.93it/s]\u001b[A\n","Iteration:  20% 85/422 [00:29<01:54,  2.93it/s]\u001b[A\n","Iteration:  20% 86/422 [00:30<01:54,  2.94it/s]\u001b[A\n","Iteration:  21% 87/422 [00:30<01:54,  2.94it/s]\u001b[A\n","Iteration:  21% 88/422 [00:30<01:53,  2.93it/s]\u001b[A\n","Iteration:  21% 89/422 [00:34<07:32,  1.36s/it]\u001b[A\n","Iteration:  21% 90/422 [00:34<05:49,  1.05s/it]\u001b[A\n","Iteration:  22% 91/422 [00:35<04:37,  1.19it/s]\u001b[A\n","Iteration:  22% 92/422 [00:35<03:47,  1.45it/s]\u001b[A\n","Iteration:  22% 93/422 [00:35<03:12,  1.71it/s]\u001b[A\n","Iteration:  22% 94/422 [00:36<02:47,  1.96it/s]\u001b[A\n","Iteration:  23% 95/422 [00:36<02:30,  2.17it/s]\u001b[A\n","Iteration:  23% 96/422 [00:36<02:18,  2.35it/s]\u001b[A\n","Iteration:  23% 97/422 [00:37<02:09,  2.50it/s]\u001b[A\n","Iteration:  23% 98/422 [00:37<02:03,  2.62it/s]\u001b[A\n","Iteration:  23% 99/422 [00:37<01:59,  2.71it/s]\u001b[A\n","Iteration:  24% 100/422 [00:38<01:56,  2.78it/s]\u001b[A\n","Iteration:  24% 101/422 [00:38<01:53,  2.82it/s]\u001b[A\n","Iteration:  24% 102/422 [00:38<01:51,  2.86it/s]\u001b[A\n","Iteration:  24% 103/422 [00:39<01:50,  2.88it/s]\u001b[A\n","Iteration:  25% 104/422 [00:39<01:49,  2.90it/s]\u001b[A\n","Iteration:  25% 105/422 [00:39<01:48,  2.92it/s]\u001b[A\n","Iteration:  25% 106/422 [00:40<01:48,  2.92it/s]\u001b[A\n","Iteration:  25% 107/422 [00:40<01:47,  2.93it/s]\u001b[A\n","Iteration:  26% 108/422 [00:41<01:47,  2.93it/s]\u001b[A\n","Iteration:  26% 109/422 [00:41<01:46,  2.93it/s]\u001b[A\n","Iteration:  26% 110/422 [00:41<01:46,  2.93it/s]\u001b[A\n","Iteration:  26% 111/422 [00:42<01:45,  2.94it/s]\u001b[A\n","Iteration:  27% 112/422 [00:42<01:45,  2.94it/s]\u001b[A\n","Iteration:  27% 113/422 [00:42<01:45,  2.93it/s]\u001b[A\n","Iteration:  27% 114/422 [00:43<01:44,  2.94it/s]\u001b[A\n","Iteration:  27% 115/422 [00:43<01:44,  2.94it/s]\u001b[A\n","Iteration:  27% 116/422 [00:43<01:44,  2.94it/s]\u001b[A\n","Iteration:  28% 117/422 [00:44<01:43,  2.94it/s]\u001b[A\n","Iteration:  28% 118/422 [00:44<01:43,  2.94it/s]\u001b[A\n","Iteration:  28% 119/422 [00:44<01:43,  2.94it/s]\u001b[A\n","Iteration:  28% 120/422 [00:45<01:43,  2.92it/s]\u001b[A\n","Iteration:  29% 121/422 [00:45<01:42,  2.94it/s]\u001b[A\n","Iteration:  29% 122/422 [00:45<01:42,  2.94it/s]\u001b[A\n","Iteration:  29% 123/422 [00:46<01:41,  2.94it/s]\u001b[A\n","Iteration:  29% 124/422 [00:46<01:41,  2.93it/s]\u001b[A\n","Iteration:  30% 125/422 [00:46<01:41,  2.94it/s]\u001b[A\n","Iteration:  30% 126/422 [00:47<01:40,  2.94it/s]\u001b[A\n","Iteration:  30% 127/422 [00:47<01:40,  2.94it/s]\u001b[A\n","Iteration:  30% 128/422 [00:47<01:40,  2.94it/s]\u001b[A\n","Iteration:  31% 129/422 [00:48<01:39,  2.93it/s]\u001b[A\n","Iteration:  31% 130/422 [00:48<01:39,  2.94it/s]\u001b[A\n","Iteration:  31% 131/422 [00:48<01:39,  2.94it/s]\u001b[A\n","Iteration:  31% 132/422 [00:49<01:38,  2.94it/s]\u001b[A\n","Iteration:  32% 133/422 [00:49<01:38,  2.94it/s]\u001b[A\n","Iteration:  32% 134/422 [00:49<01:37,  2.94it/s]\u001b[A\n","Iteration:  32% 135/422 [00:50<01:37,  2.94it/s]\u001b[A\n","Iteration:  32% 136/422 [00:50<01:37,  2.94it/s]\u001b[A\n","Iteration:  32% 137/422 [00:50<01:36,  2.94it/s]\u001b[A\n","Iteration:  33% 138/422 [00:51<01:36,  2.94it/s]\u001b[A\n","Iteration:  33% 139/422 [00:51<01:36,  2.94it/s]\u001b[A\n","Iteration:  33% 140/422 [00:51<01:36,  2.93it/s]\u001b[A\n","Iteration:  33% 141/422 [00:52<01:35,  2.93it/s]\u001b[A\n","Iteration:  34% 142/422 [00:52<01:35,  2.94it/s]\u001b[A\n","Iteration:  34% 143/422 [00:52<01:35,  2.93it/s]\u001b[A\n","Iteration:  34% 144/422 [00:53<01:34,  2.94it/s]\u001b[A\n","Iteration:  34% 145/422 [00:53<01:34,  2.94it/s]\u001b[A\n","Iteration:  35% 146/422 [00:53<01:33,  2.94it/s]\u001b[A\n","Iteration:  35% 147/422 [00:54<01:33,  2.93it/s]\u001b[A\n","Iteration:  35% 148/422 [00:54<01:33,  2.93it/s]\u001b[A\n","Iteration:  35% 149/422 [00:54<01:32,  2.94it/s]\u001b[A\n","Iteration:  36% 150/422 [00:55<01:32,  2.94it/s]\u001b[A\n","Iteration:  36% 151/422 [00:55<01:32,  2.94it/s]\u001b[A\n","Iteration:  36% 152/422 [00:55<01:32,  2.93it/s]\u001b[A\n","Iteration:  36% 153/422 [00:56<01:31,  2.94it/s]\u001b[A\n","Iteration:  36% 154/422 [00:56<01:31,  2.94it/s]\u001b[A\n","Iteration:  37% 155/422 [00:57<01:30,  2.94it/s]\u001b[A\n","Iteration:  37% 156/422 [00:57<01:30,  2.95it/s]\u001b[A\n","Iteration:  37% 157/422 [00:57<01:30,  2.94it/s]\u001b[A\n","Iteration:  37% 158/422 [00:58<01:29,  2.94it/s]\u001b[A\n","Iteration:  38% 159/422 [00:58<01:29,  2.94it/s]\u001b[A\n","Iteration:  38% 160/422 [00:58<01:29,  2.94it/s]\u001b[A\n","Iteration:  38% 161/422 [00:59<01:28,  2.94it/s]\u001b[A\n","Iteration:  38% 162/422 [00:59<01:28,  2.94it/s]\u001b[A\n","Iteration:  39% 163/422 [00:59<01:28,  2.94it/s]\u001b[A\n","Iteration:  39% 164/422 [01:00<01:27,  2.94it/s]\u001b[A\n","Iteration:  39% 165/422 [01:00<01:27,  2.94it/s]\u001b[A\n","Iteration:  39% 166/422 [01:00<01:27,  2.94it/s]\u001b[A\n","Iteration:  40% 167/422 [01:01<01:26,  2.94it/s]\u001b[A\n","Iteration:  40% 168/422 [01:01<01:26,  2.94it/s]\u001b[A\n","Iteration:  40% 169/422 [01:01<01:26,  2.94it/s]\u001b[A\n","Iteration:  40% 170/422 [01:02<01:25,  2.94it/s]\u001b[A\n","Iteration:  41% 171/422 [01:02<01:25,  2.94it/s]\u001b[A\n","Iteration:  41% 172/422 [01:02<01:24,  2.94it/s]\u001b[A\n","Iteration:  41% 173/422 [01:03<01:24,  2.94it/s]\u001b[A\n","Iteration:  41% 174/422 [01:03<01:24,  2.94it/s]\u001b[A\n","Iteration:  41% 175/422 [01:03<01:23,  2.94it/s]\u001b[A\n","Iteration:  42% 176/422 [01:04<01:23,  2.94it/s]\u001b[A\n","Iteration:  42% 177/422 [01:04<01:23,  2.94it/s]\u001b[A\n","Iteration:  42% 178/422 [01:04<01:22,  2.95it/s]\u001b[A\n","Iteration:  42% 179/422 [01:05<01:22,  2.94it/s]\u001b[A\n","Iteration:  43% 180/422 [01:05<01:22,  2.95it/s]\u001b[A\n","Iteration:  43% 181/422 [01:05<01:21,  2.94it/s]\u001b[A\n","Iteration:  43% 182/422 [01:06<01:21,  2.95it/s]\u001b[A\n","Iteration:  43% 183/422 [01:06<01:21,  2.94it/s]\u001b[A\n","Iteration:  44% 184/422 [01:06<01:20,  2.94it/s]\u001b[A\n","Iteration:  44% 185/422 [01:07<01:20,  2.94it/s]\u001b[A\n","Iteration:  44% 186/422 [01:07<01:20,  2.94it/s]\u001b[A\n","Iteration:  44% 187/422 [01:07<01:19,  2.94it/s]\u001b[A\n","Iteration:  45% 188/422 [01:08<01:19,  2.94it/s]\u001b[A\n","Iteration:  45% 189/422 [01:08<01:19,  2.94it/s]\u001b[A\n","Iteration:  45% 190/422 [01:08<01:18,  2.94it/s]\u001b[A\n","Iteration:  45% 191/422 [01:09<01:18,  2.93it/s]\u001b[A\n","Iteration:  45% 192/422 [01:09<01:18,  2.94it/s]\u001b[A\n","Iteration:  46% 193/422 [01:09<01:18,  2.93it/s]\u001b[A\n","Iteration:  46% 194/422 [01:10<01:17,  2.94it/s]\u001b[A\n","Iteration:  46% 195/422 [01:10<01:17,  2.94it/s]\u001b[A\n","Iteration:  46% 196/422 [01:10<01:17,  2.93it/s]\u001b[A\n","Iteration:  47% 197/422 [01:11<01:16,  2.94it/s]\u001b[A\n","Iteration:  47% 198/422 [01:11<01:16,  2.94it/s]\u001b[A\n","Iteration:  47% 199/422 [01:11<01:15,  2.94it/s]\u001b[A\n","Iteration:  47% 200/422 [01:12<01:15,  2.94it/s]\u001b[A\n","Iteration:  48% 201/422 [01:12<01:15,  2.94it/s]\u001b[A\n","Iteration:  48% 202/422 [01:12<01:14,  2.94it/s]\u001b[A\n","Iteration:  48% 203/422 [01:13<01:14,  2.94it/s]\u001b[A\n","Iteration:  48% 204/422 [01:13<01:14,  2.94it/s]\u001b[A\n","Iteration:  49% 205/422 [01:14<01:13,  2.94it/s]\u001b[A\n","Iteration:  49% 206/422 [01:14<01:13,  2.94it/s]\u001b[A\n","Iteration:  49% 207/422 [01:14<01:13,  2.94it/s]\u001b[A\n","Iteration:  49% 208/422 [01:15<01:12,  2.94it/s]\u001b[A\n","Iteration:  50% 209/422 [01:15<01:12,  2.94it/s]\u001b[A\n","Iteration:  50% 210/422 [01:15<01:12,  2.94it/s]\u001b[A\n","Iteration:  50% 211/422 [01:16<01:11,  2.94it/s]\u001b[A\n","Iteration:  50% 212/422 [01:16<01:11,  2.94it/s]\u001b[A\n","Iteration:  50% 213/422 [01:16<01:11,  2.93it/s]\u001b[A\n","Iteration:  51% 214/422 [01:17<01:10,  2.94it/s]\u001b[A\n","Iteration:  51% 215/422 [01:17<01:10,  2.94it/s]\u001b[A\n","Iteration:  51% 216/422 [01:17<01:10,  2.94it/s]\u001b[A\n","Iteration:  51% 217/422 [01:18<01:09,  2.94it/s]\u001b[A\n","Iteration:  52% 218/422 [01:18<01:09,  2.94it/s]\u001b[A\n","Iteration:  52% 219/422 [01:18<01:09,  2.94it/s]\u001b[A\n","Iteration:  52% 220/422 [01:19<01:08,  2.94it/s]\u001b[A\n","Iteration:  52% 221/422 [01:19<01:08,  2.94it/s]\u001b[A\n","Iteration:  53% 222/422 [01:19<01:08,  2.94it/s]\u001b[A\n","Iteration:  53% 223/422 [01:20<01:07,  2.94it/s]\u001b[A\n","Iteration:  53% 224/422 [01:20<01:07,  2.94it/s]\u001b[A\n","Iteration:  53% 225/422 [01:20<01:06,  2.94it/s]\u001b[A\n","Iteration:  54% 226/422 [01:21<01:06,  2.94it/s]\u001b[A\n","Iteration:  54% 227/422 [01:21<01:06,  2.93it/s]\u001b[A\n","Iteration:  54% 228/422 [01:21<01:06,  2.94it/s]\u001b[A\n","Iteration:  54% 229/422 [01:22<01:05,  2.93it/s]\u001b[A\n","Iteration:  55% 230/422 [01:22<01:05,  2.94it/s]\u001b[A\n","Iteration:  55% 231/422 [01:22<01:04,  2.95it/s]\u001b[A\n","Iteration:  55% 232/422 [01:23<01:04,  2.94it/s]\u001b[A\n","Iteration:  55% 233/422 [01:23<01:04,  2.94it/s]\u001b[A\n","Iteration:  55% 234/422 [01:23<01:03,  2.94it/s]\u001b[A\n","Iteration:  56% 235/422 [01:24<01:03,  2.94it/s]\u001b[A\n","Iteration:  56% 236/422 [01:24<01:03,  2.94it/s]\u001b[A\n","Iteration:  56% 237/422 [01:24<01:02,  2.94it/s]\u001b[A\n","Iteration:  56% 238/422 [01:25<01:02,  2.94it/s]\u001b[A\n","Iteration:  57% 239/422 [01:25<01:02,  2.94it/s]\u001b[A\n","Iteration:  57% 240/422 [01:25<01:01,  2.95it/s]\u001b[A\n","Iteration:  57% 241/422 [01:26<01:01,  2.95it/s]\u001b[A\n","Iteration:  57% 242/422 [01:26<01:01,  2.94it/s]\u001b[A\n","Iteration:  58% 243/422 [01:26<01:00,  2.95it/s]\u001b[A\n","Iteration:  58% 244/422 [01:27<01:00,  2.94it/s]\u001b[A\n","Iteration:  58% 245/422 [01:27<01:00,  2.94it/s]\u001b[A\n","Iteration:  58% 246/422 [01:27<00:59,  2.94it/s]\u001b[A\n","Iteration:  59% 247/422 [01:28<00:59,  2.94it/s]\u001b[A\n","Iteration:  59% 248/422 [01:28<00:59,  2.94it/s]\u001b[A\n","Iteration:  59% 249/422 [01:28<00:58,  2.94it/s]\u001b[A\n","Iteration:  59% 250/422 [01:29<00:58,  2.94it/s]\u001b[A\n","Iteration:  59% 251/422 [01:29<00:58,  2.94it/s]\u001b[A\n","Iteration:  60% 252/422 [01:29<00:57,  2.94it/s]\u001b[A\n","Iteration:  60% 253/422 [01:30<00:57,  2.94it/s]\u001b[A\n","Iteration:  60% 254/422 [01:30<00:57,  2.94it/s]\u001b[A\n","Iteration:  60% 255/422 [01:31<00:56,  2.94it/s]\u001b[A\n","Iteration:  61% 256/422 [01:31<00:56,  2.94it/s]\u001b[A\n","Iteration:  61% 257/422 [01:31<00:56,  2.93it/s]\u001b[A\n","Iteration:  61% 258/422 [01:32<00:55,  2.93it/s]\u001b[A\n","Iteration:  61% 259/422 [01:32<00:55,  2.94it/s]\u001b[A\n","Iteration:  62% 260/422 [01:32<00:55,  2.94it/s]\u001b[A\n","Iteration:  62% 261/422 [01:33<00:54,  2.94it/s]\u001b[A\n","Iteration:  62% 262/422 [01:33<00:54,  2.95it/s]\u001b[A\n","Iteration:  62% 263/422 [01:33<00:54,  2.94it/s]\u001b[A\n","Iteration:  63% 264/422 [01:34<00:53,  2.93it/s]\u001b[A\n","Iteration:  63% 265/422 [01:34<00:53,  2.94it/s]\u001b[A\n","Iteration:  63% 266/422 [01:34<00:53,  2.94it/s]\u001b[A\n","Iteration:  63% 267/422 [01:35<00:52,  2.94it/s]\u001b[A\n","Iteration:  64% 268/422 [01:35<00:52,  2.93it/s]\u001b[A\n","Iteration:  64% 269/422 [01:35<00:52,  2.94it/s]\u001b[A\n","Iteration:  64% 270/422 [01:36<00:51,  2.94it/s]\u001b[A\n","Iteration:  64% 271/422 [01:36<00:51,  2.94it/s]\u001b[A\n","Iteration:  64% 272/422 [01:36<00:50,  2.94it/s]\u001b[A\n","Iteration:  65% 273/422 [01:37<00:50,  2.94it/s]\u001b[A\n","Iteration:  65% 274/422 [01:37<00:50,  2.94it/s]\u001b[A\n","Iteration:  65% 275/422 [01:37<00:50,  2.93it/s]\u001b[A\n","Iteration:  65% 276/422 [01:38<00:49,  2.94it/s]\u001b[A\n","Iteration:  66% 277/422 [01:38<00:49,  2.94it/s]\u001b[A\n","Iteration:  66% 278/422 [01:38<00:48,  2.94it/s]\u001b[A\n","Iteration:  66% 279/422 [01:39<00:48,  2.94it/s]\u001b[A\n","Iteration:  66% 280/422 [01:39<00:48,  2.94it/s]\u001b[A\n","Iteration:  67% 281/422 [01:39<00:47,  2.94it/s]\u001b[A\n","Iteration:  67% 282/422 [01:40<00:47,  2.94it/s]\u001b[A\n","Iteration:  67% 283/422 [01:40<00:47,  2.94it/s]\u001b[A\n","Iteration:  67% 284/422 [01:40<00:47,  2.93it/s]\u001b[A\n","Iteration:  68% 285/422 [01:41<00:46,  2.94it/s]\u001b[A\n","Iteration:  68% 286/422 [01:41<00:46,  2.94it/s]\u001b[A\n","Iteration:  68% 287/422 [01:41<00:45,  2.94it/s]\u001b[A\n","Iteration:  68% 288/422 [01:42<00:45,  2.94it/s]\u001b[A\n","Iteration:  68% 289/422 [01:42<00:45,  2.94it/s]\u001b[A\n","Iteration:  69% 290/422 [01:42<00:44,  2.94it/s]\u001b[A\n","Iteration:  69% 291/422 [01:43<00:44,  2.94it/s]\u001b[A\n","Iteration:  69% 292/422 [01:43<00:44,  2.94it/s]\u001b[A\n","Iteration:  69% 293/422 [01:43<00:43,  2.94it/s]\u001b[A\n","Iteration:  70% 294/422 [01:44<00:43,  2.94it/s]\u001b[A\n","Iteration:  70% 295/422 [01:44<00:43,  2.94it/s]\u001b[A\n","Iteration:  70% 296/422 [01:44<00:42,  2.95it/s]\u001b[A\n","Iteration:  70% 297/422 [01:45<00:42,  2.95it/s]\u001b[A\n","Iteration:  71% 298/422 [01:45<00:42,  2.95it/s]\u001b[A\n","Iteration:  71% 299/422 [01:45<00:41,  2.94it/s]\u001b[A\n","Iteration:  71% 300/422 [01:46<00:41,  2.94it/s]\u001b[A\n","Iteration:  71% 301/422 [01:46<00:41,  2.94it/s]\u001b[A\n","Iteration:  72% 302/422 [01:46<00:40,  2.94it/s]\u001b[A\n","Iteration:  72% 303/422 [01:47<00:40,  2.94it/s]\u001b[A\n","Iteration:  72% 304/422 [01:47<00:40,  2.93it/s]\u001b[A\n","Iteration:  72% 305/422 [01:48<00:39,  2.94it/s]\u001b[A\n","Iteration:  73% 306/422 [01:48<00:39,  2.94it/s]\u001b[A\n","Iteration:  73% 307/422 [01:48<00:39,  2.93it/s]\u001b[A\n","Iteration:  73% 308/422 [01:49<00:38,  2.93it/s]\u001b[A\n","Iteration:  73% 309/422 [01:49<00:38,  2.94it/s]\u001b[A\n","Iteration:  73% 310/422 [01:49<00:38,  2.93it/s]\u001b[A\n","Iteration:  74% 311/422 [01:50<00:37,  2.94it/s]\u001b[A\n","Iteration:  74% 312/422 [01:50<00:37,  2.94it/s]\u001b[A\n","Iteration:  74% 313/422 [01:50<00:37,  2.94it/s]\u001b[A\n","Iteration:  74% 314/422 [01:51<00:36,  2.94it/s]\u001b[A\n","Iteration:  75% 315/422 [01:51<00:36,  2.94it/s]\u001b[A\n","Iteration:  75% 316/422 [01:51<00:36,  2.94it/s]\u001b[A\n","Iteration:  75% 317/422 [01:52<00:35,  2.94it/s]\u001b[A\n","Iteration:  75% 318/422 [01:52<00:35,  2.94it/s]\u001b[A\n","Iteration:  76% 319/422 [01:52<00:35,  2.94it/s]\u001b[A\n","Iteration:  76% 320/422 [01:53<00:34,  2.94it/s]\u001b[A\n","Iteration:  76% 321/422 [01:53<00:34,  2.94it/s]\u001b[A\n","Iteration:  76% 322/422 [01:53<00:34,  2.90it/s]\u001b[A\n","Iteration:  77% 323/422 [01:54<00:33,  2.91it/s]\u001b[A\n","Iteration:  77% 324/422 [01:54<00:33,  2.92it/s]\u001b[A\n","Iteration:  77% 325/422 [01:54<00:33,  2.93it/s]\u001b[A\n","Iteration:  77% 326/422 [01:55<00:32,  2.93it/s]\u001b[A\n","Iteration:  77% 327/422 [01:55<00:32,  2.93it/s]\u001b[A\n","Iteration:  78% 328/422 [01:55<00:32,  2.94it/s]\u001b[A\n","Iteration:  78% 329/422 [01:56<00:31,  2.94it/s]\u001b[A\n","Iteration:  78% 330/422 [01:56<00:31,  2.94it/s]\u001b[A\n","Iteration:  78% 331/422 [01:56<00:30,  2.94it/s]\u001b[A\n","Iteration:  79% 332/422 [01:57<00:30,  2.94it/s]\u001b[A\n","Iteration:  79% 333/422 [01:57<00:30,  2.94it/s]\u001b[A\n","Iteration:  79% 334/422 [01:57<00:29,  2.94it/s]\u001b[A\n","Iteration:  79% 335/422 [01:58<00:29,  2.94it/s]\u001b[A\n","Iteration:  80% 336/422 [01:58<00:29,  2.93it/s]\u001b[A\n","Iteration:  80% 337/422 [01:58<00:28,  2.94it/s]\u001b[A\n","Iteration:  80% 338/422 [01:59<00:28,  2.94it/s]\u001b[A\n","Iteration:  80% 339/422 [01:59<00:28,  2.94it/s]\u001b[A\n","Iteration:  81% 340/422 [01:59<00:27,  2.94it/s]\u001b[A\n","Iteration:  81% 341/422 [02:00<00:27,  2.94it/s]\u001b[A\n","Iteration:  81% 342/422 [02:00<00:27,  2.94it/s]\u001b[A\n","Iteration:  81% 343/422 [02:00<00:26,  2.94it/s]\u001b[A\n","Iteration:  82% 344/422 [02:01<00:26,  2.94it/s]\u001b[A\n","Iteration:  82% 345/422 [02:01<00:26,  2.94it/s]\u001b[A\n","Iteration:  82% 346/422 [02:01<00:25,  2.94it/s]\u001b[A\n","Iteration:  82% 347/422 [02:02<00:25,  2.94it/s]\u001b[A\n","Iteration:  82% 348/422 [02:02<00:25,  2.93it/s]\u001b[A\n","Iteration:  83% 349/422 [02:03<00:24,  2.94it/s]\u001b[A\n","Iteration:  83% 350/422 [02:03<00:24,  2.94it/s]\u001b[A\n","Iteration:  83% 351/422 [02:03<00:24,  2.93it/s]\u001b[A\n","Iteration:  83% 352/422 [02:04<00:23,  2.93it/s]\u001b[A\n","Iteration:  84% 353/422 [02:04<00:23,  2.94it/s]\u001b[A\n","Iteration:  84% 354/422 [02:04<00:23,  2.93it/s]\u001b[A\n","Iteration:  84% 355/422 [02:05<00:22,  2.94it/s]\u001b[A\n","Iteration:  84% 356/422 [02:05<00:22,  2.94it/s]\u001b[A\n","Iteration:  85% 357/422 [02:05<00:22,  2.94it/s]\u001b[A\n","Iteration:  85% 358/422 [02:06<00:21,  2.94it/s]\u001b[A\n","Iteration:  85% 359/422 [02:06<00:21,  2.94it/s]\u001b[A\n","Iteration:  85% 360/422 [02:06<00:21,  2.93it/s]\u001b[A\n","Iteration:  86% 361/422 [02:07<00:20,  2.93it/s]\u001b[A\n","Iteration:  86% 362/422 [02:07<00:20,  2.94it/s]\u001b[A\n","Iteration:  86% 363/422 [02:07<00:20,  2.94it/s]\u001b[A\n","Iteration:  86% 364/422 [02:08<00:19,  2.94it/s]\u001b[A\n","Iteration:  86% 365/422 [02:08<00:19,  2.94it/s]\u001b[A\n","Iteration:  87% 366/422 [02:08<00:19,  2.94it/s]\u001b[A\n","Iteration:  87% 367/422 [02:09<00:18,  2.94it/s]\u001b[A\n","Iteration:  87% 368/422 [02:09<00:18,  2.94it/s]\u001b[A\n","Iteration:  87% 369/422 [02:09<00:18,  2.94it/s]\u001b[A\n","Iteration:  88% 370/422 [02:10<00:17,  2.93it/s]\u001b[A\n","Iteration:  88% 371/422 [02:10<00:17,  2.94it/s]\u001b[A\n","Iteration:  88% 372/422 [02:10<00:17,  2.94it/s]\u001b[A\n","Iteration:  88% 373/422 [02:11<00:16,  2.94it/s]\u001b[A\n","Iteration:  89% 374/422 [02:11<00:16,  2.94it/s]\u001b[A\n","Iteration:  89% 375/422 [02:11<00:15,  2.94it/s]\u001b[A\n","Iteration:  89% 376/422 [02:12<00:15,  2.94it/s]\u001b[A\n","Iteration:  89% 377/422 [02:12<00:15,  2.94it/s]\u001b[A\n","Iteration:  90% 378/422 [02:12<00:14,  2.94it/s]\u001b[A\n","Iteration:  90% 379/422 [02:13<00:14,  2.94it/s]\u001b[A\n","Iteration:  90% 380/422 [02:13<00:14,  2.94it/s]\u001b[A\n","Iteration:  90% 381/422 [02:13<00:13,  2.94it/s]\u001b[A\n","Iteration:  91% 382/422 [02:14<00:13,  2.94it/s]\u001b[A\n","Iteration:  91% 383/422 [02:14<00:13,  2.94it/s]\u001b[A\n","Iteration:  91% 384/422 [02:14<00:12,  2.94it/s]\u001b[A\n","Iteration:  91% 385/422 [02:15<00:12,  2.94it/s]\u001b[A\n","Iteration:  91% 386/422 [02:15<00:12,  2.94it/s]\u001b[A\n","Iteration:  92% 387/422 [02:15<00:11,  2.93it/s]\u001b[A\n","Iteration:  92% 388/422 [02:16<00:11,  2.93it/s]\u001b[A\n","Iteration:  92% 389/422 [02:16<00:11,  2.94it/s]\u001b[A\n","Iteration:  92% 390/422 [02:16<00:10,  2.93it/s]\u001b[A\n","Iteration:  93% 391/422 [02:17<00:10,  2.94it/s]\u001b[A\n","Iteration:  93% 392/422 [02:17<00:10,  2.94it/s]\u001b[A\n","Iteration:  93% 393/422 [02:17<00:09,  2.94it/s]\u001b[A\n","Iteration:  93% 394/422 [02:18<00:09,  2.94it/s]\u001b[A\n","Iteration:  94% 395/422 [02:18<00:09,  2.94it/s]\u001b[A\n","Iteration:  94% 396/422 [02:18<00:08,  2.94it/s]\u001b[A\n","Iteration:  94% 397/422 [02:19<00:08,  2.94it/s]\u001b[A\n","Iteration:  94% 398/422 [02:19<00:08,  2.94it/s]\u001b[A\n","Iteration:  95% 399/422 [02:20<00:07,  2.94it/s]\u001b[A\n","Iteration:  95% 400/422 [02:20<00:07,  2.94it/s]\u001b[A\n","Iteration:  95% 401/422 [02:20<00:07,  2.94it/s]\u001b[A\n","Iteration:  95% 402/422 [02:21<00:06,  2.94it/s]\u001b[A\n","Iteration:  95% 403/422 [02:21<00:06,  2.94it/s]\u001b[A\n","Iteration:  96% 404/422 [02:21<00:06,  2.93it/s]\u001b[A\n","Iteration:  96% 405/422 [02:22<00:05,  2.94it/s]\u001b[A\n","Iteration:  96% 406/422 [02:22<00:05,  2.94it/s]\u001b[A\n","Iteration:  96% 407/422 [02:22<00:05,  2.94it/s]\u001b[A\n","Iteration:  97% 408/422 [02:23<00:04,  2.94it/s]\u001b[A\n","Iteration:  97% 409/422 [02:23<00:04,  2.94it/s]\u001b[A\n","Iteration:  97% 410/422 [02:23<00:04,  2.94it/s]\u001b[A\n","Iteration:  97% 411/422 [02:24<00:03,  2.94it/s]\u001b[A\n","Iteration:  98% 412/422 [02:24<00:03,  2.94it/s]\u001b[A\n","Iteration:  98% 413/422 [02:24<00:03,  2.94it/s]\u001b[A\n","Iteration:  98% 414/422 [02:25<00:02,  2.94it/s]\u001b[A\n","Iteration:  98% 415/422 [02:25<00:02,  2.94it/s]\u001b[A\n","Iteration:  99% 416/422 [02:25<00:02,  2.94it/s]\u001b[A\n","Iteration:  99% 417/422 [02:26<00:01,  2.94it/s]\u001b[A\n","Iteration:  99% 418/422 [02:26<00:01,  2.94it/s]\u001b[A\n","Iteration:  99% 419/422 [02:26<00:01,  2.94it/s]\u001b[A\n","Iteration: 100% 420/422 [02:27<00:00,  2.94it/s]\u001b[A\n","Iteration: 100% 421/422 [02:27<00:00,  2.95it/s]\u001b[A\n","Iteration: 100% 422/422 [02:28<00:00,  2.85it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","[2022-08-17 05:11:25,135][__main__][DEBUG] - epoch is 0\n","[2022-08-17 05:11:25,142][__main__][DEBUG] - validation loss is tensor(0.1892, device='cuda:0')\n","Epoch:   1% 1/100 [05:02<8:19:28, 302.71s/it]\n","Iteration:   0% 0/422 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\n","Iteration:   0% 1/422 [00:01<08:16,  1.18s/it]\u001b[A\n","Iteration:   0% 2/422 [00:01<04:48,  1.45it/s]\u001b[A\n","Iteration:   1% 3/422 [00:01<03:41,  1.89it/s]\u001b[A\n","Iteration:   1% 4/422 [00:02<03:09,  2.20it/s]\u001b[A\n","Iteration:   1% 5/422 [00:02<02:52,  2.42it/s]\u001b[A\n","Iteration:   1% 6/422 [00:02<02:41,  2.58it/s]\u001b[A\n","Iteration:   2% 7/422 [00:03<02:34,  2.68it/s]\u001b[A\n","Iteration:   2% 8/422 [00:03<02:29,  2.76it/s]\u001b[A\n","Iteration:   2% 9/422 [00:03<02:26,  2.81it/s]\u001b[A\n","Iteration:   2% 10/422 [00:04<02:24,  2.85it/s]\u001b[A\n","Iteration:   3% 11/422 [00:04<02:23,  2.87it/s]\u001b[A\n","Iteration:   3% 12/422 [00:04<02:21,  2.90it/s]\u001b[A\n","Iteration:   3% 13/422 [00:05<02:20,  2.91it/s]\u001b[A\n","Iteration:   3% 14/422 [00:05<02:20,  2.91it/s]\u001b[A\n","Iteration:   4% 15/422 [00:05<02:19,  2.93it/s]\u001b[A\n","Iteration:   4% 16/422 [00:06<02:18,  2.93it/s]\u001b[A\n","Iteration:   4% 17/422 [00:06<02:18,  2.93it/s]\u001b[A\n","Iteration:   4% 18/422 [00:06<02:17,  2.93it/s]\u001b[A\n","Iteration:   5% 19/422 [00:07<02:17,  2.93it/s]\u001b[A\n","Iteration:   5% 20/422 [00:07<02:17,  2.93it/s]\u001b[A\n","Iteration:   5% 21/422 [00:07<02:16,  2.94it/s]\u001b[A\n","Iteration:   5% 22/422 [00:08<02:16,  2.94it/s]\u001b[A\n","Iteration:   5% 23/422 [00:08<02:16,  2.92it/s]\u001b[A\n","Iteration:   6% 24/422 [00:09<02:15,  2.93it/s]\u001b[A\n","Iteration:   6% 25/422 [00:09<02:15,  2.94it/s]\u001b[A\n","Iteration:   6% 26/422 [00:09<02:14,  2.93it/s]\u001b[A\n","Iteration:   6% 27/422 [00:10<02:14,  2.93it/s]\u001b[A\n","Iteration:   7% 28/422 [00:10<02:14,  2.94it/s]\u001b[A\n","Iteration:   7% 29/422 [00:10<02:14,  2.93it/s]\u001b[A\n","Iteration:   7% 30/422 [00:11<02:13,  2.94it/s]\u001b[A\n","Iteration:   7% 31/422 [00:11<02:13,  2.94it/s]\u001b[A\n","Iteration:   8% 32/422 [00:11<02:12,  2.94it/s]\u001b[A\n","Iteration:   8% 33/422 [00:12<02:12,  2.94it/s]\u001b[A\n","Iteration:   8% 34/422 [00:12<02:11,  2.94it/s]\u001b[A\n","Iteration:   8% 35/422 [00:12<02:11,  2.94it/s]\u001b[A\n","Iteration:   9% 36/422 [00:13<02:11,  2.94it/s]\u001b[A\n","Iteration:   9% 37/422 [00:13<02:10,  2.94it/s]\u001b[A\n","Iteration:   9% 38/422 [00:13<02:10,  2.94it/s]\u001b[A\n","Iteration:   9% 39/422 [00:14<02:10,  2.94it/s]\u001b[A\n","Iteration:   9% 40/422 [00:14<02:09,  2.94it/s]\u001b[A\n","Iteration:  10% 41/422 [00:14<02:09,  2.94it/s]\u001b[A\n","Iteration:  10% 42/422 [00:15<02:09,  2.94it/s]\u001b[A\n","Iteration:  10% 43/422 [00:15<02:08,  2.94it/s]\u001b[A\n","Iteration:  10% 44/422 [00:15<02:08,  2.94it/s]\u001b[A\n","Iteration:  11% 45/422 [00:16<02:08,  2.94it/s]\u001b[A\n","Iteration:  11% 46/422 [00:16<02:07,  2.94it/s]\u001b[A\n","Iteration:  11% 47/422 [00:16<02:07,  2.94it/s]\u001b[A\n","Iteration:  11% 48/422 [00:17<02:07,  2.94it/s]\u001b[A\n","Iteration:  12% 49/422 [00:17<02:06,  2.94it/s]\u001b[A\n","Iteration:  12% 50/422 [00:17<02:06,  2.94it/s]\u001b[A\n","Iteration:  12% 51/422 [00:18<02:06,  2.94it/s]\u001b[A\n","Iteration:  12% 52/422 [00:18<02:05,  2.94it/s]\u001b[A\n","Iteration:  13% 53/422 [00:18<02:05,  2.94it/s]\u001b[A\n","Iteration:  13% 54/422 [00:19<02:05,  2.94it/s]\u001b[A\n","Iteration:  13% 55/422 [00:19<02:04,  2.94it/s]\u001b[A\n","Iteration:  13% 56/422 [00:19<02:04,  2.93it/s]\u001b[A\n","Iteration:  14% 57/422 [00:20<02:04,  2.93it/s]\u001b[A\n","Iteration:  14% 58/422 [00:20<02:03,  2.94it/s]\u001b[A\n","Iteration:  14% 59/422 [00:20<02:03,  2.94it/s]\u001b[A\n","Iteration:  14% 60/422 [00:21<02:02,  2.95it/s]\u001b[A\n","Iteration:  14% 61/422 [00:21<02:02,  2.94it/s]\u001b[A\n","Iteration:  15% 62/422 [00:21<02:02,  2.95it/s]\u001b[A\n","Iteration:  15% 63/422 [00:22<02:01,  2.94it/s]\u001b[A\n","Iteration:  15% 64/422 [00:22<02:01,  2.94it/s]\u001b[A\n","Iteration:  15% 65/422 [00:22<02:01,  2.94it/s]\u001b[A\n","Iteration:  16% 66/422 [00:23<02:00,  2.94it/s]\u001b[A\n","Iteration:  16% 67/422 [00:23<02:00,  2.94it/s]\u001b[A\n","Iteration:  16% 68/422 [00:23<02:00,  2.94it/s]\u001b[A\n","Iteration:  16% 69/422 [00:24<02:00,  2.94it/s]\u001b[A\n","Iteration:  17% 70/422 [00:24<01:59,  2.94it/s]\u001b[A\n","Iteration:  17% 71/422 [00:25<01:59,  2.93it/s]\u001b[A\n","Iteration:  17% 72/422 [00:25<01:59,  2.94it/s]\u001b[A\n","Iteration:  17% 73/422 [00:25<01:58,  2.94it/s]\u001b[A\n","Iteration:  18% 74/422 [00:26<01:58,  2.94it/s]\u001b[A\n","Iteration:  18% 75/422 [00:26<01:57,  2.94it/s]\u001b[A\n","Iteration:  18% 76/422 [00:26<01:57,  2.94it/s]\u001b[A\n","Iteration:  18% 77/422 [00:27<01:57,  2.94it/s]\u001b[A\n","Iteration:  18% 78/422 [00:27<01:57,  2.94it/s]\u001b[A\n","Iteration:  19% 79/422 [00:27<01:56,  2.94it/s]\u001b[A\n","Iteration:  19% 80/422 [00:28<01:56,  2.94it/s]\u001b[A\n","Iteration:  19% 81/422 [00:28<01:56,  2.94it/s]\u001b[A\n","Iteration:  19% 82/422 [00:28<01:55,  2.94it/s]\u001b[A\n","Iteration:  20% 83/422 [00:29<01:55,  2.93it/s]\u001b[A\n","Iteration:  20% 84/422 [00:29<01:55,  2.94it/s]\u001b[A\n","Iteration:  20% 85/422 [00:29<01:54,  2.94it/s]\u001b[A\n","Iteration:  20% 86/422 [00:30<01:54,  2.94it/s]\u001b[A\n","Iteration:  21% 87/422 [00:30<01:54,  2.93it/s]\u001b[A\n","Iteration:  21% 88/422 [00:30<01:53,  2.93it/s]\u001b[A\n","Iteration:  21% 89/422 [00:31<01:53,  2.94it/s]\u001b[A\n","Iteration:  21% 90/422 [00:31<01:52,  2.94it/s]\u001b[A\n","Iteration:  22% 91/422 [00:31<01:52,  2.94it/s]\u001b[A\n","Iteration:  22% 92/422 [00:32<01:52,  2.94it/s]\u001b[A\n","Iteration:  22% 93/422 [00:32<01:51,  2.94it/s]\u001b[A\n","Iteration:  22% 94/422 [00:32<01:51,  2.94it/s]\u001b[A\n","Iteration:  23% 95/422 [00:33<01:51,  2.94it/s]\u001b[A\n","Iteration:  23% 96/422 [00:33<01:50,  2.94it/s]\u001b[A\n","Iteration:  23% 97/422 [00:33<01:50,  2.94it/s]\u001b[A\n","Iteration:  23% 98/422 [00:34<01:50,  2.94it/s]\u001b[A\n","Iteration:  23% 99/422 [00:34<01:49,  2.94it/s]\u001b[A\n","Iteration:  24% 100/422 [00:34<01:49,  2.94it/s]\u001b[A\n","Iteration:  24% 101/422 [00:35<01:49,  2.94it/s]\u001b[A\n","Iteration:  24% 102/422 [00:35<01:48,  2.94it/s]\u001b[A\n","Iteration:  24% 103/422 [00:35<01:48,  2.94it/s]\u001b[A\n","Iteration:  25% 104/422 [00:36<01:48,  2.93it/s]\u001b[A\n","Iteration:  25% 105/422 [00:36<01:47,  2.94it/s]\u001b[A\n","Iteration:  25% 106/422 [00:36<01:47,  2.94it/s]\u001b[A\n","Iteration:  25% 107/422 [00:37<01:47,  2.93it/s]\u001b[A\n","Iteration:  26% 108/422 [00:37<01:46,  2.94it/s]\u001b[A\n","Iteration:  26% 109/422 [00:37<01:46,  2.94it/s]\u001b[A\n","Iteration:  26% 110/422 [00:38<01:46,  2.93it/s]\u001b[A\n","Iteration:  26% 111/422 [00:38<01:45,  2.94it/s]\u001b[A\n","Iteration:  27% 112/422 [00:38<01:45,  2.94it/s]\u001b[A\n","Iteration:  27% 113/422 [00:39<01:45,  2.94it/s]\u001b[A\n","Iteration:  27% 114/422 [00:39<01:44,  2.94it/s]\u001b[A\n","Iteration:  27% 115/422 [00:39<01:44,  2.94it/s]\u001b[A\n","Iteration:  27% 116/422 [00:40<01:44,  2.94it/s]\u001b[A\n","Iteration:  28% 117/422 [00:40<01:43,  2.94it/s]\u001b[A\n","Iteration:  28% 118/422 [00:41<01:43,  2.94it/s]\u001b[A\n","Iteration:  28% 119/422 [00:41<01:43,  2.94it/s]\u001b[A\n","Iteration:  28% 120/422 [00:41<01:42,  2.94it/s]\u001b[A\n","Iteration:  29% 121/422 [00:42<01:42,  2.94it/s]\u001b[A\n","Iteration:  29% 122/422 [00:42<01:42,  2.94it/s]\u001b[A\n","Iteration:  29% 123/422 [00:42<01:42,  2.93it/s]\u001b[A\n","Iteration:  29% 124/422 [00:43<01:41,  2.94it/s]\u001b[A\n","Iteration:  30% 125/422 [00:43<01:41,  2.94it/s]\u001b[A\n","Iteration:  30% 126/422 [00:43<01:40,  2.94it/s]\u001b[A\n","Iteration:  30% 127/422 [00:44<01:40,  2.94it/s]\u001b[A\n","Iteration:  30% 128/422 [00:44<01:40,  2.94it/s]\u001b[A\n","Iteration:  31% 129/422 [00:44<01:39,  2.94it/s]\u001b[A\n","Iteration:  31% 130/422 [00:45<01:39,  2.94it/s]\u001b[A\n","Iteration:  31% 131/422 [00:45<01:38,  2.94it/s]\u001b[A\n","Iteration:  31% 132/422 [00:45<01:38,  2.94it/s]\u001b[A\n","Iteration:  32% 133/422 [00:46<01:38,  2.94it/s]\u001b[A\n","Iteration:  32% 134/422 [00:46<01:37,  2.94it/s]\u001b[A\n","Iteration:  32% 135/422 [00:46<01:37,  2.93it/s]\u001b[A\n","Iteration:  32% 136/422 [00:47<01:37,  2.93it/s]\u001b[A\n","Iteration:  32% 137/422 [00:47<01:37,  2.93it/s]\u001b[A\n","Iteration:  33% 138/422 [00:47<01:36,  2.93it/s]\u001b[A\n","Iteration:  33% 139/422 [00:48<01:36,  2.93it/s]\u001b[A\n","Iteration:  33% 140/422 [00:48<01:36,  2.94it/s]\u001b[A\n","Iteration:  33% 141/422 [00:48<01:35,  2.94it/s]\u001b[A\n","Iteration:  34% 142/422 [00:49<01:35,  2.94it/s]\u001b[A\n","Iteration:  34% 143/422 [00:49<01:34,  2.94it/s]\u001b[A\n","Iteration:  34% 144/422 [00:49<01:34,  2.94it/s]\u001b[A\n","Iteration:  34% 145/422 [00:50<01:34,  2.94it/s]\u001b[A\n","Iteration:  35% 146/422 [00:50<01:33,  2.94it/s]\u001b[A\n","Iteration:  35% 147/422 [00:50<01:33,  2.94it/s]\u001b[A\n","Iteration:  35% 148/422 [00:51<01:33,  2.94it/s]\u001b[A\n","Iteration:  35% 149/422 [00:51<01:32,  2.94it/s]\u001b[A\n","Iteration:  36% 150/422 [00:51<01:32,  2.93it/s]\u001b[A\n","Iteration:  36% 151/422 [00:52<01:32,  2.94it/s]\u001b[A\n","Iteration:  36% 152/422 [00:52<01:31,  2.94it/s]\u001b[A\n","Iteration:  36% 153/422 [00:52<01:31,  2.94it/s]\u001b[A\n","Iteration:  36% 154/422 [00:53<01:31,  2.94it/s]\u001b[A\n","Iteration:  37% 155/422 [00:53<01:30,  2.94it/s]\u001b[A\n","Iteration:  37% 156/422 [00:53<01:30,  2.94it/s]\u001b[A\n","Iteration:  37% 157/422 [00:54<01:30,  2.94it/s]\u001b[A\n","Iteration:  37% 158/422 [00:54<01:29,  2.94it/s]\u001b[A\n","Iteration:  38% 159/422 [00:54<01:29,  2.94it/s]\u001b[A\n","Iteration:  38% 160/422 [00:55<01:29,  2.93it/s]\u001b[A\n","Iteration:  38% 161/422 [00:55<01:28,  2.94it/s]\u001b[A\n","Iteration:  38% 162/422 [00:55<01:28,  2.94it/s]\u001b[A\n","Iteration:  39% 163/422 [00:56<01:28,  2.94it/s]\u001b[A\n","Iteration:  39% 164/422 [00:56<01:27,  2.94it/s]\u001b[A\n","Iteration:  39% 165/422 [00:56<01:27,  2.94it/s]\u001b[A\n","Iteration:  39% 166/422 [00:57<01:26,  2.94it/s]\u001b[A\n","Iteration:  40% 167/422 [00:57<01:27,  2.93it/s]\u001b[A\n","Iteration:  40% 168/422 [00:58<01:26,  2.93it/s]\u001b[A\n","Iteration:  40% 169/422 [00:58<01:26,  2.94it/s]\u001b[A\n","Iteration:  40% 170/422 [00:58<01:25,  2.94it/s]\u001b[A\n","Iteration:  41% 171/422 [00:59<01:25,  2.94it/s]\u001b[A\n","Iteration:  41% 172/422 [00:59<01:25,  2.94it/s]\u001b[A\n","Iteration:  41% 173/422 [00:59<01:24,  2.94it/s]\u001b[A\n","Iteration:  41% 174/422 [01:00<01:24,  2.94it/s]\u001b[A\n","Iteration:  41% 175/422 [01:00<01:24,  2.94it/s]\u001b[A\n","Iteration:  42% 176/422 [01:00<01:23,  2.94it/s]\u001b[A\n","Iteration:  42% 177/422 [01:01<01:23,  2.94it/s]\u001b[A\n","Iteration:  42% 178/422 [01:01<01:23,  2.93it/s]\u001b[A\n","Iteration:  42% 179/422 [01:01<01:22,  2.95it/s]\u001b[A\n","Iteration:  43% 180/422 [01:02<01:22,  2.94it/s]\u001b[A\n","Iteration:  43% 181/422 [01:02<01:21,  2.94it/s]\u001b[A\n","Iteration:  43% 182/422 [01:02<01:21,  2.93it/s]\u001b[A\n","Iteration:  43% 183/422 [01:03<01:21,  2.94it/s]\u001b[A\n","Iteration:  44% 184/422 [01:03<01:21,  2.93it/s]\u001b[A\n","Iteration:  44% 185/422 [01:03<01:20,  2.94it/s]\u001b[A\n","Iteration:  44% 186/422 [01:04<01:20,  2.94it/s]\u001b[A\n","Iteration:  44% 187/422 [01:04<01:19,  2.94it/s]\u001b[A\n","Iteration:  45% 188/422 [01:04<01:19,  2.94it/s]\u001b[A\n","Iteration:  45% 189/422 [01:05<01:19,  2.94it/s]\u001b[A\n","Iteration:  45% 190/422 [01:05<01:18,  2.94it/s]\u001b[A\n","Iteration:  45% 191/422 [01:05<01:18,  2.94it/s]\u001b[A\n","Iteration:  45% 192/422 [01:06<01:18,  2.94it/s]\u001b[A\n","Iteration:  46% 193/422 [01:06<01:17,  2.94it/s]\u001b[A\n","Iteration:  46% 194/422 [01:06<01:17,  2.94it/s]\u001b[A\n","Iteration:  46% 195/422 [01:07<01:17,  2.94it/s]\u001b[A\n","Iteration:  46% 196/422 [01:07<01:16,  2.94it/s]\u001b[A\n","Iteration:  47% 197/422 [01:07<01:16,  2.94it/s]\u001b[A\n","Iteration:  47% 198/422 [01:08<01:16,  2.94it/s]\u001b[A\n","Iteration:  47% 199/422 [01:08<01:15,  2.94it/s]\u001b[A\n","Iteration:  47% 200/422 [01:08<01:15,  2.95it/s]\u001b[A\n","Iteration:  48% 201/422 [01:09<01:15,  2.94it/s]\u001b[A\n","Iteration:  48% 202/422 [01:09<01:14,  2.95it/s]\u001b[A\n","Iteration:  48% 203/422 [01:09<01:14,  2.94it/s]\u001b[A\n","Iteration:  48% 204/422 [01:10<01:14,  2.94it/s]\u001b[A\n","Iteration:  49% 205/422 [01:10<01:13,  2.94it/s]\u001b[A\n","Iteration:  49% 206/422 [01:10<01:13,  2.94it/s]\u001b[A\n","Iteration:  49% 207/422 [01:11<01:13,  2.94it/s]\u001b[A\n","Iteration:  49% 208/422 [01:11<01:12,  2.95it/s]\u001b[A\n","Iteration:  50% 209/422 [01:11<01:12,  2.94it/s]\u001b[A\n","Iteration:  50% 210/422 [01:12<01:12,  2.94it/s]\u001b[A\n","Iteration:  50% 211/422 [01:12<01:11,  2.94it/s]\u001b[A\n","Iteration:  50% 212/422 [01:12<01:11,  2.94it/s]\u001b[A\n","Iteration:  50% 213/422 [01:13<01:11,  2.94it/s]\u001b[A\n","Iteration:  51% 214/422 [01:13<01:10,  2.94it/s]\u001b[A\n","Iteration:  51% 215/422 [01:14<01:10,  2.93it/s]\u001b[A\n","Iteration:  51% 216/422 [01:14<01:09,  2.94it/s]\u001b[A\n","Iteration:  51% 217/422 [01:14<01:09,  2.94it/s]\u001b[A\n","Iteration:  52% 218/422 [01:15<01:09,  2.94it/s]\u001b[A\n","Iteration:  52% 219/422 [01:15<01:08,  2.94it/s]\u001b[A\n","Iteration:  52% 220/422 [01:15<01:08,  2.94it/s]\u001b[A\n","Iteration:  52% 221/422 [01:16<01:08,  2.94it/s]\u001b[A\n","Iteration:  53% 222/422 [01:16<01:07,  2.94it/s]\u001b[A\n","Iteration:  53% 223/422 [01:16<01:07,  2.94it/s]\u001b[A\n","Iteration:  53% 224/422 [01:17<01:07,  2.94it/s]\u001b[A\n","Iteration:  53% 225/422 [01:17<01:06,  2.94it/s]\u001b[A\n","Iteration:  54% 226/422 [01:17<01:06,  2.95it/s]\u001b[A\n","Iteration:  54% 227/422 [01:18<01:06,  2.95it/s]\u001b[A\n","Iteration:  54% 228/422 [01:18<01:05,  2.95it/s]\u001b[A\n","Iteration:  54% 229/422 [01:18<01:05,  2.94it/s]\u001b[A\n","Iteration:  55% 230/422 [01:19<01:05,  2.94it/s]\u001b[A\n","Iteration:  55% 231/422 [01:19<01:04,  2.94it/s]\u001b[A\n","Iteration:  55% 232/422 [01:19<01:04,  2.94it/s]\u001b[A\n","Iteration:  55% 233/422 [01:20<01:04,  2.94it/s]\u001b[A\n","Iteration:  55% 234/422 [01:20<01:03,  2.94it/s]\u001b[A\n","Iteration:  56% 235/422 [01:20<01:03,  2.94it/s]\u001b[A\n","Iteration:  56% 236/422 [01:21<01:03,  2.93it/s]\u001b[A\n","Iteration:  56% 237/422 [01:21<01:02,  2.94it/s]\u001b[A\n","Iteration:  56% 238/422 [01:21<01:02,  2.94it/s]\u001b[A\n","Iteration:  57% 239/422 [01:22<01:02,  2.94it/s]\u001b[A\n","Iteration:  57% 240/422 [01:22<01:01,  2.94it/s]\u001b[A\n","Iteration:  57% 241/422 [01:22<01:01,  2.94it/s]\u001b[A\n","Iteration:  57% 242/422 [01:23<01:01,  2.94it/s]\u001b[A\n","Iteration:  58% 243/422 [01:23<01:00,  2.94it/s]\u001b[A\n","Iteration:  58% 244/422 [01:23<01:00,  2.94it/s]\u001b[A\n","Iteration:  58% 245/422 [01:24<01:00,  2.94it/s]\u001b[A\n","Iteration:  58% 246/422 [01:24<00:59,  2.94it/s]\u001b[A\n","Iteration:  59% 247/422 [01:24<00:59,  2.95it/s]\u001b[A\n","Iteration:  59% 248/422 [01:25<00:59,  2.94it/s]\u001b[A\n","Iteration:  59% 249/422 [01:25<00:58,  2.94it/s]\u001b[A\n","Iteration:  59% 250/422 [01:25<00:59,  2.91it/s]\u001b[A\n","Iteration:  59% 251/422 [01:26<00:58,  2.92it/s]\u001b[A\n","Iteration:  60% 252/422 [01:26<00:58,  2.92it/s]\u001b[A\n","Iteration:  60% 253/422 [01:26<00:57,  2.93it/s]\u001b[A\n","Iteration:  60% 254/422 [01:27<00:57,  2.93it/s]\u001b[A\n","Iteration:  60% 255/422 [01:27<00:56,  2.93it/s]\u001b[A\n","Iteration:  61% 256/422 [01:27<00:56,  2.93it/s]\u001b[A\n","Iteration:  61% 257/422 [01:31<03:25,  1.24s/it]\u001b[A\n","Iteration:  61% 258/422 [01:31<02:39,  1.03it/s]\u001b[A\n","Iteration:  61% 259/422 [01:31<02:07,  1.28it/s]\u001b[A\n","Iteration:  62% 260/422 [01:32<01:45,  1.54it/s]\u001b[A\n","Iteration:  62% 261/422 [01:32<01:29,  1.80it/s]\u001b[A\n","Iteration:  62% 262/422 [01:32<01:18,  2.03it/s]\u001b[A\n","Iteration:  62% 263/422 [01:33<01:10,  2.24it/s]\u001b[A\n","Iteration:  63% 264/422 [01:33<01:05,  2.41it/s]\u001b[A\n","Iteration:  63% 265/422 [01:34<01:01,  2.55it/s]\u001b[A\n","Iteration:  63% 266/422 [01:34<00:58,  2.66it/s]\u001b[A\n","Iteration:  63% 267/422 [01:34<00:56,  2.74it/s]\u001b[A\n","Iteration:  64% 268/422 [01:35<00:55,  2.79it/s]\u001b[A\n","Iteration:  64% 269/422 [01:35<00:53,  2.83it/s]\u001b[A\n","Iteration:  64% 270/422 [01:35<00:53,  2.87it/s]\u001b[A\n","Iteration:  64% 271/422 [01:36<00:52,  2.88it/s]\u001b[A\n","Iteration:  64% 272/422 [01:36<00:51,  2.90it/s]\u001b[A\n","Iteration:  65% 273/422 [01:36<00:51,  2.91it/s]\u001b[A\n","Iteration:  65% 274/422 [01:37<00:50,  2.92it/s]\u001b[A\n","Iteration:  65% 275/422 [01:37<00:50,  2.93it/s]\u001b[A\n","Iteration:  65% 276/422 [01:37<00:49,  2.93it/s]\u001b[A\n","Iteration:  66% 277/422 [01:38<00:49,  2.93it/s]\u001b[A\n","Iteration:  66% 278/422 [01:38<00:49,  2.94it/s]\u001b[A\n","Iteration:  66% 279/422 [01:38<00:48,  2.94it/s]\u001b[A\n","Iteration:  66% 280/422 [01:39<00:48,  2.94it/s]\u001b[A\n","Iteration:  67% 281/422 [01:39<00:47,  2.94it/s]\u001b[A\n","Iteration:  67% 282/422 [01:39<00:47,  2.94it/s]\u001b[A\n","Iteration:  67% 283/422 [01:40<00:47,  2.94it/s]\u001b[A\n","Iteration:  67% 284/422 [01:40<00:46,  2.94it/s]\u001b[A\n","Iteration:  68% 285/422 [01:40<00:46,  2.94it/s]\u001b[A\n","Iteration:  68% 286/422 [01:41<00:46,  2.94it/s]\u001b[A\n","Iteration:  68% 287/422 [01:41<00:45,  2.94it/s]\u001b[A\n","Iteration:  68% 288/422 [01:41<00:45,  2.94it/s]\u001b[A\n","Iteration:  68% 289/422 [01:42<00:45,  2.93it/s]\u001b[A\n","Iteration:  69% 290/422 [01:42<00:44,  2.93it/s]\u001b[A\n","Iteration:  69% 291/422 [01:42<00:44,  2.93it/s]\u001b[A\n","Iteration:  69% 292/422 [01:43<00:44,  2.94it/s]\u001b[A\n","Iteration:  69% 293/422 [01:43<00:43,  2.94it/s]\u001b[A\n","Iteration:  70% 294/422 [01:43<00:43,  2.94it/s]\u001b[A\n","Iteration:  70% 295/422 [01:44<00:43,  2.94it/s]\u001b[A\n","Iteration:  70% 296/422 [01:44<00:42,  2.94it/s]\u001b[A\n","Iteration:  70% 297/422 [01:44<00:42,  2.94it/s]\u001b[A\n","Iteration:  71% 298/422 [01:45<00:42,  2.94it/s]\u001b[A\n","Iteration:  71% 299/422 [01:45<00:41,  2.94it/s]\u001b[A\n","Iteration:  71% 300/422 [01:45<00:41,  2.94it/s]\u001b[A\n","Iteration:  71% 301/422 [01:46<00:41,  2.94it/s]\u001b[A\n","Iteration:  72% 302/422 [01:46<00:40,  2.94it/s]\u001b[A\n","Iteration:  72% 303/422 [01:46<00:40,  2.94it/s]\u001b[A\n","Iteration:  72% 304/422 [01:47<00:40,  2.94it/s]\u001b[A\n","Iteration:  72% 305/422 [01:47<00:39,  2.94it/s]\u001b[A\n","Iteration:  73% 306/422 [01:47<00:39,  2.94it/s]\u001b[A\n","Iteration:  73% 307/422 [01:48<00:39,  2.94it/s]\u001b[A\n","Iteration:  73% 308/422 [01:48<00:38,  2.94it/s]\u001b[A\n","Iteration:  73% 309/422 [01:48<00:38,  2.94it/s]\u001b[A\n","Iteration:  73% 310/422 [01:49<00:38,  2.94it/s]\u001b[A\n","Iteration:  74% 311/422 [01:49<00:37,  2.94it/s]\u001b[A\n","Iteration:  74% 312/422 [01:50<00:37,  2.94it/s]\u001b[A\n","Iteration:  74% 313/422 [01:50<00:37,  2.94it/s]\u001b[A\n","Iteration:  74% 314/422 [01:50<00:36,  2.94it/s]\u001b[A\n","Iteration:  75% 315/422 [01:51<00:36,  2.94it/s]\u001b[A\n","Iteration:  75% 316/422 [01:51<00:36,  2.94it/s]\u001b[A\n","Iteration:  75% 317/422 [01:51<00:35,  2.93it/s]\u001b[A\n","Iteration:  75% 318/422 [01:52<00:35,  2.93it/s]\u001b[A\n","Iteration:  76% 319/422 [01:52<00:34,  2.94it/s]\u001b[A\n","Iteration:  76% 320/422 [01:52<00:34,  2.94it/s]\u001b[A\n","Iteration:  76% 321/422 [01:53<00:34,  2.94it/s]\u001b[A\n","Iteration:  76% 322/422 [01:53<00:34,  2.94it/s]\u001b[A\n","Iteration:  77% 323/422 [01:53<00:33,  2.94it/s]\u001b[A\n","Iteration:  77% 324/422 [01:54<00:33,  2.94it/s]\u001b[A\n","Iteration:  77% 325/422 [01:54<00:32,  2.94it/s]\u001b[A\n","Iteration:  77% 326/422 [01:54<00:32,  2.94it/s]\u001b[A\n","Iteration:  77% 327/422 [01:55<00:32,  2.94it/s]\u001b[A\n","Iteration:  78% 328/422 [01:55<00:31,  2.94it/s]\u001b[A\n","Iteration:  78% 329/422 [01:55<00:31,  2.94it/s]\u001b[A\n","Iteration:  78% 330/422 [01:56<00:31,  2.94it/s]\u001b[A\n","Iteration:  78% 331/422 [01:56<00:30,  2.94it/s]\u001b[A\n","Iteration:  79% 332/422 [01:56<00:30,  2.94it/s]\u001b[A\n","Iteration:  79% 333/422 [01:57<00:30,  2.94it/s]\u001b[A\n","Iteration:  79% 334/422 [01:57<00:29,  2.94it/s]\u001b[A\n","Iteration:  79% 335/422 [01:57<00:29,  2.94it/s]\u001b[A\n","Iteration:  80% 336/422 [01:58<00:29,  2.94it/s]\u001b[A\n","Iteration:  80% 337/422 [01:58<00:28,  2.94it/s]\u001b[A\n","Iteration:  80% 338/422 [01:58<00:28,  2.94it/s]\u001b[A\n","Iteration:  80% 339/422 [01:59<00:28,  2.94it/s]\u001b[A\n","Iteration:  81% 340/422 [01:59<00:27,  2.94it/s]\u001b[A\n","Iteration:  81% 341/422 [01:59<00:27,  2.94it/s]\u001b[A\n","Iteration:  81% 342/422 [02:00<00:27,  2.94it/s]\u001b[A\n","Iteration:  81% 343/422 [02:00<00:26,  2.94it/s]\u001b[A\n","Iteration:  82% 344/422 [02:00<00:26,  2.94it/s]\u001b[A\n","Iteration:  82% 345/422 [02:01<00:26,  2.94it/s]\u001b[A\n","Iteration:  82% 346/422 [02:01<00:25,  2.94it/s]\u001b[A\n","Iteration:  82% 347/422 [02:01<00:25,  2.95it/s]\u001b[A\n","Iteration:  82% 348/422 [02:02<00:25,  2.94it/s]\u001b[A\n","Iteration:  83% 349/422 [02:02<00:24,  2.94it/s]\u001b[A\n","Iteration:  83% 350/422 [02:02<00:24,  2.94it/s]\u001b[A\n","Iteration:  83% 351/422 [02:03<00:24,  2.95it/s]\u001b[A\n","Iteration:  83% 352/422 [02:03<00:23,  2.95it/s]\u001b[A\n","Iteration:  84% 353/422 [02:03<00:23,  2.94it/s]\u001b[A\n","Iteration:  84% 354/422 [02:04<00:23,  2.94it/s]\u001b[A\n","Iteration:  84% 355/422 [02:04<00:22,  2.94it/s]\u001b[A\n","Iteration:  84% 356/422 [02:04<00:22,  2.94it/s]\u001b[A\n","Iteration:  85% 357/422 [02:05<00:22,  2.94it/s]\u001b[A\n","Iteration:  85% 358/422 [02:05<00:21,  2.94it/s]\u001b[A\n","Iteration:  85% 359/422 [02:05<00:21,  2.94it/s]\u001b[A\n","Iteration:  85% 360/422 [02:06<00:21,  2.94it/s]\u001b[A\n","Iteration:  86% 361/422 [02:06<00:20,  2.94it/s]\u001b[A\n","Iteration:  86% 362/422 [02:07<00:20,  2.94it/s]\u001b[A\n","Iteration:  86% 363/422 [02:07<00:20,  2.94it/s]\u001b[A\n","Iteration:  86% 364/422 [02:07<00:19,  2.94it/s]\u001b[A\n","Iteration:  86% 365/422 [02:08<00:19,  2.94it/s]\u001b[A\n","Iteration:  87% 366/422 [02:08<00:19,  2.93it/s]\u001b[A\n","Iteration:  87% 367/422 [02:08<00:18,  2.94it/s]\u001b[A\n","Iteration:  87% 368/422 [02:09<00:18,  2.95it/s]\u001b[A\n","Iteration:  87% 369/422 [02:09<00:18,  2.94it/s]\u001b[A\n","Iteration:  88% 370/422 [02:09<00:17,  2.94it/s]\u001b[A\n","Iteration:  88% 371/422 [02:10<00:17,  2.94it/s]\u001b[A\n","Iteration:  88% 372/422 [02:10<00:16,  2.94it/s]\u001b[A\n","Iteration:  88% 373/422 [02:10<00:16,  2.94it/s]\u001b[A\n","Iteration:  89% 374/422 [02:11<00:16,  2.94it/s]\u001b[A\n","Iteration:  89% 375/422 [02:11<00:15,  2.94it/s]\u001b[A\n","Iteration:  89% 376/422 [02:11<00:15,  2.94it/s]\u001b[A\n","Iteration:  89% 377/422 [02:12<00:15,  2.94it/s]\u001b[A\n","Iteration:  90% 378/422 [02:12<00:14,  2.94it/s]\u001b[A\n","Iteration:  90% 379/422 [02:12<00:14,  2.94it/s]\u001b[A\n","Iteration:  90% 380/422 [02:13<00:14,  2.94it/s]\u001b[A\n","Iteration:  90% 381/422 [02:13<00:13,  2.95it/s]\u001b[A\n","Iteration:  91% 382/422 [02:13<00:13,  2.94it/s]\u001b[A\n","Iteration:  91% 383/422 [02:14<00:13,  2.94it/s]\u001b[A\n","Iteration:  91% 384/422 [02:14<00:12,  2.94it/s]\u001b[A\n","Iteration:  91% 385/422 [02:14<00:12,  2.94it/s]\u001b[A\n","Iteration:  91% 386/422 [02:15<00:12,  2.95it/s]\u001b[A\n","Iteration:  92% 387/422 [02:15<00:11,  2.95it/s]\u001b[A\n","Iteration:  92% 388/422 [02:15<00:11,  2.95it/s]\u001b[A\n","Iteration:  92% 389/422 [02:16<00:11,  2.94it/s]\u001b[A\n","Iteration:  92% 390/422 [02:16<00:10,  2.94it/s]\u001b[A\n","Iteration:  93% 391/422 [02:16<00:10,  2.93it/s]\u001b[A\n","Iteration:  93% 392/422 [02:17<00:10,  2.95it/s]\u001b[A\n","Iteration:  93% 393/422 [02:17<00:09,  2.95it/s]\u001b[A\n","Iteration:  93% 394/422 [02:17<00:09,  2.94it/s]\u001b[A\n","Iteration:  94% 395/422 [02:18<00:09,  2.95it/s]\u001b[A\n","Iteration:  94% 396/422 [02:18<00:08,  2.95it/s]\u001b[A\n","Iteration:  94% 397/422 [02:18<00:08,  2.94it/s]\u001b[A\n","Iteration:  94% 398/422 [02:19<00:08,  2.94it/s]\u001b[A\n","Iteration:  95% 399/422 [02:19<00:07,  2.95it/s]\u001b[A\n","Iteration:  95% 400/422 [02:19<00:07,  2.94it/s]\u001b[A\n","Iteration:  95% 401/422 [02:20<00:07,  2.95it/s]\u001b[A\n","Iteration:  95% 402/422 [02:20<00:06,  2.94it/s]\u001b[A\n","Iteration:  95% 403/422 [02:20<00:06,  2.94it/s]\u001b[A\n","Iteration:  96% 404/422 [02:21<00:06,  2.94it/s]\u001b[A\n","Iteration:  96% 405/422 [02:21<00:05,  2.94it/s]\u001b[A\n","Iteration:  96% 406/422 [02:21<00:05,  2.94it/s]\u001b[A\n","Iteration:  96% 407/422 [02:22<00:05,  2.94it/s]\u001b[A\n","Iteration:  97% 408/422 [02:22<00:04,  2.94it/s]\u001b[A\n","Iteration:  97% 409/422 [02:22<00:04,  2.93it/s]\u001b[A\n","Iteration:  97% 410/422 [02:23<00:04,  2.94it/s]\u001b[A\n","Iteration:  97% 411/422 [02:23<00:03,  2.94it/s]\u001b[A\n","Iteration:  98% 412/422 [02:23<00:03,  2.93it/s]\u001b[A\n","Iteration:  98% 413/422 [02:24<00:03,  2.94it/s]\u001b[A\n","Iteration:  98% 414/422 [02:24<00:02,  2.94it/s]\u001b[A\n","Iteration:  98% 415/422 [02:25<00:02,  2.94it/s]\u001b[A\n","Iteration:  99% 416/422 [02:25<00:02,  2.94it/s]\u001b[A\n","Iteration:  99% 417/422 [02:25<00:01,  2.94it/s]\u001b[A\n","Iteration:  99% 418/422 [02:26<00:01,  2.94it/s]\u001b[A\n","Iteration:  99% 419/422 [02:26<00:01,  2.94it/s]\u001b[A\n","Iteration: 100% 420/422 [02:26<00:00,  2.94it/s]\u001b[A\n","Iteration: 100% 421/422 [02:27<00:00,  2.94it/s]\u001b[A\n","Iteration: 100% 422/422 [02:27<00:00,  2.86it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-17 05:16:27,131][__main__][DEBUG] - early stop\n","Epoch:   1% 1/100 [10:02<16:34:39, 602.82s/it]\n"]}],"source":["!HYDRA_FULL_ERROR=1 python run.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w7sdHHb0uFV-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1db69243-8197-4ba0-b96c-5d88dd69b6f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","eval.py:21: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-17 05:16:34,199][HYDRA] Hydra 1.2.0\n","[2022-08-17 05:16:34,199][HYDRA] ===========\n","[2022-08-17 05:16:34,199][HYDRA] Installed Hydra Plugins\n","[2022-08-17 05:16:34,199][HYDRA] ***********************\n","[2022-08-17 05:16:34,199][HYDRA] \tConfigSource:\n","[2022-08-17 05:16:34,199][HYDRA] \t-------------\n","[2022-08-17 05:16:34,199][HYDRA] \t\tFileConfigSource\n","[2022-08-17 05:16:34,199][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-17 05:16:34,199][HYDRA] \t\tStructuredConfigSource\n","[2022-08-17 05:16:34,199][HYDRA] \tCompletionPlugin:\n","[2022-08-17 05:16:34,199][HYDRA] \t-----------------\n","[2022-08-17 05:16:34,199][HYDRA] \t\tBashCompletion\n","[2022-08-17 05:16:34,199][HYDRA] \t\tFishCompletion\n","[2022-08-17 05:16:34,199][HYDRA] \t\tZshCompletion\n","[2022-08-17 05:16:34,199][HYDRA] \tLauncher:\n","[2022-08-17 05:16:34,199][HYDRA] \t---------\n","[2022-08-17 05:16:34,199][HYDRA] \t\tBasicLauncher\n","[2022-08-17 05:16:34,199][HYDRA] \tSweeper:\n","[2022-08-17 05:16:34,199][HYDRA] \t--------\n","[2022-08-17 05:16:34,200][HYDRA] \t\tBasicSweeper\n","[2022-08-17 05:16:34,200][HYDRA] \n","[2022-08-17 05:16:34,200][HYDRA] Config search path\n","[2022-08-17 05:16:34,200][HYDRA] ******************\n","[2022-08-17 05:16:34,478][HYDRA] | Provider | Search path                                                           |\n","[2022-08-17 05:16:34,478][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-17 05:16:34,478][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-17 05:16:34,479][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-17 05:16:34,479][HYDRA] | schema   | structured://                                                         |\n","[2022-08-17 05:16:34,479][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-17 05:16:34,549][HYDRA] \n","[2022-08-17 05:16:34,550][HYDRA] Defaults Tree\n","[2022-08-17 05:16:34,550][HYDRA] *************\n","[2022-08-17 05:16:34,550][HYDRA] <root>:\n","[2022-08-17 05:16:34,550][HYDRA]   hydra/config:\n","[2022-08-17 05:16:34,550][HYDRA]     hydra/output: default\n","[2022-08-17 05:16:34,550][HYDRA]     hydra/launcher: basic\n","[2022-08-17 05:16:34,550][HYDRA]     hydra/sweeper: basic\n","[2022-08-17 05:16:34,550][HYDRA]     hydra/help: default\n","[2022-08-17 05:16:34,550][HYDRA]     hydra/hydra_help: default\n","[2022-08-17 05:16:34,550][HYDRA]     hydra/hydra_logging: default\n","[2022-08-17 05:16:34,550][HYDRA]     hydra/job_logging: default\n","[2022-08-17 05:16:34,550][HYDRA]     hydra/callbacks: null\n","[2022-08-17 05:16:34,551][HYDRA]     hydra/env: default\n","[2022-08-17 05:16:34,551][HYDRA]     _self_\n","[2022-08-17 05:16:34,551][HYDRA]   config:\n","[2022-08-17 05:16:34,551][HYDRA]     data/YAGO43kET\n","[2022-08-17 05:16:34,551][HYDRA]     model/Bart\n","[2022-08-17 05:16:34,551][HYDRA]     _self_\n","[2022-08-17 05:16:34,617][HYDRA] \n","[2022-08-17 05:16:34,618][HYDRA] Defaults List\n","[2022-08-17 05:16:34,618][HYDRA] *************\n","[2022-08-17 05:16:34,618][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-17 05:16:34,618][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-17 05:16:34,618][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-17 05:16:34,618][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-17 05:16:34,618][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-17 05:16:34,618][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-17 05:16:34,618][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-17 05:16:34,618][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-17 05:16:34,618][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-17 05:16:34,618][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-17 05:16:34,618][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-17 05:16:34,618][HYDRA] | data/YAGO43kET              | data                | False  | config       |\n","[2022-08-17 05:16:34,618][HYDRA] | model/Bart                  | model               | False  | config       |\n","[2022-08-17 05:16:34,618][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-17 05:16:34,618][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-17 05:16:34,734][HYDRA] Config\n","[2022-08-17 05:16:34,734][HYDRA] ******\n","[2022-08-17 05:16:34,738][HYDRA] data:\n","  name: YAGO43kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  lowest_level: false\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: Bart\n","  train_dataset: ET_1_1_train.txt\n","  pretrained_model: facebook/bart-base\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 256\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_1_1_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 256\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_1_1_test.txt\n","    unobserved_test_dataset: ET_1_1_unobserved_test.txt\n","    save_outputs: true\n","    max_output_length: 128\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: save/FB15kET/ET_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-17 05:16:34,805][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-17 05:16:34,805 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-17 05:16:34,921][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","2022-08-17 05:16:34,921 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-17 05:16:34,924][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-17 05:16:34,924 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-17 05:16:35,045][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","2022-08-17 05:16:35,045 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-17 05:16:35,046][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-17 05:16:35,046 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-17 05:16:35,046][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-17 05:16:35,046 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","tcmalloc: large alloc 7651123200 bytes == 0xd640000 @  0x7f334c444b6b 0x7f334c464379 0x7f32952d326e 0x7f32952d49e2 0x7f329664fe19 0x7f3296650b67 0x7f3296a2d059 0x7f3297191e6a 0x7f3297174f8e 0x7f3296d79cd5 0x7f3296a310c0 0x7f3297303e64 0x7f3297161ec4 0x7f3297178287 0x7f3296dd3441 0x7f3339d42d25 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x593fce 0x5118f8 0x4bc98a 0x532c1b 0x594a96 0x515600 0x593dd7 0x5118f8 0x549576\n","tcmalloc: large alloc 7651123200 bytes == 0x7f2fe01a8000 @  0x7f334c444b6b 0x7f334c464379 0x7f32952d326e 0x7f32952d49e2 0x7f329664fe19 0x7f3296650b67 0x7f3296a2d059 0x7f3297191e6a 0x7f3297174f8e 0x7f3296d79cd5 0x7f3296a310c0 0x7f3297303e64 0x7f3297161ec4 0x7f3297178287 0x7f3296dd3441 0x7f3339d42d25 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x593fce 0x5118f8 0x4bc98a 0x532c1b 0x594a96 0x515600 0x593dd7 0x5118f8 0x549576\n","[2022-08-17 05:16:40,288][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-17 05:16:40,288 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-17 05:16:40,418][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 0\n","2022-08-17 05:16:40,418 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/facebook/bart-base/config.json HTTP/1.1\" 200 0\n","[2022-08-17 05:16:40,420][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","2022-08-17 05:16:40,420 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n","[2022-08-17 05:16:40,420][transformers.configuration_utils][INFO] - Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\",\n","    \"BartForConditionalGeneration\",\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-17 05:16:40,420 INFO     Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\",\n","    \"BartForConditionalGeneration\",\n","    \"BartForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 128,\n","      \"min_length\": 12,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_cnn\": {\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"num_beams\": 4\n","    },\n","    \"summarization_xsum\": {\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 62,\n","      \"min_length\": 11,\n","      \"num_beams\": 6\n","    }\n","  },\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-17 05:16:40,424][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-17 05:16:40,424 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-17 05:16:40,538][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-17 05:16:40,538 DEBUG    https://cdn.huggingface.co:443 \"HEAD /facebook/bart-base/pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-17 05:16:40,539][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","2022-08-17 05:16:40,539 INFO     loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n","[2022-08-17 05:16:43,620][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","2022-08-17 05:16:43,620 INFO     All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","[2022-08-17 05:16:43,620][transformers.modeling_utils][INFO] - All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","2022-08-17 05:16:43,620 INFO     All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","[2022-08-17 05:16:47,372][root][DEBUG] - Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","2022-08-17 05:16:47,372 DEBUG    Parameter model.model.shared.weight: torch.Size([50265, 768]), require_grad=True\n","[2022-08-17 05:16:47,372][root][DEBUG] - Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","2022-08-17 05:16:47,372 DEBUG    Parameter model.model.encoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-17 05:16:47,373][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,373 DEBUG    Parameter model.model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,373][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,373 DEBUG    Parameter model.model.encoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,373][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,373 DEBUG    Parameter model.model.encoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,373][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,373 DEBUG    Parameter model.model.encoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,373][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,373 DEBUG    Parameter model.model.encoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,373][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,373 DEBUG    Parameter model.model.encoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,373][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,373 DEBUG    Parameter model.model.encoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,373][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,373 DEBUG    Parameter model.model.encoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,374][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,374 DEBUG    Parameter model.model.encoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,374][root][DEBUG] - Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,374 DEBUG    Parameter model.model.encoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,374][root][DEBUG] - Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,374 DEBUG    Parameter model.model.encoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,374][root][DEBUG] - Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,374 DEBUG    Parameter model.model.encoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,374][root][DEBUG] - Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,374 DEBUG    Parameter model.model.encoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,374][root][DEBUG] - Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,374 DEBUG    Parameter model.model.encoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,374][root][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,374 DEBUG    Parameter model.model.encoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,375][root][DEBUG] - Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,375 DEBUG    Parameter model.model.encoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,375][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,375 DEBUG    Parameter model.model.encoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,375][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,375 DEBUG    Parameter model.model.encoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,375][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,375 DEBUG    Parameter model.model.encoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,375][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,375 DEBUG    Parameter model.model.encoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,375][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,375 DEBUG    Parameter model.model.encoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,375][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,375 DEBUG    Parameter model.model.encoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,376][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,376 DEBUG    Parameter model.model.encoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,376][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,376 DEBUG    Parameter model.model.encoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,376][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,376 DEBUG    Parameter model.model.encoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,376][root][DEBUG] - Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,376 DEBUG    Parameter model.model.encoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,376][root][DEBUG] - Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,376 DEBUG    Parameter model.model.encoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,376][root][DEBUG] - Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,376 DEBUG    Parameter model.model.encoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,376][root][DEBUG] - Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,376 DEBUG    Parameter model.model.encoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,376][root][DEBUG] - Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,376 DEBUG    Parameter model.model.encoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,377][root][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,377 DEBUG    Parameter model.model.encoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,377][root][DEBUG] - Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,377 DEBUG    Parameter model.model.encoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,377][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,377 DEBUG    Parameter model.model.encoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,377][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,377 DEBUG    Parameter model.model.encoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,377][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,377 DEBUG    Parameter model.model.encoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,377][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,377 DEBUG    Parameter model.model.encoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,377][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,377 DEBUG    Parameter model.model.encoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,378][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,378 DEBUG    Parameter model.model.encoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,378][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,378 DEBUG    Parameter model.model.encoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,378][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,378 DEBUG    Parameter model.model.encoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,378][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,378 DEBUG    Parameter model.model.encoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,378][root][DEBUG] - Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,378 DEBUG    Parameter model.model.encoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,378][root][DEBUG] - Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,378 DEBUG    Parameter model.model.encoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,378][root][DEBUG] - Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,378 DEBUG    Parameter model.model.encoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,378][root][DEBUG] - Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,378 DEBUG    Parameter model.model.encoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,379][root][DEBUG] - Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,379 DEBUG    Parameter model.model.encoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,379][root][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,379 DEBUG    Parameter model.model.encoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,379][root][DEBUG] - Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,379 DEBUG    Parameter model.model.encoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,379][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,379 DEBUG    Parameter model.model.encoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,379][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,379 DEBUG    Parameter model.model.encoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,379][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,379 DEBUG    Parameter model.model.encoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,379][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,379 DEBUG    Parameter model.model.encoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,380][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,380 DEBUG    Parameter model.model.encoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,380][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,380 DEBUG    Parameter model.model.encoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,380][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,380 DEBUG    Parameter model.model.encoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,380][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,380 DEBUG    Parameter model.model.encoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,380][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,380 DEBUG    Parameter model.model.encoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,380][root][DEBUG] - Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,380 DEBUG    Parameter model.model.encoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,380][root][DEBUG] - Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,380 DEBUG    Parameter model.model.encoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,380][root][DEBUG] - Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,380 DEBUG    Parameter model.model.encoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,381][root][DEBUG] - Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,381 DEBUG    Parameter model.model.encoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,381][root][DEBUG] - Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,381 DEBUG    Parameter model.model.encoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,381][root][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,381 DEBUG    Parameter model.model.encoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,381][root][DEBUG] - Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,381 DEBUG    Parameter model.model.encoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,381][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,381 DEBUG    Parameter model.model.encoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,382][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,382 DEBUG    Parameter model.model.encoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,382][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,382 DEBUG    Parameter model.model.encoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,382][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,382 DEBUG    Parameter model.model.encoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,382][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,382 DEBUG    Parameter model.model.encoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,382][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,382 DEBUG    Parameter model.model.encoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,383][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,383 DEBUG    Parameter model.model.encoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,383][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,383 DEBUG    Parameter model.model.encoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,383][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,383 DEBUG    Parameter model.model.encoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,383][root][DEBUG] - Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,383 DEBUG    Parameter model.model.encoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,384][root][DEBUG] - Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,384 DEBUG    Parameter model.model.encoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,384][root][DEBUG] - Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,384 DEBUG    Parameter model.model.encoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,384][root][DEBUG] - Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,384 DEBUG    Parameter model.model.encoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,384][root][DEBUG] - Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,384 DEBUG    Parameter model.model.encoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,384][root][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,384 DEBUG    Parameter model.model.encoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,385][root][DEBUG] - Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,385 DEBUG    Parameter model.model.encoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,385][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,385 DEBUG    Parameter model.model.encoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,385][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,385 DEBUG    Parameter model.model.encoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,385][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,385 DEBUG    Parameter model.model.encoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,385][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,385 DEBUG    Parameter model.model.encoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,386][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,386 DEBUG    Parameter model.model.encoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,386][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,386 DEBUG    Parameter model.model.encoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,386][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,386 DEBUG    Parameter model.model.encoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,386][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,386 DEBUG    Parameter model.model.encoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,386][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,386 DEBUG    Parameter model.model.encoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,387][root][DEBUG] - Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,387 DEBUG    Parameter model.model.encoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,387][root][DEBUG] - Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,387 DEBUG    Parameter model.model.encoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,387][root][DEBUG] - Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,387 DEBUG    Parameter model.model.encoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,387][root][DEBUG] - Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,387 DEBUG    Parameter model.model.encoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,387][root][DEBUG] - Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,387 DEBUG    Parameter model.model.encoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,388][root][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,388 DEBUG    Parameter model.model.encoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,388][root][DEBUG] - Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,388 DEBUG    Parameter model.model.encoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,388][root][DEBUG] - Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,388 DEBUG    Parameter model.model.encoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,388][root][DEBUG] - Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,388 DEBUG    Parameter model.model.encoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,388][root][DEBUG] - Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","2022-08-17 05:16:47,388 DEBUG    Parameter model.model.decoder.embed_positions.weight: torch.Size([1026, 768]), require_grad=True\n","[2022-08-17 05:16:47,389][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,389 DEBUG    Parameter model.model.decoder.layers.0.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,389][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,389 DEBUG    Parameter model.model.decoder.layers.0.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,389][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,389 DEBUG    Parameter model.model.decoder.layers.0.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,389][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,389 DEBUG    Parameter model.model.decoder.layers.0.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,389][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,389 DEBUG    Parameter model.model.decoder.layers.0.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,389][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,389 DEBUG    Parameter model.model.decoder.layers.0.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,390][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,390 DEBUG    Parameter model.model.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,390][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,390 DEBUG    Parameter model.model.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,390][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,390 DEBUG    Parameter model.model.decoder.layers.0.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,390][root][DEBUG] - Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,390 DEBUG    Parameter model.model.decoder.layers.0.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,390][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,390 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,390][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,390 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,391][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,391 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,391][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,391 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,391][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,391 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,391][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,391 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,391][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,391 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,392][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,392 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,392][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,392 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,392][root][DEBUG] - Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,392 DEBUG    Parameter model.model.decoder.layers.0.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,392][root][DEBUG] - Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,392 DEBUG    Parameter model.model.decoder.layers.0.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,392][root][DEBUG] - Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,392 DEBUG    Parameter model.model.decoder.layers.0.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,392][root][DEBUG] - Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,392 DEBUG    Parameter model.model.decoder.layers.0.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,393][root][DEBUG] - Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,393 DEBUG    Parameter model.model.decoder.layers.0.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,393][root][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,393 DEBUG    Parameter model.model.decoder.layers.0.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,393][root][DEBUG] - Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,393 DEBUG    Parameter model.model.decoder.layers.0.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,393][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,393 DEBUG    Parameter model.model.decoder.layers.1.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,393][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,393 DEBUG    Parameter model.model.decoder.layers.1.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,393][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,393 DEBUG    Parameter model.model.decoder.layers.1.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,394][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,394 DEBUG    Parameter model.model.decoder.layers.1.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,394][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,394 DEBUG    Parameter model.model.decoder.layers.1.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,394][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,394 DEBUG    Parameter model.model.decoder.layers.1.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,394][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,394 DEBUG    Parameter model.model.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,394][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,394 DEBUG    Parameter model.model.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,395][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,395 DEBUG    Parameter model.model.decoder.layers.1.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,395][root][DEBUG] - Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,395 DEBUG    Parameter model.model.decoder.layers.1.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,395][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,395 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,395][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,395 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,395][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,395 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,395][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,395 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,396][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,396 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,396][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,396 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,396][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,396 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,396][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,396 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,396][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,396 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,397][root][DEBUG] - Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,397 DEBUG    Parameter model.model.decoder.layers.1.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,397][root][DEBUG] - Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,397 DEBUG    Parameter model.model.decoder.layers.1.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,397][root][DEBUG] - Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,397 DEBUG    Parameter model.model.decoder.layers.1.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,397][root][DEBUG] - Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,397 DEBUG    Parameter model.model.decoder.layers.1.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,397][root][DEBUG] - Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,397 DEBUG    Parameter model.model.decoder.layers.1.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,397][root][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,397 DEBUG    Parameter model.model.decoder.layers.1.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,398][root][DEBUG] - Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,398 DEBUG    Parameter model.model.decoder.layers.1.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,398][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,398 DEBUG    Parameter model.model.decoder.layers.2.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,398][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,398 DEBUG    Parameter model.model.decoder.layers.2.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,398][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,398 DEBUG    Parameter model.model.decoder.layers.2.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,398][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,398 DEBUG    Parameter model.model.decoder.layers.2.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,398][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,398 DEBUG    Parameter model.model.decoder.layers.2.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,399][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,399 DEBUG    Parameter model.model.decoder.layers.2.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,399][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,399 DEBUG    Parameter model.model.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,399][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,399 DEBUG    Parameter model.model.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,399][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,399 DEBUG    Parameter model.model.decoder.layers.2.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,399][root][DEBUG] - Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,399 DEBUG    Parameter model.model.decoder.layers.2.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,399][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,399 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,400][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,400 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,400][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,400 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,400][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,400 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,400][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,400 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,400][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,400 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,400][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,400 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,401][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,401 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,401][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,401 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,401][root][DEBUG] - Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,401 DEBUG    Parameter model.model.decoder.layers.2.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,401][root][DEBUG] - Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,401 DEBUG    Parameter model.model.decoder.layers.2.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,401][root][DEBUG] - Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,401 DEBUG    Parameter model.model.decoder.layers.2.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,402][root][DEBUG] - Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,402 DEBUG    Parameter model.model.decoder.layers.2.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,402][root][DEBUG] - Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,402 DEBUG    Parameter model.model.decoder.layers.2.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,402][root][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,402 DEBUG    Parameter model.model.decoder.layers.2.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,402][root][DEBUG] - Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,402 DEBUG    Parameter model.model.decoder.layers.2.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,402][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,402 DEBUG    Parameter model.model.decoder.layers.3.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,402][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,402 DEBUG    Parameter model.model.decoder.layers.3.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,403][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,403 DEBUG    Parameter model.model.decoder.layers.3.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,403][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,403 DEBUG    Parameter model.model.decoder.layers.3.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,403][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,403 DEBUG    Parameter model.model.decoder.layers.3.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,403][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,403 DEBUG    Parameter model.model.decoder.layers.3.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,403][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,403 DEBUG    Parameter model.model.decoder.layers.3.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,403][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,403 DEBUG    Parameter model.model.decoder.layers.3.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,404][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,404 DEBUG    Parameter model.model.decoder.layers.3.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,404][root][DEBUG] - Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,404 DEBUG    Parameter model.model.decoder.layers.3.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,404][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,404 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,404][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,404 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,405][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,405 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,405][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,405 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,405][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,405 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,405][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,405 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,405][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,405 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,406][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,406 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,406][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,406 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,406][root][DEBUG] - Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,406 DEBUG    Parameter model.model.decoder.layers.3.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,406][root][DEBUG] - Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,406 DEBUG    Parameter model.model.decoder.layers.3.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,406][root][DEBUG] - Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,406 DEBUG    Parameter model.model.decoder.layers.3.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,407][root][DEBUG] - Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,407 DEBUG    Parameter model.model.decoder.layers.3.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,407][root][DEBUG] - Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,407 DEBUG    Parameter model.model.decoder.layers.3.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,407][root][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,407 DEBUG    Parameter model.model.decoder.layers.3.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,407][root][DEBUG] - Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,407 DEBUG    Parameter model.model.decoder.layers.3.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,407][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,407 DEBUG    Parameter model.model.decoder.layers.4.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,407][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,407 DEBUG    Parameter model.model.decoder.layers.4.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,408][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,408 DEBUG    Parameter model.model.decoder.layers.4.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,408][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,408 DEBUG    Parameter model.model.decoder.layers.4.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,408][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,408 DEBUG    Parameter model.model.decoder.layers.4.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,408][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,408 DEBUG    Parameter model.model.decoder.layers.4.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,408][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,408 DEBUG    Parameter model.model.decoder.layers.4.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,408][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,408 DEBUG    Parameter model.model.decoder.layers.4.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,409][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,409 DEBUG    Parameter model.model.decoder.layers.4.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,409][root][DEBUG] - Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,409 DEBUG    Parameter model.model.decoder.layers.4.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,409][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,409 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,409][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,409 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,409][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,409 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,410][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,410 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,410][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,410 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,410][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,410 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,410][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,410 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,410][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,410 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,410][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,410 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,411][root][DEBUG] - Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,411 DEBUG    Parameter model.model.decoder.layers.4.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,411][root][DEBUG] - Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,411 DEBUG    Parameter model.model.decoder.layers.4.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,411][root][DEBUG] - Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,411 DEBUG    Parameter model.model.decoder.layers.4.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,411][root][DEBUG] - Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,411 DEBUG    Parameter model.model.decoder.layers.4.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,411][root][DEBUG] - Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,411 DEBUG    Parameter model.model.decoder.layers.4.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,411][root][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,411 DEBUG    Parameter model.model.decoder.layers.4.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,412][root][DEBUG] - Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,412 DEBUG    Parameter model.model.decoder.layers.4.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,412][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,412 DEBUG    Parameter model.model.decoder.layers.5.self_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,412][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,412 DEBUG    Parameter model.model.decoder.layers.5.self_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,412][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,412 DEBUG    Parameter model.model.decoder.layers.5.self_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,412][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,412 DEBUG    Parameter model.model.decoder.layers.5.self_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,412][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,412 DEBUG    Parameter model.model.decoder.layers.5.self_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,413][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,413 DEBUG    Parameter model.model.decoder.layers.5.self_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,413][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,413 DEBUG    Parameter model.model.decoder.layers.5.self_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,413][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,413 DEBUG    Parameter model.model.decoder.layers.5.self_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,413][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,413 DEBUG    Parameter model.model.decoder.layers.5.self_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,413][root][DEBUG] - Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,413 DEBUG    Parameter model.model.decoder.layers.5.self_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,413][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,413 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.k_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,414][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,414 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.k_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,414][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,414 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.v_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,414][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,414 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.v_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,414][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,414 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.q_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,414][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,414 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.q_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,415][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-17 05:16:47,415 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.out_proj.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-17 05:16:47,415][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,415 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn.out_proj.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,415][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,415 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,415][root][DEBUG] - Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,415 DEBUG    Parameter model.model.decoder.layers.5.encoder_attn_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,415][root][DEBUG] - Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-17 05:16:47,415 DEBUG    Parameter model.model.decoder.layers.5.fc1.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-17 05:16:47,415][root][DEBUG] - Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","2022-08-17 05:16:47,415 DEBUG    Parameter model.model.decoder.layers.5.fc1.bias: torch.Size([3072]), require_grad=True\n","[2022-08-17 05:16:47,416][root][DEBUG] - Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-17 05:16:47,416 DEBUG    Parameter model.model.decoder.layers.5.fc2.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-17 05:16:47,416][root][DEBUG] - Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,416 DEBUG    Parameter model.model.decoder.layers.5.fc2.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,416][root][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,416 DEBUG    Parameter model.model.decoder.layers.5.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,416][root][DEBUG] - Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,416 DEBUG    Parameter model.model.decoder.layers.5.final_layer_norm.bias: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,416][root][DEBUG] - Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,416 DEBUG    Parameter model.model.decoder.layernorm_embedding.weight: torch.Size([768]), require_grad=True\n","[2022-08-17 05:16:47,417][root][DEBUG] - Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","2022-08-17 05:16:47,417 DEBUG    Parameter model.model.decoder.layernorm_embedding.bias: torch.Size([768]), require_grad=True\n","Iteration:   0% 0/1400 [00:00<?, ?it/s]The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n","Iteration:   7% 99/1400 [01:15<16:27,  1.32it/s]\n","Traceback (most recent call last):\n","  File \"eval.py\", line 230, in <module>\n","    main()\n","  File \"/usr/local/lib/python3.7/dist-packages/hydra/main.py\", line 95, in decorated_main\n","    config_name=config_name,\n","  File \"/usr/local/lib/python3.7/dist-packages/hydra/_internal/utils.py\", line 396, in _run_hydra\n","    overrides=overrides,\n","  File \"/usr/local/lib/python3.7/dist-packages/hydra/_internal/utils.py\", line 453, in _run_app\n","    lambda: hydra.run(\n","  File \"/usr/local/lib/python3.7/dist-packages/hydra/_internal/utils.py\", line 213, in run_and_report\n","    return func()\n","  File \"/usr/local/lib/python3.7/dist-packages/hydra/_internal/utils.py\", line 456, in <lambda>\n","    overrides=overrides,\n","  File \"/usr/local/lib/python3.7/dist-packages/hydra/_internal/hydra.py\", line 127, in run\n","    configure_logging=with_log_configuration,\n","  File \"/usr/local/lib/python3.7/dist-packages/hydra/core/utils.py\", line 186, in run_job\n","    ret.return_value = task_function(task_cfg)\n","  File \"eval.py\", line 104, in main\n","    outputs = model.generate(batch)\n","  File \"/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/Bart.py\", line 37, in generate\n","    repetition_penalty=1.5\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\", line 1022, in generate\n","    if self.get_output_embeddings() is None:\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_bart.py\", line 1068, in get_output_embeddings\n","    return _make_linear_from_emb(self.model.shared)  # make it on the fly\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_bart.py\", line 166, in _make_linear_from_emb\n","    lin_layer = nn.Linear(vocab_size, emb_size, bias=False)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 86, in __init__\n","    self.reset_parameters()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 89, in reset_parameters\n","    init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/init.py\", line 395, in kaiming_uniform_\n","    return tensor.uniform_(-bound, bound)\n","KeyboardInterrupt\n"]}],"source":["!HYDRA_FULL_ERROR=1 python eval.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiRHm4nruPw9"},"outputs":[],"source":["!kill $(ps aux | awk '{print $2}')"]},{"cell_type":"code","source":[""],"metadata":{"id":"WPTZiAzwc_WZ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"cmd_train.ipynb","provenance":[],"mount_file_id":"1Mrwlgkjv2G7LOLpOtCehzWxaTRu9sXPA","authorship_tag":"ABX9TyM2dd7XQjK7MtzbhdCWkdas"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}