{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1660790214037,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"dymDs0Po0aES","outputId":"9a92cc58-c6ef-4e3a-cb75-829519a07504"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Aug 18 02:34:39 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1475,"status":"ok","timestamp":1660790215500,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"EfCxDoEXuzgg","outputId":"ea35ec1f-c98c-4326-ab07-baf09abc3bfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","source":["!python -m pip install bert-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bOeGCnRF9Cs","executionInfo":{"status":"ok","timestamp":1660790224443,"user_tz":-540,"elapsed":8949,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"e8a99116-9bac-472d-a133-8fb3fbfe8408"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bert-score\n","  Downloading bert_score-0.3.11-py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert-score) (3.2.2)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.12.1+cu113)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert-score) (21.3)\n","Collecting transformers>=3.0.0numpy\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 16.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (4.64.0)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.3.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert-score) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert-score) (3.0.9)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2022.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (1.21.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert-score) (4.1.1)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 69.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (3.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (4.12.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.8 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert-score) (3.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (0.11.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, bert-score\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed bert-score-0.3.11 huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":438203,"status":"ok","timestamp":1660790662629,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"mshVPsrku0kd","outputId":"fd460bc5-ff8b-4d33-a28a-a0af52fbe64b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 13 kB/s \n","\u001b[?25hCollecting transformers==3.0.0\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[K     |████████████████████████████████| 754 kB 73.3 MB/s \n","\u001b[?25hCollecting torch_scatter==2.0.4\n","  Downloading torch_scatter-2.0.4.tar.gz (20 kB)\n","Collecting dgl==0.5.3\n","  Downloading dgl-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 74.2 MB/s \n","\u001b[?25hCollecting hydra==2.4\n","  Downloading Hydra-2.4.tar.gz (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 11.0 MB/s \n","\u001b[?25hCollecting omegaconf==2.2.2\n","  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 72.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (4.64.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 64.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2.23.0)\n","Collecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 47.3 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (2.6.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (1.7.3)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 74.2 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.2.2->-r requirements.txt (line 7)) (6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.1.0)\n","Building wheels for collected packages: torch-scatter, hydra, antlr4-python3-runtime, sacremoses\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-scatter: filename=torch_scatter-2.0.4-cp37-cp37m-linux_x86_64.whl size=14800663 sha256=fb56631d7317503d40c97cc257279589631dfd55161671dbd44bc021cc7c701b\n","  Stored in directory: /root/.cache/pip/wheels/4a/3d/01/e408ecc11389070cbacee91b70c978bf3557130e9aaa18a95b\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.4-cp37-cp37m-linux_x86_64.whl size=219220 sha256=4a7c1fb23e02be037af07bbc86e30dfa240ee50fff7df892d969b89647b74546\n","  Stored in directory: /root/.cache/pip/wheels/f5/65/98/3603b340344bd22dfe1c809365013fc4d425d83d89c3e2cd17\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=0f778204507d83acf3c13d9c08f13003fcd93fe97fa63d1a513534cf71ffbe67\n","  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=e5fd3fc503d33c2fb593ecbfc23ab8a33ae3160e42d4a939d752e731c3d9b25e\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built torch-scatter hydra antlr4-python3-runtime sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, antlr4-python3-runtime, transformers, torch-scatter, torch, omegaconf, hydra, dgl\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.21.1\n","    Uninstalling transformers-4.21.1:\n","      Successfully uninstalled transformers-4.21.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed antlr4-python3-runtime-4.9.3 dgl-0.5.3 hydra-2.4 omegaconf-2.2.2 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.0rc4 torch-1.8.0 torch-scatter-2.0.4 transformers-3.0.0\n"]}],"source":["!python -m pip install -r requirements.txt"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142906,"status":"ok","timestamp":1660790805526,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"G8LmQt_jcvSZ","outputId":"a11d6c8e-ad74-462c-9190-15618ec3570f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 1.2 MB/s eta 0:17:04tcmalloc: large alloc 1147494400 bytes == 0x396ac000 @  0x7f1e5f58e615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████▌               | 1055.7 MB 68.5 MB/s eta 0:00:15tcmalloc: large alloc 1434370048 bytes == 0x7dd02000 @  0x7f1e5f58e615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:57tcmalloc: large alloc 1792966656 bytes == 0x2b34000 @  0x7f1e5f58e615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:52tcmalloc: large alloc 2241208320 bytes == 0x6d91c000 @  0x7f1e5f58e615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf327e000 @  0x7f1e5f58d1e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2551685120 bytes == 0x1e11ec000 @  0x7f1e5f58e615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 2041.3 MB 7.2 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 18.4 MB/s \n","\u001b[?25hCollecting torchaudio===0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.8.0\n","    Uninstalling torch-1.8.0:\n","      Successfully uninstalled torch-1.8.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}],"source":["!python -m pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":465,"status":"ok","timestamp":1660790805978,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"JJqgY88ou7Qp","outputId":"c9a85544-e63c-4493-bdda-4cebb0f5d66b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch-scatter 2.0.4\n","Uninstalling torch-scatter-2.0.4:\n","  Successfully uninstalled torch-scatter-2.0.4\n"]}],"source":["!python -m pip uninstall torch-scatter -y"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4248,"status":"ok","timestamp":1660790810223,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"7c7V5B7yc9Cc","outputId":"0feccdd8-a593-4679-d2ce-83f44385be3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 7.8 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.9\n"]}],"source":["!python -m pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1288,"status":"ok","timestamp":1660790811505,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"l2wm30u-c-i0","outputId":"587e3e93-1833-4665-a1fd-e1fb85f759a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.9\n"]}],"source":["!python -c \"import torch_scatter; print(torch_scatter.__version__)\""]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2942,"status":"ok","timestamp":1660790814437,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"GgPMOQSL4HVZ","outputId":"90beb811-f59a-48c8-ca15-6b1a85922032"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core) (21.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.9.0)\n","Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.2.2)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core) (3.0.9)\n","Installing collected packages: hydra-core\n","Successfully installed hydra-core-1.2.0\n"]}],"source":["!pip install hydra-core --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1660203016899,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"FT5vluqcNpey","outputId":"fb6b583e-b039-4cef-cbf9-2bf97cee58d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZROa2w4NUfm"},"outputs":[],"source":["!python preprocess.py --dataset FB15kET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDB7erFzN4St"},"outputs":[],"source":["!python preprocess.py --dataset YAGO43kET"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660798640739,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"hsnRA4_pUSzk","outputId":"491aefc7-9976-4ca2-8f25-3450133d955f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"586hjT34u-VB","outputId":"c2d3b124-4bb1-46f0-f90b-94afc617a36e","executionInfo":{"status":"ok","timestamp":1660799449202,"user_tz":-540,"elapsed":807326,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","run.py:18: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-18 04:55:17,069][HYDRA] Hydra 1.2.0\n","[2022-08-18 04:55:17,069][HYDRA] ===========\n","[2022-08-18 04:55:17,069][HYDRA] Installed Hydra Plugins\n","[2022-08-18 04:55:17,069][HYDRA] ***********************\n","[2022-08-18 04:55:17,069][HYDRA] \tConfigSource:\n","[2022-08-18 04:55:17,069][HYDRA] \t-------------\n","[2022-08-18 04:55:17,069][HYDRA] \t\tFileConfigSource\n","[2022-08-18 04:55:17,069][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-18 04:55:17,069][HYDRA] \t\tStructuredConfigSource\n","[2022-08-18 04:55:17,069][HYDRA] \tCompletionPlugin:\n","[2022-08-18 04:55:17,069][HYDRA] \t-----------------\n","[2022-08-18 04:55:17,069][HYDRA] \t\tBashCompletion\n","[2022-08-18 04:55:17,069][HYDRA] \t\tFishCompletion\n","[2022-08-18 04:55:17,069][HYDRA] \t\tZshCompletion\n","[2022-08-18 04:55:17,069][HYDRA] \tLauncher:\n","[2022-08-18 04:55:17,069][HYDRA] \t---------\n","[2022-08-18 04:55:17,069][HYDRA] \t\tBasicLauncher\n","[2022-08-18 04:55:17,069][HYDRA] \tSweeper:\n","[2022-08-18 04:55:17,070][HYDRA] \t--------\n","[2022-08-18 04:55:17,070][HYDRA] \t\tBasicSweeper\n","[2022-08-18 04:55:17,070][HYDRA] \n","[2022-08-18 04:55:17,070][HYDRA] Config search path\n","[2022-08-18 04:55:17,070][HYDRA] ******************\n","[2022-08-18 04:55:17,195][HYDRA] | Provider | Search path                                                           |\n","[2022-08-18 04:55:17,196][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-18 04:55:17,196][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-18 04:55:17,196][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-18 04:55:17,196][HYDRA] | schema   | structured://                                                         |\n","[2022-08-18 04:55:17,196][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-18 04:55:17,265][HYDRA] \n","[2022-08-18 04:55:17,265][HYDRA] Defaults Tree\n","[2022-08-18 04:55:17,265][HYDRA] *************\n","[2022-08-18 04:55:17,265][HYDRA] <root>:\n","[2022-08-18 04:55:17,265][HYDRA]   hydra/config:\n","[2022-08-18 04:55:17,265][HYDRA]     hydra/output: default\n","[2022-08-18 04:55:17,265][HYDRA]     hydra/launcher: basic\n","[2022-08-18 04:55:17,266][HYDRA]     hydra/sweeper: basic\n","[2022-08-18 04:55:17,266][HYDRA]     hydra/help: default\n","[2022-08-18 04:55:17,266][HYDRA]     hydra/hydra_help: default\n","[2022-08-18 04:55:17,266][HYDRA]     hydra/hydra_logging: default\n","[2022-08-18 04:55:17,266][HYDRA]     hydra/job_logging: default\n","[2022-08-18 04:55:17,266][HYDRA]     hydra/callbacks: null\n","[2022-08-18 04:55:17,266][HYDRA]     hydra/env: default\n","[2022-08-18 04:55:17,266][HYDRA]     _self_\n","[2022-08-18 04:55:17,266][HYDRA]   config:\n","[2022-08-18 04:55:17,266][HYDRA]     data/YAGO43kET\n","[2022-08-18 04:55:17,266][HYDRA]     model/T5\n","[2022-08-18 04:55:17,266][HYDRA]     _self_\n","[2022-08-18 04:55:17,330][HYDRA] \n","[2022-08-18 04:55:17,330][HYDRA] Defaults List\n","[2022-08-18 04:55:17,330][HYDRA] *************\n","[2022-08-18 04:55:17,330][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-18 04:55:17,330][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-18 04:55:17,330][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-18 04:55:17,330][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-18 04:55:17,330][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-18 04:55:17,330][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-18 04:55:17,331][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-18 04:55:17,331][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-18 04:55:17,331][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-18 04:55:17,331][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-18 04:55:17,331][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-18 04:55:17,331][HYDRA] | data/YAGO43kET              | data                | False  | config       |\n","[2022-08-18 04:55:17,331][HYDRA] | model/T5                    | model               | False  | config       |\n","[2022-08-18 04:55:17,331][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-18 04:55:17,331][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-18 04:55:17,446][HYDRA] Config\n","[2022-08-18 04:55:17,446][HYDRA] ******\n","[2022-08-18 04:55:17,450][HYDRA] data:\n","  name: YAGO43kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  lowest_level: false\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: T5\n","  train_dataset: ET_1_1_train.txt\n","  pretrained_model: t5-base\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 128\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_1_1_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 128\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_1_1_test.txt\n","    unobserved_test_dataset: ET_1_1_unobserved_type_test.txt\n","    save_outputs: true\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: ''\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-18 04:55:17,521][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 04:55:17,814][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 0\n","[2022-08-18 04:55:17,816][filelock][DEBUG] - Attempting to acquire lock 140376216476496 on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-18 04:55:17,820][filelock][DEBUG] - Lock 140376216476496 acquired on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-18 04:55:17,821][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpo2kxtu39\n","[2022-08-18 04:55:17,822][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 04:55:18,121][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 791656\n","Downloading: 100% 792k/792k [00:00<00:00, 2.50MB/s]\n","[2022-08-18 04:55:18,439][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model in cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-18 04:55:18,439][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-18 04:55:18,440][filelock][DEBUG] - Attempting to release lock 140376216476496 on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-18 04:55:18,440][filelock][DEBUG] - Lock 140376216476496 released on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-18 04:55:18,440][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","tcmalloc: large alloc 8591564800 bytes == 0x7fa9cfe72000 @  0x7fad65434b6b 0x7fad65454379 0x7facae2c326e 0x7facae2c49e2 0x7facaf63fe19 0x7facaf640b67 0x7facafa1d059 0x7facb0181e6a 0x7facb0164f8e 0x7facafd69cd5 0x7facafa210c0 0x7facb02f3e64 0x7facb0151ec4 0x7facb0168287 0x7facafdc3441 0x7fad52d32d25 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x593fce 0x5118f8 0x4bc98a 0x532c1b 0x594a96 0x515600 0x549e0e 0x593fce 0x5118f8\n","tcmalloc: large alloc 8591564800 bytes == 0x7fa7cc5ee000 @  0x7fad65434b6b 0x7fad65454379 0x7facae2c326e 0x7facae2c49e2 0x7facaf63fe19 0x7facaf640b67 0x7facafa1d059 0x7facb0181e6a 0x7facb0164f8e 0x7facafd69cd5 0x7facafa210c0 0x7facb02f3e64 0x7facb0151ec4 0x7facb0168287 0x7facafdc3441 0x7fad52d32d25 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x593fce 0x5118f8 0x4bc98a 0x532c1b 0x594a96 0x515600 0x549e0e 0x593fce 0x5118f8\n","[2022-08-18 04:55:24,072][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 04:55:24,358][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 0\n","[2022-08-18 04:55:24,360][filelock][DEBUG] - Attempting to acquire lock 140367258242192 on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-18 04:55:24,360][filelock][DEBUG] - Lock 140367258242192 acquired on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-18 04:55:24,360][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpoh6_usiz\n","[2022-08-18 04:55:24,362][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 04:55:24,670][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 1199\n","Downloading: 100% 1.20k/1.20k [00:00<00:00, 1.07MB/s]\n","[2022-08-18 04:55:24,673][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json in cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-18 04:55:24,673][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-18 04:55:24,673][filelock][DEBUG] - Attempting to release lock 140367258242192 on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-18 04:55:24,673][filelock][DEBUG] - Lock 140367258242192 released on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-18 04:55:24,674][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-18 04:55:24,674][transformers.configuration_utils][INFO] - Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[2022-08-18 04:55:24,676][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-18 04:55:24,765][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /t5-base-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-18 04:55:24,766][filelock][DEBUG] - Attempting to acquire lock 140367258241168 on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-18 04:55:24,766][filelock][DEBUG] - Lock 140367258241168 acquired on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-18 04:55:24,767][transformers.file_utils][INFO] - https://cdn.huggingface.co/t5-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpzeecux18\n","[2022-08-18 04:55:24,768][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-18 04:55:25,219][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"GET /t5-base-pytorch_model.bin HTTP/1.1\" 200 891691430\n","Downloading: 100% 892M/892M [00:19<00:00, 45.3MB/s]\n","[2022-08-18 04:55:44,890][transformers.file_utils][INFO] - storing https://cdn.huggingface.co/t5-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-18 04:55:44,891][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-18 04:55:44,891][filelock][DEBUG] - Attempting to release lock 140367258241168 on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-18 04:55:44,891][filelock][DEBUG] - Lock 140367258241168 released on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-18 04:55:44,891][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-18 04:55:50,420][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","[2022-08-18 04:55:50,421][transformers.modeling_utils][WARNING] - Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[2022-08-18 04:56:00,903][__main__][DEBUG] - Parameter model.shared.weight: torch.Size([32128, 768]), require_grad=True\n","[2022-08-18 04:56:00,903][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,904][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,905][__main__][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,906][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,907][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,908][__main__][DEBUG] - Parameter model.encoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,909][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,910][__main__][DEBUG] - Parameter model.encoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,911][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,911][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,911][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,911][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,911][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,911][__main__][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,911][__main__][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,911][__main__][DEBUG] - Parameter model.encoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,911][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.encoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.encoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,912][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,913][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,913][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-18 04:56:00,913][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,913][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,913][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,913][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,913][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,913][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-18 04:56:00,913][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,914][__main__][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,914][__main__][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,914][__main__][DEBUG] - Parameter model.decoder.block.0.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,914][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,914][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,914][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,914][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,914][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,914][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,989][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,989][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,989][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,989][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,990][__main__][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,990][__main__][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,990][__main__][DEBUG] - Parameter model.decoder.block.1.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,990][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,990][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,991][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,991][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,991][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,991][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,991][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,992][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,992][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,992][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,992][__main__][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,992][__main__][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,993][__main__][DEBUG] - Parameter model.decoder.block.2.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,993][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,993][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,993][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,993][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,993][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,994][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,994][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,994][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,994][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,994][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,994][__main__][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.3.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,995][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.4.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,996][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.5.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,997][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,998][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,998][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,998][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,998][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,998][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,998][__main__][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:00,998][__main__][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:00,998][__main__][DEBUG] - Parameter model.decoder.block.6.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,998][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,999][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,999][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,999][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,999][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:00,999][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,999][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,999][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,999][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:00,999][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,000][__main__][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:01,000][__main__][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:01,000][__main__][DEBUG] - Parameter model.decoder.block.7.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,000][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,000][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,000][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,000][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,000][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,000][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.8.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,001][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.9.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,002][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:01,003][__main__][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.10.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 04:56:01,004][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,005][__main__][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 04:56:01,005][__main__][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 04:56:01,005][__main__][DEBUG] - Parameter model.decoder.block.11.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 04:56:01,005][__main__][DEBUG] - Parameter model.decoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","Epoch:   0% 0/100 [00:00<?, ?it/s][2022-08-18 04:56:01,007][__main__][DEBUG] - Starting training!\n","\n","Iteration:   0% 0/422 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-18 04:56:02,016][__main__][DEBUG] - batch 0: tensor([[ 784, 9413,  908,  ...,    0,    0,    0],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1],\n","        [ 784, 9413,  908,  ...,    0,    0,    0],\n","        ...,\n","        [ 784, 9413,  908,  ...,    0,    0,    0],\n","        [ 784, 9413,  908,  ...,    0,    0,    0],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1]], device='cuda:0') \n","[2022-08-18 04:56:02,018][__main__][DEBUG] - batch 1: tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') \n","[2022-08-18 04:56:02,020][__main__][DEBUG] - batch 2: tensor([[ 1448,  1582,  6601,  ...,     0,     0,     0],\n","        [ 1448,  1582,  1886,  ...,     0,     0,     0],\n","        [ 1448,  1582,  6601,  ...,     0,     0,     0],\n","        ...,\n","        [ 1448,  1582,  6601,  ...,     0,     0,     0],\n","        [    3, 17193,  2138,  ...,     0,     0,     0],\n","        [    3, 17193,  2138,  ...,     0,     0,     0]], device='cuda:0') \n","[2022-08-18 04:56:02,021][__main__][DEBUG] - batch 3: tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0') \n","\n","Iteration:   0% 1/422 [00:01<11:04,  1.58s/it]\u001b[A\n","Iteration:   0% 2/422 [00:02<06:22,  1.10it/s]\u001b[A\n","Iteration:   1% 3/422 [00:02<04:51,  1.44it/s]\u001b[A\n","Iteration:   1% 4/422 [00:02<04:08,  1.68it/s]\u001b[A\n","Iteration:   1% 5/422 [00:03<03:44,  1.86it/s]\u001b[A\n","Iteration:   1% 6/422 [00:03<03:29,  1.98it/s]\u001b[A\n","Iteration:   2% 7/422 [00:04<03:20,  2.07it/s]\u001b[A\n","Iteration:   2% 8/422 [00:04<03:14,  2.13it/s]\u001b[A\n","Iteration:   2% 9/422 [00:05<03:09,  2.17it/s]\u001b[A\n","Iteration:   2% 10/422 [00:05<03:06,  2.21it/s]\u001b[A\n","Iteration:   3% 11/422 [00:05<03:04,  2.23it/s]\u001b[A\n","Iteration:   3% 12/422 [00:06<03:02,  2.25it/s]\u001b[A\n","Iteration:   3% 13/422 [00:06<03:01,  2.26it/s]\u001b[A\n","Iteration:   3% 14/422 [00:07<03:00,  2.26it/s]\u001b[A\n","Iteration:   4% 15/422 [00:07<02:59,  2.27it/s]\u001b[A\n","Iteration:   4% 16/422 [00:08<02:58,  2.27it/s]\u001b[A\n","Iteration:   4% 17/422 [00:08<02:58,  2.27it/s]\u001b[A\n","Iteration:   4% 18/422 [00:09<02:57,  2.28it/s]\u001b[A\n","Iteration:   5% 19/422 [00:09<02:57,  2.28it/s]\u001b[A\n","Iteration:   5% 20/422 [00:09<02:56,  2.28it/s]\u001b[A\n","Iteration:   5% 21/422 [00:10<02:56,  2.28it/s]\u001b[A\n","Iteration:   5% 22/422 [00:10<02:55,  2.28it/s]\u001b[A\n","Iteration:   5% 23/422 [00:11<02:55,  2.27it/s]\u001b[A\n","Iteration:   6% 24/422 [00:11<02:54,  2.28it/s]\u001b[A\n","Iteration:   6% 25/422 [00:12<02:54,  2.27it/s]\u001b[A\n","Iteration:   6% 26/422 [00:12<02:53,  2.28it/s]\u001b[A\n","Iteration:   6% 27/422 [00:12<02:53,  2.28it/s]\u001b[A\n","Iteration:   7% 28/422 [00:13<02:53,  2.28it/s]\u001b[A\n","Iteration:   7% 29/422 [00:13<02:52,  2.28it/s]\u001b[A\n","Iteration:   7% 30/422 [00:14<02:52,  2.28it/s]\u001b[A\n","Iteration:   7% 31/422 [00:14<02:51,  2.28it/s]\u001b[A\n","Iteration:   8% 32/422 [00:15<02:51,  2.28it/s]\u001b[A\n","Iteration:   8% 33/422 [00:15<02:50,  2.28it/s]\u001b[A\n","Iteration:   8% 34/422 [00:16<02:50,  2.28it/s]\u001b[A\n","Iteration:   8% 35/422 [00:16<02:50,  2.27it/s]\u001b[A\n","Iteration:   9% 36/422 [00:16<02:49,  2.28it/s]\u001b[A\n","Iteration:   9% 37/422 [00:17<02:49,  2.28it/s]\u001b[A\n","Iteration:   9% 38/422 [00:17<02:48,  2.28it/s]\u001b[A\n","Iteration:   9% 39/422 [00:18<02:47,  2.28it/s]\u001b[A\n","Iteration:   9% 40/422 [00:18<02:47,  2.28it/s]\u001b[A\n","Iteration:  10% 41/422 [00:19<02:47,  2.28it/s]\u001b[A\n","Iteration:  10% 42/422 [00:19<02:46,  2.28it/s]\u001b[A\n","Iteration:  10% 43/422 [00:20<02:46,  2.28it/s]\u001b[A\n","Iteration:  10% 44/422 [00:20<02:45,  2.28it/s]\u001b[A\n","Iteration:  11% 45/422 [00:20<02:45,  2.28it/s]\u001b[A\n","Iteration:  11% 46/422 [00:21<02:44,  2.28it/s]\u001b[A\n","Iteration:  11% 47/422 [00:21<02:44,  2.28it/s]\u001b[A\n","Iteration:  11% 48/422 [00:22<02:43,  2.28it/s]\u001b[A\n","Iteration:  12% 49/422 [00:22<02:43,  2.28it/s]\u001b[A\n","Iteration:  12% 50/422 [00:23<02:43,  2.28it/s]\u001b[A\n","Iteration:  12% 51/422 [00:23<02:42,  2.28it/s]\u001b[A\n","Iteration:  12% 52/422 [00:23<02:42,  2.28it/s]\u001b[A\n","Iteration:  13% 53/422 [00:24<02:41,  2.28it/s]\u001b[A\n","Iteration:  13% 54/422 [00:24<02:41,  2.28it/s]\u001b[A\n","Iteration:  13% 55/422 [00:25<02:40,  2.28it/s]\u001b[A\n","Iteration:  13% 56/422 [00:25<02:40,  2.28it/s]\u001b[A\n","Iteration:  14% 57/422 [00:26<02:39,  2.28it/s]\u001b[A\n","Iteration:  14% 58/422 [00:26<02:39,  2.28it/s]\u001b[A\n","Iteration:  14% 59/422 [00:27<02:39,  2.28it/s]\u001b[A\n","Iteration:  14% 60/422 [00:27<02:38,  2.28it/s]\u001b[A\n","Iteration:  14% 61/422 [00:27<02:38,  2.28it/s]\u001b[A\n","Iteration:  15% 62/422 [00:28<02:37,  2.28it/s]\u001b[A\n","Iteration:  15% 63/422 [00:28<02:37,  2.28it/s]\u001b[A\n","Iteration:  15% 64/422 [00:29<02:36,  2.28it/s]\u001b[A\n","Iteration:  15% 65/422 [00:29<02:36,  2.28it/s]\u001b[A\n","Iteration:  16% 66/422 [00:30<02:36,  2.28it/s]\u001b[A\n","Iteration:  16% 67/422 [00:30<02:35,  2.28it/s]\u001b[A\n","Iteration:  16% 68/422 [00:30<02:35,  2.28it/s]\u001b[A\n","Iteration:  16% 69/422 [00:31<02:34,  2.28it/s]\u001b[A\n","Iteration:  17% 70/422 [00:31<02:34,  2.28it/s]\u001b[A\n","Iteration:  17% 71/422 [00:32<02:33,  2.28it/s]\u001b[A\n","Iteration:  17% 72/422 [00:32<02:33,  2.28it/s]\u001b[A\n","Iteration:  17% 73/422 [00:33<02:33,  2.28it/s]\u001b[A\n","Iteration:  18% 74/422 [00:33<02:32,  2.28it/s]\u001b[A\n","Iteration:  18% 75/422 [00:34<02:32,  2.28it/s]\u001b[A\n","Iteration:  18% 76/422 [00:34<02:31,  2.28it/s]\u001b[A\n","Iteration:  18% 77/422 [00:34<02:31,  2.28it/s]\u001b[A\n","Iteration:  18% 78/422 [00:35<02:30,  2.28it/s]\u001b[A\n","Iteration:  19% 79/422 [00:35<02:30,  2.28it/s]\u001b[A\n","Iteration:  19% 80/422 [00:36<02:30,  2.28it/s]\u001b[A\n","Iteration:  19% 81/422 [00:36<02:29,  2.27it/s]\u001b[A\n","Iteration:  19% 82/422 [00:37<02:29,  2.27it/s]\u001b[A\n","Iteration:  20% 83/422 [00:37<02:29,  2.27it/s]\u001b[A\n","Iteration:  20% 84/422 [00:38<02:29,  2.27it/s]\u001b[A\n","Iteration:  20% 85/422 [00:38<02:29,  2.26it/s]\u001b[A\n","Iteration:  20% 86/422 [00:38<02:28,  2.26it/s]\u001b[A\n","Iteration:  21% 87/422 [00:39<02:27,  2.27it/s]\u001b[A\n","Iteration:  21% 88/422 [00:39<02:27,  2.27it/s]\u001b[A\n","Iteration:  21% 89/422 [00:40<02:26,  2.27it/s]\u001b[A\n","Iteration:  21% 90/422 [00:40<02:26,  2.27it/s]\u001b[A\n","Iteration:  22% 91/422 [00:41<02:25,  2.27it/s]\u001b[A\n","Iteration:  22% 92/422 [00:41<02:24,  2.28it/s]\u001b[A\n","Iteration:  22% 93/422 [00:41<02:24,  2.28it/s]\u001b[A\n","Iteration:  22% 94/422 [00:42<02:24,  2.28it/s]\u001b[A\n","Iteration:  23% 95/422 [00:42<02:23,  2.28it/s]\u001b[A\n","Iteration:  23% 96/422 [00:43<02:23,  2.28it/s]\u001b[A\n","Iteration:  23% 97/422 [00:43<02:22,  2.28it/s]\u001b[A\n","Iteration:  23% 98/422 [00:44<02:22,  2.28it/s]\u001b[A\n","Iteration:  23% 99/422 [00:44<02:21,  2.28it/s]\u001b[A\n","Iteration:  24% 100/422 [00:45<02:21,  2.28it/s]\u001b[A\n","Iteration:  24% 101/422 [00:45<02:20,  2.28it/s]\u001b[A\n","Iteration:  24% 102/422 [00:45<02:20,  2.28it/s]\u001b[A\n","Iteration:  24% 103/422 [00:46<02:19,  2.28it/s]\u001b[A\n","Iteration:  25% 104/422 [00:46<02:19,  2.28it/s]\u001b[A\n","Iteration:  25% 105/422 [00:47<02:19,  2.28it/s]\u001b[A\n","Iteration:  25% 106/422 [00:47<02:18,  2.28it/s]\u001b[A\n","Iteration:  25% 107/422 [00:48<02:18,  2.28it/s]\u001b[A\n","Iteration:  26% 108/422 [00:48<02:17,  2.28it/s]\u001b[A\n","Iteration:  26% 109/422 [00:48<02:17,  2.28it/s]\u001b[A\n","Iteration:  26% 110/422 [00:49<02:17,  2.28it/s]\u001b[A\n","Iteration:  26% 111/422 [00:49<02:16,  2.28it/s]\u001b[A\n","Iteration:  27% 112/422 [00:50<02:16,  2.28it/s]\u001b[A\n","Iteration:  27% 113/422 [00:50<02:15,  2.28it/s]\u001b[A\n","Iteration:  27% 114/422 [00:51<02:15,  2.28it/s]\u001b[A\n","Iteration:  27% 115/422 [00:51<02:14,  2.28it/s]\u001b[A\n","Iteration:  27% 116/422 [00:52<02:14,  2.28it/s]\u001b[A\n","Iteration:  28% 117/422 [00:52<02:13,  2.28it/s]\u001b[A\n","Iteration:  28% 118/422 [00:52<02:13,  2.28it/s]\u001b[A\n","Iteration:  28% 119/422 [00:53<02:12,  2.28it/s]\u001b[A\n","Iteration:  28% 120/422 [00:53<02:12,  2.28it/s]\u001b[A\n","Iteration:  29% 121/422 [00:54<02:11,  2.28it/s]\u001b[A\n","Iteration:  29% 122/422 [00:54<02:11,  2.28it/s]\u001b[A\n","Iteration:  29% 123/422 [00:55<02:11,  2.28it/s]\u001b[A\n","Iteration:  29% 124/422 [00:55<02:10,  2.28it/s]\u001b[A\n","Iteration:  30% 125/422 [00:55<02:10,  2.28it/s]\u001b[A\n","Iteration:  30% 126/422 [00:56<02:09,  2.28it/s]\u001b[A\n","Iteration:  30% 127/422 [00:56<02:09,  2.28it/s]\u001b[A\n","Iteration:  30% 128/422 [00:57<02:08,  2.28it/s]\u001b[A\n","Iteration:  31% 129/422 [00:57<02:08,  2.28it/s]\u001b[A\n","Iteration:  31% 130/422 [00:58<02:07,  2.28it/s]\u001b[A\n","Iteration:  31% 131/422 [00:58<02:07,  2.28it/s]\u001b[A\n","Iteration:  31% 132/422 [00:59<02:07,  2.28it/s]\u001b[A\n","Iteration:  32% 133/422 [00:59<02:06,  2.28it/s]\u001b[A\n","Iteration:  32% 134/422 [00:59<02:06,  2.28it/s]\u001b[A\n","Iteration:  32% 135/422 [01:00<02:05,  2.28it/s]\u001b[A\n","Iteration:  32% 136/422 [01:00<02:05,  2.28it/s]\u001b[A\n","Iteration:  32% 137/422 [01:01<02:04,  2.28it/s]\u001b[A\n","Iteration:  33% 138/422 [01:01<02:04,  2.28it/s]\u001b[A\n","Iteration:  33% 139/422 [01:02<02:03,  2.28it/s]\u001b[A\n","Iteration:  33% 140/422 [01:02<02:03,  2.28it/s]\u001b[A\n","Iteration:  33% 141/422 [01:03<02:03,  2.28it/s]\u001b[A\n","Iteration:  34% 142/422 [01:03<02:02,  2.28it/s]\u001b[A\n","Iteration:  34% 143/422 [01:03<02:02,  2.28it/s]\u001b[A\n","Iteration:  34% 144/422 [01:04<02:01,  2.28it/s]\u001b[A\n","Iteration:  34% 145/422 [01:04<02:01,  2.28it/s]\u001b[A\n","Iteration:  35% 146/422 [01:05<02:00,  2.28it/s]\u001b[A\n","Iteration:  35% 147/422 [01:05<02:00,  2.28it/s]\u001b[A\n","Iteration:  35% 148/422 [01:06<01:59,  2.28it/s]\u001b[A\n","Iteration:  35% 149/422 [01:06<01:59,  2.28it/s]\u001b[A\n","Iteration:  36% 150/422 [01:06<01:59,  2.28it/s]\u001b[A\n","Iteration:  36% 151/422 [01:07<01:58,  2.28it/s]\u001b[A\n","Iteration:  36% 152/422 [01:07<01:58,  2.28it/s]\u001b[A\n","Iteration:  36% 153/422 [01:08<01:57,  2.28it/s]\u001b[A\n","Iteration:  36% 154/422 [01:08<01:57,  2.28it/s]\u001b[A\n","Iteration:  37% 155/422 [01:09<01:56,  2.28it/s]\u001b[A\n","Iteration:  37% 156/422 [01:09<01:56,  2.28it/s]\u001b[A\n","Iteration:  37% 157/422 [01:10<01:56,  2.28it/s]\u001b[A\n","Iteration:  37% 158/422 [01:10<01:55,  2.28it/s]\u001b[A\n","Iteration:  38% 159/422 [01:10<01:55,  2.28it/s]\u001b[A\n","Iteration:  38% 160/422 [01:11<01:54,  2.28it/s]\u001b[A\n","Iteration:  38% 161/422 [01:11<01:54,  2.28it/s]\u001b[A\n","Iteration:  38% 162/422 [01:12<01:53,  2.28it/s]\u001b[A\n","Iteration:  39% 163/422 [01:12<01:53,  2.28it/s]\u001b[A\n","Iteration:  39% 164/422 [01:13<01:52,  2.28it/s]\u001b[A\n","Iteration:  39% 165/422 [01:13<01:52,  2.28it/s]\u001b[A\n","Iteration:  39% 166/422 [01:13<01:52,  2.28it/s]\u001b[A\n","Iteration:  40% 167/422 [01:14<01:51,  2.28it/s]\u001b[A\n","Iteration:  40% 168/422 [01:14<01:51,  2.27it/s]\u001b[A\n","Iteration:  40% 169/422 [01:15<01:51,  2.28it/s]\u001b[A\n","Iteration:  40% 170/422 [01:15<01:50,  2.28it/s]\u001b[A\n","Iteration:  41% 171/422 [01:16<01:50,  2.28it/s]\u001b[A\n","Iteration:  41% 172/422 [01:16<01:49,  2.28it/s]\u001b[A\n","Iteration:  41% 173/422 [01:17<01:49,  2.28it/s]\u001b[A\n","Iteration:  41% 174/422 [01:17<01:48,  2.28it/s]\u001b[A\n","Iteration:  41% 175/422 [01:17<01:48,  2.28it/s]\u001b[A\n","Iteration:  42% 176/422 [01:18<01:47,  2.28it/s]\u001b[A\n","Iteration:  42% 177/422 [01:18<01:47,  2.28it/s]\u001b[A\n","Iteration:  42% 178/422 [01:19<01:46,  2.28it/s]\u001b[A\n","Iteration:  42% 179/422 [01:19<01:46,  2.28it/s]\u001b[A\n","Iteration:  43% 180/422 [01:20<01:46,  2.28it/s]\u001b[A\n","Iteration:  43% 181/422 [01:20<01:45,  2.28it/s]\u001b[A\n","Iteration:  43% 182/422 [01:20<01:45,  2.28it/s]\u001b[A\n","Iteration:  43% 183/422 [01:21<01:44,  2.28it/s]\u001b[A\n","Iteration:  44% 184/422 [01:21<01:44,  2.28it/s]\u001b[A\n","Iteration:  44% 185/422 [01:22<01:43,  2.28it/s]\u001b[A\n","Iteration:  44% 186/422 [01:22<01:43,  2.28it/s]\u001b[A\n","Iteration:  44% 187/422 [01:23<01:43,  2.28it/s]\u001b[A\n","Iteration:  45% 188/422 [01:23<01:42,  2.28it/s]\u001b[A\n","Iteration:  45% 189/422 [01:24<01:42,  2.28it/s]\u001b[A\n","Iteration:  45% 190/422 [01:24<01:41,  2.28it/s]\u001b[A\n","Iteration:  45% 191/422 [01:24<01:41,  2.28it/s]\u001b[A\n","Iteration:  45% 192/422 [01:25<01:40,  2.28it/s]\u001b[A\n","Iteration:  46% 193/422 [01:25<01:40,  2.28it/s]\u001b[A\n","Iteration:  46% 194/422 [01:26<01:39,  2.28it/s]\u001b[A\n","Iteration:  46% 195/422 [01:26<01:39,  2.28it/s]\u001b[A\n","Iteration:  46% 196/422 [01:27<01:38,  2.28it/s]\u001b[A\n","Iteration:  47% 197/422 [01:27<01:38,  2.28it/s]\u001b[A\n","Iteration:  47% 198/422 [01:27<01:38,  2.28it/s]\u001b[A\n","Iteration:  47% 199/422 [01:28<01:37,  2.29it/s]\u001b[A\n","Iteration:  47% 200/422 [01:28<01:37,  2.29it/s]\u001b[A\n","Iteration:  48% 201/422 [01:29<01:36,  2.28it/s]\u001b[A\n","Iteration:  48% 202/422 [01:29<01:36,  2.28it/s]\u001b[A\n","Iteration:  48% 203/422 [01:30<01:35,  2.28it/s]\u001b[A\n","Iteration:  48% 204/422 [01:30<01:35,  2.28it/s]\u001b[A\n","Iteration:  49% 205/422 [01:31<01:35,  2.28it/s]\u001b[A\n","Iteration:  49% 206/422 [01:31<01:34,  2.28it/s]\u001b[A\n","Iteration:  49% 207/422 [01:31<01:34,  2.28it/s]\u001b[A\n","Iteration:  49% 208/422 [01:32<01:33,  2.28it/s]\u001b[A\n","Iteration:  50% 209/422 [01:32<01:33,  2.28it/s]\u001b[A\n","Iteration:  50% 210/422 [01:33<01:32,  2.28it/s]\u001b[A\n","Iteration:  50% 211/422 [01:33<01:32,  2.28it/s]\u001b[A\n","Iteration:  50% 212/422 [01:34<01:31,  2.28it/s]\u001b[A\n","Iteration:  50% 213/422 [01:34<01:31,  2.28it/s]\u001b[A\n","Iteration:  51% 214/422 [01:34<01:31,  2.28it/s]\u001b[A\n","Iteration:  51% 215/422 [01:35<01:30,  2.28it/s]\u001b[A\n","Iteration:  51% 216/422 [01:35<01:30,  2.28it/s]\u001b[A\n","Iteration:  51% 217/422 [01:36<01:29,  2.28it/s]\u001b[A\n","Iteration:  52% 218/422 [01:36<01:29,  2.28it/s]\u001b[A\n","Iteration:  52% 219/422 [01:37<01:28,  2.28it/s]\u001b[A\n","Iteration:  52% 220/422 [01:37<01:28,  2.28it/s]\u001b[A\n","Iteration:  52% 221/422 [01:38<01:28,  2.28it/s]\u001b[A\n","Iteration:  53% 222/422 [01:38<01:27,  2.28it/s]\u001b[A\n","Iteration:  53% 223/422 [01:38<01:27,  2.28it/s]\u001b[A\n","Iteration:  53% 224/422 [01:39<01:26,  2.28it/s]\u001b[A\n","Iteration:  53% 225/422 [01:39<01:26,  2.28it/s]\u001b[A\n","Iteration:  54% 226/422 [01:40<01:25,  2.28it/s]\u001b[A\n","Iteration:  54% 227/422 [01:40<01:25,  2.28it/s]\u001b[A\n","Iteration:  54% 228/422 [01:41<01:24,  2.28it/s]\u001b[A\n","Iteration:  54% 229/422 [01:41<01:24,  2.28it/s]\u001b[A\n","Iteration:  55% 230/422 [01:41<01:24,  2.28it/s]\u001b[A\n","Iteration:  55% 231/422 [01:42<01:23,  2.28it/s]\u001b[A\n","Iteration:  55% 232/422 [01:42<01:23,  2.28it/s]\u001b[A\n","Iteration:  55% 233/422 [01:43<01:22,  2.28it/s]\u001b[A\n","Iteration:  55% 234/422 [01:43<01:22,  2.28it/s]\u001b[A\n","Iteration:  56% 235/422 [01:44<01:21,  2.28it/s]\u001b[A\n","Iteration:  56% 236/422 [01:44<01:21,  2.28it/s]\u001b[A\n","Iteration:  56% 237/422 [01:45<01:21,  2.28it/s]\u001b[A\n","Iteration:  56% 238/422 [01:45<01:20,  2.28it/s]\u001b[A\n","Iteration:  57% 239/422 [01:45<01:20,  2.28it/s]\u001b[A\n","Iteration:  57% 240/422 [01:46<01:19,  2.28it/s]\u001b[A\n","Iteration:  57% 241/422 [01:46<01:19,  2.28it/s]\u001b[A\n","Iteration:  57% 242/422 [01:47<01:18,  2.28it/s]\u001b[A\n","Iteration:  58% 243/422 [01:47<01:18,  2.28it/s]\u001b[A\n","Iteration:  58% 244/422 [01:48<01:17,  2.28it/s]\u001b[A\n","Iteration:  58% 245/422 [01:48<01:17,  2.28it/s]\u001b[A\n","Iteration:  58% 246/422 [01:49<01:17,  2.28it/s]\u001b[A\n","Iteration:  59% 247/422 [01:49<01:16,  2.28it/s]\u001b[A\n","Iteration:  59% 248/422 [01:49<01:16,  2.28it/s]\u001b[A\n","Iteration:  59% 249/422 [01:50<01:15,  2.28it/s]\u001b[A\n","Iteration:  59% 250/422 [01:50<01:15,  2.28it/s]\u001b[A\n","Iteration:  59% 251/422 [01:51<01:14,  2.28it/s]\u001b[A\n","Iteration:  60% 252/422 [01:51<01:14,  2.28it/s]\u001b[A\n","Iteration:  60% 253/422 [01:52<01:14,  2.28it/s]\u001b[A\n","Iteration:  60% 254/422 [01:52<01:13,  2.28it/s]\u001b[A\n","Iteration:  60% 255/422 [01:52<01:13,  2.28it/s]\u001b[A\n","Iteration:  61% 256/422 [01:53<01:12,  2.28it/s]\u001b[A\n","Iteration:  61% 257/422 [01:53<01:12,  2.28it/s]\u001b[A\n","Iteration:  61% 258/422 [01:54<01:11,  2.28it/s]\u001b[A\n","Iteration:  61% 259/422 [01:54<01:11,  2.28it/s]\u001b[A\n","Iteration:  62% 260/422 [01:55<01:11,  2.28it/s]\u001b[A\n","Iteration:  62% 261/422 [01:55<01:10,  2.28it/s]\u001b[A\n","Iteration:  62% 262/422 [01:56<01:10,  2.28it/s]\u001b[A\n","Iteration:  62% 263/422 [01:56<01:09,  2.28it/s]\u001b[A\n","Iteration:  63% 264/422 [01:56<01:09,  2.28it/s]\u001b[A\n","Iteration:  63% 265/422 [01:57<01:08,  2.28it/s]\u001b[A\n","Iteration:  63% 266/422 [01:57<01:08,  2.28it/s]\u001b[A\n","Iteration:  63% 267/422 [01:58<01:08,  2.28it/s]\u001b[A\n","Iteration:  64% 268/422 [01:58<01:07,  2.28it/s]\u001b[A\n","Iteration:  64% 269/422 [01:59<01:07,  2.28it/s]\u001b[A\n","Iteration:  64% 270/422 [01:59<01:06,  2.28it/s]\u001b[A\n","Iteration:  64% 271/422 [01:59<01:06,  2.28it/s]\u001b[A\n","Iteration:  64% 272/422 [02:00<01:05,  2.28it/s]\u001b[A\n","Iteration:  65% 273/422 [02:00<01:05,  2.28it/s]\u001b[A\n","Iteration:  65% 274/422 [02:01<01:04,  2.28it/s]\u001b[A\n","Iteration:  65% 275/422 [02:01<01:04,  2.28it/s]\u001b[A\n","Iteration:  65% 276/422 [02:02<01:04,  2.28it/s]\u001b[A\n","Iteration:  66% 277/422 [02:02<01:03,  2.28it/s]\u001b[A\n","Iteration:  66% 278/422 [02:03<01:03,  2.28it/s]\u001b[A\n","Iteration:  66% 279/422 [02:03<01:02,  2.28it/s]\u001b[A\n","Iteration:  66% 280/422 [02:03<01:02,  2.28it/s]\u001b[A\n","Iteration:  67% 281/422 [02:04<01:01,  2.28it/s]\u001b[A\n","Iteration:  67% 282/422 [02:04<01:01,  2.28it/s]\u001b[A\n","Iteration:  67% 283/422 [02:05<01:00,  2.28it/s]\u001b[A\n","Iteration:  67% 284/422 [02:05<01:00,  2.28it/s]\u001b[A\n","Iteration:  68% 285/422 [02:06<01:00,  2.28it/s]\u001b[A\n","Iteration:  68% 286/422 [02:06<00:59,  2.28it/s]\u001b[A\n","Iteration:  68% 287/422 [02:06<00:59,  2.28it/s]\u001b[A\n","Iteration:  68% 288/422 [02:07<00:58,  2.28it/s]\u001b[A\n","Iteration:  68% 289/422 [02:07<00:58,  2.28it/s]\u001b[A\n","Iteration:  69% 290/422 [02:08<00:57,  2.28it/s]\u001b[A\n","Iteration:  69% 291/422 [02:08<00:57,  2.28it/s]\u001b[A\n","Iteration:  69% 292/422 [02:09<00:56,  2.28it/s]\u001b[A\n","Iteration:  69% 293/422 [02:09<00:56,  2.28it/s]\u001b[A\n","Iteration:  70% 294/422 [02:10<00:56,  2.28it/s]\u001b[A\n","Iteration:  70% 295/422 [02:10<00:55,  2.28it/s]\u001b[A\n","Iteration:  70% 296/422 [02:10<00:55,  2.28it/s]\u001b[A\n","Iteration:  70% 297/422 [02:11<00:54,  2.28it/s]\u001b[A\n","Iteration:  71% 298/422 [02:11<00:54,  2.28it/s]\u001b[A\n","Iteration:  71% 299/422 [02:12<00:53,  2.28it/s]\u001b[A\n","Iteration:  71% 300/422 [02:12<00:53,  2.28it/s]\u001b[A\n","Iteration:  71% 301/422 [02:13<00:53,  2.28it/s]\u001b[A\n","Iteration:  72% 302/422 [02:13<00:52,  2.28it/s]\u001b[A\n","Iteration:  72% 303/422 [02:13<00:52,  2.28it/s]\u001b[A\n","Iteration:  72% 304/422 [02:14<00:51,  2.28it/s]\u001b[A\n","Iteration:  72% 305/422 [02:14<00:51,  2.28it/s]\u001b[A\n","Iteration:  73% 306/422 [02:15<00:50,  2.28it/s]\u001b[A\n","Iteration:  73% 307/422 [02:15<00:50,  2.28it/s]\u001b[A\n","Iteration:  73% 308/422 [02:16<00:49,  2.28it/s]\u001b[A\n","Iteration:  73% 309/422 [02:16<00:49,  2.28it/s]\u001b[A\n","Iteration:  73% 310/422 [02:17<00:49,  2.28it/s]\u001b[A\n","Iteration:  74% 311/422 [02:17<00:48,  2.28it/s]\u001b[A\n","Iteration:  74% 312/422 [02:17<00:48,  2.28it/s]\u001b[A\n","Iteration:  74% 313/422 [02:18<00:47,  2.28it/s]\u001b[A\n","Iteration:  74% 314/422 [02:18<00:47,  2.28it/s]\u001b[A\n","Iteration:  75% 315/422 [02:19<00:46,  2.28it/s]\u001b[A\n","Iteration:  75% 316/422 [02:19<00:46,  2.28it/s]\u001b[A\n","Iteration:  75% 317/422 [02:20<00:46,  2.28it/s]\u001b[A\n","Iteration:  75% 318/422 [02:20<00:45,  2.28it/s]\u001b[A\n","Iteration:  76% 319/422 [02:21<00:45,  2.28it/s]\u001b[A\n","Iteration:  76% 320/422 [02:21<00:44,  2.28it/s]\u001b[A\n","Iteration:  76% 321/422 [02:21<00:44,  2.28it/s]\u001b[A\n","Iteration:  76% 322/422 [02:22<00:43,  2.28it/s]\u001b[A\n","Iteration:  77% 323/422 [02:22<00:43,  2.28it/s]\u001b[A\n","Iteration:  77% 324/422 [02:23<00:42,  2.28it/s]\u001b[A\n","Iteration:  77% 325/422 [02:23<00:42,  2.28it/s]\u001b[A\n","Iteration:  77% 326/422 [02:24<00:42,  2.28it/s]\u001b[A\n","Iteration:  77% 327/422 [02:24<00:41,  2.28it/s]\u001b[A\n","Iteration:  78% 328/422 [02:24<00:41,  2.28it/s]\u001b[A\n","Iteration:  78% 329/422 [02:25<00:40,  2.28it/s]\u001b[A\n","Iteration:  78% 330/422 [02:25<00:40,  2.28it/s]\u001b[A\n","Iteration:  78% 331/422 [02:26<00:39,  2.28it/s]\u001b[A\n","Iteration:  79% 332/422 [02:26<00:39,  2.28it/s]\u001b[A\n","Iteration:  79% 333/422 [02:27<00:38,  2.28it/s]\u001b[A\n","Iteration:  79% 334/422 [02:27<00:38,  2.28it/s]\u001b[A\n","Iteration:  79% 335/422 [02:28<00:38,  2.28it/s]\u001b[A\n","Iteration:  80% 336/422 [02:28<00:37,  2.28it/s]\u001b[A\n","Iteration:  80% 337/422 [02:28<00:37,  2.28it/s]\u001b[A\n","Iteration:  80% 338/422 [02:29<00:36,  2.28it/s]\u001b[A\n","Iteration:  80% 339/422 [02:29<00:36,  2.28it/s]\u001b[A\n","Iteration:  81% 340/422 [02:30<00:35,  2.28it/s]\u001b[A\n","Iteration:  81% 341/422 [02:30<00:35,  2.28it/s]\u001b[A\n","Iteration:  81% 342/422 [02:31<00:35,  2.28it/s]\u001b[A\n","Iteration:  81% 343/422 [02:31<00:34,  2.28it/s]\u001b[A\n","Iteration:  82% 344/422 [02:31<00:34,  2.28it/s]\u001b[A\n","Iteration:  82% 345/422 [02:32<00:33,  2.28it/s]\u001b[A\n","Iteration:  82% 346/422 [02:32<00:33,  2.28it/s]\u001b[A\n","Iteration:  82% 347/422 [02:33<00:32,  2.28it/s]\u001b[A\n","Iteration:  82% 348/422 [02:33<00:32,  2.28it/s]\u001b[A\n","Iteration:  83% 349/422 [02:34<00:31,  2.28it/s]\u001b[A\n","Iteration:  83% 350/422 [02:34<00:31,  2.28it/s]\u001b[A\n","Iteration:  83% 351/422 [02:35<00:31,  2.28it/s]\u001b[A\n","Iteration:  83% 352/422 [02:35<00:30,  2.28it/s]\u001b[A\n","Iteration:  84% 353/422 [02:35<00:30,  2.28it/s]\u001b[A\n","Iteration:  84% 354/422 [02:36<00:29,  2.28it/s]\u001b[A\n","Iteration:  84% 355/422 [02:36<00:29,  2.28it/s]\u001b[A\n","Iteration:  84% 356/422 [02:37<00:28,  2.28it/s]\u001b[A\n","Iteration:  85% 357/422 [02:37<00:28,  2.28it/s]\u001b[A\n","Iteration:  85% 358/422 [02:38<00:28,  2.28it/s]\u001b[A\n","Iteration:  85% 359/422 [02:38<00:27,  2.28it/s]\u001b[A\n","Iteration:  85% 360/422 [02:38<00:27,  2.28it/s]\u001b[A\n","Iteration:  86% 361/422 [02:39<00:26,  2.28it/s]\u001b[A\n","Iteration:  86% 362/422 [02:39<00:26,  2.28it/s]\u001b[A\n","Iteration:  86% 363/422 [02:40<00:25,  2.28it/s]\u001b[A\n","Iteration:  86% 364/422 [02:40<00:25,  2.28it/s]\u001b[A\n","Iteration:  86% 365/422 [02:41<00:24,  2.28it/s]\u001b[A\n","Iteration:  87% 366/422 [02:41<00:24,  2.28it/s]\u001b[A\n","Iteration:  87% 367/422 [02:42<00:24,  2.28it/s]\u001b[A\n","Iteration:  87% 368/422 [02:42<00:23,  2.28it/s]\u001b[A\n","Iteration:  87% 369/422 [02:42<00:23,  2.28it/s]\u001b[A\n","Iteration:  88% 370/422 [02:43<00:22,  2.28it/s]\u001b[A\n","Iteration:  88% 371/422 [02:43<00:22,  2.28it/s]\u001b[A\n","Iteration:  88% 372/422 [02:44<00:21,  2.28it/s]\u001b[A\n","Iteration:  88% 373/422 [02:44<00:21,  2.28it/s]\u001b[A\n","Iteration:  89% 374/422 [02:45<00:21,  2.28it/s]\u001b[A\n","Iteration:  89% 375/422 [02:45<00:20,  2.28it/s]\u001b[A\n","Iteration:  89% 376/422 [02:45<00:20,  2.28it/s]\u001b[A\n","Iteration:  89% 377/422 [02:46<00:19,  2.28it/s]\u001b[A\n","Iteration:  90% 378/422 [02:46<00:19,  2.28it/s]\u001b[A\n","Iteration:  90% 379/422 [02:47<00:18,  2.28it/s]\u001b[A\n","Iteration:  90% 380/422 [02:47<00:18,  2.28it/s]\u001b[A\n","Iteration:  90% 381/422 [02:48<00:17,  2.28it/s]\u001b[A\n","Iteration:  91% 382/422 [02:48<00:17,  2.28it/s]\u001b[A\n","Iteration:  91% 383/422 [02:49<00:17,  2.28it/s]\u001b[A\n","Iteration:  91% 384/422 [02:49<00:16,  2.28it/s]\u001b[A\n","Iteration:  91% 385/422 [02:49<00:16,  2.28it/s]\u001b[A\n","Iteration:  91% 386/422 [02:50<00:15,  2.28it/s]\u001b[A\n","Iteration:  92% 387/422 [02:50<00:15,  2.28it/s]\u001b[A\n","Iteration:  92% 388/422 [02:51<00:14,  2.28it/s]\u001b[A\n","Iteration:  92% 389/422 [02:51<00:14,  2.28it/s]\u001b[A\n","Iteration:  92% 390/422 [02:52<00:14,  2.28it/s]\u001b[A\n","Iteration:  93% 391/422 [02:52<00:13,  2.28it/s]\u001b[A\n","Iteration:  93% 392/422 [02:52<00:13,  2.28it/s]\u001b[A\n","Iteration:  93% 393/422 [02:53<00:12,  2.28it/s]\u001b[A\n","Iteration:  93% 394/422 [02:53<00:12,  2.28it/s]\u001b[A\n","Iteration:  94% 395/422 [02:54<00:11,  2.28it/s]\u001b[A\n","Iteration:  94% 396/422 [02:54<00:11,  2.28it/s]\u001b[A\n","Iteration:  94% 397/422 [02:55<00:10,  2.28it/s]\u001b[A\n","Iteration:  94% 398/422 [02:55<00:10,  2.28it/s]\u001b[A\n","Iteration:  95% 399/422 [02:56<00:10,  2.28it/s]\u001b[A\n","Iteration:  95% 400/422 [02:56<00:09,  2.28it/s]\u001b[A\n","Iteration:  95% 401/422 [02:56<00:09,  2.28it/s]\u001b[A\n","Iteration:  95% 402/422 [02:57<00:08,  2.28it/s]\u001b[A\n","Iteration:  95% 403/422 [02:57<00:08,  2.28it/s]\u001b[A\n","Iteration:  96% 404/422 [02:58<00:07,  2.28it/s]\u001b[A\n","Iteration:  96% 405/422 [02:58<00:07,  2.28it/s]\u001b[A\n","Iteration:  96% 406/422 [02:59<00:07,  2.28it/s]\u001b[A\n","Iteration:  96% 407/422 [02:59<00:06,  2.28it/s]\u001b[A\n","Iteration:  97% 408/422 [03:00<00:06,  2.28it/s]\u001b[A\n","Iteration:  97% 409/422 [03:00<00:05,  2.28it/s]\u001b[A\n","Iteration:  97% 410/422 [03:00<00:05,  2.27it/s]\u001b[A\n","Iteration:  97% 411/422 [03:01<00:04,  2.28it/s]\u001b[A\n","Iteration:  98% 412/422 [03:01<00:04,  2.28it/s]\u001b[A\n","Iteration:  98% 413/422 [03:02<00:03,  2.28it/s]\u001b[A\n","Iteration:  98% 414/422 [03:02<00:03,  2.28it/s]\u001b[A\n","Iteration:  98% 415/422 [03:07<00:13,  1.90s/it]\u001b[A\n","Iteration:  99% 416/422 [03:08<00:08,  1.46s/it]\u001b[A\n","Iteration:  99% 417/422 [03:08<00:05,  1.16s/it]\u001b[A\n","Iteration:  99% 418/422 [03:09<00:03,  1.06it/s]\u001b[A\n","Iteration:  99% 419/422 [03:09<00:02,  1.27it/s]\u001b[A\n","Iteration: 100% 420/422 [03:10<00:01,  1.46it/s]\u001b[A\n","Iteration: 100% 421/422 [03:10<00:00,  1.64it/s]\u001b[A\n","Iteration: 100% 422/422 [03:11<00:00,  2.21it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-18 05:02:14,045][__main__][DEBUG] - epoch is 0\n","[2022-08-18 05:02:14,072][__main__][DEBUG] - validation loss is tensor(0.1525, device='cuda:0')\n","Epoch:   1% 1/100 [06:16<10:21:43, 376.80s/it]\n","Iteration:   0% 0/422 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\n","Iteration:   0% 1/422 [00:01<09:31,  1.36s/it]\u001b[A\n","Iteration:   0% 2/422 [00:01<05:42,  1.23it/s]\u001b[A\n","Iteration:   1% 3/422 [00:02<04:29,  1.55it/s]\u001b[A\n","Iteration:   1% 4/422 [00:02<03:55,  1.78it/s]\u001b[A\n","Iteration:   1% 5/422 [00:03<03:35,  1.93it/s]\u001b[A\n","Iteration:   1% 6/422 [00:03<03:24,  2.04it/s]\u001b[A\n","Iteration:   2% 7/422 [00:03<03:16,  2.11it/s]\u001b[A\n","Iteration:   2% 8/422 [00:04<03:11,  2.16it/s]\u001b[A\n","Iteration:   2% 9/422 [00:04<03:07,  2.20it/s]\u001b[A\n","Iteration:   2% 10/422 [00:05<03:05,  2.22it/s]\u001b[A\n","Iteration:   3% 11/422 [00:05<03:03,  2.24it/s]\u001b[A\n","Iteration:   3% 12/422 [00:06<03:02,  2.25it/s]\u001b[A\n","Iteration:   3% 13/422 [00:06<03:00,  2.26it/s]\u001b[A\n","Iteration:   3% 14/422 [00:07<03:00,  2.26it/s]\u001b[A\n","Iteration:   4% 15/422 [00:07<02:59,  2.26it/s]\u001b[A\n","Iteration:   4% 16/422 [00:07<02:58,  2.27it/s]\u001b[A\n","Iteration:   4% 17/422 [00:08<02:58,  2.27it/s]\u001b[A\n","Iteration:   4% 18/422 [00:08<02:57,  2.27it/s]\u001b[A\n","Iteration:   5% 19/422 [00:09<02:57,  2.27it/s]\u001b[A\n","Iteration:   5% 20/422 [00:09<02:56,  2.27it/s]\u001b[A\n","Iteration:   5% 21/422 [00:10<02:56,  2.27it/s]\u001b[A\n","Iteration:   5% 22/422 [00:10<02:56,  2.27it/s]\u001b[A\n","Iteration:   5% 23/422 [00:11<02:55,  2.27it/s]\u001b[A\n","Iteration:   6% 24/422 [00:11<02:55,  2.27it/s]\u001b[A\n","Iteration:   6% 25/422 [00:11<02:54,  2.27it/s]\u001b[A\n","Iteration:   6% 26/422 [00:12<02:55,  2.26it/s]\u001b[A\n","Iteration:   6% 27/422 [00:12<02:55,  2.25it/s]\u001b[A\n","Iteration:   7% 28/422 [00:13<02:55,  2.25it/s]\u001b[A\n","Iteration:   7% 29/422 [00:13<02:59,  2.18it/s]\u001b[A\n","Iteration:   7% 30/422 [00:14<02:57,  2.21it/s]\u001b[A\n","Iteration:   7% 31/422 [00:14<02:55,  2.23it/s]\u001b[A\n","Iteration:   8% 32/422 [00:15<02:56,  2.21it/s]\u001b[A\n","Iteration:   8% 33/422 [00:15<02:56,  2.21it/s]\u001b[A\n","Iteration:   8% 34/422 [00:15<02:54,  2.23it/s]\u001b[A\n","Iteration:   8% 35/422 [00:16<02:52,  2.24it/s]\u001b[A\n","Iteration:   9% 36/422 [00:16<02:51,  2.25it/s]\u001b[A\n","Iteration:   9% 37/422 [00:17<02:50,  2.25it/s]\u001b[A\n","Iteration:   9% 38/422 [00:17<02:49,  2.26it/s]\u001b[A\n","Iteration:   9% 39/422 [00:18<02:49,  2.26it/s]\u001b[A\n","Iteration:   9% 40/422 [00:18<02:48,  2.27it/s]\u001b[A\n","Iteration:  10% 41/422 [00:19<02:47,  2.27it/s]\u001b[A\n","Iteration:  10% 42/422 [00:19<02:47,  2.27it/s]\u001b[A\n","Iteration:  10% 43/422 [00:19<02:46,  2.28it/s]\u001b[A\n","Iteration:  10% 44/422 [00:20<02:45,  2.28it/s]\u001b[A\n","Iteration:  11% 45/422 [00:20<02:45,  2.28it/s]\u001b[A\n","Iteration:  11% 46/422 [00:21<02:44,  2.28it/s]\u001b[A\n","Iteration:  11% 47/422 [00:21<02:44,  2.28it/s]\u001b[A\n","Iteration:  11% 48/422 [00:22<02:44,  2.28it/s]\u001b[A\n","Iteration:  12% 49/422 [00:22<02:43,  2.28it/s]\u001b[A\n","Iteration:  12% 50/422 [00:22<02:43,  2.28it/s]\u001b[A\n","Iteration:  12% 51/422 [00:23<02:42,  2.28it/s]\u001b[A\n","Iteration:  12% 52/422 [00:23<02:42,  2.28it/s]\u001b[A\n","Iteration:  13% 53/422 [00:24<02:41,  2.28it/s]\u001b[A\n","Iteration:  13% 54/422 [00:24<02:41,  2.28it/s]\u001b[A\n","Iteration:  13% 55/422 [00:25<02:40,  2.28it/s]\u001b[A\n","Iteration:  13% 56/422 [00:25<02:40,  2.28it/s]\u001b[A\n","Iteration:  14% 57/422 [00:26<02:40,  2.28it/s]\u001b[A\n","Iteration:  14% 58/422 [00:26<02:39,  2.28it/s]\u001b[A\n","Iteration:  14% 59/422 [00:26<02:39,  2.28it/s]\u001b[A\n","Iteration:  14% 60/422 [00:27<02:39,  2.27it/s]\u001b[A\n","Iteration:  14% 61/422 [00:27<02:38,  2.27it/s]\u001b[A\n","Iteration:  15% 62/422 [00:28<02:38,  2.28it/s]\u001b[A\n","Iteration:  15% 63/422 [00:33<11:30,  1.92s/it]\u001b[A\n","Iteration:  15% 64/422 [00:34<08:49,  1.48s/it]\u001b[A\n","Iteration:  15% 65/422 [00:34<06:56,  1.17s/it]\u001b[A\n","Iteration:  16% 66/422 [00:34<05:37,  1.05it/s]\u001b[A\n","Iteration:  16% 67/422 [00:35<04:42,  1.26it/s]\u001b[A\n","Iteration:  16% 68/422 [00:35<04:03,  1.45it/s]\u001b[A\n","Iteration:  16% 69/422 [00:36<03:36,  1.63it/s]\u001b[A\n","Iteration:  17% 70/422 [00:36<03:17,  1.78it/s]\u001b[A\n","Iteration:  17% 71/422 [00:37<03:03,  1.91it/s]\u001b[A\n","Iteration:  17% 72/422 [00:37<02:54,  2.01it/s]\u001b[A\n","Iteration:  17% 73/422 [00:38<02:47,  2.08it/s]\u001b[A\n","Iteration:  18% 74/422 [00:38<02:42,  2.14it/s]\u001b[A\n","Iteration:  18% 75/422 [00:38<02:39,  2.18it/s]\u001b[A\n","Iteration:  18% 76/422 [00:39<02:36,  2.21it/s]\u001b[A\n","Iteration:  18% 77/422 [00:39<02:34,  2.23it/s]\u001b[A\n","Iteration:  18% 78/422 [00:40<02:33,  2.24it/s]\u001b[A\n","Iteration:  19% 79/422 [00:40<02:32,  2.25it/s]\u001b[A\n","Iteration:  19% 80/422 [00:41<02:31,  2.26it/s]\u001b[A\n","Iteration:  19% 81/422 [00:41<02:30,  2.27it/s]\u001b[A\n","Iteration:  19% 82/422 [00:41<02:29,  2.27it/s]\u001b[A\n","Iteration:  20% 83/422 [00:42<02:29,  2.27it/s]\u001b[A\n","Iteration:  20% 84/422 [00:42<02:28,  2.27it/s]\u001b[A\n","Iteration:  20% 85/422 [00:43<02:28,  2.28it/s]\u001b[A\n","Iteration:  20% 86/422 [00:43<02:27,  2.28it/s]\u001b[A\n","Iteration:  21% 87/422 [00:44<02:27,  2.28it/s]\u001b[A\n","Iteration:  21% 88/422 [00:44<02:26,  2.28it/s]\u001b[A\n","Iteration:  21% 89/422 [00:45<02:26,  2.28it/s]\u001b[A\n","Iteration:  21% 90/422 [00:45<02:25,  2.28it/s]\u001b[A\n","Iteration:  22% 91/422 [00:45<02:25,  2.28it/s]\u001b[A\n","Iteration:  22% 92/422 [00:46<02:24,  2.28it/s]\u001b[A\n","Iteration:  22% 93/422 [00:46<02:24,  2.28it/s]\u001b[A\n","Iteration:  22% 94/422 [00:47<02:23,  2.28it/s]\u001b[A\n","Iteration:  23% 95/422 [00:47<02:23,  2.28it/s]\u001b[A\n","Iteration:  23% 96/422 [00:48<02:22,  2.28it/s]\u001b[A\n","Iteration:  23% 97/422 [00:48<02:22,  2.28it/s]\u001b[A\n","Iteration:  23% 98/422 [00:48<02:22,  2.28it/s]\u001b[A\n","Iteration:  23% 99/422 [00:49<02:21,  2.28it/s]\u001b[A\n","Iteration:  24% 100/422 [00:49<02:21,  2.28it/s]\u001b[A\n","Iteration:  24% 101/422 [00:50<02:20,  2.28it/s]\u001b[A\n","Iteration:  24% 102/422 [00:50<02:20,  2.28it/s]\u001b[A\n","Iteration:  24% 103/422 [00:51<02:19,  2.28it/s]\u001b[A\n","Iteration:  25% 104/422 [00:51<02:19,  2.28it/s]\u001b[A\n","Iteration:  25% 105/422 [00:52<02:18,  2.28it/s]\u001b[A\n","Iteration:  25% 106/422 [00:52<02:18,  2.28it/s]\u001b[A\n","Iteration:  25% 107/422 [00:52<02:17,  2.28it/s]\u001b[A\n","Iteration:  26% 108/422 [00:53<02:17,  2.28it/s]\u001b[A\n","Iteration:  26% 109/422 [00:53<02:17,  2.28it/s]\u001b[A\n","Iteration:  26% 110/422 [00:54<02:16,  2.28it/s]\u001b[A\n","Iteration:  26% 111/422 [00:54<02:16,  2.28it/s]\u001b[A\n","Iteration:  27% 112/422 [00:55<02:15,  2.28it/s]\u001b[A\n","Iteration:  27% 113/422 [00:55<02:15,  2.28it/s]\u001b[A\n","Iteration:  27% 114/422 [00:56<02:15,  2.28it/s]\u001b[A\n","Iteration:  27% 115/422 [00:56<02:14,  2.28it/s]\u001b[A\n","Iteration:  27% 116/422 [00:56<02:14,  2.28it/s]\u001b[A\n","Iteration:  28% 117/422 [00:57<02:13,  2.28it/s]\u001b[A\n","Iteration:  28% 118/422 [00:57<02:13,  2.28it/s]\u001b[A\n","Iteration:  28% 119/422 [00:58<02:12,  2.28it/s]\u001b[A\n","Iteration:  28% 120/422 [00:58<02:12,  2.28it/s]\u001b[A\n","Iteration:  29% 121/422 [00:59<02:12,  2.28it/s]\u001b[A\n","Iteration:  29% 122/422 [00:59<02:11,  2.28it/s]\u001b[A\n","Iteration:  29% 123/422 [00:59<02:11,  2.28it/s]\u001b[A\n","Iteration:  29% 124/422 [01:00<02:10,  2.28it/s]\u001b[A\n","Iteration:  30% 125/422 [01:00<02:10,  2.28it/s]\u001b[A\n","Iteration:  30% 126/422 [01:01<02:09,  2.28it/s]\u001b[A\n","Iteration:  30% 127/422 [01:01<02:09,  2.28it/s]\u001b[A\n","Iteration:  30% 128/422 [01:02<02:08,  2.28it/s]\u001b[A\n","Iteration:  31% 129/422 [01:02<02:08,  2.28it/s]\u001b[A\n","Iteration:  31% 130/422 [01:03<02:07,  2.28it/s]\u001b[A\n","Iteration:  31% 131/422 [01:03<02:07,  2.28it/s]\u001b[A\n","Iteration:  31% 132/422 [01:03<02:07,  2.28it/s]\u001b[A\n","Iteration:  32% 133/422 [01:04<02:06,  2.28it/s]\u001b[A\n","Iteration:  32% 134/422 [01:04<02:06,  2.28it/s]\u001b[A\n","Iteration:  32% 135/422 [01:05<02:05,  2.28it/s]\u001b[A\n","Iteration:  32% 136/422 [01:05<02:05,  2.28it/s]\u001b[A\n","Iteration:  32% 137/422 [01:06<02:04,  2.28it/s]\u001b[A\n","Iteration:  33% 138/422 [01:06<02:04,  2.28it/s]\u001b[A\n","Iteration:  33% 139/422 [01:06<02:04,  2.28it/s]\u001b[A\n","Iteration:  33% 140/422 [01:07<02:03,  2.28it/s]\u001b[A\n","Iteration:  33% 141/422 [01:07<02:03,  2.28it/s]\u001b[A\n","Iteration:  34% 142/422 [01:08<02:02,  2.28it/s]\u001b[A\n","Iteration:  34% 143/422 [01:08<02:02,  2.28it/s]\u001b[A\n","Iteration:  34% 144/422 [01:09<02:01,  2.28it/s]\u001b[A\n","Iteration:  34% 145/422 [01:09<02:01,  2.28it/s]\u001b[A\n","Iteration:  35% 146/422 [01:10<02:01,  2.28it/s]\u001b[A\n","Iteration:  35% 147/422 [01:10<02:00,  2.28it/s]\u001b[A\n","Iteration:  35% 148/422 [01:10<02:00,  2.28it/s]\u001b[A\n","Iteration:  35% 149/422 [01:11<01:59,  2.28it/s]\u001b[A\n","Iteration:  36% 150/422 [01:11<01:59,  2.28it/s]\u001b[A\n","Iteration:  36% 151/422 [01:12<01:58,  2.28it/s]\u001b[A\n","Iteration:  36% 152/422 [01:12<01:58,  2.28it/s]\u001b[A\n","Iteration:  36% 153/422 [01:13<01:57,  2.28it/s]\u001b[A\n","Iteration:  36% 154/422 [01:13<01:57,  2.28it/s]\u001b[A\n","Iteration:  37% 155/422 [01:13<01:56,  2.28it/s]\u001b[A\n","Iteration:  37% 156/422 [01:14<01:56,  2.28it/s]\u001b[A\n","Iteration:  37% 157/422 [01:14<01:56,  2.28it/s]\u001b[A\n","Iteration:  37% 158/422 [01:15<01:55,  2.28it/s]\u001b[A\n","Iteration:  38% 159/422 [01:15<01:55,  2.28it/s]\u001b[A\n","Iteration:  38% 160/422 [01:16<01:54,  2.28it/s]\u001b[A\n","Iteration:  38% 161/422 [01:16<01:54,  2.28it/s]\u001b[A\n","Iteration:  38% 162/422 [01:17<01:54,  2.28it/s]\u001b[A\n","Iteration:  39% 163/422 [01:17<01:53,  2.28it/s]\u001b[A\n","Iteration:  39% 164/422 [01:17<01:53,  2.28it/s]\u001b[A\n","Iteration:  39% 165/422 [01:18<01:52,  2.28it/s]\u001b[A\n","Iteration:  39% 166/422 [01:18<01:52,  2.28it/s]\u001b[A\n","Iteration:  40% 167/422 [01:19<01:51,  2.28it/s]\u001b[A\n","Iteration:  40% 168/422 [01:19<01:51,  2.28it/s]\u001b[A\n","Iteration:  40% 169/422 [01:20<01:50,  2.28it/s]\u001b[A\n","Iteration:  40% 170/422 [01:20<01:50,  2.28it/s]\u001b[A\n","Iteration:  41% 171/422 [01:20<01:50,  2.28it/s]\u001b[A\n","Iteration:  41% 172/422 [01:21<01:49,  2.28it/s]\u001b[A\n","Iteration:  41% 173/422 [01:21<01:49,  2.28it/s]\u001b[A\n","Iteration:  41% 174/422 [01:22<01:48,  2.28it/s]\u001b[A\n","Iteration:  41% 175/422 [01:22<01:48,  2.28it/s]\u001b[A\n","Iteration:  42% 176/422 [01:23<01:47,  2.28it/s]\u001b[A\n","Iteration:  42% 177/422 [01:23<01:47,  2.28it/s]\u001b[A\n","Iteration:  42% 178/422 [01:24<01:46,  2.28it/s]\u001b[A\n","Iteration:  42% 179/422 [01:24<01:46,  2.28it/s]\u001b[A\n","Iteration:  43% 180/422 [01:24<01:45,  2.28it/s]\u001b[A\n","Iteration:  43% 181/422 [01:25<01:45,  2.28it/s]\u001b[A\n","Iteration:  43% 182/422 [01:25<01:45,  2.28it/s]\u001b[A\n","Iteration:  43% 183/422 [01:26<01:44,  2.28it/s]\u001b[A\n","Iteration:  44% 184/422 [01:26<01:44,  2.28it/s]\u001b[A\n","Iteration:  44% 185/422 [01:27<01:43,  2.28it/s]\u001b[A\n","Iteration:  44% 186/422 [01:27<01:43,  2.28it/s]\u001b[A\n","Iteration:  44% 187/422 [01:28<01:42,  2.28it/s]\u001b[A\n","Iteration:  45% 188/422 [01:28<01:42,  2.28it/s]\u001b[A\n","Iteration:  45% 189/422 [01:28<01:42,  2.28it/s]\u001b[A\n","Iteration:  45% 190/422 [01:29<01:41,  2.28it/s]\u001b[A\n","Iteration:  45% 191/422 [01:29<01:41,  2.28it/s]\u001b[A\n","Iteration:  45% 192/422 [01:30<01:40,  2.28it/s]\u001b[A\n","Iteration:  46% 193/422 [01:30<01:40,  2.28it/s]\u001b[A\n","Iteration:  46% 194/422 [01:31<01:39,  2.28it/s]\u001b[A\n","Iteration:  46% 195/422 [01:31<01:39,  2.28it/s]\u001b[A\n","Iteration:  46% 196/422 [01:31<01:39,  2.28it/s]\u001b[A\n","Iteration:  47% 197/422 [01:32<01:38,  2.28it/s]\u001b[A\n","Iteration:  47% 198/422 [01:32<01:38,  2.28it/s]\u001b[A\n","Iteration:  47% 199/422 [01:33<01:37,  2.28it/s]\u001b[A\n","Iteration:  47% 200/422 [01:33<01:37,  2.28it/s]\u001b[A\n","Iteration:  48% 201/422 [01:34<01:36,  2.28it/s]\u001b[A\n","Iteration:  48% 202/422 [01:34<01:36,  2.28it/s]\u001b[A\n","Iteration:  48% 203/422 [01:35<01:36,  2.28it/s]\u001b[A\n","Iteration:  48% 204/422 [01:35<01:35,  2.28it/s]\u001b[A\n","Iteration:  49% 205/422 [01:35<01:35,  2.28it/s]\u001b[A\n","Iteration:  49% 206/422 [01:36<01:34,  2.28it/s]\u001b[A\n","Iteration:  49% 207/422 [01:36<01:34,  2.28it/s]\u001b[A\n","Iteration:  49% 208/422 [01:37<01:33,  2.28it/s]\u001b[A\n","Iteration:  50% 209/422 [01:37<01:33,  2.28it/s]\u001b[A\n","Iteration:  50% 210/422 [01:38<01:32,  2.28it/s]\u001b[A\n","Iteration:  50% 211/422 [01:38<01:32,  2.28it/s]\u001b[A\n","Iteration:  50% 212/422 [01:38<01:32,  2.28it/s]\u001b[A\n","Iteration:  50% 213/422 [01:39<01:31,  2.28it/s]\u001b[A\n","Iteration:  51% 214/422 [01:39<01:31,  2.28it/s]\u001b[A\n","Iteration:  51% 215/422 [01:40<01:30,  2.28it/s]\u001b[A\n","Iteration:  51% 216/422 [01:40<01:30,  2.28it/s]\u001b[A\n","Iteration:  51% 217/422 [01:41<01:29,  2.28it/s]\u001b[A\n","Iteration:  52% 218/422 [01:41<01:29,  2.28it/s]\u001b[A\n","Iteration:  52% 219/422 [01:42<01:28,  2.28it/s]\u001b[A\n","Iteration:  52% 220/422 [01:42<01:28,  2.28it/s]\u001b[A\n","Iteration:  52% 221/422 [01:42<01:28,  2.28it/s]\u001b[A\n","Iteration:  53% 222/422 [01:43<01:27,  2.28it/s]\u001b[A\n","Iteration:  53% 223/422 [01:43<01:27,  2.28it/s]\u001b[A\n","Iteration:  53% 224/422 [01:44<01:26,  2.28it/s]\u001b[A\n","Iteration:  53% 225/422 [01:44<01:26,  2.28it/s]\u001b[A\n","Iteration:  54% 226/422 [01:45<01:25,  2.28it/s]\u001b[A\n","Iteration:  54% 227/422 [01:45<01:25,  2.28it/s]\u001b[A\n","Iteration:  54% 228/422 [01:45<01:25,  2.28it/s]\u001b[A\n","Iteration:  54% 229/422 [01:46<01:24,  2.28it/s]\u001b[A\n","Iteration:  55% 230/422 [01:46<01:24,  2.28it/s]\u001b[A\n","Iteration:  55% 231/422 [01:47<01:23,  2.28it/s]\u001b[A\n","Iteration:  55% 232/422 [01:47<01:23,  2.28it/s]\u001b[A\n","Iteration:  55% 233/422 [01:48<01:22,  2.28it/s]\u001b[A\n","Iteration:  55% 234/422 [01:48<01:22,  2.28it/s]\u001b[A\n","Iteration:  56% 235/422 [01:49<01:21,  2.28it/s]\u001b[A\n","Iteration:  56% 236/422 [01:49<01:21,  2.28it/s]\u001b[A\n","Iteration:  56% 237/422 [01:49<01:21,  2.28it/s]\u001b[A\n","Iteration:  56% 238/422 [01:50<01:20,  2.28it/s]\u001b[A\n","Iteration:  57% 239/422 [01:50<01:20,  2.28it/s]\u001b[A\n","Iteration:  57% 240/422 [01:51<01:19,  2.28it/s]\u001b[A\n","Iteration:  57% 241/422 [01:51<01:19,  2.28it/s]\u001b[A\n","Iteration:  57% 242/422 [01:52<01:18,  2.28it/s]\u001b[A\n","Iteration:  58% 243/422 [01:52<01:18,  2.28it/s]\u001b[A\n","Iteration:  58% 244/422 [01:52<01:17,  2.28it/s]\u001b[A\n","Iteration:  58% 245/422 [01:53<01:17,  2.28it/s]\u001b[A\n","Iteration:  58% 246/422 [01:53<01:17,  2.28it/s]\u001b[A\n","Iteration:  59% 247/422 [01:54<01:16,  2.28it/s]\u001b[A\n","Iteration:  59% 248/422 [01:54<01:16,  2.28it/s]\u001b[A\n","Iteration:  59% 249/422 [01:55<01:15,  2.28it/s]\u001b[A\n","Iteration:  59% 250/422 [01:55<01:15,  2.28it/s]\u001b[A\n","Iteration:  59% 251/422 [01:56<01:14,  2.28it/s]\u001b[A\n","Iteration:  60% 252/422 [01:56<01:14,  2.28it/s]\u001b[A\n","Iteration:  60% 253/422 [01:56<01:14,  2.28it/s]\u001b[A\n","Iteration:  60% 254/422 [01:57<01:13,  2.28it/s]\u001b[A\n","Iteration:  60% 255/422 [01:57<01:13,  2.28it/s]\u001b[A\n","Iteration:  61% 256/422 [01:58<01:12,  2.28it/s]\u001b[A\n","Iteration:  61% 257/422 [01:58<01:12,  2.28it/s]\u001b[A\n","Iteration:  61% 258/422 [01:59<01:11,  2.28it/s]\u001b[A\n","Iteration:  61% 259/422 [01:59<01:11,  2.28it/s]\u001b[A\n","Iteration:  62% 260/422 [01:59<01:11,  2.28it/s]\u001b[A\n","Iteration:  62% 261/422 [02:00<01:10,  2.28it/s]\u001b[A\n","Iteration:  62% 262/422 [02:00<01:10,  2.28it/s]\u001b[A\n","Iteration:  62% 263/422 [02:01<01:09,  2.28it/s]\u001b[A\n","Iteration:  63% 264/422 [02:01<01:09,  2.28it/s]\u001b[A\n","Iteration:  63% 265/422 [02:02<01:08,  2.28it/s]\u001b[A\n","Iteration:  63% 266/422 [02:02<01:08,  2.28it/s]\u001b[A\n","Iteration:  63% 267/422 [02:03<01:07,  2.28it/s]\u001b[A\n","Iteration:  64% 268/422 [02:03<01:07,  2.28it/s]\u001b[A\n","Iteration:  64% 269/422 [02:03<01:07,  2.28it/s]\u001b[A\n","Iteration:  64% 270/422 [02:04<01:06,  2.28it/s]\u001b[A\n","Iteration:  64% 271/422 [02:04<01:06,  2.28it/s]\u001b[A\n","Iteration:  64% 272/422 [02:05<01:05,  2.28it/s]\u001b[A\n","Iteration:  65% 273/422 [02:05<01:05,  2.28it/s]\u001b[A\n","Iteration:  65% 274/422 [02:06<01:04,  2.28it/s]\u001b[A\n","Iteration:  65% 275/422 [02:06<01:04,  2.28it/s]\u001b[A\n","Iteration:  65% 276/422 [02:07<01:03,  2.28it/s]\u001b[A\n","Iteration:  66% 277/422 [02:07<01:03,  2.28it/s]\u001b[A\n","Iteration:  66% 278/422 [02:07<01:03,  2.28it/s]\u001b[A\n","Iteration:  66% 279/422 [02:08<01:02,  2.28it/s]\u001b[A\n","Iteration:  66% 280/422 [02:08<01:02,  2.28it/s]\u001b[A\n","Iteration:  67% 281/422 [02:09<01:01,  2.28it/s]\u001b[A\n","Iteration:  67% 282/422 [02:09<01:01,  2.28it/s]\u001b[A\n","Iteration:  67% 283/422 [02:10<01:00,  2.28it/s]\u001b[A\n","Iteration:  67% 284/422 [02:10<01:00,  2.28it/s]\u001b[A\n","Iteration:  68% 285/422 [02:10<01:00,  2.28it/s]\u001b[A\n","Iteration:  68% 286/422 [02:11<00:59,  2.28it/s]\u001b[A\n","Iteration:  68% 287/422 [02:11<00:59,  2.28it/s]\u001b[A\n","Iteration:  68% 288/422 [02:12<00:58,  2.28it/s]\u001b[A\n","Iteration:  68% 289/422 [02:12<00:58,  2.28it/s]\u001b[A\n","Iteration:  69% 290/422 [02:13<00:57,  2.28it/s]\u001b[A\n","Iteration:  69% 291/422 [02:13<00:57,  2.28it/s]\u001b[A\n","Iteration:  69% 292/422 [02:14<00:56,  2.28it/s]\u001b[A\n","Iteration:  69% 293/422 [02:14<00:56,  2.28it/s]\u001b[A\n","Iteration:  70% 294/422 [02:14<00:56,  2.28it/s]\u001b[A\n","Iteration:  70% 295/422 [02:15<00:55,  2.28it/s]\u001b[A\n","Iteration:  70% 296/422 [02:15<00:55,  2.28it/s]\u001b[A\n","Iteration:  70% 297/422 [02:16<00:54,  2.28it/s]\u001b[A\n","Iteration:  71% 298/422 [02:16<00:54,  2.28it/s]\u001b[A\n","Iteration:  71% 299/422 [02:17<00:53,  2.28it/s]\u001b[A\n","Iteration:  71% 300/422 [02:17<00:53,  2.28it/s]\u001b[A\n","Iteration:  71% 301/422 [02:17<00:53,  2.28it/s]\u001b[A\n","Iteration:  72% 302/422 [02:18<00:52,  2.28it/s]\u001b[A\n","Iteration:  72% 303/422 [02:18<00:52,  2.28it/s]\u001b[A\n","Iteration:  72% 304/422 [02:19<00:51,  2.28it/s]\u001b[A\n","Iteration:  72% 305/422 [02:19<00:51,  2.28it/s]\u001b[A\n","Iteration:  73% 306/422 [02:20<00:50,  2.28it/s]\u001b[A\n","Iteration:  73% 307/422 [02:20<00:50,  2.28it/s]\u001b[A\n","Iteration:  73% 308/422 [02:21<00:49,  2.28it/s]\u001b[A\n","Iteration:  73% 309/422 [02:21<00:49,  2.28it/s]\u001b[A\n","Iteration:  73% 310/422 [02:21<00:49,  2.28it/s]\u001b[A\n","Iteration:  74% 311/422 [02:22<00:48,  2.28it/s]\u001b[A\n","Iteration:  74% 312/422 [02:22<00:48,  2.28it/s]\u001b[A\n","Iteration:  74% 313/422 [02:23<00:47,  2.28it/s]\u001b[A\n","Iteration:  74% 314/422 [02:23<00:47,  2.28it/s]\u001b[A\n","Iteration:  75% 315/422 [02:24<00:46,  2.28it/s]\u001b[A\n","Iteration:  75% 316/422 [02:24<00:46,  2.28it/s]\u001b[A\n","Iteration:  75% 317/422 [02:24<00:46,  2.28it/s]\u001b[A\n","Iteration:  75% 318/422 [02:25<00:45,  2.28it/s]\u001b[A\n","Iteration:  76% 319/422 [02:25<00:45,  2.28it/s]\u001b[A\n","Iteration:  76% 320/422 [02:26<00:44,  2.28it/s]\u001b[A\n","Iteration:  76% 321/422 [02:26<00:44,  2.28it/s]\u001b[A\n","Iteration:  76% 322/422 [02:27<00:43,  2.28it/s]\u001b[A\n","Iteration:  77% 323/422 [02:27<00:43,  2.28it/s]\u001b[A\n","Iteration:  77% 324/422 [02:28<00:42,  2.28it/s]\u001b[A\n","Iteration:  77% 325/422 [02:28<00:42,  2.28it/s]\u001b[A\n","Iteration:  77% 326/422 [02:28<00:42,  2.28it/s]\u001b[A\n","Iteration:  77% 327/422 [02:29<00:41,  2.28it/s]\u001b[A\n","Iteration:  78% 328/422 [02:29<00:41,  2.28it/s]\u001b[A\n","Iteration:  78% 329/422 [02:30<00:40,  2.28it/s]\u001b[A\n","Iteration:  78% 330/422 [02:30<00:40,  2.28it/s]\u001b[A\n","Iteration:  78% 331/422 [02:31<00:39,  2.28it/s]\u001b[A\n","Iteration:  79% 332/422 [02:31<00:39,  2.28it/s]\u001b[A\n","Iteration:  79% 333/422 [02:31<00:39,  2.28it/s]\u001b[A\n","Iteration:  79% 334/422 [02:32<00:38,  2.28it/s]\u001b[A\n","Iteration:  79% 335/422 [02:32<00:38,  2.28it/s]\u001b[A\n","Iteration:  80% 336/422 [02:33<00:37,  2.28it/s]\u001b[A\n","Iteration:  80% 337/422 [02:33<00:37,  2.28it/s]\u001b[A\n","Iteration:  80% 338/422 [02:34<00:36,  2.28it/s]\u001b[A\n","Iteration:  80% 339/422 [02:34<00:36,  2.28it/s]\u001b[A\n","Iteration:  81% 340/422 [02:35<00:35,  2.28it/s]\u001b[A\n","Iteration:  81% 341/422 [02:35<00:35,  2.28it/s]\u001b[A\n","Iteration:  81% 342/422 [02:35<00:35,  2.28it/s]\u001b[A\n","Iteration:  81% 343/422 [02:36<00:34,  2.28it/s]\u001b[A\n","Iteration:  82% 344/422 [02:36<00:34,  2.28it/s]\u001b[A\n","Iteration:  82% 345/422 [02:37<00:33,  2.28it/s]\u001b[A\n","Iteration:  82% 346/422 [02:37<00:33,  2.28it/s]\u001b[A\n","Iteration:  82% 347/422 [02:38<00:32,  2.28it/s]\u001b[A\n","Iteration:  82% 348/422 [02:38<00:32,  2.28it/s]\u001b[A\n","Iteration:  83% 349/422 [02:39<00:31,  2.28it/s]\u001b[A\n","Iteration:  83% 350/422 [02:39<00:31,  2.28it/s]\u001b[A\n","Iteration:  83% 351/422 [02:39<00:31,  2.28it/s]\u001b[A\n","Iteration:  83% 352/422 [02:40<00:30,  2.28it/s]\u001b[A\n","Iteration:  84% 353/422 [02:40<00:30,  2.28it/s]\u001b[A\n","Iteration:  84% 354/422 [02:41<00:29,  2.28it/s]\u001b[A\n","Iteration:  84% 355/422 [02:41<00:29,  2.28it/s]\u001b[A\n","Iteration:  84% 356/422 [02:42<00:28,  2.28it/s]\u001b[A\n","Iteration:  85% 357/422 [02:42<00:28,  2.28it/s]\u001b[A\n","Iteration:  85% 358/422 [02:42<00:28,  2.28it/s]\u001b[A\n","Iteration:  85% 359/422 [02:43<00:27,  2.28it/s]\u001b[A\n","Iteration:  85% 360/422 [02:43<00:27,  2.28it/s]\u001b[A\n","Iteration:  86% 361/422 [02:44<00:26,  2.28it/s]\u001b[A\n","Iteration:  86% 362/422 [02:44<00:26,  2.28it/s]\u001b[A\n","Iteration:  86% 363/422 [02:45<00:25,  2.28it/s]\u001b[A\n","Iteration:  86% 364/422 [02:45<00:25,  2.28it/s]\u001b[A\n","Iteration:  86% 365/422 [02:46<00:25,  2.28it/s]\u001b[A\n","Iteration:  87% 366/422 [02:46<00:24,  2.28it/s]\u001b[A\n","Iteration:  87% 367/422 [02:46<00:24,  2.28it/s]\u001b[A\n","Iteration:  87% 368/422 [02:47<00:23,  2.28it/s]\u001b[A\n","Iteration:  87% 369/422 [02:47<00:23,  2.28it/s]\u001b[A\n","Iteration:  88% 370/422 [02:48<00:22,  2.28it/s]\u001b[A\n","Iteration:  88% 371/422 [02:48<00:22,  2.28it/s]\u001b[A\n","Iteration:  88% 372/422 [02:49<00:21,  2.28it/s]\u001b[A\n","Iteration:  88% 373/422 [02:49<00:21,  2.28it/s]\u001b[A\n","Iteration:  89% 374/422 [02:49<00:21,  2.28it/s]\u001b[A\n","Iteration:  89% 375/422 [02:50<00:20,  2.28it/s]\u001b[A\n","Iteration:  89% 376/422 [02:50<00:20,  2.28it/s]\u001b[A\n","Iteration:  89% 377/422 [02:51<00:19,  2.28it/s]\u001b[A\n","Iteration:  90% 378/422 [02:51<00:19,  2.28it/s]\u001b[A\n","Iteration:  90% 379/422 [02:52<00:18,  2.28it/s]\u001b[A\n","Iteration:  90% 380/422 [02:52<00:18,  2.28it/s]\u001b[A\n","Iteration:  90% 381/422 [02:53<00:17,  2.28it/s]\u001b[A\n","Iteration:  91% 382/422 [02:53<00:17,  2.28it/s]\u001b[A\n","Iteration:  91% 383/422 [02:53<00:17,  2.28it/s]\u001b[A\n","Iteration:  91% 384/422 [02:54<00:16,  2.28it/s]\u001b[A\n","Iteration:  91% 385/422 [02:54<00:16,  2.28it/s]\u001b[A\n","Iteration:  91% 386/422 [02:55<00:15,  2.28it/s]\u001b[A\n","Iteration:  92% 387/422 [02:55<00:15,  2.28it/s]\u001b[A\n","Iteration:  92% 388/422 [02:56<00:14,  2.28it/s]\u001b[A\n","Iteration:  92% 389/422 [02:56<00:14,  2.28it/s]\u001b[A\n","Iteration:  92% 390/422 [02:56<00:14,  2.28it/s]\u001b[A\n","Iteration:  93% 391/422 [02:57<00:13,  2.28it/s]\u001b[A\n","Iteration:  93% 392/422 [02:57<00:13,  2.28it/s]\u001b[A\n","Iteration:  93% 393/422 [02:58<00:12,  2.28it/s]\u001b[A\n","Iteration:  93% 394/422 [02:58<00:12,  2.28it/s]\u001b[A\n","Iteration:  94% 395/422 [02:59<00:11,  2.28it/s]\u001b[A\n","Iteration:  94% 396/422 [02:59<00:11,  2.28it/s]\u001b[A\n","Iteration:  94% 397/422 [03:00<00:10,  2.28it/s]\u001b[A\n","Iteration:  94% 398/422 [03:00<00:10,  2.28it/s]\u001b[A\n","Iteration:  95% 399/422 [03:00<00:10,  2.28it/s]\u001b[A\n","Iteration:  95% 400/422 [03:01<00:09,  2.28it/s]\u001b[A\n","Iteration:  95% 401/422 [03:01<00:09,  2.28it/s]\u001b[A\n","Iteration:  95% 402/422 [03:02<00:08,  2.28it/s]\u001b[A\n","Iteration:  95% 403/422 [03:02<00:08,  2.28it/s]\u001b[A\n","Iteration:  96% 404/422 [03:03<00:07,  2.28it/s]\u001b[A\n","Iteration:  96% 405/422 [03:03<00:07,  2.28it/s]\u001b[A\n","Iteration:  96% 406/422 [03:03<00:07,  2.28it/s]\u001b[A\n","Iteration:  96% 407/422 [03:04<00:06,  2.28it/s]\u001b[A\n","Iteration:  97% 408/422 [03:04<00:06,  2.28it/s]\u001b[A\n","Iteration:  97% 409/422 [03:05<00:05,  2.28it/s]\u001b[A\n","Iteration:  97% 410/422 [03:05<00:05,  2.28it/s]\u001b[A\n","Iteration:  97% 411/422 [03:06<00:04,  2.28it/s]\u001b[A\n","Iteration:  98% 412/422 [03:06<00:04,  2.28it/s]\u001b[A\n","Iteration:  98% 413/422 [03:07<00:03,  2.28it/s]\u001b[A\n","Iteration:  98% 414/422 [03:07<00:03,  2.28it/s]\u001b[A\n","Iteration:  98% 415/422 [03:07<00:03,  2.28it/s]\u001b[A\n","Iteration:  99% 416/422 [03:08<00:02,  2.28it/s]\u001b[A\n","Iteration:  99% 417/422 [03:08<00:02,  2.28it/s]\u001b[A\n","Iteration:  99% 418/422 [03:09<00:01,  2.28it/s]\u001b[A\n","Iteration:  99% 419/422 [03:09<00:01,  2.28it/s]\u001b[A\n","Iteration: 100% 420/422 [03:10<00:00,  2.28it/s]\u001b[A\n","Iteration: 100% 421/422 [03:10<00:00,  2.28it/s]\u001b[A\n","Iteration: 100% 422/422 [03:11<00:00,  2.21it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-18 05:08:30,253][__main__][DEBUG] - early stop\n","Epoch:   1% 1/100 [12:29<20:36:15, 749.25s/it]\n"]}],"source":["!HYDRA_FULL_ERROR=1 python run.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"w7sdHHb0uFV-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660801678422,"user_tz":-540,"elapsed":2229252,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"726a6c6f-2907-4a22-899f-b4d4e2fedb77"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","eval.py:21: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-18 05:08:45,143][HYDRA] Hydra 1.2.0\n","[2022-08-18 05:08:45,144][HYDRA] ===========\n","[2022-08-18 05:08:45,144][HYDRA] Installed Hydra Plugins\n","[2022-08-18 05:08:45,144][HYDRA] ***********************\n","[2022-08-18 05:08:45,144][HYDRA] \tConfigSource:\n","[2022-08-18 05:08:45,144][HYDRA] \t-------------\n","[2022-08-18 05:08:45,144][HYDRA] \t\tFileConfigSource\n","[2022-08-18 05:08:45,144][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-18 05:08:45,144][HYDRA] \t\tStructuredConfigSource\n","[2022-08-18 05:08:45,144][HYDRA] \tCompletionPlugin:\n","[2022-08-18 05:08:45,144][HYDRA] \t-----------------\n","[2022-08-18 05:08:45,144][HYDRA] \t\tBashCompletion\n","[2022-08-18 05:08:45,144][HYDRA] \t\tFishCompletion\n","[2022-08-18 05:08:45,144][HYDRA] \t\tZshCompletion\n","[2022-08-18 05:08:45,144][HYDRA] \tLauncher:\n","[2022-08-18 05:08:45,144][HYDRA] \t---------\n","[2022-08-18 05:08:45,144][HYDRA] \t\tBasicLauncher\n","[2022-08-18 05:08:45,144][HYDRA] \tSweeper:\n","[2022-08-18 05:08:45,144][HYDRA] \t--------\n","[2022-08-18 05:08:45,144][HYDRA] \t\tBasicSweeper\n","[2022-08-18 05:08:45,144][HYDRA] \n","[2022-08-18 05:08:45,144][HYDRA] Config search path\n","[2022-08-18 05:08:45,144][HYDRA] ******************\n","[2022-08-18 05:08:45,418][HYDRA] | Provider | Search path                                                           |\n","[2022-08-18 05:08:45,418][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-18 05:08:45,419][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-18 05:08:45,419][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-18 05:08:45,419][HYDRA] | schema   | structured://                                                         |\n","[2022-08-18 05:08:45,419][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-18 05:08:45,488][HYDRA] \n","[2022-08-18 05:08:45,488][HYDRA] Defaults Tree\n","[2022-08-18 05:08:45,488][HYDRA] *************\n","[2022-08-18 05:08:45,488][HYDRA] <root>:\n","[2022-08-18 05:08:45,488][HYDRA]   hydra/config:\n","[2022-08-18 05:08:45,488][HYDRA]     hydra/output: default\n","[2022-08-18 05:08:45,488][HYDRA]     hydra/launcher: basic\n","[2022-08-18 05:08:45,488][HYDRA]     hydra/sweeper: basic\n","[2022-08-18 05:08:45,488][HYDRA]     hydra/help: default\n","[2022-08-18 05:08:45,488][HYDRA]     hydra/hydra_help: default\n","[2022-08-18 05:08:45,488][HYDRA]     hydra/hydra_logging: default\n","[2022-08-18 05:08:45,488][HYDRA]     hydra/job_logging: default\n","[2022-08-18 05:08:45,488][HYDRA]     hydra/callbacks: null\n","[2022-08-18 05:08:45,488][HYDRA]     hydra/env: default\n","[2022-08-18 05:08:45,488][HYDRA]     _self_\n","[2022-08-18 05:08:45,488][HYDRA]   config:\n","[2022-08-18 05:08:45,489][HYDRA]     data/YAGO43kET\n","[2022-08-18 05:08:45,489][HYDRA]     model/T5\n","[2022-08-18 05:08:45,489][HYDRA]     _self_\n","[2022-08-18 05:08:45,556][HYDRA] \n","[2022-08-18 05:08:45,556][HYDRA] Defaults List\n","[2022-08-18 05:08:45,556][HYDRA] *************\n","[2022-08-18 05:08:45,556][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-18 05:08:45,557][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-18 05:08:45,557][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-18 05:08:45,557][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-18 05:08:45,557][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-18 05:08:45,557][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-18 05:08:45,557][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-18 05:08:45,557][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-18 05:08:45,557][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-18 05:08:45,557][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-18 05:08:45,557][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-18 05:08:45,557][HYDRA] | data/YAGO43kET              | data                | False  | config       |\n","[2022-08-18 05:08:45,557][HYDRA] | model/T5                    | model               | False  | config       |\n","[2022-08-18 05:08:45,557][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-18 05:08:45,557][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-18 05:08:45,669][HYDRA] Config\n","[2022-08-18 05:08:45,669][HYDRA] ******\n","[2022-08-18 05:08:45,672][HYDRA] data:\n","  name: YAGO43kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  lowest_level: false\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: T5\n","  train_dataset: ET_1_1_train.txt\n","  pretrained_model: t5-base\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 128\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_1_1_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 128\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_1_1_test.txt\n","    unobserved_test_dataset: ET_1_1_unobserved_type_test.txt\n","    save_outputs: true\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: ''\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-18 05:08:45,741][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:08:45,741 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:08:46,041][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 0\n","2022-08-18 05:08:46,041 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 0\n","[2022-08-18 05:08:46,043][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","2022-08-18 05:08:46,043 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","tcmalloc: large alloc 8591564800 bytes == 0x7feb8fe72000 @  0x7fef2e7a6b6b 0x7fef2e7c6379 0x7fee7763526e 0x7fee776369e2 0x7fee789b1e19 0x7fee789b2b67 0x7fee78d8f059 0x7fee794f3e6a 0x7fee794d6f8e 0x7fee790dbcd5 0x7fee78d930c0 0x7fee79665e64 0x7fee794c3ec4 0x7fee794da287 0x7fee79135441 0x7fef1c0a4d25 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x593fce 0x5118f8 0x4bc98a 0x532c1b 0x594a96 0x515600 0x593dd7 0x5118f8 0x549576\n","tcmalloc: large alloc 8591564800 bytes == 0x7fe98f0a4000 @  0x7fef2e7a6b6b 0x7fef2e7c6379 0x7fee7763526e 0x7fee776369e2 0x7fee789b1e19 0x7fee789b2b67 0x7fee78d8f059 0x7fee794f3e6a 0x7fee794d6f8e 0x7fee790dbcd5 0x7fee78d930c0 0x7fee79665e64 0x7fee794c3ec4 0x7fee794da287 0x7fee79135441 0x7fef1c0a4d25 0x593784 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549576 0x593fce 0x5118f8 0x4bc98a 0x532c1b 0x594a96 0x515600 0x593dd7 0x5118f8 0x549576\n","[2022-08-18 05:08:51,589][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:08:51,589 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:08:51,885][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 0\n","2022-08-18 05:08:51,885 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 0\n","[2022-08-18 05:08:51,887][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","2022-08-18 05:08:51,887 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-18 05:08:51,888][transformers.configuration_utils][INFO] - Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","2022-08-18 05:08:51,888 INFO     Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[2022-08-18 05:08:51,890][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-18 05:08:51,890 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-18 05:08:51,995][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /t5-base-pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-18 05:08:51,995 DEBUG    https://cdn.huggingface.co:443 \"HEAD /t5-base-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-18 05:08:51,997][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","2022-08-18 05:08:51,997 INFO     loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-18 05:09:01,381][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","2022-08-18 05:09:01,381 INFO     All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","[2022-08-18 05:09:01,382][transformers.modeling_utils][WARNING] - Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2022-08-18 05:09:01,382 WARNING  Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[2022-08-18 05:09:06,828][root][DEBUG] - Parameter model.shared.weight: torch.Size([32128, 768]), require_grad=True\n","2022-08-18 05:09:06,828 DEBUG    Parameter model.shared.weight: torch.Size([32128, 768]), require_grad=True\n","[2022-08-18 05:09:06,828][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,828 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,829][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,829 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,829][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,829 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,829][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,829 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,829][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","2022-08-18 05:09:06,829 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-18 05:09:06,829][root][DEBUG] - Parameter model.encoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,829 DEBUG    Parameter model.encoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,830][root][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,830 DEBUG    Parameter model.encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,830][root][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,830 DEBUG    Parameter model.encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,830][root][DEBUG] - Parameter model.encoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,830 DEBUG    Parameter model.encoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,830][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,830 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,831][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,831 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,831][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,831 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,831][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,831 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,832][root][DEBUG] - Parameter model.encoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,832 DEBUG    Parameter model.encoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,832][root][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,832 DEBUG    Parameter model.encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,832][root][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,832 DEBUG    Parameter model.encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,832][root][DEBUG] - Parameter model.encoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,832 DEBUG    Parameter model.encoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,832][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,832 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,833][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,833 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,833][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,833 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,833][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,833 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,833][root][DEBUG] - Parameter model.encoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,833 DEBUG    Parameter model.encoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,834][root][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,834 DEBUG    Parameter model.encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,834][root][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,834 DEBUG    Parameter model.encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,834][root][DEBUG] - Parameter model.encoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,834 DEBUG    Parameter model.encoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,834][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,834 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,834][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,834 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,835][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,835 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,835][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,835 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,835][root][DEBUG] - Parameter model.encoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,835 DEBUG    Parameter model.encoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,835][root][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,835 DEBUG    Parameter model.encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,835][root][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,835 DEBUG    Parameter model.encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,836][root][DEBUG] - Parameter model.encoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,836 DEBUG    Parameter model.encoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,836][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,836 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,836][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,836 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,836][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,836 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,836][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,836 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,837][root][DEBUG] - Parameter model.encoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,837 DEBUG    Parameter model.encoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,837][root][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,837 DEBUG    Parameter model.encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,837][root][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,837 DEBUG    Parameter model.encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,837][root][DEBUG] - Parameter model.encoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,837 DEBUG    Parameter model.encoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,837][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,837 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,838][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,838 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,838][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,838 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,838][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,838 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,838][root][DEBUG] - Parameter model.encoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,838 DEBUG    Parameter model.encoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,838][root][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,838 DEBUG    Parameter model.encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,839][root][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,839 DEBUG    Parameter model.encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,839][root][DEBUG] - Parameter model.encoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,839 DEBUG    Parameter model.encoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,839][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,839 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,839][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,839 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,839][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,839 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,839][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,839 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,840][root][DEBUG] - Parameter model.encoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,840 DEBUG    Parameter model.encoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,840][root][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,840 DEBUG    Parameter model.encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,840][root][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,840 DEBUG    Parameter model.encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,840][root][DEBUG] - Parameter model.encoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,840 DEBUG    Parameter model.encoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,840][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,840 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,841][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,841 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,841][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,841 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,841][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,841 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,924][root][DEBUG] - Parameter model.encoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,924 DEBUG    Parameter model.encoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,924][root][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,924 DEBUG    Parameter model.encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,924][root][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,924 DEBUG    Parameter model.encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,924][root][DEBUG] - Parameter model.encoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,924 DEBUG    Parameter model.encoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,925][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,925 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,925][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,925 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,925][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,925 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,925][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,925 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,925][root][DEBUG] - Parameter model.encoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,925 DEBUG    Parameter model.encoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,925][root][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,925 DEBUG    Parameter model.encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,925][root][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,925 DEBUG    Parameter model.encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,925][root][DEBUG] - Parameter model.encoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,925 DEBUG    Parameter model.encoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,926][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,926 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,926][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,926 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,926][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,926 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,926][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,926 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,926][root][DEBUG] - Parameter model.encoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,926 DEBUG    Parameter model.encoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,927][root][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,927 DEBUG    Parameter model.encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,927][root][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,927 DEBUG    Parameter model.encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,927][root][DEBUG] - Parameter model.encoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,927 DEBUG    Parameter model.encoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,927][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,927 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,927][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,927 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,928][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,928 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,928][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,928 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,928][root][DEBUG] - Parameter model.encoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,928 DEBUG    Parameter model.encoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,928][root][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,928 DEBUG    Parameter model.encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,929][root][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,929 DEBUG    Parameter model.encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,929][root][DEBUG] - Parameter model.encoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,929 DEBUG    Parameter model.encoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,929][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,929 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,929][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,929 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,930][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,930 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,930][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,930 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,930][root][DEBUG] - Parameter model.encoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,930 DEBUG    Parameter model.encoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,930][root][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,930 DEBUG    Parameter model.encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,931][root][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,931 DEBUG    Parameter model.encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,931][root][DEBUG] - Parameter model.encoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,931 DEBUG    Parameter model.encoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,931][root][DEBUG] - Parameter model.encoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,931 DEBUG    Parameter model.encoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,931][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,931 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,932][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,932 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,932][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,932 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,932][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,932 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,932][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","2022-08-18 05:09:06,932 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-18 05:09:06,932][root][DEBUG] - Parameter model.decoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,932 DEBUG    Parameter model.decoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,933][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,933 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,933][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,933 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,933][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,933 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,933][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,933 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,934][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","2022-08-18 05:09:06,934 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-18 05:09:06,934][root][DEBUG] - Parameter model.decoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,934 DEBUG    Parameter model.decoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,934][root][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,934 DEBUG    Parameter model.decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,934][root][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,934 DEBUG    Parameter model.decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,935][root][DEBUG] - Parameter model.decoder.block.0.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,935 DEBUG    Parameter model.decoder.block.0.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,935][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,935 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,935][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,935 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,935][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,935 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,935][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,935 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,936][root][DEBUG] - Parameter model.decoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,936 DEBUG    Parameter model.decoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,936][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,936 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,936][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,936 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,936][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,936 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,936][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,936 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,937][root][DEBUG] - Parameter model.decoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,937 DEBUG    Parameter model.decoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,937][root][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,937 DEBUG    Parameter model.decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,937][root][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,937 DEBUG    Parameter model.decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,937][root][DEBUG] - Parameter model.decoder.block.1.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,937 DEBUG    Parameter model.decoder.block.1.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,938][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,938 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,938][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,938 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,938][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,938 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,938][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,938 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,938][root][DEBUG] - Parameter model.decoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,938 DEBUG    Parameter model.decoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,939][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,939 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,939][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,939 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,939][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,939 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,939][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,939 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,939][root][DEBUG] - Parameter model.decoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,939 DEBUG    Parameter model.decoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,940][root][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,940 DEBUG    Parameter model.decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,940][root][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,940 DEBUG    Parameter model.decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,940][root][DEBUG] - Parameter model.decoder.block.2.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,940 DEBUG    Parameter model.decoder.block.2.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,940][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,940 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,940][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,940 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,941][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,941 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,941][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,941 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,941][root][DEBUG] - Parameter model.decoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,941 DEBUG    Parameter model.decoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,941][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,941 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,941][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,941 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,942][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,942 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,942][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,942 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,942][root][DEBUG] - Parameter model.decoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,942 DEBUG    Parameter model.decoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,942][root][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,942 DEBUG    Parameter model.decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,942][root][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,942 DEBUG    Parameter model.decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,943][root][DEBUG] - Parameter model.decoder.block.3.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,943 DEBUG    Parameter model.decoder.block.3.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,943][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,943 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,943][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,943 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,943][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,943 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,943][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,943 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,944][root][DEBUG] - Parameter model.decoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,944 DEBUG    Parameter model.decoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,944][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,944 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,944][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,944 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,944][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,944 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,944][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,944 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,945][root][DEBUG] - Parameter model.decoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,945 DEBUG    Parameter model.decoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,945][root][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,945 DEBUG    Parameter model.decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,945][root][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,945 DEBUG    Parameter model.decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,945][root][DEBUG] - Parameter model.decoder.block.4.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,945 DEBUG    Parameter model.decoder.block.4.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,946][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,946 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,946][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,946 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,946][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,946 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,946][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,946 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,946][root][DEBUG] - Parameter model.decoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,946 DEBUG    Parameter model.decoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,947][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,947 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,947][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,947 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,947][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,947 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,947][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,947 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,947][root][DEBUG] - Parameter model.decoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,947 DEBUG    Parameter model.decoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,948][root][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,948 DEBUG    Parameter model.decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,948][root][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,948 DEBUG    Parameter model.decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,948][root][DEBUG] - Parameter model.decoder.block.5.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,948 DEBUG    Parameter model.decoder.block.5.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,948][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,948 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,948][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,948 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,949][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,949 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,949][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,949 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,949][root][DEBUG] - Parameter model.decoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,949 DEBUG    Parameter model.decoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,949][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,949 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,949][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,949 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,950][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,950 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,950][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,950 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,950][root][DEBUG] - Parameter model.decoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,950 DEBUG    Parameter model.decoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,950][root][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,950 DEBUG    Parameter model.decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,950][root][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,950 DEBUG    Parameter model.decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,951][root][DEBUG] - Parameter model.decoder.block.6.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,951 DEBUG    Parameter model.decoder.block.6.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,951][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,951 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,951][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,951 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,951][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,951 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,951][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,951 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,952][root][DEBUG] - Parameter model.decoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,952 DEBUG    Parameter model.decoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,952][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,952 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,952][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,952 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,952][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,952 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,952][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,952 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,953][root][DEBUG] - Parameter model.decoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,953 DEBUG    Parameter model.decoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,953][root][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,953 DEBUG    Parameter model.decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,953][root][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,953 DEBUG    Parameter model.decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,953][root][DEBUG] - Parameter model.decoder.block.7.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,953 DEBUG    Parameter model.decoder.block.7.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,954][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,954 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,954][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,954 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,954][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,954 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,954][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,954 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,955][root][DEBUG] - Parameter model.decoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,955 DEBUG    Parameter model.decoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,955][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,955 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,955][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,955 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,955][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,955 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,955][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,955 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,956][root][DEBUG] - Parameter model.decoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,956 DEBUG    Parameter model.decoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,956][root][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,956 DEBUG    Parameter model.decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,956][root][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,956 DEBUG    Parameter model.decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,956][root][DEBUG] - Parameter model.decoder.block.8.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,956 DEBUG    Parameter model.decoder.block.8.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,956][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,956 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,957][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,957 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,957][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,957 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,957][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,957 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,957][root][DEBUG] - Parameter model.decoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,957 DEBUG    Parameter model.decoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,957][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,957 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,958][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,958 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,958][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,958 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,958][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,958 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,958][root][DEBUG] - Parameter model.decoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,958 DEBUG    Parameter model.decoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,958][root][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,958 DEBUG    Parameter model.decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,959][root][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,959 DEBUG    Parameter model.decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,959][root][DEBUG] - Parameter model.decoder.block.9.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,959 DEBUG    Parameter model.decoder.block.9.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,959][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,959 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,959][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,959 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,959][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,959 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,959][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,959 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,960][root][DEBUG] - Parameter model.decoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,960 DEBUG    Parameter model.decoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,960][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,960 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,960][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,960 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,960][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,960 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,960][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,960 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,960][root][DEBUG] - Parameter model.decoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,960 DEBUG    Parameter model.decoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,960][root][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,960 DEBUG    Parameter model.decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,960][root][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,960 DEBUG    Parameter model.decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,960][root][DEBUG] - Parameter model.decoder.block.10.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,960 DEBUG    Parameter model.decoder.block.10.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-18 05:09:06,961][root][DEBUG] - Parameter model.decoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,961 DEBUG    Parameter model.decoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,962][root][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-18 05:09:06,962 DEBUG    Parameter model.decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-18 05:09:06,962][root][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-18 05:09:06,962 DEBUG    Parameter model.decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-18 05:09:06,962][root][DEBUG] - Parameter model.decoder.block.11.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,962 DEBUG    Parameter model.decoder.block.11.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-18 05:09:06,962][root][DEBUG] - Parameter model.decoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-18 05:09:06,962 DEBUG    Parameter model.decoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","Iteration:   0% 0/1400 [00:00<?, ?it/s]The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","Iteration: 100% 1400/1400 [29:59<00:00,  1.29s/it]\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","[2022-08-18 05:39:14,257][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:39:14,257 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:39:14,540][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-18 05:39:14,540 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-18 05:39:14,544][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-18 05:39:14,544 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-18 05:39:14,545][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-18 05:39:14,545 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-18 05:39:14,546][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:39:14,546 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:39:14,838][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","2022-08-18 05:39:14,838 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-18 05:39:14,841][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:39:14,841 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:39:15,121][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","2022-08-18 05:39:15,121 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-18 05:39:15,122][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-18 05:39:15,122 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-18 05:39:15,123][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-18 05:39:15,123 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-18 05:39:15,210][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:39:15,210 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:39:15,477][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-18 05:39:15,477 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-18 05:39:15,479][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-18 05:39:15,479 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-18 05:39:15,479][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-18 05:39:15,479 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-18 05:39:15,481][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-18 05:39:15,481 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-18 05:39:15,637][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-18 05:39:15,637 DEBUG    https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-18 05:39:15,638][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","2022-08-18 05:39:15,638 INFO     loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","[2022-08-18 05:39:31,175][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing RobertaModel.\n","\n","2022-08-18 05:39:31,175 INFO     All model checkpoint weights were used when initializing RobertaModel.\n","\n","[2022-08-18 05:39:31,175][transformers.modeling_utils][INFO] - All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","2022-08-18 05:39:31,175 INFO     All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","calculating scores...\n","computing bert embedding.\n","100% 107/107 [00:10<00:00, 10.56it/s]\n","computing greedy matching.\n","100% 175/175 [00:01<00:00, 113.54it/s]\n","done in 11.71 seconds, 955.60 sentences/sec\n","[2022-08-18 05:39:43,297][root][INFO] - test data set : ET_1_1_test.txt\n","2022-08-18 05:39:43,297 INFO     test data set : ET_1_1_test.txt\n","[2022-08-18 05:39:43,297][root][INFO] - N-grams: 1-0.2591697514109031, 2-0.09489979987531325, 3-0.07758190761129395, 4-0.05804792689052344\n","2022-08-18 05:39:43,297 INFO     N-grams: 1-0.2591697514109031, 2-0.09489979987531325, 3-0.07758190761129395, 4-0.05804792689052344\n","[2022-08-18 05:39:43,297][root][INFO] - BERT-P:0.889310, BERT-R:0.881346, BERT-F1:0.885159\n","2022-08-18 05:39:43,297 INFO     BERT-P:0.889310, BERT-R:0.881346, BERT-F1:0.885159\n","Iteration:   0% 0/257 [00:00<?, ?it/s]The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","Iteration: 100% 257/257 [05:29<00:00,  1.28s/it]\n","[2022-08-18 05:45:13,377][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:45:13,377 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:45:13,701][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-18 05:45:13,701 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-18 05:45:13,703][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-18 05:45:13,703 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-18 05:45:13,704][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-18 05:45:13,704 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-18 05:45:13,705][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:45:13,705 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:45:13,977][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","2022-08-18 05:45:13,977 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-18 05:45:13,981][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:45:13,981 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:45:14,264][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","2022-08-18 05:45:14,264 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-18 05:45:14,266][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-18 05:45:14,266 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-18 05:45:14,267][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-18 05:45:14,267 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-18 05:45:14,348][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-18 05:45:14,348 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-18 05:45:14,631][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-18 05:45:14,631 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-18 05:45:14,633][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-18 05:45:14,633 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-18 05:45:14,633][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-18 05:45:14,633 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-18 05:45:14,635][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-18 05:45:14,635 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-18 05:45:14,725][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-18 05:45:14,725 DEBUG    https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-18 05:45:14,726][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","2022-08-18 05:45:14,726 INFO     loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","[2022-08-18 05:45:30,413][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing RobertaModel.\n","\n","2022-08-18 05:45:30,413 INFO     All model checkpoint weights were used when initializing RobertaModel.\n","\n","[2022-08-18 05:45:30,465][transformers.modeling_utils][INFO] - All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","2022-08-18 05:45:30,465 INFO     All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","calculating scores...\n","computing bert embedding.\n","100% 44/44 [00:04<00:00,  9.07it/s]\n","computing greedy matching.\n","100% 33/33 [00:00<00:00, 103.95it/s]\n","done in 5.28 seconds, 388.86 sentences/sec\n","[2022-08-18 05:45:36,262][root][INFO] - test data set : ET_1_1_test.txt\n","2022-08-18 05:45:36,262 INFO     test data set : ET_1_1_test.txt\n","[2022-08-18 05:45:36,263][root][INFO] - N-grams: 1-0.20602429590248203, 2-0.03160816833932641, 3-0.015580199192120926, 4-0.005042326620797772\n","2022-08-18 05:45:36,263 INFO     N-grams: 1-0.20602429590248203, 2-0.03160816833932641, 3-0.015580199192120926, 4-0.005042326620797772\n","[2022-08-18 05:45:36,263][root][INFO] - BERT-P:0.890293, BERT-R:0.872512, BERT-F1:0.881136\n","2022-08-18 05:45:36,263 INFO     BERT-P:0.890293, BERT-R:0.872512, BERT-F1:0.881136\n"]}],"source":["!HYDRA_FULL_ERROR=1 python eval.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiRHm4nruPw9"},"outputs":[],"source":["!kill $(ps aux | awk '{print $2}')"]},{"cell_type":"code","source":[""],"metadata":{"id":"WPTZiAzwc_WZ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"cmd_train.ipynb","provenance":[],"mount_file_id":"1Mrwlgkjv2G7LOLpOtCehzWxaTRu9sXPA","authorship_tag":"ABX9TyM2dd7XQjK7MtzbhdCWkdas"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}