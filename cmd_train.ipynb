{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1660605939985,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"dymDs0Po0aES","outputId":"63a0df44-dcb4-42dc-c73b-3371a3644a55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Aug 15 23:23:23 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1181,"status":"ok","timestamp":1660605941153,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"EfCxDoEXuzgg","outputId":"21a4bc91-9935-44e8-e288-bba5a39b4408"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","source":["!python -m pip install bert-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bOeGCnRF9Cs","executionInfo":{"status":"ok","timestamp":1660605952113,"user_tz":-540,"elapsed":10965,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"46408f12-ce58-43c1-9e45-e5d8ca08ef53"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bert-score\n","  Downloading bert_score-0.3.11-py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert-score) (3.2.2)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.12.1+cu113)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.3.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert-score) (2.23.0)\n","Collecting transformers>=3.0.0numpy\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (4.64.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert-score) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert-score) (3.0.9)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert-score) (4.1.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 58.7 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 88.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (3.8.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert-score) (3.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (0.11.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, bert-score\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed bert-score-0.3.11 huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":454813,"status":"ok","timestamp":1660606406914,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"mshVPsrku0kd","outputId":"d4846a78-1486-4d61-f40f-3d60cf61da3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 12 kB/s \n","\u001b[?25hCollecting transformers==3.0.0\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[K     |████████████████████████████████| 754 kB 73.6 MB/s \n","\u001b[?25hCollecting torch_scatter==2.0.4\n","  Downloading torch_scatter-2.0.4.tar.gz (20 kB)\n","Collecting dgl==0.5.3\n","  Downloading dgl-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 24.4 MB/s \n","\u001b[?25hCollecting hydra==2.4\n","  Downloading Hydra-2.4.tar.gz (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 10.3 MB/s \n","\u001b[?25hCollecting omegaconf==2.2.2\n","  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 74.8 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 49.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2.23.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 66.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (4.64.0)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (2.6.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (1.7.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.2.2->-r requirements.txt (line 7)) (6.0)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 70.6 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.1.0)\n","Building wheels for collected packages: torch-scatter, hydra, antlr4-python3-runtime, sacremoses\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-scatter: filename=torch_scatter-2.0.4-cp37-cp37m-linux_x86_64.whl size=14800807 sha256=a0dcf4426e4a519052ff72cc63d97b24b2c3e261fd5fb16410fa3b23e2244cae\n","  Stored in directory: /root/.cache/pip/wheels/4a/3d/01/e408ecc11389070cbacee91b70c978bf3557130e9aaa18a95b\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.4-cp37-cp37m-linux_x86_64.whl size=219229 sha256=a8a35949c6c4e97162c9d9279dcea08203a3ae7cf6f4fb2cc5aba6e652d86504\n","  Stored in directory: /root/.cache/pip/wheels/f5/65/98/3603b340344bd22dfe1c809365013fc4d425d83d89c3e2cd17\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=d54239df8917376b51b3596003db065356d440c3b3e01be6c9497548236596b0\n","  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=0b3ccfb78d64b1767f0896c4cc0331572360108e4b0fdeb7ec0a692c071946d8\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built torch-scatter hydra antlr4-python3-runtime sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, antlr4-python3-runtime, transformers, torch-scatter, torch, omegaconf, hydra, dgl\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.21.1\n","    Uninstalling transformers-4.21.1:\n","      Successfully uninstalled transformers-4.21.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed antlr4-python3-runtime-4.9.3 dgl-0.5.3 hydra-2.4 omegaconf-2.2.2 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.0rc4 torch-1.8.0 torch-scatter-2.0.4 transformers-3.0.0\n"]}],"source":["!python -m pip install -r requirements.txt"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164927,"status":"ok","timestamp":1660606571818,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"G8LmQt_jcvSZ","outputId":"720e732b-c459-4097-89d2-bd70d5f6518f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 1.6 MB/s eta 0:12:17tcmalloc: large alloc 1147494400 bytes == 0x39568000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████▌               | 1055.7 MB 65.8 MB/s eta 0:00:15tcmalloc: large alloc 1434370048 bytes == 0x7dbbe000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.7 MB/s eta 0:06:57tcmalloc: large alloc 1792966656 bytes == 0x29f0000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 2.2 MB/s eta 0:02:40tcmalloc: large alloc 2241208320 bytes == 0x6d7d8000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf313a000 @  0x7f247bed71e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2551685120 bytes == 0x1e10a8000 @  0x7f247bed8615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 2041.3 MB 7.2 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 1.2 MB/s \n","\u001b[?25hCollecting torchaudio===0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.8.0\n","    Uninstalling torch-1.8.0:\n","      Successfully uninstalled torch-1.8.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}],"source":["!python -m pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":567,"status":"ok","timestamp":1660606572363,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"JJqgY88ou7Qp","outputId":"b395ab72-6a7a-45c9-bb30-b7aab8ff9fe1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch-scatter 2.0.4\n","Uninstalling torch-scatter-2.0.4:\n","  Successfully uninstalled torch-scatter-2.0.4\n"]}],"source":["!python -m pip uninstall torch-scatter -y"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6155,"status":"ok","timestamp":1660606578513,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"7c7V5B7yc9Cc","outputId":"a9318985-21c4-48c9-ffb6-d427430cf38b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 4.0 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.9\n"]}],"source":["!python -m pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":586,"status":"ok","timestamp":1660606579087,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"l2wm30u-c-i0","outputId":"5824397c-a614-4e58-8428-3ebd7c852bab"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.9\n"]}],"source":["!python -c \"import torch_scatter; print(torch_scatter.__version__)\""]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3259,"status":"ok","timestamp":1660606582334,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"GgPMOQSL4HVZ","outputId":"e7850895-c35f-448e-ff7e-b39c20934720"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.9.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.2.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core) (21.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core) (3.0.9)\n","Installing collected packages: hydra-core\n","Successfully installed hydra-core-1.2.0\n"]}],"source":["!pip install hydra-core --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1660203016899,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"FT5vluqcNpey","outputId":"fb6b583e-b039-4cef-cbf9-2bf97cee58d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZROa2w4NUfm"},"outputs":[],"source":["!python preprocess.py --dataset FB15kET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDB7erFzN4St"},"outputs":[],"source":["!python preprocess.py --dataset YAGO43kET"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":766,"status":"ok","timestamp":1660624992129,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"hsnRA4_pUSzk","outputId":"8bd43959-1698-48e4-c4a0-edde8ed009c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"586hjT34u-VB","outputId":"2fe64c4f-60a9-432f-ce21-4f280bec52d1","executionInfo":{"status":"ok","timestamp":1660628489730,"user_tz":-540,"elapsed":3496756,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","run.py:18: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-16 04:41:03,796][HYDRA] Hydra 1.2.0\n","[2022-08-16 04:41:03,796][HYDRA] ===========\n","[2022-08-16 04:41:03,796][HYDRA] Installed Hydra Plugins\n","[2022-08-16 04:41:03,797][HYDRA] ***********************\n","[2022-08-16 04:41:03,797][HYDRA] \tConfigSource:\n","[2022-08-16 04:41:03,797][HYDRA] \t-------------\n","[2022-08-16 04:41:03,797][HYDRA] \t\tFileConfigSource\n","[2022-08-16 04:41:03,797][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-16 04:41:03,797][HYDRA] \t\tStructuredConfigSource\n","[2022-08-16 04:41:03,797][HYDRA] \tCompletionPlugin:\n","[2022-08-16 04:41:03,797][HYDRA] \t-----------------\n","[2022-08-16 04:41:03,797][HYDRA] \t\tBashCompletion\n","[2022-08-16 04:41:03,797][HYDRA] \t\tFishCompletion\n","[2022-08-16 04:41:03,797][HYDRA] \t\tZshCompletion\n","[2022-08-16 04:41:03,797][HYDRA] \tLauncher:\n","[2022-08-16 04:41:03,797][HYDRA] \t---------\n","[2022-08-16 04:41:03,797][HYDRA] \t\tBasicLauncher\n","[2022-08-16 04:41:03,797][HYDRA] \tSweeper:\n","[2022-08-16 04:41:03,797][HYDRA] \t--------\n","[2022-08-16 04:41:03,797][HYDRA] \t\tBasicSweeper\n","[2022-08-16 04:41:03,797][HYDRA] \n","[2022-08-16 04:41:03,797][HYDRA] Config search path\n","[2022-08-16 04:41:03,797][HYDRA] ******************\n","[2022-08-16 04:41:03,925][HYDRA] | Provider | Search path                                                           |\n","[2022-08-16 04:41:03,925][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-16 04:41:03,925][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-16 04:41:03,925][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-16 04:41:03,926][HYDRA] | schema   | structured://                                                         |\n","[2022-08-16 04:41:03,926][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-16 04:41:03,998][HYDRA] \n","[2022-08-16 04:41:03,998][HYDRA] Defaults Tree\n","[2022-08-16 04:41:03,998][HYDRA] *************\n","[2022-08-16 04:41:03,998][HYDRA] <root>:\n","[2022-08-16 04:41:03,998][HYDRA]   hydra/config:\n","[2022-08-16 04:41:03,998][HYDRA]     hydra/output: default\n","[2022-08-16 04:41:03,998][HYDRA]     hydra/launcher: basic\n","[2022-08-16 04:41:03,998][HYDRA]     hydra/sweeper: basic\n","[2022-08-16 04:41:03,999][HYDRA]     hydra/help: default\n","[2022-08-16 04:41:03,999][HYDRA]     hydra/hydra_help: default\n","[2022-08-16 04:41:03,999][HYDRA]     hydra/hydra_logging: default\n","[2022-08-16 04:41:03,999][HYDRA]     hydra/job_logging: default\n","[2022-08-16 04:41:03,999][HYDRA]     hydra/callbacks: null\n","[2022-08-16 04:41:03,999][HYDRA]     hydra/env: default\n","[2022-08-16 04:41:03,999][HYDRA]     _self_\n","[2022-08-16 04:41:03,999][HYDRA]   config:\n","[2022-08-16 04:41:03,999][HYDRA]     data/FB15kET\n","[2022-08-16 04:41:03,999][HYDRA]     model/T5\n","[2022-08-16 04:41:03,999][HYDRA]     _self_\n","[2022-08-16 04:41:04,069][HYDRA] \n","[2022-08-16 04:41:04,069][HYDRA] Defaults List\n","[2022-08-16 04:41:04,069][HYDRA] *************\n","[2022-08-16 04:41:04,069][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-16 04:41:04,069][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-16 04:41:04,070][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-16 04:41:04,070][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-16 04:41:04,070][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-16 04:41:04,070][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-16 04:41:04,070][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-16 04:41:04,070][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-16 04:41:04,070][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-16 04:41:04,070][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-16 04:41:04,070][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-16 04:41:04,070][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-08-16 04:41:04,070][HYDRA] | model/T5                    | model               | False  | config       |\n","[2022-08-16 04:41:04,070][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-16 04:41:04,070][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-16 04:41:04,189][HYDRA] Config\n","[2022-08-16 04:41:04,190][HYDRA] ******\n","[2022-08-16 04:41:04,194][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: false\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: T5\n","  train_dataset: ET_train.txt\n","  pretrained_model: t5-base\n","  append_another_bos: false\n","  append_sep_token: true\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 128\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 128\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_test.txt\n","    save_outputs: true\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: Exp/Exp19/save/ET_1_1_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-16 04:41:04,259][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 04:41:05,073][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 0\n","[2022-08-16 04:41:05,075][filelock][DEBUG] - Attempting to acquire lock 140318982678864 on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-16 04:41:05,075][filelock][DEBUG] - Lock 140318982678864 acquired on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-16 04:41:05,075][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpukouojvo\n","[2022-08-16 04:41:05,077][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 04:41:05,869][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 791656\n","Downloading: 100% 792k/792k [00:00<00:00, 856kB/s]\n","[2022-08-16 04:41:06,795][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model in cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-16 04:41:06,795][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-16 04:41:06,796][filelock][DEBUG] - Attempting to release lock 140318982678864 on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-16 04:41:06,796][filelock][DEBUG] - Lock 140318982678864 released on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-16 04:41:06,796][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-16 04:41:22,410][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 04:41:23,177][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 0\n","[2022-08-16 04:41:23,179][filelock][DEBUG] - Attempting to acquire lock 140317724981328 on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-16 04:41:23,179][filelock][DEBUG] - Lock 140317724981328 acquired on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-16 04:41:23,180][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpr47d1k0r\n","[2022-08-16 04:41:23,181][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 04:41:23,980][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 1199\n","Downloading: 100% 1.20k/1.20k [00:00<00:00, 1.08MB/s]\n","[2022-08-16 04:41:23,982][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json in cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-16 04:41:23,982][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-16 04:41:23,983][filelock][DEBUG] - Attempting to release lock 140317724981328 on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-16 04:41:23,983][filelock][DEBUG] - Lock 140317724981328 released on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-16 04:41:23,983][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-16 04:41:23,984][transformers.configuration_utils][INFO] - Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[2022-08-16 04:41:23,985][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-16 04:41:24,097][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /t5-base-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-16 04:41:24,099][filelock][DEBUG] - Attempting to acquire lock 140318982731152 on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-16 04:41:24,099][filelock][DEBUG] - Lock 140318982731152 acquired on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-16 04:41:24,100][transformers.file_utils][INFO] - https://cdn.huggingface.co/t5-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpdsd46nyl\n","[2022-08-16 04:41:24,102][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-16 04:41:25,159][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"GET /t5-base-pytorch_model.bin HTTP/1.1\" 200 891691430\n","Downloading: 100% 892M/892M [00:45<00:00, 19.4MB/s]\n","[2022-08-16 04:42:11,037][transformers.file_utils][INFO] - storing https://cdn.huggingface.co/t5-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-16 04:42:11,038][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-16 04:42:11,038][filelock][DEBUG] - Attempting to release lock 140318982731152 on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-16 04:42:11,038][filelock][DEBUG] - Lock 140318982731152 released on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-16 04:42:11,038][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-16 04:42:16,631][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","[2022-08-16 04:42:16,632][transformers.modeling_utils][WARNING] - Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[2022-08-16 04:42:21,550][__main__][DEBUG] - Parameter model.shared.weight: torch.Size([32128, 768]), require_grad=True\n","[2022-08-16 04:42:21,550][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,551][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,551][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,551][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,551][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-16 04:42:21,551][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,551][__main__][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,551][__main__][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,551][__main__][DEBUG] - Parameter model.encoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,551][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,552][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,552][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,552][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,552][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,552][__main__][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,552][__main__][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,552][__main__][DEBUG] - Parameter model.encoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,552][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,552][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,553][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,553][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,553][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,553][__main__][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,553][__main__][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,553][__main__][DEBUG] - Parameter model.encoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,553][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,553][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,554][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,554][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,554][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,554][__main__][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,554][__main__][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,554][__main__][DEBUG] - Parameter model.encoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,554][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,554][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,555][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,555][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,555][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,555][__main__][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,555][__main__][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,555][__main__][DEBUG] - Parameter model.encoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,555][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,555][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,555][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,556][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,556][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,556][__main__][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,556][__main__][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,556][__main__][DEBUG] - Parameter model.encoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,556][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,556][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,556][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,556][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,557][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,557][__main__][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,557][__main__][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,557][__main__][DEBUG] - Parameter model.encoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,557][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,557][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,557][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,557][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,557][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,558][__main__][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,558][__main__][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,558][__main__][DEBUG] - Parameter model.encoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,558][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,558][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,558][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,558][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,558][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,559][__main__][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,559][__main__][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,559][__main__][DEBUG] - Parameter model.encoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,559][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,559][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,559][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,559][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,559][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,560][__main__][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,561][__main__][DEBUG] - Parameter model.encoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,561][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,561][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,561][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,561][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,561][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,561][__main__][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,561][__main__][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,562][__main__][DEBUG] - Parameter model.encoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,562][__main__][DEBUG] - Parameter model.encoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,562][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,562][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,562][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,562][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,562][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-16 04:42:21,563][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,563][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,563][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,563][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,563][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,563][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-16 04:42:21,563][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,563][__main__][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,564][__main__][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,564][__main__][DEBUG] - Parameter model.decoder.block.0.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,564][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,564][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,564][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,564][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,564][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,564][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,604][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,604][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,604][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,604][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,605][__main__][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,605][__main__][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,605][__main__][DEBUG] - Parameter model.decoder.block.1.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,605][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,606][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,606][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,606][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,606][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,606][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,606][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,607][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,607][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,607][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,607][__main__][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,607][__main__][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,607][__main__][DEBUG] - Parameter model.decoder.block.2.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,608][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,608][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,608][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,608][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,608][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,608][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,608][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,608][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.3.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,609][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.4.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,610][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.5.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,611][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.6.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,612][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,613][__main__][DEBUG] - Parameter model.decoder.block.7.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,614][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.8.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,615][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.9.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,616][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.10.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,617][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 04:42:21,618][__main__][DEBUG] - Parameter model.decoder.block.11.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 04:42:21,619][__main__][DEBUG] - Parameter model.decoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","Epoch:   0% 0/100 [00:00<?, ?it/s][2022-08-16 04:42:21,621][__main__][DEBUG] - Starting training!\n","\n","Iteration:   0% 0/1851 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-16 04:42:22,607][__main__][DEBUG] - batch 0: tensor([[ 784, 9413,  908,  ..., 6327,  908,    1],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1],\n","        ...,\n","        [ 784, 9413,  908,  ..., 6327,  908,    1],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1]], device='cuda:0') \n","[2022-08-16 04:42:22,619][__main__][DEBUG] - batch 1: tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') \n","[2022-08-16 04:42:22,622][__main__][DEBUG] - batch 2: tensor([[    3,    87, 18011,  ...,     0,     0,     0],\n","        [    3,    87, 10925,  ...,     3,    87,     1],\n","        [    3,    87, 22170,  ...,     0,     0,     0],\n","        ...,\n","        [    3,    87,    17,  ...,    17,   208,     1],\n","        [    3,    87, 10925,  ...,     0,     0,     0],\n","        [    3,    87,     9,  ...,     0,     0,     0]], device='cuda:0') \n","[2022-08-16 04:42:22,624][__main__][DEBUG] - batch 3: tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0') \n","\n","Iteration:   0% 1/1851 [00:01<55:00,  1.78s/it]\u001b[A\n","Iteration:   0% 2/1851 [00:02<35:05,  1.14s/it]\u001b[A\n","Iteration:   0% 3/1851 [00:03<28:53,  1.07it/s]\u001b[A\n","Iteration:   0% 4/1851 [00:03<25:55,  1.19it/s]\u001b[A\n","Iteration:   0% 5/1851 [00:04<24:19,  1.27it/s]\u001b[A\n","Iteration:   0% 6/1851 [00:05<23:27,  1.31it/s]\u001b[A\n","Iteration:   0% 7/1851 [00:05<22:45,  1.35it/s]\u001b[A\n","Iteration:   0% 8/1851 [00:06<22:19,  1.38it/s]\u001b[A\n","Iteration:   0% 9/1851 [00:07<22:03,  1.39it/s]\u001b[A\n","Iteration:   1% 10/1851 [00:08<21:54,  1.40it/s]\u001b[A\n","Iteration:   1% 11/1851 [00:08<21:42,  1.41it/s]\u001b[A\n","Iteration:   1% 12/1851 [00:09<21:41,  1.41it/s]\u001b[A\n","Iteration:   1% 13/1851 [00:10<21:37,  1.42it/s]\u001b[A\n","Iteration:   1% 14/1851 [00:10<21:34,  1.42it/s]\u001b[A\n","Iteration:   1% 15/1851 [00:11<21:33,  1.42it/s]\u001b[A\n","Iteration:   1% 16/1851 [00:12<21:33,  1.42it/s]\u001b[A\n","Iteration:   1% 17/1851 [00:12<21:34,  1.42it/s]\u001b[A\n","Iteration:   1% 18/1851 [00:13<21:33,  1.42it/s]\u001b[A\n","Iteration:   1% 19/1851 [00:14<21:34,  1.42it/s]\u001b[A\n","Iteration:   1% 20/1851 [00:15<21:32,  1.42it/s]\u001b[A\n","Iteration:   1% 21/1851 [00:15<21:29,  1.42it/s]\u001b[A\n","Iteration:   1% 22/1851 [00:16<21:29,  1.42it/s]\u001b[A\n","Iteration:   1% 23/1851 [00:17<21:26,  1.42it/s]\u001b[A\n","Iteration:   1% 24/1851 [00:17<21:29,  1.42it/s]\u001b[A\n","Iteration:   1% 25/1851 [00:18<21:30,  1.41it/s]\u001b[A\n","Iteration:   1% 26/1851 [00:19<21:29,  1.41it/s]\u001b[A\n","Iteration:   1% 27/1851 [00:20<21:30,  1.41it/s]\u001b[A\n","Iteration:   2% 28/1851 [00:20<21:33,  1.41it/s]\u001b[A\n","Iteration:   2% 29/1851 [00:21<21:33,  1.41it/s]\u001b[A\n","Iteration:   2% 30/1851 [00:22<21:32,  1.41it/s]\u001b[A\n","Iteration:   2% 31/1851 [00:22<21:32,  1.41it/s]\u001b[A\n","Iteration:   2% 32/1851 [00:23<21:33,  1.41it/s]\u001b[A\n","Iteration:   2% 33/1851 [00:24<21:34,  1.40it/s]\u001b[A\n","Iteration:   2% 34/1851 [00:25<21:36,  1.40it/s]\u001b[A\n","Iteration:   2% 35/1851 [00:25<21:36,  1.40it/s]\u001b[A\n","Iteration:   2% 36/1851 [00:26<21:32,  1.40it/s]\u001b[A\n","Iteration:   2% 37/1851 [00:27<21:30,  1.41it/s]\u001b[A\n","Iteration:   2% 38/1851 [00:27<21:35,  1.40it/s]\u001b[A\n","Iteration:   2% 39/1851 [00:28<21:35,  1.40it/s]\u001b[A\n","Iteration:   2% 40/1851 [00:29<21:35,  1.40it/s]\u001b[A\n","Iteration:   2% 41/1851 [00:30<21:36,  1.40it/s]\u001b[A\n","Iteration:   2% 42/1851 [00:30<21:36,  1.40it/s]\u001b[A\n","Iteration:   2% 43/1851 [00:31<21:36,  1.39it/s]\u001b[A\n","Iteration:   2% 44/1851 [00:32<21:39,  1.39it/s]\u001b[A\n","Iteration:   2% 45/1851 [00:32<21:37,  1.39it/s]\u001b[A\n","Iteration:   2% 46/1851 [00:33<21:39,  1.39it/s]\u001b[A\n","Iteration:   3% 47/1851 [00:34<21:38,  1.39it/s]\u001b[A\n","Iteration:   3% 48/1851 [00:35<21:38,  1.39it/s]\u001b[A\n","Iteration:   3% 49/1851 [00:35<21:39,  1.39it/s]\u001b[A\n","Iteration:   3% 50/1851 [00:36<21:39,  1.39it/s]\u001b[A\n","Iteration:   3% 51/1851 [00:37<21:42,  1.38it/s]\u001b[A\n","Iteration:   3% 52/1851 [00:37<21:43,  1.38it/s]\u001b[A\n","Iteration:   3% 53/1851 [00:38<21:44,  1.38it/s]\u001b[A\n","Iteration:   3% 54/1851 [00:39<21:47,  1.37it/s]\u001b[A\n","Iteration:   3% 55/1851 [00:40<21:47,  1.37it/s]\u001b[A\n","Iteration:   3% 56/1851 [00:40<21:47,  1.37it/s]\u001b[A\n","Iteration:   3% 57/1851 [00:41<21:50,  1.37it/s]\u001b[A\n","Iteration:   3% 58/1851 [00:42<21:51,  1.37it/s]\u001b[A\n","Iteration:   3% 59/1851 [00:43<21:50,  1.37it/s]\u001b[A\n","Iteration:   3% 60/1851 [00:43<21:50,  1.37it/s]\u001b[A\n","Iteration:   3% 61/1851 [00:44<21:49,  1.37it/s]\u001b[A\n","Iteration:   3% 62/1851 [00:45<21:50,  1.37it/s]\u001b[A\n","Iteration:   3% 63/1851 [00:46<21:54,  1.36it/s]\u001b[A\n","Iteration:   3% 64/1851 [00:46<21:53,  1.36it/s]\u001b[A\n","Iteration:   4% 65/1851 [00:47<21:52,  1.36it/s]\u001b[A\n","Iteration:   4% 66/1851 [00:48<21:57,  1.36it/s]\u001b[A\n","Iteration:   4% 67/1851 [00:49<21:56,  1.36it/s]\u001b[A\n","Iteration:   4% 68/1851 [00:49<21:57,  1.35it/s]\u001b[A\n","Iteration:   4% 69/1851 [00:50<21:58,  1.35it/s]\u001b[A\n","Iteration:   4% 70/1851 [00:51<21:56,  1.35it/s]\u001b[A\n","Iteration:   4% 71/1851 [00:51<21:56,  1.35it/s]\u001b[A\n","Iteration:   4% 72/1851 [00:52<21:56,  1.35it/s]\u001b[A\n","Iteration:   4% 73/1851 [00:53<22:00,  1.35it/s]\u001b[A\n","Iteration:   4% 74/1851 [00:54<22:00,  1.35it/s]\u001b[A\n","Iteration:   4% 75/1851 [00:54<22:01,  1.34it/s]\u001b[A\n","Iteration:   4% 76/1851 [00:55<22:00,  1.34it/s]\u001b[A\n","Iteration:   4% 77/1851 [00:56<22:01,  1.34it/s]\u001b[A\n","Iteration:   4% 78/1851 [00:57<22:01,  1.34it/s]\u001b[A\n","Iteration:   4% 79/1851 [00:57<22:00,  1.34it/s]\u001b[A\n","Iteration:   4% 80/1851 [00:58<22:00,  1.34it/s]\u001b[A\n","Iteration:   4% 81/1851 [00:59<22:02,  1.34it/s]\u001b[A\n","Iteration:   4% 82/1851 [01:00<22:04,  1.34it/s]\u001b[A\n","Iteration:   4% 83/1851 [01:00<22:04,  1.33it/s]\u001b[A\n","Iteration:   5% 84/1851 [01:01<22:03,  1.34it/s]\u001b[A\n","Iteration:   5% 85/1851 [01:02<22:05,  1.33it/s]\u001b[A\n","Iteration:   5% 86/1851 [01:03<22:06,  1.33it/s]\u001b[A\n","Iteration:   5% 87/1851 [01:03<22:07,  1.33it/s]\u001b[A\n","Iteration:   5% 88/1851 [01:04<22:07,  1.33it/s]\u001b[A\n","Iteration:   5% 89/1851 [01:05<22:08,  1.33it/s]\u001b[A\n","Iteration:   5% 90/1851 [01:06<22:07,  1.33it/s]\u001b[A\n","Iteration:   5% 91/1851 [01:06<22:07,  1.33it/s]\u001b[A\n","Iteration:   5% 92/1851 [01:07<22:13,  1.32it/s]\u001b[A\n","Iteration:   5% 93/1851 [01:08<22:11,  1.32it/s]\u001b[A\n","Iteration:   5% 94/1851 [01:09<22:14,  1.32it/s]\u001b[A\n","Iteration:   5% 95/1851 [01:10<22:18,  1.31it/s]\u001b[A\n","Iteration:   5% 96/1851 [01:10<22:21,  1.31it/s]\u001b[A\n","Iteration:   5% 97/1851 [01:11<22:19,  1.31it/s]\u001b[A\n","Iteration:   5% 98/1851 [01:12<22:21,  1.31it/s]\u001b[A\n","Iteration:   5% 99/1851 [01:13<22:22,  1.30it/s]\u001b[A\n","Iteration:   5% 100/1851 [01:13<22:24,  1.30it/s]\u001b[A\n","Iteration:   5% 101/1851 [01:14<22:24,  1.30it/s]\u001b[A\n","Iteration:   6% 102/1851 [01:15<22:26,  1.30it/s]\u001b[A\n","Iteration:   6% 103/1851 [01:16<22:26,  1.30it/s]\u001b[A\n","Iteration:   6% 104/1851 [01:16<22:27,  1.30it/s]\u001b[A\n","Iteration:   6% 105/1851 [01:17<22:27,  1.30it/s]\u001b[A\n","Iteration:   6% 106/1851 [01:18<22:29,  1.29it/s]\u001b[A\n","Iteration:   6% 107/1851 [01:19<22:29,  1.29it/s]\u001b[A\n","Iteration:   6% 108/1851 [01:20<22:28,  1.29it/s]\u001b[A\n","Iteration:   6% 109/1851 [01:20<22:30,  1.29it/s]\u001b[A\n","Iteration:   6% 110/1851 [01:21<22:32,  1.29it/s]\u001b[A\n","Iteration:   6% 111/1851 [01:22<22:34,  1.28it/s]\u001b[A\n","Iteration:   6% 112/1851 [01:23<22:39,  1.28it/s]\u001b[A\n","Iteration:   6% 113/1851 [01:23<22:41,  1.28it/s]\u001b[A\n","Iteration:   6% 114/1851 [01:24<22:43,  1.27it/s]\u001b[A\n","Iteration:   6% 115/1851 [01:25<22:45,  1.27it/s]\u001b[A\n","Iteration:   6% 116/1851 [01:26<22:47,  1.27it/s]\u001b[A\n","Iteration:   6% 117/1851 [01:27<22:48,  1.27it/s]\u001b[A\n","Iteration:   6% 118/1851 [01:27<22:51,  1.26it/s]\u001b[A\n","Iteration:   6% 119/1851 [01:28<22:53,  1.26it/s]\u001b[A\n","Iteration:   6% 120/1851 [01:29<22:53,  1.26it/s]\u001b[A\n","Iteration:   7% 121/1851 [01:30<22:55,  1.26it/s]\u001b[A\n","Iteration:   7% 122/1851 [01:31<22:56,  1.26it/s]\u001b[A\n","Iteration:   7% 123/1851 [01:31<22:50,  1.26it/s]\u001b[A\n","Iteration:   7% 124/1851 [01:32<22:49,  1.26it/s]\u001b[A\n","Iteration:   7% 125/1851 [01:33<22:49,  1.26it/s]\u001b[A\n","Iteration:   7% 126/1851 [01:34<22:52,  1.26it/s]\u001b[A\n","Iteration:   7% 127/1851 [01:35<22:53,  1.26it/s]\u001b[A\n","Iteration:   7% 128/1851 [01:35<22:48,  1.26it/s]\u001b[A\n","Iteration:   7% 129/1851 [01:36<22:42,  1.26it/s]\u001b[A\n","Iteration:   7% 130/1851 [01:37<22:37,  1.27it/s]\u001b[A\n","Iteration:   7% 131/1851 [01:38<22:37,  1.27it/s]\u001b[A\n","Iteration:   7% 132/1851 [01:39<22:34,  1.27it/s]\u001b[A\n","Iteration:   7% 133/1851 [01:39<22:35,  1.27it/s]\u001b[A\n","Iteration:   7% 134/1851 [01:40<22:29,  1.27it/s]\u001b[A\n","Iteration:   7% 135/1851 [01:41<22:28,  1.27it/s]\u001b[A\n","Iteration:   7% 136/1851 [01:42<22:30,  1.27it/s]\u001b[A\n","Iteration:   7% 137/1851 [01:42<22:24,  1.27it/s]\u001b[A\n","Iteration:   7% 138/1851 [01:43<22:22,  1.28it/s]\u001b[A\n","Iteration:   8% 139/1851 [01:44<22:18,  1.28it/s]\u001b[A\n","Iteration:   8% 140/1851 [01:45<22:14,  1.28it/s]\u001b[A\n","Iteration:   8% 141/1851 [01:46<22:11,  1.28it/s]\u001b[A\n","Iteration:   8% 142/1851 [01:46<22:11,  1.28it/s]\u001b[A\n","Iteration:   8% 143/1851 [01:47<22:08,  1.29it/s]\u001b[A\n","Iteration:   8% 144/1851 [01:48<22:05,  1.29it/s]\u001b[A\n","Iteration:   8% 145/1851 [01:49<22:03,  1.29it/s]\u001b[A\n","Iteration:   8% 146/1851 [01:49<22:03,  1.29it/s]\u001b[A\n","Iteration:   8% 147/1851 [01:50<22:03,  1.29it/s]\u001b[A\n","Iteration:   8% 148/1851 [01:51<21:59,  1.29it/s]\u001b[A\n","Iteration:   8% 149/1851 [01:52<23:35,  1.20it/s]\u001b[A\n","Iteration:   8% 150/1851 [01:53<23:15,  1.22it/s]\u001b[A\n","Iteration:   8% 151/1851 [01:54<22:51,  1.24it/s]\u001b[A\n","Iteration:   8% 152/1851 [01:54<22:30,  1.26it/s]\u001b[A\n","Iteration:   8% 153/1851 [01:55<22:15,  1.27it/s]\u001b[A\n","Iteration:   8% 154/1851 [01:56<22:08,  1.28it/s]\u001b[A\n","Iteration:   8% 155/1851 [01:57<22:01,  1.28it/s]\u001b[A\n","Iteration:   8% 156/1851 [01:57<21:55,  1.29it/s]\u001b[A\n","Iteration:   8% 157/1851 [01:58<21:52,  1.29it/s]\u001b[A\n","Iteration:   9% 158/1851 [01:59<21:47,  1.29it/s]\u001b[A\n","Iteration:   9% 159/1851 [02:00<21:47,  1.29it/s]\u001b[A\n","Iteration:   9% 160/1851 [02:00<21:45,  1.30it/s]\u001b[A\n","Iteration:   9% 161/1851 [02:01<21:44,  1.30it/s]\u001b[A\n","Iteration:   9% 162/1851 [02:02<21:43,  1.30it/s]\u001b[A\n","Iteration:   9% 163/1851 [02:03<21:41,  1.30it/s]\u001b[A\n","Iteration:   9% 164/1851 [02:04<21:38,  1.30it/s]\u001b[A\n","Iteration:   9% 165/1851 [02:04<21:34,  1.30it/s]\u001b[A\n","Iteration:   9% 166/1851 [02:05<21:33,  1.30it/s]\u001b[A\n","Iteration:   9% 167/1851 [02:06<21:28,  1.31it/s]\u001b[A\n","Iteration:   9% 168/1851 [02:07<21:30,  1.30it/s]\u001b[A\n","Iteration:   9% 169/1851 [02:07<21:27,  1.31it/s]\u001b[A\n","Iteration:   9% 170/1851 [02:08<21:26,  1.31it/s]\u001b[A\n","Iteration:   9% 171/1851 [02:09<21:26,  1.31it/s]\u001b[A\n","Iteration:   9% 172/1851 [02:10<21:26,  1.31it/s]\u001b[A\n","Iteration:   9% 173/1851 [02:10<21:22,  1.31it/s]\u001b[A\n","Iteration:   9% 174/1851 [02:11<21:22,  1.31it/s]\u001b[A\n","Iteration:   9% 175/1851 [02:12<21:20,  1.31it/s]\u001b[A\n","Iteration:  10% 176/1851 [02:13<21:19,  1.31it/s]\u001b[A\n","Iteration:  10% 177/1851 [02:13<21:17,  1.31it/s]\u001b[A\n","Iteration:  10% 178/1851 [02:14<21:15,  1.31it/s]\u001b[A\n","Iteration:  10% 179/1851 [02:15<21:14,  1.31it/s]\u001b[A\n","Iteration:  10% 180/1851 [02:16<21:14,  1.31it/s]\u001b[A\n","Iteration:  10% 181/1851 [02:17<21:12,  1.31it/s]\u001b[A\n","Iteration:  10% 182/1851 [02:17<21:12,  1.31it/s]\u001b[A\n","Iteration:  10% 183/1851 [02:18<21:14,  1.31it/s]\u001b[A\n","Iteration:  10% 184/1851 [02:19<21:11,  1.31it/s]\u001b[A\n","Iteration:  10% 185/1851 [02:20<21:11,  1.31it/s]\u001b[A\n","Iteration:  10% 186/1851 [02:20<21:12,  1.31it/s]\u001b[A\n","Iteration:  10% 187/1851 [02:21<21:11,  1.31it/s]\u001b[A\n","Iteration:  10% 188/1851 [02:22<21:09,  1.31it/s]\u001b[A\n","Iteration:  10% 189/1851 [02:23<21:10,  1.31it/s]\u001b[A\n","Iteration:  10% 190/1851 [02:23<21:09,  1.31it/s]\u001b[A\n","Iteration:  10% 191/1851 [02:24<21:07,  1.31it/s]\u001b[A\n","Iteration:  10% 192/1851 [02:25<21:08,  1.31it/s]\u001b[A\n","Iteration:  10% 193/1851 [02:26<21:07,  1.31it/s]\u001b[A\n","Iteration:  10% 194/1851 [02:26<21:07,  1.31it/s]\u001b[A\n","Iteration:  11% 195/1851 [02:27<21:05,  1.31it/s]\u001b[A\n","Iteration:  11% 196/1851 [02:28<21:06,  1.31it/s]\u001b[A\n","Iteration:  11% 197/1851 [02:29<21:06,  1.31it/s]\u001b[A\n","Iteration:  11% 198/1851 [02:30<21:05,  1.31it/s]\u001b[A\n","Iteration:  11% 199/1851 [02:30<21:07,  1.30it/s]\u001b[A\n","Iteration:  11% 200/1851 [02:31<21:04,  1.31it/s]\u001b[A\n","Iteration:  11% 201/1851 [02:32<21:03,  1.31it/s]\u001b[A\n","Iteration:  11% 202/1851 [02:33<21:04,  1.30it/s]\u001b[A\n","Iteration:  11% 203/1851 [02:33<21:04,  1.30it/s]\u001b[A\n","Iteration:  11% 204/1851 [02:34<21:04,  1.30it/s]\u001b[A\n","Iteration:  11% 205/1851 [02:35<21:02,  1.30it/s]\u001b[A\n","Iteration:  11% 206/1851 [02:36<21:00,  1.30it/s]\u001b[A\n","Iteration:  11% 207/1851 [02:36<20:56,  1.31it/s]\u001b[A\n","Iteration:  11% 208/1851 [02:37<20:59,  1.30it/s]\u001b[A\n","Iteration:  11% 209/1851 [02:38<20:57,  1.31it/s]\u001b[A\n","Iteration:  11% 210/1851 [02:39<20:56,  1.31it/s]\u001b[A\n","Iteration:  11% 211/1851 [02:39<20:56,  1.30it/s]\u001b[A\n","Iteration:  11% 212/1851 [02:40<20:55,  1.31it/s]\u001b[A\n","Iteration:  12% 213/1851 [02:41<20:57,  1.30it/s]\u001b[A\n","Iteration:  12% 214/1851 [02:42<20:58,  1.30it/s]\u001b[A\n","Iteration:  12% 215/1851 [02:43<20:58,  1.30it/s]\u001b[A\n","Iteration:  12% 216/1851 [02:43<20:59,  1.30it/s]\u001b[A\n","Iteration:  12% 217/1851 [02:44<20:59,  1.30it/s]\u001b[A\n","Iteration:  12% 218/1851 [02:45<20:56,  1.30it/s]\u001b[A\n","Iteration:  12% 219/1851 [02:46<20:58,  1.30it/s]\u001b[A\n","Iteration:  12% 220/1851 [02:46<20:58,  1.30it/s]\u001b[A\n","Iteration:  12% 221/1851 [02:47<20:56,  1.30it/s]\u001b[A\n","Iteration:  12% 222/1851 [02:48<20:56,  1.30it/s]\u001b[A\n","Iteration:  12% 223/1851 [02:49<20:57,  1.29it/s]\u001b[A\n","Iteration:  12% 224/1851 [02:49<20:54,  1.30it/s]\u001b[A\n","Iteration:  12% 225/1851 [02:50<20:54,  1.30it/s]\u001b[A\n","Iteration:  12% 226/1851 [02:51<20:53,  1.30it/s]\u001b[A\n","Iteration:  12% 227/1851 [02:52<20:54,  1.29it/s]\u001b[A\n","Iteration:  12% 228/1851 [02:53<20:53,  1.30it/s]\u001b[A\n","Iteration:  12% 229/1851 [02:53<20:53,  1.29it/s]\u001b[A\n","Iteration:  12% 230/1851 [02:54<20:51,  1.30it/s]\u001b[A\n","Iteration:  12% 231/1851 [02:55<20:50,  1.30it/s]\u001b[A\n","Iteration:  13% 232/1851 [02:56<20:50,  1.29it/s]\u001b[A\n","Iteration:  13% 233/1851 [02:56<20:50,  1.29it/s]\u001b[A\n","Iteration:  13% 234/1851 [02:57<20:47,  1.30it/s]\u001b[A\n","Iteration:  13% 235/1851 [02:58<20:48,  1.29it/s]\u001b[A\n","Iteration:  13% 236/1851 [02:59<20:46,  1.30it/s]\u001b[A\n","Iteration:  13% 237/1851 [03:00<20:46,  1.30it/s]\u001b[A\n","Iteration:  13% 238/1851 [03:00<20:46,  1.29it/s]\u001b[A\n","Iteration:  13% 239/1851 [03:01<20:46,  1.29it/s]\u001b[A\n","Iteration:  13% 240/1851 [03:02<20:45,  1.29it/s]\u001b[A\n","Iteration:  13% 241/1851 [03:03<20:44,  1.29it/s]\u001b[A\n","Iteration:  13% 242/1851 [03:03<20:42,  1.30it/s]\u001b[A\n","Iteration:  13% 243/1851 [03:04<20:43,  1.29it/s]\u001b[A\n","Iteration:  13% 244/1851 [03:05<20:42,  1.29it/s]\u001b[A\n","Iteration:  13% 245/1851 [03:06<20:40,  1.29it/s]\u001b[A\n","Iteration:  13% 246/1851 [03:06<20:42,  1.29it/s]\u001b[A\n","Iteration:  13% 247/1851 [03:07<20:41,  1.29it/s]\u001b[A\n","Iteration:  13% 248/1851 [03:08<20:39,  1.29it/s]\u001b[A\n","Iteration:  13% 249/1851 [03:09<20:39,  1.29it/s]\u001b[A\n","Iteration:  14% 250/1851 [03:10<20:36,  1.30it/s]\u001b[A\n","Iteration:  14% 251/1851 [03:10<20:34,  1.30it/s]\u001b[A\n","Iteration:  14% 252/1851 [03:11<20:33,  1.30it/s]\u001b[A\n","Iteration:  14% 253/1851 [03:12<20:32,  1.30it/s]\u001b[A\n","Iteration:  14% 254/1851 [03:13<20:34,  1.29it/s]\u001b[A\n","Iteration:  14% 255/1851 [03:13<20:35,  1.29it/s]\u001b[A\n","Iteration:  14% 256/1851 [03:14<20:35,  1.29it/s]\u001b[A\n","Iteration:  14% 257/1851 [03:15<20:31,  1.29it/s]\u001b[A\n","Iteration:  14% 258/1851 [03:16<20:30,  1.29it/s]\u001b[A\n","Iteration:  14% 259/1851 [03:17<20:29,  1.30it/s]\u001b[A\n","Iteration:  14% 260/1851 [03:17<20:30,  1.29it/s]\u001b[A\n","Iteration:  14% 261/1851 [03:18<20:30,  1.29it/s]\u001b[A\n","Iteration:  14% 262/1851 [03:19<20:30,  1.29it/s]\u001b[A\n","Iteration:  14% 263/1851 [03:20<20:28,  1.29it/s]\u001b[A\n","Iteration:  14% 264/1851 [03:20<20:27,  1.29it/s]\u001b[A\n","Iteration:  14% 265/1851 [03:21<20:25,  1.29it/s]\u001b[A\n","Iteration:  14% 266/1851 [03:22<20:28,  1.29it/s]\u001b[A\n","Iteration:  14% 267/1851 [03:23<20:24,  1.29it/s]\u001b[A\n","Iteration:  14% 268/1851 [03:23<20:22,  1.29it/s]\u001b[A\n","Iteration:  15% 269/1851 [03:24<20:21,  1.29it/s]\u001b[A\n","Iteration:  15% 270/1851 [03:25<20:20,  1.30it/s]\u001b[A\n","Iteration:  15% 271/1851 [03:26<20:19,  1.30it/s]\u001b[A\n","Iteration:  15% 272/1851 [03:27<20:16,  1.30it/s]\u001b[A\n","Iteration:  15% 273/1851 [03:27<20:18,  1.30it/s]\u001b[A\n","Iteration:  15% 274/1851 [03:28<20:17,  1.30it/s]\u001b[A\n","Iteration:  15% 275/1851 [03:29<20:16,  1.30it/s]\u001b[A\n","Iteration:  15% 276/1851 [03:30<20:15,  1.30it/s]\u001b[A\n","Iteration:  15% 277/1851 [03:30<20:17,  1.29it/s]\u001b[A\n","Iteration:  15% 278/1851 [03:31<20:16,  1.29it/s]\u001b[A\n","Iteration:  15% 279/1851 [03:32<20:15,  1.29it/s]\u001b[A\n","Iteration:  15% 280/1851 [03:33<20:13,  1.29it/s]\u001b[A\n","Iteration:  15% 281/1851 [03:34<20:13,  1.29it/s]\u001b[A\n","Iteration:  15% 282/1851 [03:34<20:09,  1.30it/s]\u001b[A\n","Iteration:  15% 283/1851 [03:35<20:07,  1.30it/s]\u001b[A\n","Iteration:  15% 284/1851 [03:36<20:06,  1.30it/s]\u001b[A\n","Iteration:  15% 285/1851 [03:37<20:07,  1.30it/s]\u001b[A\n","Iteration:  15% 286/1851 [03:37<20:05,  1.30it/s]\u001b[A\n","Iteration:  16% 287/1851 [03:38<20:04,  1.30it/s]\u001b[A\n","Iteration:  16% 288/1851 [03:39<20:03,  1.30it/s]\u001b[A\n","Iteration:  16% 289/1851 [03:40<20:04,  1.30it/s]\u001b[A\n","Iteration:  16% 290/1851 [03:40<20:03,  1.30it/s]\u001b[A\n","Iteration:  16% 291/1851 [03:41<20:02,  1.30it/s]\u001b[A\n","Iteration:  16% 292/1851 [03:42<20:01,  1.30it/s]\u001b[A\n","Iteration:  16% 293/1851 [03:43<20:01,  1.30it/s]\u001b[A\n","Iteration:  16% 294/1851 [03:44<19:57,  1.30it/s]\u001b[A\n","Iteration:  16% 295/1851 [03:44<19:59,  1.30it/s]\u001b[A\n","Iteration:  16% 296/1851 [03:45<19:58,  1.30it/s]\u001b[A\n","Iteration:  16% 297/1851 [03:46<19:58,  1.30it/s]\u001b[A\n","Iteration:  16% 298/1851 [03:47<19:57,  1.30it/s]\u001b[A\n","Iteration:  16% 299/1851 [03:47<19:56,  1.30it/s]\u001b[A\n","Iteration:  16% 300/1851 [03:48<19:56,  1.30it/s]\u001b[A\n","Iteration:  16% 301/1851 [03:49<19:55,  1.30it/s]\u001b[A\n","Iteration:  16% 302/1851 [03:50<19:54,  1.30it/s]\u001b[A\n","Iteration:  16% 303/1851 [03:50<19:56,  1.29it/s]\u001b[A\n","Iteration:  16% 304/1851 [03:51<19:55,  1.29it/s]\u001b[A\n","Iteration:  16% 305/1851 [03:52<19:54,  1.29it/s]\u001b[A\n","Iteration:  17% 306/1851 [03:53<19:52,  1.30it/s]\u001b[A\n","Iteration:  17% 307/1851 [03:54<19:50,  1.30it/s]\u001b[A\n","Iteration:  17% 308/1851 [03:54<19:51,  1.29it/s]\u001b[A\n","Iteration:  17% 309/1851 [03:55<19:50,  1.30it/s]\u001b[A\n","Iteration:  17% 310/1851 [03:56<19:49,  1.30it/s]\u001b[A\n","Iteration:  17% 311/1851 [03:57<19:47,  1.30it/s]\u001b[A\n","Iteration:  17% 312/1851 [03:57<19:47,  1.30it/s]\u001b[A\n","Iteration:  17% 313/1851 [03:58<19:47,  1.29it/s]\u001b[A\n","Iteration:  17% 314/1851 [03:59<19:45,  1.30it/s]\u001b[A\n","Iteration:  17% 315/1851 [04:00<19:47,  1.29it/s]\u001b[A\n","Iteration:  17% 316/1851 [04:01<19:44,  1.30it/s]\u001b[A\n","Iteration:  17% 317/1851 [04:01<19:43,  1.30it/s]\u001b[A\n","Iteration:  17% 318/1851 [04:02<19:41,  1.30it/s]\u001b[A\n","Iteration:  17% 319/1851 [04:03<19:41,  1.30it/s]\u001b[A\n","Iteration:  17% 320/1851 [04:04<19:40,  1.30it/s]\u001b[A\n","Iteration:  17% 321/1851 [04:04<19:38,  1.30it/s]\u001b[A\n","Iteration:  17% 322/1851 [04:05<19:36,  1.30it/s]\u001b[A\n","Iteration:  17% 323/1851 [04:06<19:37,  1.30it/s]\u001b[A\n","Iteration:  18% 324/1851 [04:07<19:36,  1.30it/s]\u001b[A\n","Iteration:  18% 325/1851 [04:07<19:35,  1.30it/s]\u001b[A\n","Iteration:  18% 326/1851 [04:08<19:34,  1.30it/s]\u001b[A\n","Iteration:  18% 327/1851 [04:09<19:33,  1.30it/s]\u001b[A\n","Iteration:  18% 328/1851 [04:10<19:34,  1.30it/s]\u001b[A\n","Iteration:  18% 329/1851 [04:11<19:33,  1.30it/s]\u001b[A\n","Iteration:  18% 330/1851 [04:11<19:30,  1.30it/s]\u001b[A\n","Iteration:  18% 331/1851 [04:12<19:30,  1.30it/s]\u001b[A\n","Iteration:  18% 332/1851 [04:13<19:30,  1.30it/s]\u001b[A\n","Iteration:  18% 333/1851 [04:14<19:29,  1.30it/s]\u001b[A\n","Iteration:  18% 334/1851 [04:14<19:28,  1.30it/s]\u001b[A\n","Iteration:  18% 335/1851 [04:15<19:28,  1.30it/s]\u001b[A\n","Iteration:  18% 336/1851 [04:16<19:26,  1.30it/s]\u001b[A\n","Iteration:  18% 337/1851 [04:17<19:25,  1.30it/s]\u001b[A\n","Iteration:  18% 338/1851 [04:17<19:26,  1.30it/s]\u001b[A\n","Iteration:  18% 339/1851 [04:18<19:25,  1.30it/s]\u001b[A\n","Iteration:  18% 340/1851 [04:19<19:24,  1.30it/s]\u001b[A\n","Iteration:  18% 341/1851 [04:20<19:24,  1.30it/s]\u001b[A\n","Iteration:  18% 342/1851 [04:21<19:22,  1.30it/s]\u001b[A\n","Iteration:  19% 343/1851 [04:21<19:21,  1.30it/s]\u001b[A\n","Iteration:  19% 344/1851 [04:22<19:21,  1.30it/s]\u001b[A\n","Iteration:  19% 345/1851 [04:23<19:20,  1.30it/s]\u001b[A\n","Iteration:  19% 346/1851 [04:24<19:16,  1.30it/s]\u001b[A\n","Iteration:  19% 347/1851 [04:24<19:19,  1.30it/s]\u001b[A\n","Iteration:  19% 348/1851 [04:25<19:16,  1.30it/s]\u001b[A\n","Iteration:  19% 349/1851 [04:26<19:18,  1.30it/s]\u001b[A\n","Iteration:  19% 350/1851 [04:27<19:18,  1.30it/s]\u001b[A\n","Iteration:  19% 351/1851 [04:27<19:17,  1.30it/s]\u001b[A\n","Iteration:  19% 352/1851 [04:28<19:14,  1.30it/s]\u001b[A\n","Iteration:  19% 353/1851 [04:29<19:14,  1.30it/s]\u001b[A\n","Iteration:  19% 354/1851 [04:30<19:13,  1.30it/s]\u001b[A\n","Iteration:  19% 355/1851 [04:31<19:14,  1.30it/s]\u001b[A\n","Iteration:  19% 356/1851 [04:31<19:13,  1.30it/s]\u001b[A\n","Iteration:  19% 357/1851 [04:32<19:11,  1.30it/s]\u001b[A\n","Iteration:  19% 358/1851 [04:33<19:10,  1.30it/s]\u001b[A\n","Iteration:  19% 359/1851 [04:34<19:09,  1.30it/s]\u001b[A\n","Iteration:  19% 360/1851 [04:34<19:08,  1.30it/s]\u001b[A\n","Iteration:  20% 361/1851 [04:35<19:05,  1.30it/s]\u001b[A\n","Iteration:  20% 362/1851 [04:36<19:07,  1.30it/s]\u001b[A\n","Iteration:  20% 363/1851 [04:37<19:07,  1.30it/s]\u001b[A\n","Iteration:  20% 364/1851 [04:38<19:06,  1.30it/s]\u001b[A\n","Iteration:  20% 365/1851 [04:38<19:05,  1.30it/s]\u001b[A\n","Iteration:  20% 366/1851 [04:39<19:04,  1.30it/s]\u001b[A\n","Iteration:  20% 367/1851 [04:40<19:03,  1.30it/s]\u001b[A\n","Iteration:  20% 368/1851 [04:41<19:03,  1.30it/s]\u001b[A\n","Iteration:  20% 369/1851 [04:41<19:01,  1.30it/s]\u001b[A\n","Iteration:  20% 370/1851 [04:42<19:00,  1.30it/s]\u001b[A\n","Iteration:  20% 371/1851 [04:43<18:59,  1.30it/s]\u001b[A\n","Iteration:  20% 372/1851 [04:44<18:58,  1.30it/s]\u001b[A\n","Iteration:  20% 373/1851 [04:44<18:56,  1.30it/s]\u001b[A\n","Iteration:  20% 374/1851 [04:45<18:56,  1.30it/s]\u001b[A\n","Iteration:  20% 375/1851 [04:46<18:56,  1.30it/s]\u001b[A\n","Iteration:  20% 376/1851 [04:47<18:56,  1.30it/s]\u001b[A\n","Iteration:  20% 377/1851 [04:48<18:55,  1.30it/s]\u001b[A\n","Iteration:  20% 378/1851 [04:48<18:57,  1.30it/s]\u001b[A\n","Iteration:  20% 379/1851 [04:49<18:55,  1.30it/s]\u001b[A\n","Iteration:  21% 380/1851 [04:50<18:52,  1.30it/s]\u001b[A\n","Iteration:  21% 381/1851 [04:51<18:52,  1.30it/s]\u001b[A\n","Iteration:  21% 382/1851 [04:51<18:51,  1.30it/s]\u001b[A\n","Iteration:  21% 383/1851 [04:52<18:51,  1.30it/s]\u001b[A\n","Iteration:  21% 384/1851 [04:53<18:50,  1.30it/s]\u001b[A\n","Iteration:  21% 385/1851 [04:54<18:51,  1.30it/s]\u001b[A\n","Iteration:  21% 386/1851 [04:54<18:51,  1.30it/s]\u001b[A\n","Iteration:  21% 387/1851 [04:55<18:49,  1.30it/s]\u001b[A\n","Iteration:  21% 388/1851 [04:56<18:46,  1.30it/s]\u001b[A\n","Iteration:  21% 389/1851 [04:57<18:46,  1.30it/s]\u001b[A\n","Iteration:  21% 390/1851 [04:58<18:46,  1.30it/s]\u001b[A\n","Iteration:  21% 391/1851 [04:58<18:46,  1.30it/s]\u001b[A\n","Iteration:  21% 392/1851 [04:59<18:45,  1.30it/s]\u001b[A\n","Iteration:  21% 393/1851 [05:00<18:42,  1.30it/s]\u001b[A\n","Iteration:  21% 394/1851 [05:01<18:40,  1.30it/s]\u001b[A\n","Iteration:  21% 395/1851 [05:01<18:40,  1.30it/s]\u001b[A\n","Iteration:  21% 396/1851 [05:02<18:39,  1.30it/s]\u001b[A\n","Iteration:  21% 397/1851 [05:03<18:38,  1.30it/s]\u001b[A\n","Iteration:  22% 398/1851 [05:04<18:37,  1.30it/s]\u001b[A\n","Iteration:  22% 399/1851 [05:04<18:34,  1.30it/s]\u001b[A\n","Iteration:  22% 400/1851 [05:05<18:34,  1.30it/s]\u001b[A\n","Iteration:  22% 401/1851 [05:06<18:36,  1.30it/s]\u001b[A\n","Iteration:  22% 402/1851 [05:07<18:36,  1.30it/s]\u001b[A\n","Iteration:  22% 403/1851 [05:08<18:37,  1.30it/s]\u001b[A\n","Iteration:  22% 404/1851 [05:08<18:37,  1.29it/s]\u001b[A\n","Iteration:  22% 405/1851 [05:09<18:36,  1.29it/s]\u001b[A\n","Iteration:  22% 406/1851 [05:10<18:35,  1.29it/s]\u001b[A\n","Iteration:  22% 407/1851 [05:11<18:34,  1.30it/s]\u001b[A\n","Iteration:  22% 408/1851 [05:11<18:32,  1.30it/s]\u001b[A\n","Iteration:  22% 409/1851 [05:12<18:30,  1.30it/s]\u001b[A\n","Iteration:  22% 410/1851 [05:13<18:27,  1.30it/s]\u001b[A\n","Iteration:  22% 411/1851 [05:14<18:25,  1.30it/s]\u001b[A\n","Iteration:  22% 412/1851 [05:14<18:27,  1.30it/s]\u001b[A\n","Iteration:  22% 413/1851 [05:15<18:25,  1.30it/s]\u001b[A\n","Iteration:  22% 414/1851 [05:16<18:25,  1.30it/s]\u001b[A\n","Iteration:  22% 415/1851 [05:17<18:25,  1.30it/s]\u001b[A\n","Iteration:  22% 416/1851 [05:18<18:25,  1.30it/s]\u001b[A\n","Iteration:  23% 417/1851 [05:18<18:24,  1.30it/s]\u001b[A\n","Iteration:  23% 418/1851 [05:19<18:22,  1.30it/s]\u001b[A\n","Iteration:  23% 419/1851 [05:20<18:21,  1.30it/s]\u001b[A\n","Iteration:  23% 420/1851 [05:21<18:20,  1.30it/s]\u001b[A\n","Iteration:  23% 421/1851 [05:21<18:20,  1.30it/s]\u001b[A\n","Iteration:  23% 422/1851 [05:22<18:20,  1.30it/s]\u001b[A\n","Iteration:  23% 423/1851 [05:23<18:21,  1.30it/s]\u001b[A\n","Iteration:  23% 424/1851 [05:24<18:20,  1.30it/s]\u001b[A\n","Iteration:  23% 425/1851 [05:24<18:19,  1.30it/s]\u001b[A\n","Iteration:  23% 426/1851 [05:25<18:19,  1.30it/s]\u001b[A\n","Iteration:  23% 427/1851 [05:26<18:16,  1.30it/s]\u001b[A\n","Iteration:  23% 428/1851 [05:27<18:17,  1.30it/s]\u001b[A\n","Iteration:  23% 429/1851 [05:28<18:16,  1.30it/s]\u001b[A\n","Iteration:  23% 430/1851 [05:28<18:14,  1.30it/s]\u001b[A\n","Iteration:  23% 431/1851 [05:29<18:12,  1.30it/s]\u001b[A\n","Iteration:  23% 432/1851 [05:30<18:14,  1.30it/s]\u001b[A\n","Iteration:  23% 433/1851 [05:31<18:12,  1.30it/s]\u001b[A\n","Iteration:  23% 434/1851 [05:31<18:11,  1.30it/s]\u001b[A\n","Iteration:  24% 435/1851 [05:32<18:10,  1.30it/s]\u001b[A\n","Iteration:  24% 436/1851 [05:33<18:09,  1.30it/s]\u001b[A\n","Iteration:  24% 437/1851 [05:34<18:07,  1.30it/s]\u001b[A\n","Iteration:  24% 438/1851 [05:35<18:06,  1.30it/s]\u001b[A\n","Iteration:  24% 439/1851 [05:35<18:07,  1.30it/s]\u001b[A\n","Iteration:  24% 440/1851 [05:36<18:06,  1.30it/s]\u001b[A\n","Iteration:  24% 441/1851 [05:37<18:05,  1.30it/s]\u001b[A\n","Iteration:  24% 442/1851 [05:38<18:06,  1.30it/s]\u001b[A\n","Iteration:  24% 443/1851 [05:38<18:04,  1.30it/s]\u001b[A\n","Iteration:  24% 444/1851 [05:39<18:03,  1.30it/s]\u001b[A\n","Iteration:  24% 445/1851 [05:40<18:04,  1.30it/s]\u001b[A\n","Iteration:  24% 446/1851 [05:41<18:03,  1.30it/s]\u001b[A\n","Iteration:  24% 447/1851 [05:41<18:02,  1.30it/s]\u001b[A\n","Iteration:  24% 448/1851 [05:42<18:01,  1.30it/s]\u001b[A\n","Iteration:  24% 449/1851 [05:43<17:59,  1.30it/s]\u001b[A\n","Iteration:  24% 450/1851 [05:44<17:58,  1.30it/s]\u001b[A\n","Iteration:  24% 451/1851 [05:45<17:56,  1.30it/s]\u001b[A\n","Iteration:  24% 452/1851 [05:45<17:57,  1.30it/s]\u001b[A\n","Iteration:  24% 453/1851 [05:46<17:56,  1.30it/s]\u001b[A\n","Iteration:  25% 454/1851 [05:47<17:56,  1.30it/s]\u001b[A\n","Iteration:  25% 455/1851 [05:48<17:55,  1.30it/s]\u001b[A\n","Iteration:  25% 456/1851 [05:48<17:53,  1.30it/s]\u001b[A\n","Iteration:  25% 457/1851 [05:49<17:54,  1.30it/s]\u001b[A\n","Iteration:  25% 458/1851 [05:50<17:52,  1.30it/s]\u001b[A\n","Iteration:  25% 459/1851 [05:51<17:53,  1.30it/s]\u001b[A\n","Iteration:  25% 460/1851 [05:51<17:52,  1.30it/s]\u001b[A\n","Iteration:  25% 461/1851 [05:52<17:51,  1.30it/s]\u001b[A\n","Iteration:  25% 462/1851 [05:53<17:51,  1.30it/s]\u001b[A\n","Iteration:  25% 463/1851 [05:54<17:48,  1.30it/s]\u001b[A\n","Iteration:  25% 464/1851 [05:55<17:48,  1.30it/s]\u001b[A\n","Iteration:  25% 465/1851 [05:55<17:48,  1.30it/s]\u001b[A\n","Iteration:  25% 466/1851 [05:56<17:47,  1.30it/s]\u001b[A\n","Iteration:  25% 467/1851 [05:57<17:46,  1.30it/s]\u001b[A\n","Iteration:  25% 468/1851 [05:58<17:45,  1.30it/s]\u001b[A\n","Iteration:  25% 469/1851 [05:58<17:44,  1.30it/s]\u001b[A\n","Iteration:  25% 470/1851 [05:59<17:45,  1.30it/s]\u001b[A\n","Iteration:  25% 471/1851 [06:00<17:43,  1.30it/s]\u001b[A\n","Iteration:  25% 472/1851 [06:01<17:42,  1.30it/s]\u001b[A\n","Iteration:  26% 473/1851 [06:01<17:41,  1.30it/s]\u001b[A\n","Iteration:  26% 474/1851 [06:02<17:41,  1.30it/s]\u001b[A\n","Iteration:  26% 475/1851 [06:03<17:42,  1.30it/s]\u001b[A\n","Iteration:  26% 476/1851 [06:04<17:40,  1.30it/s]\u001b[A\n","Iteration:  26% 477/1851 [06:05<17:40,  1.30it/s]\u001b[A\n","Iteration:  26% 478/1851 [06:05<17:39,  1.30it/s]\u001b[A\n","Iteration:  26% 479/1851 [06:06<17:37,  1.30it/s]\u001b[A\n","Iteration:  26% 480/1851 [06:07<17:37,  1.30it/s]\u001b[A\n","Iteration:  26% 481/1851 [06:08<17:36,  1.30it/s]\u001b[A\n","Iteration:  26% 482/1851 [06:08<17:34,  1.30it/s]\u001b[A\n","Iteration:  26% 483/1851 [06:09<17:33,  1.30it/s]\u001b[A\n","Iteration:  26% 484/1851 [06:10<17:34,  1.30it/s]\u001b[A\n","Iteration:  26% 485/1851 [06:11<17:32,  1.30it/s]\u001b[A\n","Iteration:  26% 486/1851 [06:12<17:32,  1.30it/s]\u001b[A\n","Iteration:  26% 487/1851 [06:12<17:31,  1.30it/s]\u001b[A\n","Iteration:  26% 488/1851 [06:13<17:32,  1.30it/s]\u001b[A\n","Iteration:  26% 489/1851 [06:14<17:30,  1.30it/s]\u001b[A\n","Iteration:  26% 490/1851 [06:15<17:30,  1.30it/s]\u001b[A\n","Iteration:  27% 491/1851 [06:15<17:29,  1.30it/s]\u001b[A\n","Iteration:  27% 492/1851 [06:16<17:28,  1.30it/s]\u001b[A\n","Iteration:  27% 493/1851 [06:17<17:28,  1.30it/s]\u001b[A\n","Iteration:  27% 494/1851 [06:18<17:27,  1.30it/s]\u001b[A\n","Iteration:  27% 495/1851 [06:18<17:27,  1.29it/s]\u001b[A\n","Iteration:  27% 496/1851 [06:19<17:27,  1.29it/s]\u001b[A\n","Iteration:  27% 497/1851 [06:20<17:26,  1.29it/s]\u001b[A\n","Iteration:  27% 498/1851 [06:21<17:26,  1.29it/s]\u001b[A\n","Iteration:  27% 499/1851 [06:22<17:25,  1.29it/s]\u001b[A\n","Iteration:  27% 500/1851 [06:22<17:24,  1.29it/s]\u001b[A\n","Iteration:  27% 501/1851 [06:23<17:20,  1.30it/s]\u001b[A\n","Iteration:  27% 502/1851 [06:24<17:20,  1.30it/s]\u001b[A\n","Iteration:  27% 503/1851 [06:25<17:20,  1.30it/s]\u001b[A\n","Iteration:  27% 504/1851 [06:25<17:18,  1.30it/s]\u001b[A\n","Iteration:  27% 505/1851 [06:26<17:18,  1.30it/s]\u001b[A\n","Iteration:  27% 506/1851 [06:27<17:16,  1.30it/s]\u001b[A\n","Iteration:  27% 507/1851 [06:28<17:15,  1.30it/s]\u001b[A\n","Iteration:  27% 508/1851 [06:28<17:15,  1.30it/s]\u001b[A\n","Iteration:  27% 509/1851 [06:29<17:15,  1.30it/s]\u001b[A\n","Iteration:  28% 510/1851 [06:30<17:15,  1.29it/s]\u001b[A\n","Iteration:  28% 511/1851 [06:31<17:14,  1.29it/s]\u001b[A\n","Iteration:  28% 512/1851 [06:32<17:15,  1.29it/s]\u001b[A\n","Iteration:  28% 513/1851 [06:32<17:15,  1.29it/s]\u001b[A\n","Iteration:  28% 514/1851 [06:33<17:14,  1.29it/s]\u001b[A\n","Iteration:  28% 515/1851 [06:34<17:13,  1.29it/s]\u001b[A\n","Iteration:  28% 516/1851 [06:35<17:11,  1.29it/s]\u001b[A\n","Iteration:  28% 517/1851 [06:35<17:12,  1.29it/s]\u001b[A\n","Iteration:  28% 518/1851 [06:36<17:13,  1.29it/s]\u001b[A\n","Iteration:  28% 519/1851 [06:37<17:09,  1.29it/s]\u001b[A\n","Iteration:  28% 520/1851 [06:38<17:08,  1.29it/s]\u001b[A\n","Iteration:  28% 521/1851 [06:39<17:08,  1.29it/s]\u001b[A\n","Iteration:  28% 522/1851 [06:39<17:06,  1.29it/s]\u001b[A\n","Iteration:  28% 523/1851 [06:40<17:04,  1.30it/s]\u001b[A\n","Iteration:  28% 524/1851 [06:41<17:04,  1.29it/s]\u001b[A\n","Iteration:  28% 525/1851 [06:42<17:05,  1.29it/s]\u001b[A\n","Iteration:  28% 526/1851 [06:42<17:06,  1.29it/s]\u001b[A\n","Iteration:  28% 527/1851 [06:43<17:06,  1.29it/s]\u001b[A\n","Iteration:  29% 528/1851 [06:44<17:03,  1.29it/s]\u001b[A\n","Iteration:  29% 529/1851 [06:45<17:01,  1.29it/s]\u001b[A\n","Iteration:  29% 530/1851 [06:45<16:58,  1.30it/s]\u001b[A\n","Iteration:  29% 531/1851 [06:46<16:57,  1.30it/s]\u001b[A\n","Iteration:  29% 532/1851 [06:47<16:56,  1.30it/s]\u001b[A\n","Iteration:  29% 533/1851 [06:48<16:57,  1.30it/s]\u001b[A\n","Iteration:  29% 534/1851 [06:49<16:58,  1.29it/s]\u001b[A\n","Iteration:  29% 535/1851 [06:49<16:57,  1.29it/s]\u001b[A\n","Iteration:  29% 536/1851 [06:50<16:57,  1.29it/s]\u001b[A\n","Iteration:  29% 537/1851 [06:51<16:55,  1.29it/s]\u001b[A\n","Iteration:  29% 538/1851 [06:52<16:53,  1.30it/s]\u001b[A\n","Iteration:  29% 539/1851 [06:52<16:51,  1.30it/s]\u001b[A\n","Iteration:  29% 540/1851 [06:53<16:51,  1.30it/s]\u001b[A\n","Iteration:  29% 541/1851 [06:54<16:49,  1.30it/s]\u001b[A\n","Iteration:  29% 542/1851 [06:55<16:48,  1.30it/s]\u001b[A\n","Iteration:  29% 543/1851 [06:56<16:47,  1.30it/s]\u001b[A\n","Iteration:  29% 544/1851 [06:56<16:47,  1.30it/s]\u001b[A\n","Iteration:  29% 545/1851 [06:57<16:48,  1.30it/s]\u001b[A\n","Iteration:  29% 546/1851 [06:58<16:47,  1.29it/s]\u001b[A\n","Iteration:  30% 547/1851 [06:59<16:46,  1.30it/s]\u001b[A\n","Iteration:  30% 548/1851 [06:59<16:47,  1.29it/s]\u001b[A\n","Iteration:  30% 549/1851 [07:00<16:46,  1.29it/s]\u001b[A\n","Iteration:  30% 550/1851 [07:01<16:44,  1.29it/s]\u001b[A\n","Iteration:  30% 551/1851 [07:02<16:45,  1.29it/s]\u001b[A\n","Iteration:  30% 552/1851 [07:02<16:44,  1.29it/s]\u001b[A\n","Iteration:  30% 553/1851 [07:03<16:41,  1.30it/s]\u001b[A\n","Iteration:  30% 554/1851 [07:04<16:40,  1.30it/s]\u001b[A\n","Iteration:  30% 555/1851 [07:05<16:40,  1.30it/s]\u001b[A\n","Iteration:  30% 556/1851 [07:06<16:40,  1.29it/s]\u001b[A\n","Iteration:  30% 557/1851 [07:06<16:41,  1.29it/s]\u001b[A\n","Iteration:  30% 558/1851 [07:07<16:39,  1.29it/s]\u001b[A\n","Iteration:  30% 559/1851 [07:08<16:37,  1.30it/s]\u001b[A\n","Iteration:  30% 560/1851 [07:09<16:36,  1.30it/s]\u001b[A\n","Iteration:  30% 561/1851 [07:09<16:35,  1.30it/s]\u001b[A\n","Iteration:  30% 562/1851 [07:10<16:33,  1.30it/s]\u001b[A\n","Iteration:  30% 563/1851 [07:11<16:32,  1.30it/s]\u001b[A\n","Iteration:  30% 564/1851 [07:12<16:32,  1.30it/s]\u001b[A\n","Iteration:  31% 565/1851 [07:13<16:32,  1.30it/s]\u001b[A\n","Iteration:  31% 566/1851 [07:13<16:32,  1.29it/s]\u001b[A\n","Iteration:  31% 567/1851 [07:14<16:32,  1.29it/s]\u001b[A\n","Iteration:  31% 568/1851 [07:15<16:31,  1.29it/s]\u001b[A\n","Iteration:  31% 569/1851 [07:16<16:29,  1.30it/s]\u001b[A\n","Iteration:  31% 570/1851 [07:16<16:29,  1.29it/s]\u001b[A\n","Iteration:  31% 571/1851 [07:17<16:28,  1.29it/s]\u001b[A\n","Iteration:  31% 572/1851 [07:18<16:26,  1.30it/s]\u001b[A\n","Iteration:  31% 573/1851 [07:19<16:24,  1.30it/s]\u001b[A\n","Iteration:  31% 574/1851 [07:19<16:25,  1.30it/s]\u001b[A\n","Iteration:  31% 575/1851 [07:20<16:25,  1.30it/s]\u001b[A\n","Iteration:  31% 576/1851 [07:21<16:24,  1.30it/s]\u001b[A\n","Iteration:  31% 577/1851 [07:22<16:21,  1.30it/s]\u001b[A\n","Iteration:  31% 578/1851 [07:23<16:21,  1.30it/s]\u001b[A\n","Iteration:  31% 579/1851 [07:23<16:20,  1.30it/s]\u001b[A\n","Iteration:  31% 580/1851 [07:24<16:22,  1.29it/s]\u001b[A\n","Iteration:  31% 581/1851 [07:25<17:02,  1.24it/s]\u001b[A\n","Iteration:  31% 582/1851 [07:26<16:52,  1.25it/s]\u001b[A\n","Iteration:  31% 583/1851 [07:27<16:41,  1.27it/s]\u001b[A\n","Iteration:  32% 584/1851 [07:27<17:47,  1.19it/s]\u001b[A\n","Iteration:  32% 585/1851 [07:28<17:25,  1.21it/s]\u001b[A\n","Iteration:  32% 586/1851 [07:29<17:03,  1.24it/s]\u001b[A\n","Iteration:  32% 587/1851 [07:30<16:49,  1.25it/s]\u001b[A\n","Iteration:  32% 588/1851 [07:31<16:39,  1.26it/s]\u001b[A\n","Iteration:  32% 589/1851 [07:31<16:32,  1.27it/s]\u001b[A\n","Iteration:  32% 590/1851 [07:32<16:26,  1.28it/s]\u001b[A\n","Iteration:  32% 591/1851 [07:33<16:19,  1.29it/s]\u001b[A\n","Iteration:  32% 592/1851 [07:34<16:15,  1.29it/s]\u001b[A\n","Iteration:  32% 593/1851 [07:34<16:14,  1.29it/s]\u001b[A\n","Iteration:  32% 594/1851 [07:35<16:11,  1.29it/s]\u001b[A\n","Iteration:  32% 595/1851 [07:36<16:09,  1.30it/s]\u001b[A\n","Iteration:  32% 596/1851 [07:37<16:09,  1.29it/s]\u001b[A\n","Iteration:  32% 597/1851 [07:38<16:07,  1.30it/s]\u001b[A\n","Iteration:  32% 598/1851 [07:38<16:06,  1.30it/s]\u001b[A\n","Iteration:  32% 599/1851 [07:39<16:05,  1.30it/s]\u001b[A\n","Iteration:  32% 600/1851 [07:40<16:04,  1.30it/s]\u001b[A\n","Iteration:  32% 601/1851 [07:41<16:05,  1.30it/s]\u001b[A\n","Iteration:  33% 602/1851 [07:41<16:02,  1.30it/s]\u001b[A\n","Iteration:  33% 603/1851 [07:42<16:00,  1.30it/s]\u001b[A\n","Iteration:  33% 604/1851 [07:43<16:00,  1.30it/s]\u001b[A\n","Iteration:  33% 605/1851 [07:44<16:00,  1.30it/s]\u001b[A\n","Iteration:  33% 606/1851 [07:44<15:59,  1.30it/s]\u001b[A\n","Iteration:  33% 607/1851 [07:45<15:57,  1.30it/s]\u001b[A\n","Iteration:  33% 608/1851 [07:46<15:57,  1.30it/s]\u001b[A\n","Iteration:  33% 609/1851 [07:47<15:57,  1.30it/s]\u001b[A\n","Iteration:  33% 610/1851 [07:48<15:55,  1.30it/s]\u001b[A\n","Iteration:  33% 611/1851 [07:48<15:56,  1.30it/s]\u001b[A\n","Iteration:  33% 612/1851 [07:49<15:54,  1.30it/s]\u001b[A\n","Iteration:  33% 613/1851 [07:50<15:53,  1.30it/s]\u001b[A\n","Iteration:  33% 614/1851 [07:51<15:52,  1.30it/s]\u001b[A\n","Iteration:  33% 615/1851 [07:51<15:52,  1.30it/s]\u001b[A\n","Iteration:  33% 616/1851 [07:52<15:51,  1.30it/s]\u001b[A\n","Iteration:  33% 617/1851 [07:53<15:50,  1.30it/s]\u001b[A\n","Iteration:  33% 618/1851 [07:54<15:49,  1.30it/s]\u001b[A\n","Iteration:  33% 619/1851 [07:54<15:47,  1.30it/s]\u001b[A\n","Iteration:  33% 620/1851 [07:55<15:48,  1.30it/s]\u001b[A\n","Iteration:  34% 621/1851 [07:56<15:48,  1.30it/s]\u001b[A\n","Iteration:  34% 622/1851 [07:57<15:47,  1.30it/s]\u001b[A\n","Iteration:  34% 623/1851 [07:58<15:47,  1.30it/s]\u001b[A\n","Iteration:  34% 624/1851 [07:58<15:45,  1.30it/s]\u001b[A\n","Iteration:  34% 625/1851 [07:59<15:43,  1.30it/s]\u001b[A\n","Iteration:  34% 626/1851 [08:00<15:43,  1.30it/s]\u001b[A\n","Iteration:  34% 627/1851 [08:01<15:43,  1.30it/s]\u001b[A\n","Iteration:  34% 628/1851 [08:01<15:42,  1.30it/s]\u001b[A\n","Iteration:  34% 629/1851 [08:02<15:42,  1.30it/s]\u001b[A\n","Iteration:  34% 630/1851 [08:03<15:41,  1.30it/s]\u001b[A\n","Iteration:  34% 631/1851 [08:04<15:41,  1.30it/s]\u001b[A\n","Iteration:  34% 632/1851 [08:05<15:40,  1.30it/s]\u001b[A\n","Iteration:  34% 633/1851 [08:05<15:40,  1.29it/s]\u001b[A\n","Iteration:  34% 634/1851 [08:06<15:38,  1.30it/s]\u001b[A\n","Iteration:  34% 635/1851 [08:07<15:36,  1.30it/s]\u001b[A\n","Iteration:  34% 636/1851 [08:08<15:36,  1.30it/s]\u001b[A\n","Iteration:  34% 637/1851 [08:08<15:34,  1.30it/s]\u001b[A\n","Iteration:  34% 638/1851 [08:09<15:34,  1.30it/s]\u001b[A\n","Iteration:  35% 639/1851 [08:10<15:33,  1.30it/s]\u001b[A\n","Iteration:  35% 640/1851 [08:11<15:33,  1.30it/s]\u001b[A\n","Iteration:  35% 641/1851 [08:11<15:32,  1.30it/s]\u001b[A\n","Iteration:  35% 642/1851 [08:12<15:31,  1.30it/s]\u001b[A\n","Iteration:  35% 643/1851 [08:13<15:29,  1.30it/s]\u001b[A\n","Iteration:  35% 644/1851 [08:14<15:29,  1.30it/s]\u001b[A\n","Iteration:  35% 645/1851 [08:15<15:29,  1.30it/s]\u001b[A\n","Iteration:  35% 646/1851 [08:15<15:29,  1.30it/s]\u001b[A\n","Iteration:  35% 647/1851 [08:16<15:28,  1.30it/s]\u001b[A\n","Iteration:  35% 648/1851 [08:17<15:28,  1.30it/s]\u001b[A\n","Iteration:  35% 649/1851 [08:18<15:27,  1.30it/s]\u001b[A\n","Iteration:  35% 650/1851 [08:18<15:24,  1.30it/s]\u001b[A\n","Iteration:  35% 651/1851 [08:19<15:23,  1.30it/s]\u001b[A\n","Iteration:  35% 652/1851 [08:20<15:22,  1.30it/s]\u001b[A\n","Iteration:  35% 653/1851 [08:21<15:22,  1.30it/s]\u001b[A\n","Iteration:  35% 654/1851 [08:21<15:20,  1.30it/s]\u001b[A\n","Iteration:  35% 655/1851 [08:22<15:23,  1.30it/s]\u001b[A\n","Iteration:  35% 656/1851 [08:23<15:23,  1.29it/s]\u001b[A\n","Iteration:  35% 657/1851 [08:24<15:22,  1.29it/s]\u001b[A\n","Iteration:  36% 658/1851 [08:25<15:22,  1.29it/s]\u001b[A\n","Iteration:  36% 659/1851 [08:25<15:20,  1.30it/s]\u001b[A\n","Iteration:  36% 660/1851 [08:26<15:19,  1.30it/s]\u001b[A\n","Iteration:  36% 661/1851 [08:27<15:18,  1.30it/s]\u001b[A\n","Iteration:  36% 662/1851 [08:28<15:17,  1.30it/s]\u001b[A\n","Iteration:  36% 663/1851 [08:28<15:16,  1.30it/s]\u001b[A\n","Iteration:  36% 664/1851 [08:29<15:16,  1.29it/s]\u001b[A\n","Iteration:  36% 665/1851 [08:30<15:16,  1.29it/s]\u001b[A\n","Iteration:  36% 666/1851 [08:31<15:15,  1.29it/s]\u001b[A\n","Iteration:  36% 667/1851 [08:31<15:12,  1.30it/s]\u001b[A\n","Iteration:  36% 668/1851 [08:32<15:12,  1.30it/s]\u001b[A\n","Iteration:  36% 669/1851 [08:33<15:11,  1.30it/s]\u001b[A\n","Iteration:  36% 670/1851 [08:34<15:09,  1.30it/s]\u001b[A\n","Iteration:  36% 671/1851 [08:35<15:08,  1.30it/s]\u001b[A\n","Iteration:  36% 672/1851 [08:35<15:09,  1.30it/s]\u001b[A\n","Iteration:  36% 673/1851 [08:36<15:07,  1.30it/s]\u001b[A\n","Iteration:  36% 674/1851 [08:37<15:06,  1.30it/s]\u001b[A\n","Iteration:  36% 675/1851 [08:38<15:05,  1.30it/s]\u001b[A\n","Iteration:  37% 676/1851 [08:38<15:04,  1.30it/s]\u001b[A\n","Iteration:  37% 677/1851 [08:39<15:04,  1.30it/s]\u001b[A\n","Iteration:  37% 678/1851 [08:40<15:03,  1.30it/s]\u001b[A\n","Iteration:  37% 679/1851 [08:41<15:03,  1.30it/s]\u001b[A\n","Iteration:  37% 680/1851 [08:42<15:01,  1.30it/s]\u001b[A\n","Iteration:  37% 681/1851 [08:42<15:01,  1.30it/s]\u001b[A\n","Iteration:  37% 682/1851 [08:43<15:00,  1.30it/s]\u001b[A\n","Iteration:  37% 683/1851 [08:44<15:00,  1.30it/s]\u001b[A\n","Iteration:  37% 684/1851 [08:45<14:59,  1.30it/s]\u001b[A\n","Iteration:  37% 685/1851 [08:45<14:58,  1.30it/s]\u001b[A\n","Iteration:  37% 686/1851 [08:46<14:58,  1.30it/s]\u001b[A\n","Iteration:  37% 687/1851 [08:47<14:57,  1.30it/s]\u001b[A\n","Iteration:  37% 688/1851 [08:48<14:55,  1.30it/s]\u001b[A\n","Iteration:  37% 689/1851 [08:48<14:55,  1.30it/s]\u001b[A\n","Iteration:  37% 690/1851 [08:49<14:54,  1.30it/s]\u001b[A\n","Iteration:  37% 691/1851 [08:50<14:52,  1.30it/s]\u001b[A\n","Iteration:  37% 692/1851 [08:51<14:52,  1.30it/s]\u001b[A\n","Iteration:  37% 693/1851 [08:52<14:50,  1.30it/s]\u001b[A\n","Iteration:  37% 694/1851 [08:52<14:51,  1.30it/s]\u001b[A\n","Iteration:  38% 695/1851 [08:53<14:52,  1.30it/s]\u001b[A\n","Iteration:  38% 696/1851 [08:54<14:50,  1.30it/s]\u001b[A\n","Iteration:  38% 697/1851 [08:55<14:48,  1.30it/s]\u001b[A\n","Iteration:  38% 698/1851 [08:55<14:49,  1.30it/s]\u001b[A\n","Iteration:  38% 699/1851 [08:56<14:48,  1.30it/s]\u001b[A\n","Iteration:  38% 700/1851 [08:57<14:46,  1.30it/s]\u001b[A\n","Iteration:  38% 701/1851 [08:58<14:45,  1.30it/s]\u001b[A\n","Iteration:  38% 702/1851 [08:58<14:45,  1.30it/s]\u001b[A\n","Iteration:  38% 703/1851 [08:59<14:45,  1.30it/s]\u001b[A\n","Iteration:  38% 704/1851 [09:00<14:42,  1.30it/s]\u001b[A\n","Iteration:  38% 705/1851 [09:01<14:41,  1.30it/s]\u001b[A\n","Iteration:  38% 706/1851 [09:02<14:42,  1.30it/s]\u001b[A\n","Iteration:  38% 707/1851 [09:02<14:39,  1.30it/s]\u001b[A\n","Iteration:  38% 708/1851 [09:03<14:40,  1.30it/s]\u001b[A\n","Iteration:  38% 709/1851 [09:04<14:40,  1.30it/s]\u001b[A\n","Iteration:  38% 710/1851 [09:05<14:38,  1.30it/s]\u001b[A\n","Iteration:  38% 711/1851 [09:05<14:38,  1.30it/s]\u001b[A\n","Iteration:  38% 712/1851 [09:06<14:38,  1.30it/s]\u001b[A\n","Iteration:  39% 713/1851 [09:07<14:37,  1.30it/s]\u001b[A\n","Iteration:  39% 714/1851 [09:08<14:36,  1.30it/s]\u001b[A\n","Iteration:  39% 715/1851 [09:08<14:34,  1.30it/s]\u001b[A\n","Iteration:  39% 716/1851 [09:09<14:33,  1.30it/s]\u001b[A\n","Iteration:  39% 717/1851 [09:10<14:33,  1.30it/s]\u001b[A\n","Iteration:  39% 718/1851 [09:11<14:31,  1.30it/s]\u001b[A\n","Iteration:  39% 719/1851 [09:12<14:32,  1.30it/s]\u001b[A\n","Iteration:  39% 720/1851 [09:12<14:31,  1.30it/s]\u001b[A\n","Iteration:  39% 721/1851 [09:13<14:31,  1.30it/s]\u001b[A\n","Iteration:  39% 722/1851 [09:14<14:30,  1.30it/s]\u001b[A\n","Iteration:  39% 723/1851 [09:15<14:30,  1.30it/s]\u001b[A\n","Iteration:  39% 724/1851 [09:15<14:29,  1.30it/s]\u001b[A\n","Iteration:  39% 725/1851 [09:16<14:28,  1.30it/s]\u001b[A\n","Iteration:  39% 726/1851 [09:17<14:27,  1.30it/s]\u001b[A\n","Iteration:  39% 727/1851 [09:18<14:27,  1.30it/s]\u001b[A\n","Iteration:  39% 728/1851 [09:19<14:26,  1.30it/s]\u001b[A\n","Iteration:  39% 729/1851 [09:19<14:25,  1.30it/s]\u001b[A\n","Iteration:  39% 730/1851 [09:20<14:25,  1.30it/s]\u001b[A\n","Iteration:  39% 731/1851 [09:21<14:24,  1.30it/s]\u001b[A\n","Iteration:  40% 732/1851 [09:22<14:24,  1.29it/s]\u001b[A\n","Iteration:  40% 733/1851 [09:22<14:22,  1.30it/s]\u001b[A\n","Iteration:  40% 734/1851 [09:23<14:20,  1.30it/s]\u001b[A\n","Iteration:  40% 735/1851 [09:24<14:19,  1.30it/s]\u001b[A\n","Iteration:  40% 736/1851 [09:25<14:19,  1.30it/s]\u001b[A\n","Iteration:  40% 737/1851 [09:25<14:19,  1.30it/s]\u001b[A\n","Iteration:  40% 738/1851 [09:26<14:19,  1.30it/s]\u001b[A\n","Iteration:  40% 739/1851 [09:27<14:17,  1.30it/s]\u001b[A\n","Iteration:  40% 740/1851 [09:28<14:15,  1.30it/s]\u001b[A\n","Iteration:  40% 741/1851 [09:29<14:14,  1.30it/s]\u001b[A\n","Iteration:  40% 742/1851 [09:29<14:14,  1.30it/s]\u001b[A\n","Iteration:  40% 743/1851 [09:30<14:14,  1.30it/s]\u001b[A\n","Iteration:  40% 744/1851 [09:31<14:13,  1.30it/s]\u001b[A\n","Iteration:  40% 745/1851 [09:32<14:13,  1.30it/s]\u001b[A\n","Iteration:  40% 746/1851 [09:32<14:12,  1.30it/s]\u001b[A\n","Iteration:  40% 747/1851 [09:33<14:11,  1.30it/s]\u001b[A\n","Iteration:  40% 748/1851 [09:34<14:11,  1.30it/s]\u001b[A\n","Iteration:  40% 749/1851 [09:35<14:09,  1.30it/s]\u001b[A\n","Iteration:  41% 750/1851 [09:35<14:09,  1.30it/s]\u001b[A\n","Iteration:  41% 751/1851 [09:36<14:09,  1.30it/s]\u001b[A\n","Iteration:  41% 752/1851 [09:37<14:08,  1.30it/s]\u001b[A\n","Iteration:  41% 753/1851 [09:38<14:07,  1.29it/s]\u001b[A\n","Iteration:  41% 754/1851 [09:39<14:07,  1.29it/s]\u001b[A\n","Iteration:  41% 755/1851 [09:39<14:05,  1.30it/s]\u001b[A\n","Iteration:  41% 756/1851 [09:40<14:04,  1.30it/s]\u001b[A\n","Iteration:  41% 757/1851 [09:41<14:04,  1.30it/s]\u001b[A\n","Iteration:  41% 758/1851 [09:42<14:02,  1.30it/s]\u001b[A\n","Iteration:  41% 759/1851 [09:42<14:02,  1.30it/s]\u001b[A\n","Iteration:  41% 760/1851 [09:43<14:01,  1.30it/s]\u001b[A\n","Iteration:  41% 761/1851 [09:44<14:00,  1.30it/s]\u001b[A\n","Iteration:  41% 762/1851 [09:45<14:00,  1.30it/s]\u001b[A\n","Iteration:  41% 763/1851 [09:45<13:58,  1.30it/s]\u001b[A\n","Iteration:  41% 764/1851 [09:46<13:57,  1.30it/s]\u001b[A\n","Iteration:  41% 765/1851 [09:47<13:56,  1.30it/s]\u001b[A\n","Iteration:  41% 766/1851 [09:48<13:57,  1.30it/s]\u001b[A\n","Iteration:  41% 767/1851 [09:49<13:56,  1.30it/s]\u001b[A\n","Iteration:  41% 768/1851 [09:49<13:55,  1.30it/s]\u001b[A\n","Iteration:  42% 769/1851 [09:50<13:54,  1.30it/s]\u001b[A\n","Iteration:  42% 770/1851 [09:51<13:53,  1.30it/s]\u001b[A\n","Iteration:  42% 771/1851 [09:52<13:54,  1.29it/s]\u001b[A\n","Iteration:  42% 772/1851 [09:52<13:53,  1.29it/s]\u001b[A\n","Iteration:  42% 773/1851 [09:53<13:53,  1.29it/s]\u001b[A\n","Iteration:  42% 774/1851 [09:54<13:51,  1.30it/s]\u001b[A\n","Iteration:  42% 775/1851 [09:55<13:51,  1.29it/s]\u001b[A\n","Iteration:  42% 776/1851 [09:56<13:48,  1.30it/s]\u001b[A\n","Iteration:  42% 777/1851 [09:56<13:47,  1.30it/s]\u001b[A\n","Iteration:  42% 778/1851 [09:57<13:47,  1.30it/s]\u001b[A\n","Iteration:  42% 779/1851 [09:58<13:46,  1.30it/s]\u001b[A\n","Iteration:  42% 780/1851 [09:59<13:45,  1.30it/s]\u001b[A\n","Iteration:  42% 781/1851 [09:59<13:44,  1.30it/s]\u001b[A\n","Iteration:  42% 782/1851 [10:00<13:44,  1.30it/s]\u001b[A\n","Iteration:  42% 783/1851 [10:01<13:43,  1.30it/s]\u001b[A\n","Iteration:  42% 784/1851 [10:02<13:42,  1.30it/s]\u001b[A\n","Iteration:  42% 785/1851 [10:02<13:41,  1.30it/s]\u001b[A\n","Iteration:  42% 786/1851 [10:03<13:40,  1.30it/s]\u001b[A\n","Iteration:  43% 787/1851 [10:04<13:40,  1.30it/s]\u001b[A\n","Iteration:  43% 788/1851 [10:05<13:40,  1.30it/s]\u001b[A\n","Iteration:  43% 789/1851 [10:06<13:40,  1.29it/s]\u001b[A\n","Iteration:  43% 790/1851 [10:06<13:40,  1.29it/s]\u001b[A\n","Iteration:  43% 791/1851 [10:07<13:39,  1.29it/s]\u001b[A\n","Iteration:  43% 792/1851 [10:08<13:37,  1.30it/s]\u001b[A\n","Iteration:  43% 793/1851 [10:09<13:36,  1.30it/s]\u001b[A\n","Iteration:  43% 794/1851 [10:09<13:34,  1.30it/s]\u001b[A\n","Iteration:  43% 795/1851 [10:10<13:33,  1.30it/s]\u001b[A\n","Iteration:  43% 796/1851 [10:11<13:33,  1.30it/s]\u001b[A\n","Iteration:  43% 797/1851 [10:12<13:31,  1.30it/s]\u001b[A\n","Iteration:  43% 798/1851 [10:12<13:29,  1.30it/s]\u001b[A\n","Iteration:  43% 799/1851 [10:13<13:30,  1.30it/s]\u001b[A\n","Iteration:  43% 800/1851 [10:14<13:29,  1.30it/s]\u001b[A\n","Iteration:  43% 801/1851 [10:15<13:30,  1.30it/s]\u001b[A\n","Iteration:  43% 802/1851 [10:16<13:27,  1.30it/s]\u001b[A\n","Iteration:  43% 803/1851 [10:16<13:28,  1.30it/s]\u001b[A\n","Iteration:  43% 804/1851 [10:17<13:27,  1.30it/s]\u001b[A\n","Iteration:  43% 805/1851 [10:18<13:27,  1.30it/s]\u001b[A\n","Iteration:  44% 806/1851 [10:19<13:26,  1.29it/s]\u001b[A\n","Iteration:  44% 807/1851 [10:19<13:24,  1.30it/s]\u001b[A\n","Iteration:  44% 808/1851 [10:20<13:24,  1.30it/s]\u001b[A\n","Iteration:  44% 809/1851 [10:21<13:23,  1.30it/s]\u001b[A\n","Iteration:  44% 810/1851 [10:22<13:22,  1.30it/s]\u001b[A\n","Iteration:  44% 811/1851 [10:23<13:21,  1.30it/s]\u001b[A\n","Iteration:  44% 812/1851 [10:23<13:19,  1.30it/s]\u001b[A\n","Iteration:  44% 813/1851 [10:24<13:20,  1.30it/s]\u001b[A\n","Iteration:  44% 814/1851 [10:25<13:18,  1.30it/s]\u001b[A\n","Iteration:  44% 815/1851 [10:26<13:18,  1.30it/s]\u001b[A\n","Iteration:  44% 816/1851 [10:26<13:17,  1.30it/s]\u001b[A\n","Iteration:  44% 817/1851 [10:27<13:17,  1.30it/s]\u001b[A\n","Iteration:  44% 818/1851 [10:28<13:15,  1.30it/s]\u001b[A\n","Iteration:  44% 819/1851 [10:29<13:13,  1.30it/s]\u001b[A\n","Iteration:  44% 820/1851 [10:29<13:14,  1.30it/s]\u001b[A\n","Iteration:  44% 821/1851 [10:30<13:12,  1.30it/s]\u001b[A\n","Iteration:  44% 822/1851 [10:31<13:13,  1.30it/s]\u001b[A\n","Iteration:  44% 823/1851 [10:32<13:11,  1.30it/s]\u001b[A\n","Iteration:  45% 824/1851 [10:33<13:10,  1.30it/s]\u001b[A\n","Iteration:  45% 825/1851 [10:33<13:10,  1.30it/s]\u001b[A\n","Iteration:  45% 826/1851 [10:34<13:09,  1.30it/s]\u001b[A\n","Iteration:  45% 827/1851 [10:35<13:08,  1.30it/s]\u001b[A\n","Iteration:  45% 828/1851 [10:36<13:08,  1.30it/s]\u001b[A\n","Iteration:  45% 829/1851 [10:36<13:06,  1.30it/s]\u001b[A\n","Iteration:  45% 830/1851 [10:37<13:07,  1.30it/s]\u001b[A\n","Iteration:  45% 831/1851 [10:38<13:06,  1.30it/s]\u001b[A\n","Iteration:  45% 832/1851 [10:39<13:06,  1.30it/s]\u001b[A\n","Iteration:  45% 833/1851 [10:39<13:06,  1.30it/s]\u001b[A\n","Iteration:  45% 834/1851 [10:40<13:04,  1.30it/s]\u001b[A\n","Iteration:  45% 835/1851 [10:41<13:03,  1.30it/s]\u001b[A\n","Iteration:  45% 836/1851 [10:42<13:01,  1.30it/s]\u001b[A\n","Iteration:  45% 837/1851 [10:43<13:01,  1.30it/s]\u001b[A\n","Iteration:  45% 838/1851 [10:43<13:01,  1.30it/s]\u001b[A\n","Iteration:  45% 839/1851 [10:44<12:59,  1.30it/s]\u001b[A\n","Iteration:  45% 840/1851 [10:45<12:59,  1.30it/s]\u001b[A\n","Iteration:  45% 841/1851 [10:46<12:58,  1.30it/s]\u001b[A\n","Iteration:  45% 842/1851 [10:46<12:58,  1.30it/s]\u001b[A\n","Iteration:  46% 843/1851 [10:47<12:57,  1.30it/s]\u001b[A\n","Iteration:  46% 844/1851 [10:48<12:57,  1.30it/s]\u001b[A\n","Iteration:  46% 845/1851 [10:49<12:56,  1.30it/s]\u001b[A\n","Iteration:  46% 846/1851 [10:49<12:55,  1.30it/s]\u001b[A\n","Iteration:  46% 847/1851 [10:50<12:55,  1.29it/s]\u001b[A\n","Iteration:  46% 848/1851 [10:51<12:53,  1.30it/s]\u001b[A\n","Iteration:  46% 849/1851 [10:52<12:52,  1.30it/s]\u001b[A\n","Iteration:  46% 850/1851 [10:53<12:51,  1.30it/s]\u001b[A\n","Iteration:  46% 851/1851 [10:53<12:50,  1.30it/s]\u001b[A\n","Iteration:  46% 852/1851 [10:54<12:50,  1.30it/s]\u001b[A\n","Iteration:  46% 853/1851 [10:55<12:50,  1.30it/s]\u001b[A\n","Iteration:  46% 854/1851 [10:56<12:48,  1.30it/s]\u001b[A\n","Iteration:  46% 855/1851 [10:56<12:48,  1.30it/s]\u001b[A\n","Iteration:  46% 856/1851 [10:57<12:48,  1.29it/s]\u001b[A\n","Iteration:  46% 857/1851 [10:58<12:47,  1.29it/s]\u001b[A\n","Iteration:  46% 858/1851 [10:59<12:46,  1.30it/s]\u001b[A\n","Iteration:  46% 859/1851 [11:00<12:46,  1.29it/s]\u001b[A\n","Iteration:  46% 860/1851 [11:00<12:45,  1.30it/s]\u001b[A\n","Iteration:  47% 861/1851 [11:01<12:44,  1.30it/s]\u001b[A\n","Iteration:  47% 862/1851 [11:02<12:44,  1.29it/s]\u001b[A\n","Iteration:  47% 863/1851 [11:03<12:43,  1.29it/s]\u001b[A\n","Iteration:  47% 864/1851 [11:03<12:40,  1.30it/s]\u001b[A\n","Iteration:  47% 865/1851 [11:04<12:40,  1.30it/s]\u001b[A\n","Iteration:  47% 866/1851 [11:05<12:40,  1.29it/s]\u001b[A\n","Iteration:  47% 867/1851 [11:06<12:39,  1.29it/s]\u001b[A\n","Iteration:  47% 868/1851 [11:06<12:38,  1.30it/s]\u001b[A\n","Iteration:  47% 869/1851 [11:07<12:37,  1.30it/s]\u001b[A\n","Iteration:  47% 870/1851 [11:08<12:38,  1.29it/s]\u001b[A\n","Iteration:  47% 871/1851 [11:09<12:37,  1.29it/s]\u001b[A\n","Iteration:  47% 872/1851 [11:10<12:36,  1.29it/s]\u001b[A\n","Iteration:  47% 873/1851 [11:10<12:34,  1.30it/s]\u001b[A\n","Iteration:  47% 874/1851 [11:11<12:33,  1.30it/s]\u001b[A\n","Iteration:  47% 875/1851 [11:12<12:32,  1.30it/s]\u001b[A\n","Iteration:  47% 876/1851 [11:13<12:31,  1.30it/s]\u001b[A\n","Iteration:  47% 877/1851 [11:13<12:31,  1.30it/s]\u001b[A\n","Iteration:  47% 878/1851 [11:14<12:30,  1.30it/s]\u001b[A\n","Iteration:  47% 879/1851 [11:15<12:30,  1.30it/s]\u001b[A\n","Iteration:  48% 880/1851 [11:16<12:28,  1.30it/s]\u001b[A\n","Iteration:  48% 881/1851 [11:17<12:27,  1.30it/s]\u001b[A\n","Iteration:  48% 882/1851 [11:17<12:27,  1.30it/s]\u001b[A\n","Iteration:  48% 883/1851 [11:18<12:25,  1.30it/s]\u001b[A\n","Iteration:  48% 884/1851 [11:19<12:25,  1.30it/s]\u001b[A\n","Iteration:  48% 885/1851 [11:20<12:24,  1.30it/s]\u001b[A\n","Iteration:  48% 886/1851 [11:20<12:24,  1.30it/s]\u001b[A\n","Iteration:  48% 887/1851 [11:21<12:22,  1.30it/s]\u001b[A\n","Iteration:  48% 888/1851 [11:22<12:22,  1.30it/s]\u001b[A\n","Iteration:  48% 889/1851 [11:23<12:22,  1.29it/s]\u001b[A\n","Iteration:  48% 890/1851 [11:23<12:23,  1.29it/s]\u001b[A\n","Iteration:  48% 891/1851 [11:24<12:22,  1.29it/s]\u001b[A\n","Iteration:  48% 892/1851 [11:25<12:22,  1.29it/s]\u001b[A\n","Iteration:  48% 893/1851 [11:26<12:20,  1.29it/s]\u001b[A\n","Iteration:  48% 894/1851 [11:27<13:17,  1.20it/s]\u001b[A\n","Iteration:  48% 895/1851 [11:28<13:03,  1.22it/s]\u001b[A\n","Iteration:  48% 896/1851 [11:28<12:50,  1.24it/s]\u001b[A\n","Iteration:  48% 897/1851 [11:29<12:38,  1.26it/s]\u001b[A\n","Iteration:  49% 898/1851 [11:30<12:30,  1.27it/s]\u001b[A\n","Iteration:  49% 899/1851 [11:31<12:26,  1.28it/s]\u001b[A\n","Iteration:  49% 900/1851 [11:31<12:22,  1.28it/s]\u001b[A\n","Iteration:  49% 901/1851 [11:32<12:18,  1.29it/s]\u001b[A\n","Iteration:  49% 902/1851 [11:33<12:16,  1.29it/s]\u001b[A\n","Iteration:  49% 903/1851 [11:34<12:14,  1.29it/s]\u001b[A\n","Iteration:  49% 904/1851 [11:34<12:12,  1.29it/s]\u001b[A\n","Iteration:  49% 905/1851 [11:35<12:10,  1.30it/s]\u001b[A\n","Iteration:  49% 906/1851 [11:36<12:09,  1.30it/s]\u001b[A\n","Iteration:  49% 907/1851 [11:37<12:09,  1.29it/s]\u001b[A\n","Iteration:  49% 908/1851 [11:38<12:06,  1.30it/s]\u001b[A\n","Iteration:  49% 909/1851 [11:38<12:06,  1.30it/s]\u001b[A\n","Iteration:  49% 910/1851 [11:39<12:05,  1.30it/s]\u001b[A\n","Iteration:  49% 911/1851 [11:40<12:05,  1.30it/s]\u001b[A\n","Iteration:  49% 912/1851 [11:41<12:04,  1.30it/s]\u001b[A\n","Iteration:  49% 913/1851 [11:41<12:02,  1.30it/s]\u001b[A\n","Iteration:  49% 914/1851 [11:42<12:02,  1.30it/s]\u001b[A\n","Iteration:  49% 915/1851 [11:43<12:02,  1.30it/s]\u001b[A\n","Iteration:  49% 916/1851 [11:44<12:01,  1.30it/s]\u001b[A\n","Iteration:  50% 917/1851 [11:45<12:00,  1.30it/s]\u001b[A\n","Iteration:  50% 918/1851 [11:45<12:00,  1.29it/s]\u001b[A\n","Iteration:  50% 919/1851 [11:46<12:00,  1.29it/s]\u001b[A\n","Iteration:  50% 920/1851 [11:47<11:59,  1.29it/s]\u001b[A\n","Iteration:  50% 921/1851 [11:48<11:58,  1.29it/s]\u001b[A\n","Iteration:  50% 922/1851 [11:48<11:58,  1.29it/s]\u001b[A\n","Iteration:  50% 923/1851 [11:49<11:56,  1.29it/s]\u001b[A\n","Iteration:  50% 924/1851 [11:50<11:56,  1.29it/s]\u001b[A\n","Iteration:  50% 925/1851 [11:51<11:56,  1.29it/s]\u001b[A\n","Iteration:  50% 926/1851 [11:51<11:54,  1.30it/s]\u001b[A\n","Iteration:  50% 927/1851 [11:52<11:54,  1.29it/s]\u001b[A\n","Iteration:  50% 928/1851 [11:53<11:52,  1.30it/s]\u001b[A\n","Iteration:  50% 929/1851 [11:54<11:52,  1.29it/s]\u001b[A\n","Iteration:  50% 930/1851 [11:55<11:51,  1.29it/s]\u001b[A\n","Iteration:  50% 931/1851 [11:55<11:50,  1.30it/s]\u001b[A\n","Iteration:  50% 932/1851 [11:56<11:50,  1.29it/s]\u001b[A\n","Iteration:  50% 933/1851 [11:57<11:50,  1.29it/s]\u001b[A\n","Iteration:  50% 934/1851 [11:58<11:49,  1.29it/s]\u001b[A\n","Iteration:  51% 935/1851 [11:58<11:48,  1.29it/s]\u001b[A\n","Iteration:  51% 936/1851 [11:59<11:48,  1.29it/s]\u001b[A\n","Iteration:  51% 937/1851 [12:00<11:47,  1.29it/s]\u001b[A\n","Iteration:  51% 938/1851 [12:01<11:47,  1.29it/s]\u001b[A\n","Iteration:  51% 939/1851 [12:02<11:45,  1.29it/s]\u001b[A\n","Iteration:  51% 940/1851 [12:02<11:46,  1.29it/s]\u001b[A\n","Iteration:  51% 941/1851 [12:03<11:44,  1.29it/s]\u001b[A\n","Iteration:  51% 942/1851 [12:04<11:43,  1.29it/s]\u001b[A\n","Iteration:  51% 943/1851 [12:05<11:42,  1.29it/s]\u001b[A\n","Iteration:  51% 944/1851 [12:05<11:40,  1.29it/s]\u001b[A\n","Iteration:  51% 945/1851 [12:06<11:38,  1.30it/s]\u001b[A\n","Iteration:  51% 946/1851 [12:07<11:38,  1.30it/s]\u001b[A\n","Iteration:  51% 947/1851 [12:08<11:37,  1.30it/s]\u001b[A\n","Iteration:  51% 948/1851 [12:08<11:37,  1.29it/s]\u001b[A\n","Iteration:  51% 949/1851 [12:09<11:36,  1.29it/s]\u001b[A\n","Iteration:  51% 950/1851 [12:10<11:36,  1.29it/s]\u001b[A\n","Iteration:  51% 951/1851 [12:11<11:36,  1.29it/s]\u001b[A\n","Iteration:  51% 952/1851 [12:12<11:35,  1.29it/s]\u001b[A\n","Iteration:  51% 953/1851 [12:12<11:34,  1.29it/s]\u001b[A\n","Iteration:  52% 954/1851 [12:13<11:32,  1.30it/s]\u001b[A\n","Iteration:  52% 955/1851 [12:14<11:30,  1.30it/s]\u001b[A\n","Iteration:  52% 956/1851 [12:15<11:29,  1.30it/s]\u001b[A\n","Iteration:  52% 957/1851 [12:15<11:28,  1.30it/s]\u001b[A\n","Iteration:  52% 958/1851 [12:16<11:28,  1.30it/s]\u001b[A\n","Iteration:  52% 959/1851 [12:17<11:27,  1.30it/s]\u001b[A\n","Iteration:  52% 960/1851 [12:18<11:27,  1.30it/s]\u001b[A\n","Iteration:  52% 961/1851 [12:19<11:27,  1.29it/s]\u001b[A\n","Iteration:  52% 962/1851 [12:19<11:27,  1.29it/s]\u001b[A\n","Iteration:  52% 963/1851 [12:20<11:26,  1.29it/s]\u001b[A\n","Iteration:  52% 964/1851 [12:21<11:25,  1.29it/s]\u001b[A\n","Iteration:  52% 965/1851 [12:22<11:24,  1.30it/s]\u001b[A\n","Iteration:  52% 966/1851 [12:22<11:22,  1.30it/s]\u001b[A\n","Iteration:  52% 967/1851 [12:23<11:22,  1.30it/s]\u001b[A\n","Iteration:  52% 968/1851 [12:24<11:21,  1.30it/s]\u001b[A\n","Iteration:  52% 969/1851 [12:25<11:19,  1.30it/s]\u001b[A\n","Iteration:  52% 970/1851 [12:25<11:19,  1.30it/s]\u001b[A\n","Iteration:  52% 971/1851 [12:26<11:17,  1.30it/s]\u001b[A\n","Iteration:  53% 972/1851 [12:27<11:17,  1.30it/s]\u001b[A\n","Iteration:  53% 973/1851 [12:28<11:15,  1.30it/s]\u001b[A\n","Iteration:  53% 974/1851 [12:29<11:15,  1.30it/s]\u001b[A\n","Iteration:  53% 975/1851 [12:29<11:15,  1.30it/s]\u001b[A\n","Iteration:  53% 976/1851 [12:30<11:14,  1.30it/s]\u001b[A\n","Iteration:  53% 977/1851 [12:31<11:15,  1.29it/s]\u001b[A\n","Iteration:  53% 978/1851 [12:32<11:15,  1.29it/s]\u001b[A\n","Iteration:  53% 979/1851 [12:32<11:14,  1.29it/s]\u001b[A\n","Iteration:  53% 980/1851 [12:33<11:12,  1.29it/s]\u001b[A\n","Iteration:  53% 981/1851 [12:34<11:12,  1.29it/s]\u001b[A\n","Iteration:  53% 982/1851 [12:35<11:12,  1.29it/s]\u001b[A\n","Iteration:  53% 983/1851 [12:36<11:11,  1.29it/s]\u001b[A\n","Iteration:  53% 984/1851 [12:36<11:11,  1.29it/s]\u001b[A\n","Iteration:  53% 985/1851 [12:37<11:10,  1.29it/s]\u001b[A\n","Iteration:  53% 986/1851 [12:38<11:08,  1.29it/s]\u001b[A\n","Iteration:  53% 987/1851 [12:39<11:07,  1.30it/s]\u001b[A\n","Iteration:  53% 988/1851 [12:39<11:06,  1.29it/s]\u001b[A\n","Iteration:  53% 989/1851 [12:40<11:06,  1.29it/s]\u001b[A\n","Iteration:  53% 990/1851 [12:41<11:06,  1.29it/s]\u001b[A\n","Iteration:  54% 991/1851 [12:42<11:06,  1.29it/s]\u001b[A\n","Iteration:  54% 992/1851 [12:42<11:05,  1.29it/s]\u001b[A\n","Iteration:  54% 993/1851 [12:43<11:03,  1.29it/s]\u001b[A\n","Iteration:  54% 994/1851 [12:44<11:01,  1.30it/s]\u001b[A\n","Iteration:  54% 995/1851 [12:45<11:01,  1.29it/s]\u001b[A\n","Iteration:  54% 996/1851 [12:46<11:00,  1.29it/s]\u001b[A\n","Iteration:  54% 997/1851 [12:46<10:58,  1.30it/s]\u001b[A\n","Iteration:  54% 998/1851 [12:47<10:58,  1.30it/s]\u001b[A\n","Iteration:  54% 999/1851 [12:48<10:56,  1.30it/s]\u001b[A\n","Iteration:  54% 1000/1851 [12:49<10:56,  1.30it/s]\u001b[A\n","Iteration:  54% 1001/1851 [12:49<10:54,  1.30it/s]\u001b[A\n","Iteration:  54% 1002/1851 [12:50<10:54,  1.30it/s]\u001b[A\n","Iteration:  54% 1003/1851 [12:51<10:53,  1.30it/s]\u001b[A\n","Iteration:  54% 1004/1851 [12:52<10:53,  1.30it/s]\u001b[A\n","Iteration:  54% 1005/1851 [12:52<10:52,  1.30it/s]\u001b[A\n","Iteration:  54% 1006/1851 [12:53<10:52,  1.30it/s]\u001b[A\n","Iteration:  54% 1007/1851 [12:54<10:51,  1.30it/s]\u001b[A\n","Iteration:  54% 1008/1851 [12:55<10:51,  1.29it/s]\u001b[A\n","Iteration:  55% 1009/1851 [12:56<10:50,  1.29it/s]\u001b[A\n","Iteration:  55% 1010/1851 [12:56<10:49,  1.30it/s]\u001b[A\n","Iteration:  55% 1011/1851 [12:57<10:49,  1.29it/s]\u001b[A\n","Iteration:  55% 1012/1851 [12:58<10:48,  1.29it/s]\u001b[A\n","Iteration:  55% 1013/1851 [12:59<10:48,  1.29it/s]\u001b[A\n","Iteration:  55% 1014/1851 [12:59<10:47,  1.29it/s]\u001b[A\n","Iteration:  55% 1015/1851 [13:00<10:46,  1.29it/s]\u001b[A\n","Iteration:  55% 1016/1851 [13:01<10:46,  1.29it/s]\u001b[A\n","Iteration:  55% 1017/1851 [13:02<10:44,  1.29it/s]\u001b[A\n","Iteration:  55% 1018/1851 [13:03<10:42,  1.30it/s]\u001b[A\n","Iteration:  55% 1019/1851 [13:03<10:41,  1.30it/s]\u001b[A\n","Iteration:  55% 1020/1851 [13:04<10:42,  1.29it/s]\u001b[A\n","Iteration:  55% 1021/1851 [13:05<10:40,  1.30it/s]\u001b[A\n","Iteration:  55% 1022/1851 [13:06<10:38,  1.30it/s]\u001b[A\n","Iteration:  55% 1023/1851 [13:06<10:37,  1.30it/s]\u001b[A\n","Iteration:  55% 1024/1851 [13:07<10:37,  1.30it/s]\u001b[A\n","Iteration:  55% 1025/1851 [13:08<10:36,  1.30it/s]\u001b[A\n","Iteration:  55% 1026/1851 [13:09<10:36,  1.30it/s]\u001b[A\n","Iteration:  55% 1027/1851 [13:09<10:35,  1.30it/s]\u001b[A\n","Iteration:  56% 1028/1851 [13:10<10:33,  1.30it/s]\u001b[A\n","Iteration:  56% 1029/1851 [13:11<10:33,  1.30it/s]\u001b[A\n","Iteration:  56% 1030/1851 [13:12<10:33,  1.30it/s]\u001b[A\n","Iteration:  56% 1031/1851 [13:13<10:32,  1.30it/s]\u001b[A\n","Iteration:  56% 1032/1851 [13:13<10:29,  1.30it/s]\u001b[A\n","Iteration:  56% 1033/1851 [13:14<10:29,  1.30it/s]\u001b[A\n","Iteration:  56% 1034/1851 [13:15<10:28,  1.30it/s]\u001b[A\n","Iteration:  56% 1035/1851 [13:16<10:28,  1.30it/s]\u001b[A\n","Iteration:  56% 1036/1851 [13:16<10:28,  1.30it/s]\u001b[A\n","Iteration:  56% 1037/1851 [13:17<10:28,  1.30it/s]\u001b[A\n","Iteration:  56% 1038/1851 [13:18<10:26,  1.30it/s]\u001b[A\n","Iteration:  56% 1039/1851 [13:19<10:25,  1.30it/s]\u001b[A\n","Iteration:  56% 1040/1851 [13:19<10:25,  1.30it/s]\u001b[A\n","Iteration:  56% 1041/1851 [13:20<10:24,  1.30it/s]\u001b[A\n","Iteration:  56% 1042/1851 [13:21<10:23,  1.30it/s]\u001b[A\n","Iteration:  56% 1043/1851 [13:22<10:22,  1.30it/s]\u001b[A\n","Iteration:  56% 1044/1851 [13:23<10:21,  1.30it/s]\u001b[A\n","Iteration:  56% 1045/1851 [13:23<10:19,  1.30it/s]\u001b[A\n","Iteration:  57% 1046/1851 [13:24<10:19,  1.30it/s]\u001b[A\n","Iteration:  57% 1047/1851 [13:25<10:19,  1.30it/s]\u001b[A\n","Iteration:  57% 1048/1851 [13:26<10:18,  1.30it/s]\u001b[A\n","Iteration:  57% 1049/1851 [13:26<10:17,  1.30it/s]\u001b[A\n","Iteration:  57% 1050/1851 [13:27<10:17,  1.30it/s]\u001b[A\n","Iteration:  57% 1051/1851 [13:28<10:16,  1.30it/s]\u001b[A\n","Iteration:  57% 1052/1851 [13:29<10:16,  1.30it/s]\u001b[A\n","Iteration:  57% 1053/1851 [13:30<10:15,  1.30it/s]\u001b[A\n","Iteration:  57% 1054/1851 [13:30<10:15,  1.30it/s]\u001b[A\n","Iteration:  57% 1055/1851 [13:31<10:15,  1.29it/s]\u001b[A\n","Iteration:  57% 1056/1851 [13:32<10:14,  1.29it/s]\u001b[A\n","Iteration:  57% 1057/1851 [13:33<10:11,  1.30it/s]\u001b[A\n","Iteration:  57% 1058/1851 [13:33<10:12,  1.30it/s]\u001b[A\n","Iteration:  57% 1059/1851 [13:34<10:11,  1.30it/s]\u001b[A\n","Iteration:  57% 1060/1851 [13:35<10:10,  1.30it/s]\u001b[A\n","Iteration:  57% 1061/1851 [13:36<10:10,  1.29it/s]\u001b[A\n","Iteration:  57% 1062/1851 [13:36<10:08,  1.30it/s]\u001b[A\n","Iteration:  57% 1063/1851 [13:37<10:07,  1.30it/s]\u001b[A\n","Iteration:  57% 1064/1851 [13:38<10:05,  1.30it/s]\u001b[A\n","Iteration:  58% 1065/1851 [13:39<10:05,  1.30it/s]\u001b[A\n","Iteration:  58% 1066/1851 [13:40<10:04,  1.30it/s]\u001b[A\n","Iteration:  58% 1067/1851 [13:40<10:03,  1.30it/s]\u001b[A\n","Iteration:  58% 1068/1851 [13:41<10:03,  1.30it/s]\u001b[A\n","Iteration:  58% 1069/1851 [13:42<10:02,  1.30it/s]\u001b[A\n","Iteration:  58% 1070/1851 [13:43<10:00,  1.30it/s]\u001b[A\n","Iteration:  58% 1071/1851 [13:43<09:59,  1.30it/s]\u001b[A\n","Iteration:  58% 1072/1851 [13:44<10:00,  1.30it/s]\u001b[A\n","Iteration:  58% 1073/1851 [13:45<09:59,  1.30it/s]\u001b[A\n","Iteration:  58% 1074/1851 [13:46<09:58,  1.30it/s]\u001b[A\n","Iteration:  58% 1075/1851 [13:46<09:57,  1.30it/s]\u001b[A\n","Iteration:  58% 1076/1851 [13:47<09:56,  1.30it/s]\u001b[A\n","Iteration:  58% 1077/1851 [13:48<09:56,  1.30it/s]\u001b[A\n","Iteration:  58% 1078/1851 [13:49<09:55,  1.30it/s]\u001b[A\n","Iteration:  58% 1079/1851 [13:50<09:54,  1.30it/s]\u001b[A\n","Iteration:  58% 1080/1851 [13:50<09:53,  1.30it/s]\u001b[A\n","Iteration:  58% 1081/1851 [13:51<09:53,  1.30it/s]\u001b[A\n","Iteration:  58% 1082/1851 [13:52<09:53,  1.30it/s]\u001b[A\n","Iteration:  59% 1083/1851 [13:53<09:51,  1.30it/s]\u001b[A\n","Iteration:  59% 1084/1851 [13:53<09:52,  1.30it/s]\u001b[A\n","Iteration:  59% 1085/1851 [13:54<09:52,  1.29it/s]\u001b[A\n","Iteration:  59% 1086/1851 [13:55<09:51,  1.29it/s]\u001b[A\n","Iteration:  59% 1087/1851 [13:56<09:50,  1.29it/s]\u001b[A\n","Iteration:  59% 1088/1851 [13:56<09:49,  1.29it/s]\u001b[A\n","Iteration:  59% 1089/1851 [13:57<09:47,  1.30it/s]\u001b[A\n","Iteration:  59% 1090/1851 [13:58<09:47,  1.29it/s]\u001b[A\n","Iteration:  59% 1091/1851 [13:59<09:46,  1.30it/s]\u001b[A\n","Iteration:  59% 1092/1851 [14:00<09:44,  1.30it/s]\u001b[A\n","Iteration:  59% 1093/1851 [14:00<09:44,  1.30it/s]\u001b[A\n","Iteration:  59% 1094/1851 [14:01<09:43,  1.30it/s]\u001b[A\n","Iteration:  59% 1095/1851 [14:02<09:42,  1.30it/s]\u001b[A\n","Iteration:  59% 1096/1851 [14:03<09:41,  1.30it/s]\u001b[A\n","Iteration:  59% 1097/1851 [14:03<09:41,  1.30it/s]\u001b[A\n","Iteration:  59% 1098/1851 [14:04<09:41,  1.30it/s]\u001b[A\n","Iteration:  59% 1099/1851 [14:05<09:39,  1.30it/s]\u001b[A\n","Iteration:  59% 1100/1851 [14:06<09:39,  1.30it/s]\u001b[A\n","Iteration:  59% 1101/1851 [14:07<09:38,  1.30it/s]\u001b[A\n","Iteration:  60% 1102/1851 [14:07<09:38,  1.30it/s]\u001b[A\n","Iteration:  60% 1103/1851 [14:08<09:37,  1.30it/s]\u001b[A\n","Iteration:  60% 1104/1851 [14:09<09:35,  1.30it/s]\u001b[A\n","Iteration:  60% 1105/1851 [14:10<09:34,  1.30it/s]\u001b[A\n","Iteration:  60% 1106/1851 [14:10<09:33,  1.30it/s]\u001b[A\n","Iteration:  60% 1107/1851 [14:11<09:33,  1.30it/s]\u001b[A\n","Iteration:  60% 1108/1851 [14:12<09:31,  1.30it/s]\u001b[A\n","Iteration:  60% 1109/1851 [14:13<09:31,  1.30it/s]\u001b[A\n","Iteration:  60% 1110/1851 [14:13<09:30,  1.30it/s]\u001b[A\n","Iteration:  60% 1111/1851 [14:14<09:29,  1.30it/s]\u001b[A\n","Iteration:  60% 1112/1851 [14:15<09:29,  1.30it/s]\u001b[A\n","Iteration:  60% 1113/1851 [14:16<09:29,  1.30it/s]\u001b[A\n","Iteration:  60% 1114/1851 [14:17<09:28,  1.30it/s]\u001b[A\n","Iteration:  60% 1115/1851 [14:17<09:27,  1.30it/s]\u001b[A\n","Iteration:  60% 1116/1851 [14:18<09:26,  1.30it/s]\u001b[A\n","Iteration:  60% 1117/1851 [14:19<09:25,  1.30it/s]\u001b[A\n","Iteration:  60% 1118/1851 [14:20<09:24,  1.30it/s]\u001b[A\n","Iteration:  60% 1119/1851 [14:20<09:23,  1.30it/s]\u001b[A\n","Iteration:  61% 1120/1851 [14:21<09:22,  1.30it/s]\u001b[A\n","Iteration:  61% 1121/1851 [14:22<09:22,  1.30it/s]\u001b[A\n","Iteration:  61% 1122/1851 [14:23<09:21,  1.30it/s]\u001b[A\n","Iteration:  61% 1123/1851 [14:23<09:20,  1.30it/s]\u001b[A\n","Iteration:  61% 1124/1851 [14:24<09:20,  1.30it/s]\u001b[A\n","Iteration:  61% 1125/1851 [14:25<09:18,  1.30it/s]\u001b[A\n","Iteration:  61% 1126/1851 [14:26<09:18,  1.30it/s]\u001b[A\n","Iteration:  61% 1127/1851 [14:27<09:17,  1.30it/s]\u001b[A\n","Iteration:  61% 1128/1851 [14:27<09:17,  1.30it/s]\u001b[A\n","Iteration:  61% 1129/1851 [14:28<09:16,  1.30it/s]\u001b[A\n","Iteration:  61% 1130/1851 [14:29<09:15,  1.30it/s]\u001b[A\n","Iteration:  61% 1131/1851 [14:30<09:15,  1.30it/s]\u001b[A\n","Iteration:  61% 1132/1851 [14:30<09:15,  1.29it/s]\u001b[A\n","Iteration:  61% 1133/1851 [14:31<09:14,  1.29it/s]\u001b[A\n","Iteration:  61% 1134/1851 [14:32<09:14,  1.29it/s]\u001b[A\n","Iteration:  61% 1135/1851 [14:33<09:12,  1.30it/s]\u001b[A\n","Iteration:  61% 1136/1851 [14:34<09:12,  1.29it/s]\u001b[A\n","Iteration:  61% 1137/1851 [14:34<09:10,  1.30it/s]\u001b[A\n","Iteration:  61% 1138/1851 [14:35<09:09,  1.30it/s]\u001b[A\n","Iteration:  62% 1139/1851 [14:36<09:08,  1.30it/s]\u001b[A\n","Iteration:  62% 1140/1851 [14:37<09:08,  1.30it/s]\u001b[A\n","Iteration:  62% 1141/1851 [14:37<09:07,  1.30it/s]\u001b[A\n","Iteration:  62% 1142/1851 [14:38<09:06,  1.30it/s]\u001b[A\n","Iteration:  62% 1143/1851 [14:39<09:05,  1.30it/s]\u001b[A\n","Iteration:  62% 1144/1851 [14:40<09:04,  1.30it/s]\u001b[A\n","Iteration:  62% 1145/1851 [14:40<09:04,  1.30it/s]\u001b[A\n","Iteration:  62% 1146/1851 [14:41<09:03,  1.30it/s]\u001b[A\n","Iteration:  62% 1147/1851 [14:42<09:04,  1.29it/s]\u001b[A\n","Iteration:  62% 1148/1851 [14:43<09:03,  1.29it/s]\u001b[A\n","Iteration:  62% 1149/1851 [14:44<09:02,  1.29it/s]\u001b[A\n","Iteration:  62% 1150/1851 [14:44<09:01,  1.29it/s]\u001b[A\n","Iteration:  62% 1151/1851 [14:45<09:00,  1.30it/s]\u001b[A\n","Iteration:  62% 1152/1851 [14:46<08:58,  1.30it/s]\u001b[A\n","Iteration:  62% 1153/1851 [14:47<08:58,  1.30it/s]\u001b[A\n","Iteration:  62% 1154/1851 [14:47<08:57,  1.30it/s]\u001b[A\n","Iteration:  62% 1155/1851 [14:48<08:56,  1.30it/s]\u001b[A\n","Iteration:  62% 1156/1851 [14:49<08:55,  1.30it/s]\u001b[A\n","Iteration:  63% 1157/1851 [14:50<08:54,  1.30it/s]\u001b[A\n","Iteration:  63% 1158/1851 [14:50<08:53,  1.30it/s]\u001b[A\n","Iteration:  63% 1159/1851 [14:51<08:53,  1.30it/s]\u001b[A\n","Iteration:  63% 1160/1851 [14:52<08:53,  1.30it/s]\u001b[A\n","Iteration:  63% 1161/1851 [14:53<08:51,  1.30it/s]\u001b[A\n","Iteration:  63% 1162/1851 [14:54<08:50,  1.30it/s]\u001b[A\n","Iteration:  63% 1163/1851 [14:54<08:50,  1.30it/s]\u001b[A\n","Iteration:  63% 1164/1851 [14:55<08:50,  1.30it/s]\u001b[A\n","Iteration:  63% 1165/1851 [14:56<08:49,  1.30it/s]\u001b[A\n","Iteration:  63% 1166/1851 [14:57<08:49,  1.29it/s]\u001b[A\n","Iteration:  63% 1167/1851 [14:57<08:49,  1.29it/s]\u001b[A\n","Iteration:  63% 1168/1851 [14:58<08:48,  1.29it/s]\u001b[A\n","Iteration:  63% 1169/1851 [14:59<08:47,  1.29it/s]\u001b[A\n","Iteration:  63% 1170/1851 [15:00<08:45,  1.30it/s]\u001b[A\n","Iteration:  63% 1171/1851 [15:01<08:44,  1.30it/s]\u001b[A\n","Iteration:  63% 1172/1851 [15:01<08:45,  1.29it/s]\u001b[A\n","Iteration:  63% 1173/1851 [15:02<08:43,  1.30it/s]\u001b[A\n","Iteration:  63% 1174/1851 [15:03<08:42,  1.30it/s]\u001b[A\n","Iteration:  63% 1175/1851 [15:04<08:41,  1.30it/s]\u001b[A\n","Iteration:  64% 1176/1851 [15:04<08:41,  1.29it/s]\u001b[A\n","Iteration:  64% 1177/1851 [15:05<08:41,  1.29it/s]\u001b[A\n","Iteration:  64% 1178/1851 [15:06<08:40,  1.29it/s]\u001b[A\n","Iteration:  64% 1179/1851 [15:07<08:39,  1.29it/s]\u001b[A\n","Iteration:  64% 1180/1851 [15:07<08:39,  1.29it/s]\u001b[A\n","Iteration:  64% 1181/1851 [15:08<08:38,  1.29it/s]\u001b[A\n","Iteration:  64% 1182/1851 [15:09<08:37,  1.29it/s]\u001b[A\n","Iteration:  64% 1183/1851 [15:10<08:37,  1.29it/s]\u001b[A\n","Iteration:  64% 1184/1851 [15:11<08:36,  1.29it/s]\u001b[A\n","Iteration:  64% 1185/1851 [15:11<08:34,  1.29it/s]\u001b[A\n","Iteration:  64% 1186/1851 [15:12<08:33,  1.29it/s]\u001b[A\n","Iteration:  64% 1187/1851 [15:13<08:32,  1.29it/s]\u001b[A\n","Iteration:  64% 1188/1851 [15:14<08:32,  1.29it/s]\u001b[A\n","Iteration:  64% 1189/1851 [15:14<08:30,  1.30it/s]\u001b[A\n","Iteration:  64% 1190/1851 [15:15<08:30,  1.30it/s]\u001b[A\n","Iteration:  64% 1191/1851 [15:16<08:29,  1.29it/s]\u001b[A\n","Iteration:  64% 1192/1851 [15:17<08:28,  1.30it/s]\u001b[A\n","Iteration:  64% 1193/1851 [15:17<08:26,  1.30it/s]\u001b[A\n","Iteration:  65% 1194/1851 [15:18<08:27,  1.30it/s]\u001b[A\n","Iteration:  65% 1195/1851 [15:19<08:27,  1.29it/s]\u001b[A\n","Iteration:  65% 1196/1851 [15:20<08:26,  1.29it/s]\u001b[A\n","Iteration:  65% 1197/1851 [15:21<08:25,  1.29it/s]\u001b[A\n","Iteration:  65% 1198/1851 [15:21<08:24,  1.30it/s]\u001b[A\n","Iteration:  65% 1199/1851 [15:22<08:23,  1.30it/s]\u001b[A\n","Iteration:  65% 1200/1851 [15:23<08:22,  1.30it/s]\u001b[A\n","Iteration:  65% 1201/1851 [15:24<08:21,  1.30it/s]\u001b[A\n","Iteration:  65% 1202/1851 [15:24<08:21,  1.30it/s]\u001b[A\n","Iteration:  65% 1203/1851 [15:25<08:19,  1.30it/s]\u001b[A\n","Iteration:  65% 1204/1851 [15:26<08:19,  1.30it/s]\u001b[A\n","Iteration:  65% 1205/1851 [15:27<08:18,  1.30it/s]\u001b[A\n","Iteration:  65% 1206/1851 [15:28<08:17,  1.30it/s]\u001b[A\n","Iteration:  65% 1207/1851 [15:28<08:16,  1.30it/s]\u001b[A\n","Iteration:  65% 1208/1851 [15:29<08:16,  1.29it/s]\u001b[A\n","Iteration:  65% 1209/1851 [15:30<08:15,  1.29it/s]\u001b[A\n","Iteration:  65% 1210/1851 [15:31<08:15,  1.29it/s]\u001b[A\n","Iteration:  65% 1211/1851 [15:31<08:14,  1.29it/s]\u001b[A\n","Iteration:  65% 1212/1851 [15:32<08:13,  1.29it/s]\u001b[A\n","Iteration:  66% 1213/1851 [15:33<08:12,  1.30it/s]\u001b[A\n","Iteration:  66% 1214/1851 [15:34<08:11,  1.30it/s]\u001b[A\n","Iteration:  66% 1215/1851 [15:34<08:11,  1.29it/s]\u001b[A\n","Iteration:  66% 1216/1851 [15:35<08:10,  1.30it/s]\u001b[A\n","Iteration:  66% 1217/1851 [15:36<08:08,  1.30it/s]\u001b[A\n","Iteration:  66% 1218/1851 [15:37<08:08,  1.29it/s]\u001b[A\n","Iteration:  66% 1219/1851 [15:38<08:07,  1.30it/s]\u001b[A\n","Iteration:  66% 1220/1851 [15:38<08:06,  1.30it/s]\u001b[A\n","Iteration:  66% 1221/1851 [15:39<08:06,  1.30it/s]\u001b[A\n","Iteration:  66% 1222/1851 [15:40<08:06,  1.29it/s]\u001b[A\n","Iteration:  66% 1223/1851 [15:41<08:05,  1.29it/s]\u001b[A\n","Iteration:  66% 1224/1851 [15:41<08:04,  1.29it/s]\u001b[A\n","Iteration:  66% 1225/1851 [15:42<08:03,  1.29it/s]\u001b[A\n","Iteration:  66% 1226/1851 [15:43<08:02,  1.29it/s]\u001b[A\n","Iteration:  66% 1227/1851 [15:44<08:01,  1.30it/s]\u001b[A\n","Iteration:  66% 1228/1851 [15:45<07:59,  1.30it/s]\u001b[A\n","Iteration:  66% 1229/1851 [15:45<07:59,  1.30it/s]\u001b[A\n","Iteration:  66% 1230/1851 [15:46<07:59,  1.29it/s]\u001b[A\n","Iteration:  67% 1231/1851 [15:47<07:57,  1.30it/s]\u001b[A\n","Iteration:  67% 1232/1851 [15:48<07:56,  1.30it/s]\u001b[A\n","Iteration:  67% 1233/1851 [15:48<07:56,  1.30it/s]\u001b[A\n","Iteration:  67% 1234/1851 [15:49<07:54,  1.30it/s]\u001b[A\n","Iteration:  67% 1235/1851 [15:50<07:54,  1.30it/s]\u001b[A\n","Iteration:  67% 1236/1851 [15:51<07:53,  1.30it/s]\u001b[A\n","Iteration:  67% 1237/1851 [15:51<07:53,  1.30it/s]\u001b[A\n","Iteration:  67% 1238/1851 [15:52<07:53,  1.30it/s]\u001b[A\n","Iteration:  67% 1239/1851 [15:53<07:51,  1.30it/s]\u001b[A\n","Iteration:  67% 1240/1851 [15:54<07:52,  1.29it/s]\u001b[A\n","Iteration:  67% 1241/1851 [15:55<07:51,  1.29it/s]\u001b[A\n","Iteration:  67% 1242/1851 [15:55<07:51,  1.29it/s]\u001b[A\n","Iteration:  67% 1243/1851 [15:56<07:49,  1.29it/s]\u001b[A\n","Iteration:  67% 1244/1851 [15:57<07:50,  1.29it/s]\u001b[A\n","Iteration:  67% 1245/1851 [15:58<07:49,  1.29it/s]\u001b[A\n","Iteration:  67% 1246/1851 [15:58<07:48,  1.29it/s]\u001b[A\n","Iteration:  67% 1247/1851 [15:59<07:46,  1.29it/s]\u001b[A\n","Iteration:  67% 1248/1851 [16:00<07:46,  1.29it/s]\u001b[A\n","Iteration:  67% 1249/1851 [16:01<07:44,  1.29it/s]\u001b[A\n","Iteration:  68% 1250/1851 [16:02<07:43,  1.30it/s]\u001b[A\n","Iteration:  68% 1251/1851 [16:02<07:42,  1.30it/s]\u001b[A\n","Iteration:  68% 1252/1851 [16:03<07:42,  1.30it/s]\u001b[A\n","Iteration:  68% 1253/1851 [16:04<07:41,  1.30it/s]\u001b[A\n","Iteration:  68% 1254/1851 [16:05<07:40,  1.30it/s]\u001b[A\n","Iteration:  68% 1255/1851 [16:05<07:40,  1.29it/s]\u001b[A\n","Iteration:  68% 1256/1851 [16:06<07:39,  1.29it/s]\u001b[A\n","Iteration:  68% 1257/1851 [16:07<07:40,  1.29it/s]\u001b[A\n","Iteration:  68% 1258/1851 [16:08<07:38,  1.29it/s]\u001b[A\n","Iteration:  68% 1259/1851 [16:08<07:37,  1.30it/s]\u001b[A\n","Iteration:  68% 1260/1851 [16:09<07:35,  1.30it/s]\u001b[A\n","Iteration:  68% 1261/1851 [16:10<07:34,  1.30it/s]\u001b[A\n","Iteration:  68% 1262/1851 [16:11<07:34,  1.30it/s]\u001b[A\n","Iteration:  68% 1263/1851 [16:12<07:33,  1.30it/s]\u001b[A\n","Iteration:  68% 1264/1851 [16:12<07:32,  1.30it/s]\u001b[A\n","Iteration:  68% 1265/1851 [16:13<07:32,  1.30it/s]\u001b[A\n","Iteration:  68% 1266/1851 [16:14<07:31,  1.29it/s]\u001b[A\n","Iteration:  68% 1267/1851 [16:15<07:31,  1.29it/s]\u001b[A\n","Iteration:  69% 1268/1851 [16:15<07:29,  1.30it/s]\u001b[A\n","Iteration:  69% 1269/1851 [16:16<07:28,  1.30it/s]\u001b[A\n","Iteration:  69% 1270/1851 [16:17<07:28,  1.30it/s]\u001b[A\n","Iteration:  69% 1271/1851 [16:18<07:27,  1.30it/s]\u001b[A\n","Iteration:  69% 1272/1851 [16:18<07:26,  1.30it/s]\u001b[A\n","Iteration:  69% 1273/1851 [16:19<07:25,  1.30it/s]\u001b[A\n","Iteration:  69% 1274/1851 [16:20<07:25,  1.30it/s]\u001b[A\n","Iteration:  69% 1275/1851 [16:21<07:24,  1.29it/s]\u001b[A\n","Iteration:  69% 1276/1851 [16:22<07:23,  1.30it/s]\u001b[A\n","Iteration:  69% 1277/1851 [16:22<07:22,  1.30it/s]\u001b[A\n","Iteration:  69% 1278/1851 [16:23<07:21,  1.30it/s]\u001b[A\n","Iteration:  69% 1279/1851 [16:24<07:21,  1.30it/s]\u001b[A\n","Iteration:  69% 1280/1851 [16:25<07:21,  1.29it/s]\u001b[A\n","Iteration:  69% 1281/1851 [16:25<07:20,  1.29it/s]\u001b[A\n","Iteration:  69% 1282/1851 [16:26<07:18,  1.30it/s]\u001b[A\n","Iteration:  69% 1283/1851 [16:27<07:18,  1.30it/s]\u001b[A\n","Iteration:  69% 1284/1851 [16:28<07:17,  1.29it/s]\u001b[A\n","Iteration:  69% 1285/1851 [16:29<07:16,  1.30it/s]\u001b[A\n","Iteration:  69% 1286/1851 [16:29<07:16,  1.30it/s]\u001b[A\n","Iteration:  70% 1287/1851 [16:30<07:13,  1.30it/s]\u001b[A\n","Iteration:  70% 1288/1851 [16:31<07:13,  1.30it/s]\u001b[A\n","Iteration:  70% 1289/1851 [16:32<07:12,  1.30it/s]\u001b[A\n","Iteration:  70% 1290/1851 [16:32<07:11,  1.30it/s]\u001b[A\n","Iteration:  70% 1291/1851 [16:33<07:11,  1.30it/s]\u001b[A\n","Iteration:  70% 1292/1851 [16:34<07:10,  1.30it/s]\u001b[A\n","Iteration:  70% 1293/1851 [16:35<07:09,  1.30it/s]\u001b[A\n","Iteration:  70% 1294/1851 [16:35<07:08,  1.30it/s]\u001b[A\n","Iteration:  70% 1295/1851 [16:36<07:08,  1.30it/s]\u001b[A\n","Iteration:  70% 1296/1851 [16:37<07:07,  1.30it/s]\u001b[A\n","Iteration:  70% 1297/1851 [16:38<07:06,  1.30it/s]\u001b[A\n","Iteration:  70% 1298/1851 [16:39<07:05,  1.30it/s]\u001b[A\n","Iteration:  70% 1299/1851 [16:39<07:04,  1.30it/s]\u001b[A\n","Iteration:  70% 1300/1851 [16:40<07:04,  1.30it/s]\u001b[A\n","Iteration:  70% 1301/1851 [16:41<07:04,  1.30it/s]\u001b[A\n","Iteration:  70% 1302/1851 [16:42<07:02,  1.30it/s]\u001b[A\n","Iteration:  70% 1303/1851 [16:42<07:02,  1.30it/s]\u001b[A\n","Iteration:  70% 1304/1851 [16:43<07:02,  1.30it/s]\u001b[A\n","Iteration:  71% 1305/1851 [16:44<07:00,  1.30it/s]\u001b[A\n","Iteration:  71% 1306/1851 [16:45<07:00,  1.30it/s]\u001b[A\n","Iteration:  71% 1307/1851 [16:45<06:58,  1.30it/s]\u001b[A\n","Iteration:  71% 1308/1851 [16:46<06:58,  1.30it/s]\u001b[A\n","Iteration:  71% 1309/1851 [16:47<06:57,  1.30it/s]\u001b[A\n","Iteration:  71% 1310/1851 [16:48<06:57,  1.30it/s]\u001b[A\n","Iteration:  71% 1311/1851 [16:49<06:57,  1.29it/s]\u001b[A\n","Iteration:  71% 1312/1851 [16:49<06:56,  1.29it/s]\u001b[A\n","Iteration:  71% 1313/1851 [16:50<06:55,  1.29it/s]\u001b[A\n","Iteration:  71% 1314/1851 [16:51<06:54,  1.29it/s]\u001b[A\n","Iteration:  71% 1315/1851 [16:52<06:53,  1.30it/s]\u001b[A\n","Iteration:  71% 1316/1851 [16:52<06:52,  1.30it/s]\u001b[A\n","Iteration:  71% 1317/1851 [16:53<06:51,  1.30it/s]\u001b[A\n","Iteration:  71% 1318/1851 [16:54<06:51,  1.30it/s]\u001b[A\n","Iteration:  71% 1319/1851 [16:55<06:50,  1.30it/s]\u001b[A\n","Iteration:  71% 1320/1851 [16:56<06:49,  1.30it/s]\u001b[A\n","Iteration:  71% 1321/1851 [16:56<06:49,  1.30it/s]\u001b[A\n","Iteration:  71% 1322/1851 [16:57<06:48,  1.29it/s]\u001b[A\n","Iteration:  71% 1323/1851 [16:58<06:47,  1.29it/s]\u001b[A\n","Iteration:  72% 1324/1851 [16:59<06:47,  1.29it/s]\u001b[A\n","Iteration:  72% 1325/1851 [16:59<06:46,  1.30it/s]\u001b[A\n","Iteration:  72% 1326/1851 [17:00<06:45,  1.29it/s]\u001b[A\n","Iteration:  72% 1327/1851 [17:01<06:44,  1.30it/s]\u001b[A\n","Iteration:  72% 1328/1851 [17:02<06:43,  1.30it/s]\u001b[A\n","Iteration:  72% 1329/1851 [17:02<06:43,  1.29it/s]\u001b[A\n","Iteration:  72% 1330/1851 [17:03<06:41,  1.30it/s]\u001b[A\n","Iteration:  72% 1331/1851 [17:04<06:41,  1.30it/s]\u001b[A\n","Iteration:  72% 1332/1851 [17:05<06:39,  1.30it/s]\u001b[A\n","Iteration:  72% 1333/1851 [17:06<06:39,  1.30it/s]\u001b[A\n","Iteration:  72% 1334/1851 [17:06<06:38,  1.30it/s]\u001b[A\n","Iteration:  72% 1335/1851 [17:07<06:36,  1.30it/s]\u001b[A\n","Iteration:  72% 1336/1851 [17:08<06:36,  1.30it/s]\u001b[A\n","Iteration:  72% 1337/1851 [17:09<06:36,  1.30it/s]\u001b[A\n","Iteration:  72% 1338/1851 [17:09<06:35,  1.30it/s]\u001b[A\n","Iteration:  72% 1339/1851 [17:10<06:34,  1.30it/s]\u001b[A\n","Iteration:  72% 1340/1851 [17:11<06:33,  1.30it/s]\u001b[A\n","Iteration:  72% 1341/1851 [17:12<06:33,  1.30it/s]\u001b[A\n","Iteration:  73% 1342/1851 [17:12<06:32,  1.30it/s]\u001b[A\n","Iteration:  73% 1343/1851 [17:13<06:31,  1.30it/s]\u001b[A\n","Iteration:  73% 1344/1851 [17:14<06:31,  1.30it/s]\u001b[A\n","Iteration:  73% 1345/1851 [17:15<06:30,  1.30it/s]\u001b[A\n","Iteration:  73% 1346/1851 [17:16<06:29,  1.30it/s]\u001b[A\n","Iteration:  73% 1347/1851 [17:16<06:28,  1.30it/s]\u001b[A\n","Iteration:  73% 1348/1851 [17:17<06:27,  1.30it/s]\u001b[A\n","Iteration:  73% 1349/1851 [17:18<06:27,  1.30it/s]\u001b[A\n","Iteration:  73% 1350/1851 [17:19<06:26,  1.30it/s]\u001b[A\n","Iteration:  73% 1351/1851 [17:19<06:25,  1.30it/s]\u001b[A\n","Iteration:  73% 1352/1851 [17:20<06:24,  1.30it/s]\u001b[A\n","Iteration:  73% 1353/1851 [17:21<06:24,  1.30it/s]\u001b[A\n","Iteration:  73% 1354/1851 [17:22<06:23,  1.30it/s]\u001b[A\n","Iteration:  73% 1355/1851 [17:22<06:22,  1.30it/s]\u001b[A\n","Iteration:  73% 1356/1851 [17:23<06:21,  1.30it/s]\u001b[A\n","Iteration:  73% 1357/1851 [17:24<06:21,  1.30it/s]\u001b[A\n","Iteration:  73% 1358/1851 [17:25<06:20,  1.30it/s]\u001b[A\n","Iteration:  73% 1359/1851 [17:26<06:19,  1.30it/s]\u001b[A\n","Iteration:  73% 1360/1851 [17:26<06:19,  1.29it/s]\u001b[A\n","Iteration:  74% 1361/1851 [17:27<06:18,  1.29it/s]\u001b[A\n","Iteration:  74% 1362/1851 [17:28<06:17,  1.30it/s]\u001b[A\n","Iteration:  74% 1363/1851 [17:29<06:16,  1.30it/s]\u001b[A\n","Iteration:  74% 1364/1851 [17:29<06:15,  1.30it/s]\u001b[A\n","Iteration:  74% 1365/1851 [17:30<06:15,  1.30it/s]\u001b[A\n","Iteration:  74% 1366/1851 [17:31<06:14,  1.29it/s]\u001b[A\n","Iteration:  74% 1367/1851 [17:32<06:13,  1.30it/s]\u001b[A\n","Iteration:  74% 1368/1851 [17:33<06:13,  1.29it/s]\u001b[A\n","Iteration:  74% 1369/1851 [17:33<06:11,  1.30it/s]\u001b[A\n","Iteration:  74% 1370/1851 [17:34<06:10,  1.30it/s]\u001b[A\n","Iteration:  74% 1371/1851 [17:35<06:10,  1.30it/s]\u001b[A\n","Iteration:  74% 1372/1851 [17:36<06:09,  1.30it/s]\u001b[A\n","Iteration:  74% 1373/1851 [17:36<06:09,  1.29it/s]\u001b[A\n","Iteration:  74% 1374/1851 [17:37<06:08,  1.29it/s]\u001b[A\n","Iteration:  74% 1375/1851 [17:38<06:06,  1.30it/s]\u001b[A\n","Iteration:  74% 1376/1851 [17:39<06:05,  1.30it/s]\u001b[A\n","Iteration:  74% 1377/1851 [17:39<06:04,  1.30it/s]\u001b[A\n","Iteration:  74% 1378/1851 [17:40<06:04,  1.30it/s]\u001b[A\n","Iteration:  75% 1379/1851 [17:41<06:04,  1.30it/s]\u001b[A\n","Iteration:  75% 1380/1851 [17:42<06:02,  1.30it/s]\u001b[A\n","Iteration:  75% 1381/1851 [17:43<06:02,  1.30it/s]\u001b[A\n","Iteration:  75% 1382/1851 [17:43<06:01,  1.30it/s]\u001b[A\n","Iteration:  75% 1383/1851 [17:44<06:00,  1.30it/s]\u001b[A\n","Iteration:  75% 1384/1851 [17:45<06:00,  1.30it/s]\u001b[A\n","Iteration:  75% 1385/1851 [17:46<05:59,  1.30it/s]\u001b[A\n","Iteration:  75% 1386/1851 [17:46<05:58,  1.30it/s]\u001b[A\n","Iteration:  75% 1387/1851 [17:47<05:57,  1.30it/s]\u001b[A\n","Iteration:  75% 1388/1851 [17:48<05:57,  1.30it/s]\u001b[A\n","Iteration:  75% 1389/1851 [17:49<05:56,  1.30it/s]\u001b[A\n","Iteration:  75% 1390/1851 [17:49<05:55,  1.30it/s]\u001b[A\n","Iteration:  75% 1391/1851 [17:50<05:54,  1.30it/s]\u001b[A\n","Iteration:  75% 1392/1851 [17:51<05:53,  1.30it/s]\u001b[A\n","Iteration:  75% 1393/1851 [17:52<05:52,  1.30it/s]\u001b[A\n","Iteration:  75% 1394/1851 [17:53<05:51,  1.30it/s]\u001b[A\n","Iteration:  75% 1395/1851 [17:53<05:51,  1.30it/s]\u001b[A\n","Iteration:  75% 1396/1851 [17:54<05:50,  1.30it/s]\u001b[A\n","Iteration:  75% 1397/1851 [17:55<05:50,  1.30it/s]\u001b[A\n","Iteration:  76% 1398/1851 [17:56<05:48,  1.30it/s]\u001b[A\n","Iteration:  76% 1399/1851 [17:56<05:48,  1.30it/s]\u001b[A\n","Iteration:  76% 1400/1851 [17:57<05:47,  1.30it/s]\u001b[A\n","Iteration:  76% 1401/1851 [17:58<05:46,  1.30it/s]\u001b[A\n","Iteration:  76% 1402/1851 [17:59<05:45,  1.30it/s]\u001b[A\n","Iteration:  76% 1403/1851 [18:00<05:45,  1.30it/s]\u001b[A\n","Iteration:  76% 1404/1851 [18:00<05:44,  1.30it/s]\u001b[A\n","Iteration:  76% 1405/1851 [18:01<05:43,  1.30it/s]\u001b[A\n","Iteration:  76% 1406/1851 [18:02<05:42,  1.30it/s]\u001b[A\n","Iteration:  76% 1407/1851 [18:03<05:42,  1.30it/s]\u001b[A\n","Iteration:  76% 1408/1851 [18:03<05:42,  1.30it/s]\u001b[A\n","Iteration:  76% 1409/1851 [18:04<05:40,  1.30it/s]\u001b[A\n","Iteration:  76% 1410/1851 [18:05<05:39,  1.30it/s]\u001b[A\n","Iteration:  76% 1411/1851 [18:06<05:39,  1.30it/s]\u001b[A\n","Iteration:  76% 1412/1851 [18:06<05:38,  1.30it/s]\u001b[A\n","Iteration:  76% 1413/1851 [18:07<05:37,  1.30it/s]\u001b[A\n","Iteration:  76% 1414/1851 [18:08<05:36,  1.30it/s]\u001b[A\n","Iteration:  76% 1415/1851 [18:09<05:35,  1.30it/s]\u001b[A\n","Iteration:  76% 1416/1851 [18:10<05:35,  1.30it/s]\u001b[A\n","Iteration:  77% 1417/1851 [18:10<05:34,  1.30it/s]\u001b[A\n","Iteration:  77% 1418/1851 [18:11<05:33,  1.30it/s]\u001b[A\n","Iteration:  77% 1419/1851 [18:12<05:32,  1.30it/s]\u001b[A\n","Iteration:  77% 1420/1851 [18:13<05:32,  1.30it/s]\u001b[A\n","Iteration:  77% 1421/1851 [18:13<05:31,  1.30it/s]\u001b[A\n","Iteration:  77% 1422/1851 [18:14<05:30,  1.30it/s]\u001b[A\n","Iteration:  77% 1423/1851 [18:15<05:29,  1.30it/s]\u001b[A\n","Iteration:  77% 1424/1851 [18:16<05:29,  1.30it/s]\u001b[A\n","Iteration:  77% 1425/1851 [18:16<05:27,  1.30it/s]\u001b[A\n","Iteration:  77% 1426/1851 [18:17<05:27,  1.30it/s]\u001b[A\n","Iteration:  77% 1427/1851 [18:18<05:26,  1.30it/s]\u001b[A\n","Iteration:  77% 1428/1851 [18:19<05:25,  1.30it/s]\u001b[A\n","Iteration:  77% 1429/1851 [18:20<05:25,  1.30it/s]\u001b[A\n","Iteration:  77% 1430/1851 [18:20<05:25,  1.30it/s]\u001b[A\n","Iteration:  77% 1431/1851 [18:21<05:23,  1.30it/s]\u001b[A\n","Iteration:  77% 1432/1851 [18:22<05:22,  1.30it/s]\u001b[A\n","Iteration:  77% 1433/1851 [18:23<05:22,  1.30it/s]\u001b[A\n","Iteration:  77% 1434/1851 [18:23<05:21,  1.30it/s]\u001b[A\n","Iteration:  78% 1435/1851 [18:24<05:20,  1.30it/s]\u001b[A\n","Iteration:  78% 1436/1851 [18:25<05:19,  1.30it/s]\u001b[A\n","Iteration:  78% 1437/1851 [18:26<05:19,  1.30it/s]\u001b[A\n","Iteration:  78% 1438/1851 [18:26<05:18,  1.30it/s]\u001b[A\n","Iteration:  78% 1439/1851 [18:27<05:17,  1.30it/s]\u001b[A\n","Iteration:  78% 1440/1851 [18:28<05:16,  1.30it/s]\u001b[A\n","Iteration:  78% 1441/1851 [18:29<05:15,  1.30it/s]\u001b[A\n","Iteration:  78% 1442/1851 [18:30<05:15,  1.30it/s]\u001b[A\n","Iteration:  78% 1443/1851 [18:30<05:14,  1.30it/s]\u001b[A\n","Iteration:  78% 1444/1851 [18:31<05:14,  1.30it/s]\u001b[A\n","Iteration:  78% 1445/1851 [18:32<05:13,  1.30it/s]\u001b[A\n","Iteration:  78% 1446/1851 [18:33<05:12,  1.30it/s]\u001b[A\n","Iteration:  78% 1447/1851 [18:33<05:12,  1.29it/s]\u001b[A\n","Iteration:  78% 1448/1851 [18:34<05:10,  1.30it/s]\u001b[A\n","Iteration:  78% 1449/1851 [18:35<05:10,  1.30it/s]\u001b[A\n","Iteration:  78% 1450/1851 [18:36<05:09,  1.30it/s]\u001b[A\n","Iteration:  78% 1451/1851 [18:37<05:09,  1.29it/s]\u001b[A\n","Iteration:  78% 1452/1851 [18:37<05:08,  1.29it/s]\u001b[A\n","Iteration:  78% 1453/1851 [18:38<05:07,  1.29it/s]\u001b[A\n","Iteration:  79% 1454/1851 [18:39<05:06,  1.30it/s]\u001b[A\n","Iteration:  79% 1455/1851 [18:40<05:05,  1.30it/s]\u001b[A\n","Iteration:  79% 1456/1851 [18:40<05:04,  1.30it/s]\u001b[A\n","Iteration:  79% 1457/1851 [18:41<05:03,  1.30it/s]\u001b[A\n","Iteration:  79% 1458/1851 [18:42<05:02,  1.30it/s]\u001b[A\n","Iteration:  79% 1459/1851 [18:43<05:01,  1.30it/s]\u001b[A\n","Iteration:  79% 1460/1851 [18:43<05:00,  1.30it/s]\u001b[A\n","Iteration:  79% 1461/1851 [18:44<04:59,  1.30it/s]\u001b[A\n","Iteration:  79% 1462/1851 [18:45<04:59,  1.30it/s]\u001b[A\n","Iteration:  79% 1463/1851 [18:46<04:58,  1.30it/s]\u001b[A\n","Iteration:  79% 1464/1851 [18:47<04:57,  1.30it/s]\u001b[A\n","Iteration:  79% 1465/1851 [18:47<04:56,  1.30it/s]\u001b[A\n","Iteration:  79% 1466/1851 [18:48<04:56,  1.30it/s]\u001b[A\n","Iteration:  79% 1467/1851 [18:49<04:55,  1.30it/s]\u001b[A\n","Iteration:  79% 1468/1851 [18:50<04:54,  1.30it/s]\u001b[A\n","Iteration:  79% 1469/1851 [18:50<04:53,  1.30it/s]\u001b[A\n","Iteration:  79% 1470/1851 [18:51<04:52,  1.30it/s]\u001b[A\n","Iteration:  79% 1471/1851 [18:52<04:52,  1.30it/s]\u001b[A\n","Iteration:  80% 1472/1851 [18:53<04:51,  1.30it/s]\u001b[A\n","Iteration:  80% 1473/1851 [18:53<04:50,  1.30it/s]\u001b[A\n","Iteration:  80% 1474/1851 [18:54<04:50,  1.30it/s]\u001b[A\n","Iteration:  80% 1475/1851 [18:55<04:49,  1.30it/s]\u001b[A\n","Iteration:  80% 1476/1851 [18:56<04:48,  1.30it/s]\u001b[A\n","Iteration:  80% 1477/1851 [18:57<04:48,  1.30it/s]\u001b[A\n","Iteration:  80% 1478/1851 [18:57<04:47,  1.30it/s]\u001b[A\n","Iteration:  80% 1479/1851 [18:58<04:46,  1.30it/s]\u001b[A\n","Iteration:  80% 1480/1851 [18:59<04:46,  1.30it/s]\u001b[A\n","Iteration:  80% 1481/1851 [19:00<04:45,  1.30it/s]\u001b[A\n","Iteration:  80% 1482/1851 [19:00<04:44,  1.30it/s]\u001b[A\n","Iteration:  80% 1483/1851 [19:01<04:43,  1.30it/s]\u001b[A\n","Iteration:  80% 1484/1851 [19:02<04:43,  1.30it/s]\u001b[A\n","Iteration:  80% 1485/1851 [19:03<04:42,  1.30it/s]\u001b[A\n","Iteration:  80% 1486/1851 [19:03<04:41,  1.30it/s]\u001b[A\n","Iteration:  80% 1487/1851 [19:04<04:41,  1.29it/s]\u001b[A\n","Iteration:  80% 1488/1851 [19:05<04:40,  1.29it/s]\u001b[A\n","Iteration:  80% 1489/1851 [19:06<04:39,  1.29it/s]\u001b[A\n","Iteration:  80% 1490/1851 [19:07<04:38,  1.29it/s]\u001b[A\n","Iteration:  81% 1491/1851 [19:07<04:38,  1.29it/s]\u001b[A\n","Iteration:  81% 1492/1851 [19:08<04:37,  1.29it/s]\u001b[A\n","Iteration:  81% 1493/1851 [19:09<04:37,  1.29it/s]\u001b[A\n","Iteration:  81% 1494/1851 [19:10<04:36,  1.29it/s]\u001b[A\n","Iteration:  81% 1495/1851 [19:10<04:35,  1.29it/s]\u001b[A\n","Iteration:  81% 1496/1851 [19:11<04:34,  1.29it/s]\u001b[A\n","Iteration:  81% 1497/1851 [19:12<04:33,  1.30it/s]\u001b[A\n","Iteration:  81% 1498/1851 [19:13<04:32,  1.30it/s]\u001b[A\n","Iteration:  81% 1499/1851 [19:14<04:31,  1.30it/s]\u001b[A\n","Iteration:  81% 1500/1851 [19:14<04:30,  1.30it/s]\u001b[A\n","Iteration:  81% 1501/1851 [19:15<04:30,  1.29it/s]\u001b[A\n","Iteration:  81% 1502/1851 [19:16<04:30,  1.29it/s]\u001b[A\n","Iteration:  81% 1503/1851 [19:17<04:29,  1.29it/s]\u001b[A\n","Iteration:  81% 1504/1851 [19:17<04:28,  1.29it/s]\u001b[A\n","Iteration:  81% 1505/1851 [19:18<04:27,  1.30it/s]\u001b[A\n","Iteration:  81% 1506/1851 [19:19<04:26,  1.30it/s]\u001b[A\n","Iteration:  81% 1507/1851 [19:20<04:25,  1.30it/s]\u001b[A\n","Iteration:  81% 1508/1851 [19:20<04:24,  1.30it/s]\u001b[A\n","Iteration:  82% 1509/1851 [19:21<04:23,  1.30it/s]\u001b[A\n","Iteration:  82% 1510/1851 [19:22<04:23,  1.30it/s]\u001b[A\n","Iteration:  82% 1511/1851 [19:23<04:21,  1.30it/s]\u001b[A\n","Iteration:  82% 1512/1851 [19:24<04:21,  1.30it/s]\u001b[A\n","Iteration:  82% 1513/1851 [19:24<04:20,  1.30it/s]\u001b[A\n","Iteration:  82% 1514/1851 [19:25<04:20,  1.29it/s]\u001b[A\n","Iteration:  82% 1515/1851 [19:26<04:19,  1.29it/s]\u001b[A\n","Iteration:  82% 1516/1851 [19:27<04:18,  1.29it/s]\u001b[A\n","Iteration:  82% 1517/1851 [19:27<04:18,  1.29it/s]\u001b[A\n","Iteration:  82% 1518/1851 [19:28<04:17,  1.29it/s]\u001b[A\n","Iteration:  82% 1519/1851 [19:29<04:16,  1.30it/s]\u001b[A\n","Iteration:  82% 1520/1851 [19:30<04:15,  1.30it/s]\u001b[A\n","Iteration:  82% 1521/1851 [19:30<04:14,  1.30it/s]\u001b[A\n","Iteration:  82% 1522/1851 [19:31<04:13,  1.30it/s]\u001b[A\n","Iteration:  82% 1523/1851 [19:32<04:12,  1.30it/s]\u001b[A\n","Iteration:  82% 1524/1851 [19:33<04:11,  1.30it/s]\u001b[A\n","Iteration:  82% 1525/1851 [19:34<04:11,  1.30it/s]\u001b[A\n","Iteration:  82% 1526/1851 [19:34<04:10,  1.30it/s]\u001b[A\n","Iteration:  82% 1527/1851 [19:35<04:10,  1.30it/s]\u001b[A\n","Iteration:  83% 1528/1851 [19:36<04:09,  1.30it/s]\u001b[A\n","Iteration:  83% 1529/1851 [19:37<04:08,  1.30it/s]\u001b[A\n","Iteration:  83% 1530/1851 [19:37<04:07,  1.30it/s]\u001b[A\n","Iteration:  83% 1531/1851 [19:38<04:06,  1.30it/s]\u001b[A\n","Iteration:  83% 1532/1851 [19:39<04:06,  1.30it/s]\u001b[A\n","Iteration:  83% 1533/1851 [19:40<04:05,  1.29it/s]\u001b[A\n","Iteration:  83% 1534/1851 [19:41<04:05,  1.29it/s]\u001b[A\n","Iteration:  83% 1535/1851 [19:41<04:04,  1.29it/s]\u001b[A\n","Iteration:  83% 1536/1851 [19:42<04:03,  1.29it/s]\u001b[A\n","Iteration:  83% 1537/1851 [19:43<04:02,  1.29it/s]\u001b[A\n","Iteration:  83% 1538/1851 [19:44<04:01,  1.30it/s]\u001b[A\n","Iteration:  83% 1539/1851 [19:44<04:00,  1.30it/s]\u001b[A\n","Iteration:  83% 1540/1851 [19:45<03:59,  1.30it/s]\u001b[A\n","Iteration:  83% 1541/1851 [19:46<03:59,  1.30it/s]\u001b[A\n","Iteration:  83% 1542/1851 [19:47<03:58,  1.29it/s]\u001b[A\n","Iteration:  83% 1543/1851 [19:47<03:57,  1.30it/s]\u001b[A\n","Iteration:  83% 1544/1851 [19:48<03:56,  1.30it/s]\u001b[A\n","Iteration:  83% 1545/1851 [19:49<03:56,  1.29it/s]\u001b[A\n","Iteration:  84% 1546/1851 [19:50<03:55,  1.30it/s]\u001b[A\n","Iteration:  84% 1547/1851 [19:51<03:54,  1.30it/s]\u001b[A\n","Iteration:  84% 1548/1851 [19:51<03:53,  1.30it/s]\u001b[A\n","Iteration:  84% 1549/1851 [19:52<03:53,  1.29it/s]\u001b[A\n","Iteration:  84% 1550/1851 [19:53<03:52,  1.29it/s]\u001b[A\n","Iteration:  84% 1551/1851 [19:54<03:52,  1.29it/s]\u001b[A\n","Iteration:  84% 1552/1851 [19:54<03:51,  1.29it/s]\u001b[A\n","Iteration:  84% 1553/1851 [19:55<03:50,  1.29it/s]\u001b[A\n","Iteration:  84% 1554/1851 [19:56<03:49,  1.30it/s]\u001b[A\n","Iteration:  84% 1555/1851 [19:57<03:48,  1.30it/s]\u001b[A\n","Iteration:  84% 1556/1851 [19:58<03:47,  1.30it/s]\u001b[A\n","Iteration:  84% 1557/1851 [19:58<03:47,  1.29it/s]\u001b[A\n","Iteration:  84% 1558/1851 [19:59<03:46,  1.29it/s]\u001b[A\n","Iteration:  84% 1559/1851 [20:00<03:46,  1.29it/s]\u001b[A\n","Iteration:  84% 1560/1851 [20:01<03:44,  1.29it/s]\u001b[A\n","Iteration:  84% 1561/1851 [20:01<03:44,  1.29it/s]\u001b[A\n","Iteration:  84% 1562/1851 [20:02<03:43,  1.29it/s]\u001b[A\n","Iteration:  84% 1563/1851 [20:03<03:42,  1.29it/s]\u001b[A\n","Iteration:  84% 1564/1851 [20:04<03:42,  1.29it/s]\u001b[A\n","Iteration:  85% 1565/1851 [20:04<03:41,  1.29it/s]\u001b[A\n","Iteration:  85% 1566/1851 [20:05<03:40,  1.29it/s]\u001b[A\n","Iteration:  85% 1567/1851 [20:06<03:39,  1.29it/s]\u001b[A\n","Iteration:  85% 1568/1851 [20:07<03:38,  1.29it/s]\u001b[A\n","Iteration:  85% 1569/1851 [20:08<03:38,  1.29it/s]\u001b[A\n","Iteration:  85% 1570/1851 [20:08<03:37,  1.29it/s]\u001b[A\n","Iteration:  85% 1571/1851 [20:09<03:36,  1.29it/s]\u001b[A\n","Iteration:  85% 1572/1851 [20:10<03:35,  1.29it/s]\u001b[A\n","Iteration:  85% 1573/1851 [20:11<03:34,  1.30it/s]\u001b[A\n","Iteration:  85% 1574/1851 [20:11<03:33,  1.30it/s]\u001b[A\n","Iteration:  85% 1575/1851 [20:12<03:32,  1.30it/s]\u001b[A\n","Iteration:  85% 1576/1851 [20:13<03:32,  1.30it/s]\u001b[A\n","Iteration:  85% 1577/1851 [20:14<03:32,  1.29it/s]\u001b[A\n","Iteration:  85% 1578/1851 [20:15<03:31,  1.29it/s]\u001b[A\n","Iteration:  85% 1579/1851 [20:15<03:30,  1.29it/s]\u001b[A\n","Iteration:  85% 1580/1851 [20:16<03:29,  1.29it/s]\u001b[A\n","Iteration:  85% 1581/1851 [20:17<03:28,  1.29it/s]\u001b[A\n","Iteration:  85% 1582/1851 [20:18<03:28,  1.29it/s]\u001b[A\n","Iteration:  86% 1583/1851 [20:18<03:27,  1.29it/s]\u001b[A\n","Iteration:  86% 1584/1851 [20:19<03:26,  1.29it/s]\u001b[A\n","Iteration:  86% 1585/1851 [20:20<03:25,  1.29it/s]\u001b[A\n","Iteration:  86% 1586/1851 [20:21<03:24,  1.29it/s]\u001b[A\n","Iteration:  86% 1587/1851 [20:21<03:24,  1.29it/s]\u001b[A\n","Iteration:  86% 1588/1851 [20:22<03:23,  1.29it/s]\u001b[A\n","Iteration:  86% 1589/1851 [20:23<03:22,  1.29it/s]\u001b[A\n","Iteration:  86% 1590/1851 [20:24<03:22,  1.29it/s]\u001b[A\n","Iteration:  86% 1591/1851 [20:25<03:21,  1.29it/s]\u001b[A\n","Iteration:  86% 1592/1851 [20:25<03:20,  1.29it/s]\u001b[A\n","Iteration:  86% 1593/1851 [20:26<03:20,  1.29it/s]\u001b[A\n","Iteration:  86% 1594/1851 [20:27<03:19,  1.29it/s]\u001b[A\n","Iteration:  86% 1595/1851 [20:28<03:18,  1.29it/s]\u001b[A\n","Iteration:  86% 1596/1851 [20:28<03:17,  1.29it/s]\u001b[A\n","Iteration:  86% 1597/1851 [20:29<03:16,  1.29it/s]\u001b[A\n","Iteration:  86% 1598/1851 [20:30<03:15,  1.30it/s]\u001b[A\n","Iteration:  86% 1599/1851 [20:31<03:14,  1.29it/s]\u001b[A\n","Iteration:  86% 1600/1851 [20:32<03:14,  1.29it/s]\u001b[A\n","Iteration:  86% 1601/1851 [20:32<03:13,  1.29it/s]\u001b[A\n","Iteration:  87% 1602/1851 [20:33<03:12,  1.29it/s]\u001b[A\n","Iteration:  87% 1603/1851 [20:34<03:11,  1.29it/s]\u001b[A\n","Iteration:  87% 1604/1851 [20:35<03:11,  1.29it/s]\u001b[A\n","Iteration:  87% 1605/1851 [20:35<03:10,  1.29it/s]\u001b[A\n","Iteration:  87% 1606/1851 [20:36<03:09,  1.29it/s]\u001b[A\n","Iteration:  87% 1607/1851 [20:37<03:08,  1.29it/s]\u001b[A\n","Iteration:  87% 1608/1851 [20:38<03:08,  1.29it/s]\u001b[A\n","Iteration:  87% 1609/1851 [20:39<03:07,  1.29it/s]\u001b[A\n","Iteration:  87% 1610/1851 [20:39<03:06,  1.29it/s]\u001b[A\n","Iteration:  87% 1611/1851 [20:40<03:06,  1.29it/s]\u001b[A\n","Iteration:  87% 1612/1851 [20:41<03:04,  1.29it/s]\u001b[A\n","Iteration:  87% 1613/1851 [20:42<03:04,  1.29it/s]\u001b[A\n","Iteration:  87% 1614/1851 [20:42<03:03,  1.29it/s]\u001b[A\n","Iteration:  87% 1615/1851 [20:43<03:02,  1.30it/s]\u001b[A\n","Iteration:  87% 1616/1851 [20:44<03:01,  1.29it/s]\u001b[A\n","Iteration:  87% 1617/1851 [20:45<03:00,  1.29it/s]\u001b[A\n","Iteration:  87% 1618/1851 [20:45<02:59,  1.29it/s]\u001b[A\n","Iteration:  87% 1619/1851 [20:46<02:59,  1.29it/s]\u001b[A\n","Iteration:  88% 1620/1851 [20:47<02:58,  1.29it/s]\u001b[A\n","Iteration:  88% 1621/1851 [20:48<02:58,  1.29it/s]\u001b[A\n","Iteration:  88% 1622/1851 [20:49<02:57,  1.29it/s]\u001b[A\n","Iteration:  88% 1623/1851 [20:49<02:56,  1.29it/s]\u001b[A\n","Iteration:  88% 1624/1851 [20:50<02:55,  1.29it/s]\u001b[A\n","Iteration:  88% 1625/1851 [20:51<02:54,  1.29it/s]\u001b[A\n","Iteration:  88% 1626/1851 [20:52<02:53,  1.29it/s]\u001b[A\n","Iteration:  88% 1627/1851 [20:52<02:53,  1.29it/s]\u001b[A\n","Iteration:  88% 1628/1851 [20:53<02:52,  1.29it/s]\u001b[A\n","Iteration:  88% 1629/1851 [20:54<02:51,  1.30it/s]\u001b[A\n","Iteration:  88% 1630/1851 [20:55<02:50,  1.29it/s]\u001b[A\n","Iteration:  88% 1631/1851 [20:56<02:49,  1.30it/s]\u001b[A\n","Iteration:  88% 1632/1851 [20:56<02:49,  1.29it/s]\u001b[A\n","Iteration:  88% 1633/1851 [20:57<02:48,  1.29it/s]\u001b[A\n","Iteration:  88% 1634/1851 [20:58<02:47,  1.29it/s]\u001b[A\n","Iteration:  88% 1635/1851 [20:59<02:47,  1.29it/s]\u001b[A\n","Iteration:  88% 1636/1851 [20:59<02:46,  1.29it/s]\u001b[A\n","Iteration:  88% 1637/1851 [21:00<02:45,  1.29it/s]\u001b[A\n","Iteration:  88% 1638/1851 [21:01<02:44,  1.29it/s]\u001b[A\n","Iteration:  89% 1639/1851 [21:02<02:43,  1.29it/s]\u001b[A\n","Iteration:  89% 1640/1851 [21:02<02:43,  1.29it/s]\u001b[A\n","Iteration:  89% 1641/1851 [21:03<02:42,  1.29it/s]\u001b[A\n","Iteration:  89% 1642/1851 [21:04<02:41,  1.29it/s]\u001b[A\n","Iteration:  89% 1643/1851 [21:05<02:41,  1.29it/s]\u001b[A\n","Iteration:  89% 1644/1851 [21:06<02:40,  1.29it/s]\u001b[A\n","Iteration:  89% 1645/1851 [21:06<02:39,  1.29it/s]\u001b[A\n","Iteration:  89% 1646/1851 [21:07<02:38,  1.29it/s]\u001b[A\n","Iteration:  89% 1647/1851 [21:08<02:38,  1.29it/s]\u001b[A\n","Iteration:  89% 1648/1851 [21:09<02:37,  1.29it/s]\u001b[A\n","Iteration:  89% 1649/1851 [21:09<02:36,  1.29it/s]\u001b[A\n","Iteration:  89% 1650/1851 [21:10<02:35,  1.29it/s]\u001b[A\n","Iteration:  89% 1651/1851 [21:11<02:34,  1.29it/s]\u001b[A\n","Iteration:  89% 1652/1851 [21:12<02:34,  1.29it/s]\u001b[A\n","Iteration:  89% 1653/1851 [21:13<02:33,  1.29it/s]\u001b[A\n","Iteration:  89% 1654/1851 [21:13<02:32,  1.30it/s]\u001b[A\n","Iteration:  89% 1655/1851 [21:14<02:31,  1.30it/s]\u001b[A\n","Iteration:  89% 1656/1851 [21:15<02:30,  1.30it/s]\u001b[A\n","Iteration:  90% 1657/1851 [21:16<02:29,  1.30it/s]\u001b[A\n","Iteration:  90% 1658/1851 [21:16<02:28,  1.30it/s]\u001b[A\n","Iteration:  90% 1659/1851 [21:17<02:27,  1.30it/s]\u001b[A\n","Iteration:  90% 1660/1851 [21:18<02:27,  1.30it/s]\u001b[A\n","Iteration:  90% 1661/1851 [21:19<02:26,  1.29it/s]\u001b[A\n","Iteration:  90% 1662/1851 [21:20<02:26,  1.29it/s]\u001b[A\n","Iteration:  90% 1663/1851 [21:20<02:25,  1.29it/s]\u001b[A\n","Iteration:  90% 1664/1851 [21:21<02:24,  1.29it/s]\u001b[A\n","Iteration:  90% 1665/1851 [21:22<02:23,  1.30it/s]\u001b[A\n","Iteration:  90% 1666/1851 [21:23<02:23,  1.29it/s]\u001b[A\n","Iteration:  90% 1667/1851 [21:23<02:22,  1.29it/s]\u001b[A\n","Iteration:  90% 1668/1851 [21:24<02:21,  1.29it/s]\u001b[A\n","Iteration:  90% 1669/1851 [21:25<02:21,  1.29it/s]\u001b[A\n","Iteration:  90% 1670/1851 [21:26<02:20,  1.29it/s]\u001b[A\n","Iteration:  90% 1671/1851 [21:26<02:19,  1.29it/s]\u001b[A\n","Iteration:  90% 1672/1851 [21:27<02:18,  1.29it/s]\u001b[A\n","Iteration:  90% 1673/1851 [21:28<02:17,  1.29it/s]\u001b[A\n","Iteration:  90% 1674/1851 [21:29<02:16,  1.29it/s]\u001b[A\n","Iteration:  90% 1675/1851 [21:30<02:16,  1.29it/s]\u001b[A\n","Iteration:  91% 1676/1851 [21:30<02:15,  1.29it/s]\u001b[A\n","Iteration:  91% 1677/1851 [21:31<02:14,  1.29it/s]\u001b[A\n","Iteration:  91% 1678/1851 [21:32<02:13,  1.29it/s]\u001b[A\n","Iteration:  91% 1679/1851 [21:33<02:12,  1.29it/s]\u001b[A\n","Iteration:  91% 1680/1851 [21:33<02:12,  1.29it/s]\u001b[A\n","Iteration:  91% 1681/1851 [21:34<02:11,  1.29it/s]\u001b[A\n","Iteration:  91% 1682/1851 [21:35<02:11,  1.29it/s]\u001b[A\n","Iteration:  91% 1683/1851 [21:36<02:10,  1.29it/s]\u001b[A\n","Iteration:  91% 1684/1851 [21:37<02:09,  1.29it/s]\u001b[A\n","Iteration:  91% 1685/1851 [21:37<02:08,  1.29it/s]\u001b[A\n","Iteration:  91% 1686/1851 [21:38<02:07,  1.29it/s]\u001b[A\n","Iteration:  91% 1687/1851 [21:39<02:06,  1.30it/s]\u001b[A\n","Iteration:  91% 1688/1851 [21:40<02:05,  1.30it/s]\u001b[A\n","Iteration:  91% 1689/1851 [21:40<02:04,  1.30it/s]\u001b[A\n","Iteration:  91% 1690/1851 [21:41<02:04,  1.30it/s]\u001b[A\n","Iteration:  91% 1691/1851 [21:42<02:03,  1.30it/s]\u001b[A\n","Iteration:  91% 1692/1851 [21:43<02:02,  1.30it/s]\u001b[A\n","Iteration:  91% 1693/1851 [21:43<02:01,  1.30it/s]\u001b[A\n","Iteration:  92% 1694/1851 [21:44<02:00,  1.30it/s]\u001b[A\n","Iteration:  92% 1695/1851 [21:45<02:00,  1.30it/s]\u001b[A\n","Iteration:  92% 1696/1851 [21:46<01:59,  1.30it/s]\u001b[A\n","Iteration:  92% 1697/1851 [21:47<01:58,  1.30it/s]\u001b[A\n","Iteration:  92% 1698/1851 [21:47<01:58,  1.29it/s]\u001b[A\n","Iteration:  92% 1699/1851 [21:48<01:57,  1.29it/s]\u001b[A\n","Iteration:  92% 1700/1851 [21:49<01:56,  1.29it/s]\u001b[A\n","Iteration:  92% 1701/1851 [21:50<01:56,  1.29it/s]\u001b[A\n","Iteration:  92% 1702/1851 [21:50<01:55,  1.29it/s]\u001b[A\n","Iteration:  92% 1703/1851 [21:51<01:54,  1.29it/s]\u001b[A\n","Iteration:  92% 1704/1851 [21:52<01:53,  1.29it/s]\u001b[A\n","Iteration:  92% 1705/1851 [21:53<01:53,  1.29it/s]\u001b[A\n","Iteration:  92% 1706/1851 [21:54<01:52,  1.29it/s]\u001b[A\n","Iteration:  92% 1707/1851 [21:54<01:51,  1.29it/s]\u001b[A\n","Iteration:  92% 1708/1851 [21:55<01:50,  1.29it/s]\u001b[A\n","Iteration:  92% 1709/1851 [21:56<01:49,  1.29it/s]\u001b[A\n","Iteration:  92% 1710/1851 [21:57<01:48,  1.29it/s]\u001b[A\n","Iteration:  92% 1711/1851 [21:57<01:48,  1.29it/s]\u001b[A\n","Iteration:  92% 1712/1851 [21:58<01:47,  1.29it/s]\u001b[A\n","Iteration:  93% 1713/1851 [21:59<01:46,  1.29it/s]\u001b[A\n","Iteration:  93% 1714/1851 [22:00<01:46,  1.29it/s]\u001b[A\n","Iteration:  93% 1715/1851 [22:01<01:45,  1.29it/s]\u001b[A\n","Iteration:  93% 1716/1851 [22:01<01:44,  1.29it/s]\u001b[A\n","Iteration:  93% 1717/1851 [22:02<01:43,  1.29it/s]\u001b[A\n","Iteration:  93% 1718/1851 [22:03<01:42,  1.29it/s]\u001b[A\n","Iteration:  93% 1719/1851 [22:04<01:42,  1.29it/s]\u001b[A\n","Iteration:  93% 1720/1851 [22:04<01:41,  1.29it/s]\u001b[A\n","Iteration:  93% 1721/1851 [22:05<01:40,  1.29it/s]\u001b[A\n","Iteration:  93% 1722/1851 [22:06<01:39,  1.29it/s]\u001b[A\n","Iteration:  93% 1723/1851 [22:07<01:39,  1.29it/s]\u001b[A\n","Iteration:  93% 1724/1851 [22:07<01:38,  1.29it/s]\u001b[A\n","Iteration:  93% 1725/1851 [22:08<01:37,  1.29it/s]\u001b[A\n","Iteration:  93% 1726/1851 [22:09<01:36,  1.30it/s]\u001b[A\n","Iteration:  93% 1727/1851 [22:10<01:35,  1.30it/s]\u001b[A\n","Iteration:  93% 1728/1851 [22:11<01:34,  1.30it/s]\u001b[A\n","Iteration:  93% 1729/1851 [22:11<01:34,  1.30it/s]\u001b[A\n","Iteration:  93% 1730/1851 [22:12<01:33,  1.30it/s]\u001b[A\n","Iteration:  94% 1731/1851 [22:13<01:32,  1.30it/s]\u001b[A\n","Iteration:  94% 1732/1851 [22:14<01:31,  1.30it/s]\u001b[A\n","Iteration:  94% 1733/1851 [22:14<01:31,  1.30it/s]\u001b[A\n","Iteration:  94% 1734/1851 [22:15<01:30,  1.29it/s]\u001b[A\n","Iteration:  94% 1735/1851 [22:16<01:29,  1.29it/s]\u001b[A\n","Iteration:  94% 1736/1851 [22:17<01:28,  1.29it/s]\u001b[A\n","Iteration:  94% 1737/1851 [22:18<01:28,  1.29it/s]\u001b[A\n","Iteration:  94% 1738/1851 [22:18<01:27,  1.29it/s]\u001b[A\n","Iteration:  94% 1739/1851 [22:19<01:26,  1.30it/s]\u001b[A\n","Iteration:  94% 1740/1851 [22:20<01:25,  1.30it/s]\u001b[A\n","Iteration:  94% 1741/1851 [22:21<01:24,  1.30it/s]\u001b[A\n","Iteration:  94% 1742/1851 [22:21<01:24,  1.30it/s]\u001b[A\n","Iteration:  94% 1743/1851 [22:22<01:23,  1.29it/s]\u001b[A\n","Iteration:  94% 1744/1851 [22:23<01:22,  1.29it/s]\u001b[A\n","Iteration:  94% 1745/1851 [22:24<01:21,  1.29it/s]\u001b[A\n","Iteration:  94% 1746/1851 [22:24<01:21,  1.29it/s]\u001b[A\n","Iteration:  94% 1747/1851 [22:25<01:20,  1.29it/s]\u001b[A\n","Iteration:  94% 1748/1851 [22:26<01:19,  1.30it/s]\u001b[A\n","Iteration:  94% 1749/1851 [22:27<01:18,  1.29it/s]\u001b[A\n","Iteration:  95% 1750/1851 [22:28<01:17,  1.30it/s]\u001b[A\n","Iteration:  95% 1751/1851 [22:28<01:17,  1.29it/s]\u001b[A\n","Iteration:  95% 1752/1851 [22:29<01:16,  1.29it/s]\u001b[A\n","Iteration:  95% 1753/1851 [22:30<01:15,  1.29it/s]\u001b[A\n","Iteration:  95% 1754/1851 [22:31<01:15,  1.29it/s]\u001b[A\n","Iteration:  95% 1755/1851 [22:31<01:14,  1.29it/s]\u001b[A\n","Iteration:  95% 1756/1851 [22:32<01:13,  1.29it/s]\u001b[A\n","Iteration:  95% 1757/1851 [22:33<01:12,  1.30it/s]\u001b[A\n","Iteration:  95% 1758/1851 [22:34<01:11,  1.30it/s]\u001b[A\n","Iteration:  95% 1759/1851 [22:34<01:11,  1.29it/s]\u001b[A\n","Iteration:  95% 1760/1851 [22:35<01:10,  1.29it/s]\u001b[A\n","Iteration:  95% 1761/1851 [22:36<01:09,  1.29it/s]\u001b[A\n","Iteration:  95% 1762/1851 [22:37<01:08,  1.29it/s]\u001b[A\n","Iteration:  95% 1763/1851 [22:38<01:07,  1.29it/s]\u001b[A\n","Iteration:  95% 1764/1851 [22:38<01:07,  1.30it/s]\u001b[A\n","Iteration:  95% 1765/1851 [22:39<01:06,  1.30it/s]\u001b[A\n","Iteration:  95% 1766/1851 [22:40<01:05,  1.29it/s]\u001b[A\n","Iteration:  95% 1767/1851 [22:41<01:05,  1.29it/s]\u001b[A\n","Iteration:  96% 1768/1851 [22:41<01:04,  1.29it/s]\u001b[A\n","Iteration:  96% 1769/1851 [22:42<01:03,  1.30it/s]\u001b[A\n","Iteration:  96% 1770/1851 [22:43<01:02,  1.30it/s]\u001b[A\n","Iteration:  96% 1771/1851 [22:44<01:01,  1.30it/s]\u001b[A\n","Iteration:  96% 1772/1851 [22:45<01:01,  1.29it/s]\u001b[A\n","Iteration:  96% 1773/1851 [22:45<01:00,  1.29it/s]\u001b[A\n","Iteration:  96% 1774/1851 [22:46<00:59,  1.29it/s]\u001b[A\n","Iteration:  96% 1775/1851 [22:47<00:58,  1.29it/s]\u001b[A\n","Iteration:  96% 1776/1851 [22:48<00:58,  1.29it/s]\u001b[A\n","Iteration:  96% 1777/1851 [22:48<00:57,  1.29it/s]\u001b[A\n","Iteration:  96% 1778/1851 [22:49<00:56,  1.29it/s]\u001b[A\n","Iteration:  96% 1779/1851 [22:50<00:55,  1.30it/s]\u001b[A\n","Iteration:  96% 1780/1851 [22:51<00:54,  1.29it/s]\u001b[A\n","Iteration:  96% 1781/1851 [22:52<00:54,  1.29it/s]\u001b[A\n","Iteration:  96% 1782/1851 [22:52<00:53,  1.29it/s]\u001b[A\n","Iteration:  96% 1783/1851 [22:53<00:52,  1.29it/s]\u001b[A\n","Iteration:  96% 1784/1851 [22:54<00:51,  1.29it/s]\u001b[A\n","Iteration:  96% 1785/1851 [22:55<00:51,  1.29it/s]\u001b[A\n","Iteration:  96% 1786/1851 [22:55<00:50,  1.30it/s]\u001b[A\n","Iteration:  97% 1787/1851 [22:56<00:49,  1.29it/s]\u001b[A\n","Iteration:  97% 1788/1851 [22:57<00:48,  1.30it/s]\u001b[A\n","Iteration:  97% 1789/1851 [22:58<00:47,  1.30it/s]\u001b[A\n","Iteration:  97% 1790/1851 [22:58<00:47,  1.30it/s]\u001b[A\n","Iteration:  97% 1791/1851 [22:59<00:46,  1.29it/s]\u001b[A\n","Iteration:  97% 1792/1851 [23:00<00:45,  1.29it/s]\u001b[A\n","Iteration:  97% 1793/1851 [23:01<00:44,  1.29it/s]\u001b[A\n","Iteration:  97% 1794/1851 [23:02<00:44,  1.29it/s]\u001b[A\n","Iteration:  97% 1795/1851 [23:02<00:43,  1.29it/s]\u001b[A\n","Iteration:  97% 1796/1851 [23:03<00:42,  1.29it/s]\u001b[A\n","Iteration:  97% 1797/1851 [23:04<00:41,  1.29it/s]\u001b[A\n","Iteration:  97% 1798/1851 [23:05<00:40,  1.29it/s]\u001b[A\n","Iteration:  97% 1799/1851 [23:05<00:40,  1.29it/s]\u001b[A\n","Iteration:  97% 1800/1851 [23:06<00:39,  1.29it/s]\u001b[A\n","Iteration:  97% 1801/1851 [23:07<00:38,  1.29it/s]\u001b[A\n","Iteration:  97% 1802/1851 [23:08<00:37,  1.29it/s]\u001b[A\n","Iteration:  97% 1803/1851 [23:09<00:37,  1.30it/s]\u001b[A\n","Iteration:  97% 1804/1851 [23:09<00:36,  1.30it/s]\u001b[A\n","Iteration:  98% 1805/1851 [23:10<00:35,  1.30it/s]\u001b[A\n","Iteration:  98% 1806/1851 [23:11<00:34,  1.30it/s]\u001b[A\n","Iteration:  98% 1807/1851 [23:12<00:33,  1.30it/s]\u001b[A\n","Iteration:  98% 1808/1851 [23:12<00:33,  1.30it/s]\u001b[A\n","Iteration:  98% 1809/1851 [23:13<00:32,  1.30it/s]\u001b[A\n","Iteration:  98% 1810/1851 [23:14<00:31,  1.30it/s]\u001b[A\n","Iteration:  98% 1811/1851 [23:15<00:30,  1.30it/s]\u001b[A\n","Iteration:  98% 1812/1851 [23:15<00:30,  1.30it/s]\u001b[A\n","Iteration:  98% 1813/1851 [23:16<00:29,  1.30it/s]\u001b[A\n","Iteration:  98% 1814/1851 [23:17<00:28,  1.29it/s]\u001b[A\n","Iteration:  98% 1815/1851 [23:18<00:27,  1.29it/s]\u001b[A\n","Iteration:  98% 1816/1851 [23:19<00:27,  1.29it/s]\u001b[A\n","Iteration:  98% 1817/1851 [23:19<00:26,  1.29it/s]\u001b[A\n","Iteration:  98% 1818/1851 [23:20<00:25,  1.29it/s]\u001b[A\n","Iteration:  98% 1819/1851 [23:21<00:24,  1.29it/s]\u001b[A\n","Iteration:  98% 1820/1851 [23:22<00:23,  1.29it/s]\u001b[A\n","Iteration:  98% 1821/1851 [23:22<00:23,  1.30it/s]\u001b[A\n","Iteration:  98% 1822/1851 [23:23<00:22,  1.29it/s]\u001b[A\n","Iteration:  98% 1823/1851 [23:24<00:21,  1.29it/s]\u001b[A\n","Iteration:  99% 1824/1851 [23:25<00:20,  1.29it/s]\u001b[A\n","Iteration:  99% 1825/1851 [23:25<00:20,  1.29it/s]\u001b[A\n","Iteration:  99% 1826/1851 [23:26<00:19,  1.30it/s]\u001b[A\n","Iteration:  99% 1827/1851 [23:27<00:18,  1.30it/s]\u001b[A\n","Iteration:  99% 1828/1851 [23:28<00:17,  1.30it/s]\u001b[A\n","Iteration:  99% 1829/1851 [23:29<00:16,  1.30it/s]\u001b[A\n","Iteration:  99% 1830/1851 [23:29<00:16,  1.30it/s]\u001b[A\n","Iteration:  99% 1831/1851 [23:30<00:15,  1.29it/s]\u001b[A\n","Iteration:  99% 1832/1851 [23:31<00:14,  1.29it/s]\u001b[A\n","Iteration:  99% 1833/1851 [23:32<00:13,  1.29it/s]\u001b[A\n","Iteration:  99% 1834/1851 [23:32<00:13,  1.29it/s]\u001b[A\n","Iteration:  99% 1835/1851 [23:33<00:12,  1.29it/s]\u001b[A\n","Iteration:  99% 1836/1851 [23:34<00:11,  1.29it/s]\u001b[A\n","Iteration:  99% 1837/1851 [23:35<00:10,  1.29it/s]\u001b[A\n","Iteration:  99% 1838/1851 [23:36<00:10,  1.29it/s]\u001b[A\n","Iteration:  99% 1839/1851 [23:36<00:09,  1.29it/s]\u001b[A\n","Iteration:  99% 1840/1851 [23:37<00:08,  1.30it/s]\u001b[A\n","Iteration:  99% 1841/1851 [23:38<00:07,  1.29it/s]\u001b[A\n","Iteration: 100% 1842/1851 [23:39<00:06,  1.29it/s]\u001b[A\n","Iteration: 100% 1843/1851 [23:39<00:06,  1.29it/s]\u001b[A\n","Iteration: 100% 1844/1851 [23:40<00:05,  1.29it/s]\u001b[A\n","Iteration: 100% 1845/1851 [23:41<00:04,  1.29it/s]\u001b[A\n","Iteration: 100% 1846/1851 [23:42<00:03,  1.29it/s]\u001b[A\n","Iteration: 100% 1847/1851 [23:42<00:03,  1.29it/s]\u001b[A\n","Iteration: 100% 1848/1851 [23:43<00:02,  1.29it/s]\u001b[A\n","Iteration: 100% 1849/1851 [23:44<00:01,  1.29it/s]\u001b[A\n","Iteration: 100% 1850/1851 [23:45<00:00,  1.29it/s]\u001b[A\n","Iteration: 100% 1851/1851 [23:46<00:00,  1.30it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-16 05:10:42,147][__main__][DEBUG] - epoch is 0\n","[2022-08-16 05:10:42,149][__main__][DEBUG] - validation loss is tensor(0.1373, device='cuda:0')\n","Epoch:   1% 1/100 [28:23<46:50:45, 1703.49s/it]\n","Iteration:   0% 0/1851 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\n","Iteration:   0% 1/1851 [00:01<55:53,  1.81s/it]\u001b[A\n","Iteration:   0% 2/1851 [00:02<36:52,  1.20s/it]\u001b[A\n","Iteration:   0% 3/1851 [00:03<30:47,  1.00it/s]\u001b[A\n","Iteration:   0% 4/1851 [00:04<27:53,  1.10it/s]\u001b[A\n","Iteration:   0% 5/1851 [00:04<26:24,  1.16it/s]\u001b[A\n","Iteration:   0% 6/1851 [00:05<25:28,  1.21it/s]\u001b[A\n","Iteration:   0% 7/1851 [00:06<24:53,  1.24it/s]\u001b[A\n","Iteration:   0% 8/1851 [00:07<24:29,  1.25it/s]\u001b[A\n","Iteration:   0% 9/1851 [00:07<24:13,  1.27it/s]\u001b[A\n","Iteration:   1% 10/1851 [00:08<24:04,  1.27it/s]\u001b[A\n","Iteration:   1% 11/1851 [00:09<23:55,  1.28it/s]\u001b[A\n","Iteration:   1% 12/1851 [00:10<23:49,  1.29it/s]\u001b[A\n","Iteration:   1% 13/1851 [00:11<23:47,  1.29it/s]\u001b[A\n","Iteration:   1% 14/1851 [00:11<23:41,  1.29it/s]\u001b[A\n","Iteration:   1% 15/1851 [00:12<23:40,  1.29it/s]\u001b[A\n","Iteration:   1% 16/1851 [00:13<23:39,  1.29it/s]\u001b[A\n","Iteration:   1% 17/1851 [00:14<23:41,  1.29it/s]\u001b[A\n","Iteration:   1% 18/1851 [00:14<23:42,  1.29it/s]\u001b[A\n","Iteration:   1% 19/1851 [00:15<23:39,  1.29it/s]\u001b[A\n","Iteration:   1% 20/1851 [00:16<23:38,  1.29it/s]\u001b[A\n","Iteration:   1% 21/1851 [00:17<23:41,  1.29it/s]\u001b[A\n","Iteration:   1% 22/1851 [00:18<23:40,  1.29it/s]\u001b[A\n","Iteration:   1% 23/1851 [00:18<23:40,  1.29it/s]\u001b[A\n","Iteration:   1% 24/1851 [00:19<23:37,  1.29it/s]\u001b[A\n","Iteration:   1% 25/1851 [00:20<23:37,  1.29it/s]\u001b[A\n","Iteration:   1% 26/1851 [00:21<23:38,  1.29it/s]\u001b[A\n","Iteration:   1% 27/1851 [00:21<23:38,  1.29it/s]\u001b[A\n","Iteration:   2% 28/1851 [00:22<23:40,  1.28it/s]\u001b[A\n","Iteration:   2% 29/1851 [00:23<23:39,  1.28it/s]\u001b[A\n","Iteration:   2% 30/1851 [00:24<23:35,  1.29it/s]\u001b[A\n","Iteration:   2% 31/1851 [00:25<23:36,  1.28it/s]\u001b[A\n","Iteration:   2% 32/1851 [00:25<23:35,  1.29it/s]\u001b[A\n","Iteration:   2% 33/1851 [00:26<23:34,  1.28it/s]\u001b[A\n","Iteration:   2% 34/1851 [00:27<23:37,  1.28it/s]\u001b[A\n","Iteration:   2% 35/1851 [00:28<23:36,  1.28it/s]\u001b[A\n","Iteration:   2% 36/1851 [00:28<23:35,  1.28it/s]\u001b[A\n","Iteration:   2% 37/1851 [00:29<23:33,  1.28it/s]\u001b[A\n","Iteration:   2% 38/1851 [00:30<23:32,  1.28it/s]\u001b[A\n","Iteration:   2% 39/1851 [00:31<23:30,  1.28it/s]\u001b[A\n","Iteration:   2% 40/1851 [00:32<23:30,  1.28it/s]\u001b[A\n","Iteration:   2% 41/1851 [00:32<23:28,  1.28it/s]\u001b[A\n","Iteration:   2% 42/1851 [00:33<23:27,  1.29it/s]\u001b[A\n","Iteration:   2% 43/1851 [00:34<23:23,  1.29it/s]\u001b[A\n","Iteration:   2% 44/1851 [00:35<23:25,  1.29it/s]\u001b[A\n","Iteration:   2% 45/1851 [00:35<23:25,  1.29it/s]\u001b[A\n","Iteration:   2% 46/1851 [00:36<23:25,  1.28it/s]\u001b[A\n","Iteration:   3% 47/1851 [00:37<23:24,  1.28it/s]\u001b[A\n","Iteration:   3% 48/1851 [00:38<23:21,  1.29it/s]\u001b[A\n","Iteration:   3% 49/1851 [00:39<23:21,  1.29it/s]\u001b[A\n","Iteration:   3% 50/1851 [00:39<23:22,  1.28it/s]\u001b[A\n","Iteration:   3% 51/1851 [00:40<23:20,  1.29it/s]\u001b[A\n","Iteration:   3% 52/1851 [00:41<23:19,  1.29it/s]\u001b[A\n","Iteration:   3% 53/1851 [00:42<23:14,  1.29it/s]\u001b[A\n","Iteration:   3% 54/1851 [00:42<23:12,  1.29it/s]\u001b[A\n","Iteration:   3% 55/1851 [00:43<23:10,  1.29it/s]\u001b[A\n","Iteration:   3% 56/1851 [00:44<23:10,  1.29it/s]\u001b[A\n","Iteration:   3% 57/1851 [00:45<23:13,  1.29it/s]\u001b[A\n","Iteration:   3% 58/1851 [00:46<23:09,  1.29it/s]\u001b[A\n","Iteration:   3% 59/1851 [00:46<23:07,  1.29it/s]\u001b[A\n","Iteration:   3% 60/1851 [00:47<23:07,  1.29it/s]\u001b[A\n","Iteration:   3% 61/1851 [00:48<23:07,  1.29it/s]\u001b[A\n","Iteration:   3% 62/1851 [00:49<23:06,  1.29it/s]\u001b[A\n","Iteration:   3% 63/1851 [00:49<23:02,  1.29it/s]\u001b[A\n","Iteration:   3% 64/1851 [00:50<23:01,  1.29it/s]\u001b[A\n","Iteration:   4% 65/1851 [00:51<23:00,  1.29it/s]\u001b[A\n","Iteration:   4% 66/1851 [00:52<22:57,  1.30it/s]\u001b[A\n","Iteration:   4% 67/1851 [00:52<22:57,  1.29it/s]\u001b[A\n","Iteration:   4% 68/1851 [00:53<22:55,  1.30it/s]\u001b[A\n","Iteration:   4% 69/1851 [00:54<22:51,  1.30it/s]\u001b[A\n","Iteration:   4% 70/1851 [00:55<22:52,  1.30it/s]\u001b[A\n","Iteration:   4% 71/1851 [00:56<22:51,  1.30it/s]\u001b[A\n","Iteration:   4% 72/1851 [00:56<22:49,  1.30it/s]\u001b[A\n","Iteration:   4% 73/1851 [00:57<22:48,  1.30it/s]\u001b[A\n","Iteration:   4% 74/1851 [00:58<22:49,  1.30it/s]\u001b[A\n","Iteration:   4% 75/1851 [00:59<22:48,  1.30it/s]\u001b[A\n","Iteration:   4% 76/1851 [00:59<22:46,  1.30it/s]\u001b[A\n","Iteration:   4% 77/1851 [01:00<22:46,  1.30it/s]\u001b[A\n","Iteration:   4% 78/1851 [01:01<22:45,  1.30it/s]\u001b[A\n","Iteration:   4% 79/1851 [01:02<22:44,  1.30it/s]\u001b[A\n","Iteration:   4% 80/1851 [01:02<22:42,  1.30it/s]\u001b[A\n","Iteration:   4% 81/1851 [01:03<22:40,  1.30it/s]\u001b[A\n","Iteration:   4% 82/1851 [01:04<22:41,  1.30it/s]\u001b[A\n","Iteration:   4% 83/1851 [01:05<22:41,  1.30it/s]\u001b[A\n","Iteration:   5% 84/1851 [01:06<22:40,  1.30it/s]\u001b[A\n","Iteration:   5% 85/1851 [01:06<22:39,  1.30it/s]\u001b[A\n","Iteration:   5% 86/1851 [01:07<22:38,  1.30it/s]\u001b[A\n","Iteration:   5% 87/1851 [01:08<22:36,  1.30it/s]\u001b[A\n","Iteration:   5% 88/1851 [01:09<22:37,  1.30it/s]\u001b[A\n","Iteration:   5% 89/1851 [01:09<22:35,  1.30it/s]\u001b[A\n","Iteration:   5% 90/1851 [01:10<22:35,  1.30it/s]\u001b[A\n","Iteration:   5% 91/1851 [01:11<22:35,  1.30it/s]\u001b[A\n","Iteration:   5% 92/1851 [01:12<22:34,  1.30it/s]\u001b[A\n","Iteration:   5% 93/1851 [01:12<22:33,  1.30it/s]\u001b[A\n","Iteration:   5% 94/1851 [01:13<22:34,  1.30it/s]\u001b[A\n","Iteration:   5% 95/1851 [01:14<22:31,  1.30it/s]\u001b[A\n","Iteration:   5% 96/1851 [01:15<22:30,  1.30it/s]\u001b[A\n","Iteration:   5% 97/1851 [01:16<22:28,  1.30it/s]\u001b[A\n","Iteration:   5% 98/1851 [01:16<22:31,  1.30it/s]\u001b[A\n","Iteration:   5% 99/1851 [01:17<22:30,  1.30it/s]\u001b[A\n","Iteration:   5% 100/1851 [01:18<22:30,  1.30it/s]\u001b[A\n","Iteration:   5% 101/1851 [01:19<22:28,  1.30it/s]\u001b[A\n","Iteration:   6% 102/1851 [01:19<22:27,  1.30it/s]\u001b[A\n","Iteration:   6% 103/1851 [01:20<22:29,  1.30it/s]\u001b[A\n","Iteration:   6% 104/1851 [01:21<22:28,  1.30it/s]\u001b[A\n","Iteration:   6% 105/1851 [01:22<22:27,  1.30it/s]\u001b[A\n","Iteration:   6% 106/1851 [01:23<22:27,  1.30it/s]\u001b[A\n","Iteration:   6% 107/1851 [01:23<22:25,  1.30it/s]\u001b[A\n","Iteration:   6% 108/1851 [01:24<22:26,  1.29it/s]\u001b[A\n","Iteration:   6% 109/1851 [01:25<22:25,  1.29it/s]\u001b[A\n","Iteration:   6% 110/1851 [01:26<22:23,  1.30it/s]\u001b[A\n","Iteration:   6% 111/1851 [01:26<22:20,  1.30it/s]\u001b[A\n","Iteration:   6% 112/1851 [01:27<22:20,  1.30it/s]\u001b[A\n","Iteration:   6% 113/1851 [01:28<22:20,  1.30it/s]\u001b[A\n","Iteration:   6% 114/1851 [01:29<22:19,  1.30it/s]\u001b[A\n","Iteration:   6% 115/1851 [01:29<22:19,  1.30it/s]\u001b[A\n","Iteration:   6% 116/1851 [01:30<22:18,  1.30it/s]\u001b[A\n","Iteration:   6% 117/1851 [01:31<22:18,  1.30it/s]\u001b[A\n","Iteration:   6% 118/1851 [01:32<22:18,  1.30it/s]\u001b[A\n","Iteration:   6% 119/1851 [01:33<22:16,  1.30it/s]\u001b[A\n","Iteration:   6% 120/1851 [01:33<22:13,  1.30it/s]\u001b[A\n","Iteration:   7% 121/1851 [01:34<22:15,  1.30it/s]\u001b[A\n","Iteration:   7% 122/1851 [01:35<22:15,  1.29it/s]\u001b[A\n","Iteration:   7% 123/1851 [01:36<22:14,  1.30it/s]\u001b[A\n","Iteration:   7% 124/1851 [01:36<22:13,  1.30it/s]\u001b[A\n","Iteration:   7% 125/1851 [01:37<22:12,  1.29it/s]\u001b[A\n","Iteration:   7% 126/1851 [01:38<22:11,  1.30it/s]\u001b[A\n","Iteration:   7% 127/1851 [01:39<22:09,  1.30it/s]\u001b[A\n","Iteration:   7% 128/1851 [01:39<22:08,  1.30it/s]\u001b[A\n","Iteration:   7% 129/1851 [01:40<22:07,  1.30it/s]\u001b[A\n","Iteration:   7% 130/1851 [01:41<22:05,  1.30it/s]\u001b[A\n","Iteration:   7% 131/1851 [01:42<22:06,  1.30it/s]\u001b[A\n","Iteration:   7% 132/1851 [01:43<22:05,  1.30it/s]\u001b[A\n","Iteration:   7% 133/1851 [01:43<22:05,  1.30it/s]\u001b[A\n","Iteration:   7% 134/1851 [01:44<22:06,  1.29it/s]\u001b[A\n","Iteration:   7% 135/1851 [01:45<22:05,  1.29it/s]\u001b[A\n","Iteration:   7% 136/1851 [01:46<22:06,  1.29it/s]\u001b[A\n","Iteration:   7% 137/1851 [01:46<22:06,  1.29it/s]\u001b[A\n","Iteration:   7% 138/1851 [01:47<22:05,  1.29it/s]\u001b[A\n","Iteration:   8% 139/1851 [01:48<22:03,  1.29it/s]\u001b[A\n","Iteration:   8% 140/1851 [01:49<22:02,  1.29it/s]\u001b[A\n","Iteration:   8% 141/1851 [01:50<22:03,  1.29it/s]\u001b[A\n","Iteration:   8% 142/1851 [01:50<22:02,  1.29it/s]\u001b[A\n","Iteration:   8% 143/1851 [01:51<22:01,  1.29it/s]\u001b[A\n","Iteration:   8% 144/1851 [01:52<22:00,  1.29it/s]\u001b[A\n","Iteration:   8% 145/1851 [01:53<21:58,  1.29it/s]\u001b[A\n","Iteration:   8% 146/1851 [01:53<21:59,  1.29it/s]\u001b[A\n","Iteration:   8% 147/1851 [01:54<21:59,  1.29it/s]\u001b[A\n","Iteration:   8% 148/1851 [01:55<21:59,  1.29it/s]\u001b[A\n","Iteration:   8% 149/1851 [01:56<21:56,  1.29it/s]\u001b[A\n","Iteration:   8% 150/1851 [01:57<21:55,  1.29it/s]\u001b[A\n","Iteration:   8% 151/1851 [01:57<21:56,  1.29it/s]\u001b[A\n","Iteration:   8% 152/1851 [01:58<21:54,  1.29it/s]\u001b[A\n","Iteration:   8% 153/1851 [01:59<21:53,  1.29it/s]\u001b[A\n","Iteration:   8% 154/1851 [02:00<21:53,  1.29it/s]\u001b[A\n","Iteration:   8% 155/1851 [02:00<21:52,  1.29it/s]\u001b[A\n","Iteration:   8% 156/1851 [02:01<21:51,  1.29it/s]\u001b[A\n","Iteration:   8% 157/1851 [02:02<21:51,  1.29it/s]\u001b[A\n","Iteration:   9% 158/1851 [02:03<21:51,  1.29it/s]\u001b[A\n","Iteration:   9% 159/1851 [02:03<21:49,  1.29it/s]\u001b[A\n","Iteration:   9% 160/1851 [02:04<21:46,  1.29it/s]\u001b[A\n","Iteration:   9% 161/1851 [02:05<21:45,  1.29it/s]\u001b[A\n","Iteration:   9% 162/1851 [02:06<21:45,  1.29it/s]\u001b[A\n","Iteration:   9% 163/1851 [02:07<21:44,  1.29it/s]\u001b[A\n","Iteration:   9% 164/1851 [02:07<21:45,  1.29it/s]\u001b[A\n","Iteration:   9% 165/1851 [02:08<21:45,  1.29it/s]\u001b[A\n","Iteration:   9% 166/1851 [02:09<21:45,  1.29it/s]\u001b[A\n","Iteration:   9% 167/1851 [02:10<21:43,  1.29it/s]\u001b[A\n","Iteration:   9% 168/1851 [02:10<21:40,  1.29it/s]\u001b[A\n","Iteration:   9% 169/1851 [02:11<21:43,  1.29it/s]\u001b[A\n","Iteration:   9% 170/1851 [02:12<21:43,  1.29it/s]\u001b[A\n","Iteration:   9% 171/1851 [02:13<21:41,  1.29it/s]\u001b[A\n","Iteration:   9% 172/1851 [02:14<21:37,  1.29it/s]\u001b[A\n","Iteration:   9% 173/1851 [02:14<21:36,  1.29it/s]\u001b[A\n","Iteration:   9% 174/1851 [02:15<21:37,  1.29it/s]\u001b[A\n","Iteration:   9% 175/1851 [02:16<21:40,  1.29it/s]\u001b[A\n","Iteration:  10% 176/1851 [02:17<21:37,  1.29it/s]\u001b[A\n","Iteration:  10% 177/1851 [02:17<21:37,  1.29it/s]\u001b[A\n","Iteration:  10% 178/1851 [02:18<21:38,  1.29it/s]\u001b[A\n","Iteration:  10% 179/1851 [02:19<21:37,  1.29it/s]\u001b[A\n","Iteration:  10% 180/1851 [02:20<21:35,  1.29it/s]\u001b[A\n","Iteration:  10% 181/1851 [02:21<21:34,  1.29it/s]\u001b[A\n","Iteration:  10% 182/1851 [02:21<21:31,  1.29it/s]\u001b[A\n","Iteration:  10% 183/1851 [02:22<21:33,  1.29it/s]\u001b[A\n","Iteration:  10% 184/1851 [02:23<21:32,  1.29it/s]\u001b[A\n","Iteration:  10% 185/1851 [02:24<21:33,  1.29it/s]\u001b[A\n","Iteration:  10% 186/1851 [02:24<21:30,  1.29it/s]\u001b[A\n","Iteration:  10% 187/1851 [02:25<21:29,  1.29it/s]\u001b[A\n","Iteration:  10% 188/1851 [02:26<21:30,  1.29it/s]\u001b[A\n","Iteration:  10% 189/1851 [02:27<21:29,  1.29it/s]\u001b[A\n","Iteration:  10% 190/1851 [02:27<21:26,  1.29it/s]\u001b[A\n","Iteration:  10% 191/1851 [02:28<21:25,  1.29it/s]\u001b[A\n","Iteration:  10% 192/1851 [02:29<21:24,  1.29it/s]\u001b[A\n","Iteration:  10% 193/1851 [02:30<21:22,  1.29it/s]\u001b[A\n","Iteration:  10% 194/1851 [02:31<21:23,  1.29it/s]\u001b[A\n","Iteration:  11% 195/1851 [02:31<21:25,  1.29it/s]\u001b[A\n","Iteration:  11% 196/1851 [02:32<21:23,  1.29it/s]\u001b[A\n","Iteration:  11% 197/1851 [02:33<21:18,  1.29it/s]\u001b[A\n","Iteration:  11% 198/1851 [02:34<21:27,  1.28it/s]\u001b[A\n","Iteration:  11% 199/1851 [02:34<21:27,  1.28it/s]\u001b[A\n","Iteration:  11% 200/1851 [02:35<21:25,  1.28it/s]\u001b[A\n","Iteration:  11% 201/1851 [02:36<21:21,  1.29it/s]\u001b[A\n","Iteration:  11% 202/1851 [02:37<21:16,  1.29it/s]\u001b[A\n","Iteration:  11% 203/1851 [02:38<21:18,  1.29it/s]\u001b[A\n","Iteration:  11% 204/1851 [02:38<21:17,  1.29it/s]\u001b[A\n","Iteration:  11% 205/1851 [02:39<21:15,  1.29it/s]\u001b[A\n","Iteration:  11% 206/1851 [02:40<21:13,  1.29it/s]\u001b[A\n","Iteration:  11% 207/1851 [02:41<21:10,  1.29it/s]\u001b[A\n","Iteration:  11% 208/1851 [02:41<21:10,  1.29it/s]\u001b[A\n","Iteration:  11% 209/1851 [02:42<21:10,  1.29it/s]\u001b[A\n","Iteration:  11% 210/1851 [02:43<21:10,  1.29it/s]\u001b[A\n","Iteration:  11% 211/1851 [02:44<21:10,  1.29it/s]\u001b[A\n","Iteration:  11% 212/1851 [02:45<21:09,  1.29it/s]\u001b[A\n","Iteration:  12% 213/1851 [02:45<21:07,  1.29it/s]\u001b[A\n","Iteration:  12% 214/1851 [02:46<21:05,  1.29it/s]\u001b[A\n","Iteration:  12% 215/1851 [02:47<21:05,  1.29it/s]\u001b[A\n","Iteration:  12% 216/1851 [02:48<21:06,  1.29it/s]\u001b[A\n","Iteration:  12% 217/1851 [02:48<21:05,  1.29it/s]\u001b[A\n","Iteration:  12% 218/1851 [02:49<21:06,  1.29it/s]\u001b[A\n","Iteration:  12% 219/1851 [02:50<21:04,  1.29it/s]\u001b[A\n","Iteration:  12% 220/1851 [02:51<21:03,  1.29it/s]\u001b[A\n","Iteration:  12% 221/1851 [02:52<21:03,  1.29it/s]\u001b[A\n","Iteration:  12% 222/1851 [02:52<21:02,  1.29it/s]\u001b[A\n","Iteration:  12% 223/1851 [02:53<20:58,  1.29it/s]\u001b[A\n","Iteration:  12% 224/1851 [02:54<20:57,  1.29it/s]\u001b[A\n","Iteration:  12% 225/1851 [02:55<20:54,  1.30it/s]\u001b[A\n","Iteration:  12% 226/1851 [02:55<20:53,  1.30it/s]\u001b[A\n","Iteration:  12% 227/1851 [02:56<20:54,  1.29it/s]\u001b[A\n","Iteration:  12% 228/1851 [02:57<20:52,  1.30it/s]\u001b[A\n","Iteration:  12% 229/1851 [02:58<20:51,  1.30it/s]\u001b[A\n","Iteration:  12% 230/1851 [02:58<20:50,  1.30it/s]\u001b[A\n","Iteration:  12% 231/1851 [02:59<20:49,  1.30it/s]\u001b[A\n","Iteration:  13% 232/1851 [03:00<20:49,  1.30it/s]\u001b[A\n","Iteration:  13% 233/1851 [03:01<20:50,  1.29it/s]\u001b[A\n","Iteration:  13% 234/1851 [03:02<20:51,  1.29it/s]\u001b[A\n","Iteration:  13% 235/1851 [03:02<20:50,  1.29it/s]\u001b[A\n","Iteration:  13% 236/1851 [03:03<20:50,  1.29it/s]\u001b[A\n","Iteration:  13% 237/1851 [03:04<20:49,  1.29it/s]\u001b[A\n","Iteration:  13% 238/1851 [03:05<20:47,  1.29it/s]\u001b[A\n","Iteration:  13% 239/1851 [03:05<20:49,  1.29it/s]\u001b[A\n","Iteration:  13% 240/1851 [03:06<20:46,  1.29it/s]\u001b[A\n","Iteration:  13% 241/1851 [03:07<20:45,  1.29it/s]\u001b[A\n","Iteration:  13% 242/1851 [03:08<20:44,  1.29it/s]\u001b[A\n","Iteration:  13% 243/1851 [03:09<20:43,  1.29it/s]\u001b[A\n","Iteration:  13% 244/1851 [03:09<20:45,  1.29it/s]\u001b[A\n","Iteration:  13% 245/1851 [03:10<20:44,  1.29it/s]\u001b[A\n","Iteration:  13% 246/1851 [03:11<20:42,  1.29it/s]\u001b[A\n","Iteration:  13% 247/1851 [03:12<20:41,  1.29it/s]\u001b[A\n","Iteration:  13% 248/1851 [03:12<20:39,  1.29it/s]\u001b[A\n","Iteration:  13% 249/1851 [03:13<20:39,  1.29it/s]\u001b[A\n","Iteration:  14% 250/1851 [03:14<20:37,  1.29it/s]\u001b[A\n","Iteration:  14% 251/1851 [03:15<20:36,  1.29it/s]\u001b[A\n","Iteration:  14% 252/1851 [03:15<20:36,  1.29it/s]\u001b[A\n","Iteration:  14% 253/1851 [03:16<20:37,  1.29it/s]\u001b[A\n","Iteration:  14% 254/1851 [03:17<20:34,  1.29it/s]\u001b[A\n","Iteration:  14% 255/1851 [03:18<20:36,  1.29it/s]\u001b[A\n","Iteration:  14% 256/1851 [03:19<20:35,  1.29it/s]\u001b[A\n","Iteration:  14% 257/1851 [03:19<20:35,  1.29it/s]\u001b[A\n","Iteration:  14% 258/1851 [03:20<20:32,  1.29it/s]\u001b[A\n","Iteration:  14% 259/1851 [03:21<20:30,  1.29it/s]\u001b[A\n","Iteration:  14% 260/1851 [03:22<20:28,  1.30it/s]\u001b[A\n","Iteration:  14% 261/1851 [03:22<20:28,  1.29it/s]\u001b[A\n","Iteration:  14% 262/1851 [03:23<20:30,  1.29it/s]\u001b[A\n","Iteration:  14% 263/1851 [03:24<20:29,  1.29it/s]\u001b[A\n","Iteration:  14% 264/1851 [03:25<20:29,  1.29it/s]\u001b[A\n","Iteration:  14% 265/1851 [03:26<20:29,  1.29it/s]\u001b[A\n","Iteration:  14% 266/1851 [03:26<20:29,  1.29it/s]\u001b[A\n","Iteration:  14% 267/1851 [03:27<20:26,  1.29it/s]\u001b[A\n","Iteration:  14% 268/1851 [03:28<20:24,  1.29it/s]\u001b[A\n","Iteration:  15% 269/1851 [03:29<20:21,  1.29it/s]\u001b[A\n","Iteration:  15% 270/1851 [03:29<20:21,  1.29it/s]\u001b[A\n","Iteration:  15% 271/1851 [03:30<20:19,  1.30it/s]\u001b[A\n","Iteration:  15% 272/1851 [03:31<20:17,  1.30it/s]\u001b[A\n","Iteration:  15% 273/1851 [03:32<20:18,  1.30it/s]\u001b[A\n","Iteration:  15% 274/1851 [03:32<20:14,  1.30it/s]\u001b[A\n","Iteration:  15% 275/1851 [03:33<20:14,  1.30it/s]\u001b[A\n","Iteration:  15% 276/1851 [03:34<20:14,  1.30it/s]\u001b[A\n","Iteration:  15% 277/1851 [03:35<20:14,  1.30it/s]\u001b[A\n","Iteration:  15% 278/1851 [03:36<20:14,  1.30it/s]\u001b[A\n","Iteration:  15% 279/1851 [03:36<20:14,  1.29it/s]\u001b[A\n","Iteration:  15% 280/1851 [03:37<20:15,  1.29it/s]\u001b[A\n","Iteration:  15% 281/1851 [03:38<20:16,  1.29it/s]\u001b[A\n","Iteration:  15% 282/1851 [03:39<20:14,  1.29it/s]\u001b[A\n","Iteration:  15% 283/1851 [03:39<20:11,  1.29it/s]\u001b[A\n","Iteration:  15% 284/1851 [03:40<20:11,  1.29it/s]\u001b[A\n","Iteration:  15% 285/1851 [03:41<20:10,  1.29it/s]\u001b[A\n","Iteration:  15% 286/1851 [03:42<20:09,  1.29it/s]\u001b[A\n","Iteration:  16% 287/1851 [03:43<20:07,  1.29it/s]\u001b[A\n","Iteration:  16% 288/1851 [03:43<20:05,  1.30it/s]\u001b[A\n","Iteration:  16% 289/1851 [03:44<20:07,  1.29it/s]\u001b[A\n","Iteration:  16% 290/1851 [03:45<20:06,  1.29it/s]\u001b[A\n","Iteration:  16% 291/1851 [03:46<20:03,  1.30it/s]\u001b[A\n","Iteration:  16% 292/1851 [03:46<20:03,  1.30it/s]\u001b[A\n","Iteration:  16% 293/1851 [03:47<19:59,  1.30it/s]\u001b[A\n","Iteration:  16% 294/1851 [03:48<20:01,  1.30it/s]\u001b[A\n","Iteration:  16% 295/1851 [03:49<20:00,  1.30it/s]\u001b[A\n","Iteration:  16% 296/1851 [03:49<20:00,  1.30it/s]\u001b[A\n","Iteration:  16% 297/1851 [03:50<19:59,  1.30it/s]\u001b[A\n","Iteration:  16% 298/1851 [03:51<19:59,  1.29it/s]\u001b[A\n","Iteration:  16% 299/1851 [03:52<19:58,  1.29it/s]\u001b[A\n","Iteration:  16% 300/1851 [03:53<19:55,  1.30it/s]\u001b[A\n","Iteration:  16% 301/1851 [03:53<19:55,  1.30it/s]\u001b[A\n","Iteration:  16% 302/1851 [03:54<19:54,  1.30it/s]\u001b[A\n","Iteration:  16% 303/1851 [03:55<19:56,  1.29it/s]\u001b[A\n","Iteration:  16% 304/1851 [03:56<19:53,  1.30it/s]\u001b[A\n","Iteration:  16% 305/1851 [03:56<19:55,  1.29it/s]\u001b[A\n","Iteration:  17% 306/1851 [03:57<19:53,  1.29it/s]\u001b[A\n","Iteration:  17% 307/1851 [03:58<19:51,  1.30it/s]\u001b[A\n","Iteration:  17% 308/1851 [03:59<19:51,  1.29it/s]\u001b[A\n","Iteration:  17% 309/1851 [04:00<19:50,  1.30it/s]\u001b[A\n","Iteration:  17% 310/1851 [04:00<19:47,  1.30it/s]\u001b[A\n","Iteration:  17% 311/1851 [04:01<19:45,  1.30it/s]\u001b[A\n","Iteration:  17% 312/1851 [04:02<19:45,  1.30it/s]\u001b[A\n","Iteration:  17% 313/1851 [04:03<19:45,  1.30it/s]\u001b[A\n","Iteration:  17% 314/1851 [04:03<19:45,  1.30it/s]\u001b[A\n","Iteration:  17% 315/1851 [04:04<19:46,  1.29it/s]\u001b[A\n","Iteration:  17% 316/1851 [04:05<19:47,  1.29it/s]\u001b[A\n","Iteration:  17% 317/1851 [04:06<19:47,  1.29it/s]\u001b[A\n","Iteration:  17% 318/1851 [04:06<19:45,  1.29it/s]\u001b[A\n","Iteration:  17% 319/1851 [04:07<19:43,  1.29it/s]\u001b[A\n","Iteration:  17% 320/1851 [04:08<19:42,  1.29it/s]\u001b[A\n","Iteration:  17% 321/1851 [04:09<19:39,  1.30it/s]\u001b[A\n","Iteration:  17% 322/1851 [04:10<19:40,  1.30it/s]\u001b[A\n","Iteration:  17% 323/1851 [04:10<19:38,  1.30it/s]\u001b[A\n","Iteration:  18% 324/1851 [04:11<19:36,  1.30it/s]\u001b[A\n","Iteration:  18% 325/1851 [04:12<19:35,  1.30it/s]\u001b[A\n","Iteration:  18% 326/1851 [04:13<19:36,  1.30it/s]\u001b[A\n","Iteration:  18% 327/1851 [04:13<19:39,  1.29it/s]\u001b[A\n","Iteration:  18% 328/1851 [04:14<19:36,  1.29it/s]\u001b[A\n","Iteration:  18% 329/1851 [04:15<19:36,  1.29it/s]\u001b[A\n","Iteration:  18% 330/1851 [04:16<19:35,  1.29it/s]\u001b[A\n","Iteration:  18% 331/1851 [04:16<19:34,  1.29it/s]\u001b[A\n","Iteration:  18% 332/1851 [04:17<19:31,  1.30it/s]\u001b[A\n","Iteration:  18% 333/1851 [04:18<19:30,  1.30it/s]\u001b[A\n","Iteration:  18% 334/1851 [04:19<19:29,  1.30it/s]\u001b[A\n","Iteration:  18% 335/1851 [04:20<19:29,  1.30it/s]\u001b[A\n","Iteration:  18% 336/1851 [04:20<19:27,  1.30it/s]\u001b[A\n","Iteration:  18% 337/1851 [04:21<19:26,  1.30it/s]\u001b[A\n","Iteration:  18% 338/1851 [04:22<19:24,  1.30it/s]\u001b[A\n","Iteration:  18% 339/1851 [04:23<19:25,  1.30it/s]\u001b[A\n","Iteration:  18% 340/1851 [04:23<19:24,  1.30it/s]\u001b[A\n","Iteration:  18% 341/1851 [04:24<19:25,  1.30it/s]\u001b[A\n","Iteration:  18% 342/1851 [04:25<19:26,  1.29it/s]\u001b[A\n","Iteration:  19% 343/1851 [04:26<19:22,  1.30it/s]\u001b[A\n","Iteration:  19% 344/1851 [04:27<19:21,  1.30it/s]\u001b[A\n","Iteration:  19% 345/1851 [04:27<19:19,  1.30it/s]\u001b[A\n","Iteration:  19% 346/1851 [04:28<19:19,  1.30it/s]\u001b[A\n","Iteration:  19% 347/1851 [04:29<19:20,  1.30it/s]\u001b[A\n","Iteration:  19% 348/1851 [04:30<19:17,  1.30it/s]\u001b[A\n","Iteration:  19% 349/1851 [04:30<19:16,  1.30it/s]\u001b[A\n","Iteration:  19% 350/1851 [04:31<19:16,  1.30it/s]\u001b[A\n","Iteration:  19% 351/1851 [04:32<19:15,  1.30it/s]\u001b[A\n","Iteration:  19% 352/1851 [04:33<19:14,  1.30it/s]\u001b[A\n","Iteration:  19% 353/1851 [04:33<19:13,  1.30it/s]\u001b[A\n","Iteration:  19% 354/1851 [04:34<19:13,  1.30it/s]\u001b[A\n","Iteration:  19% 355/1851 [04:35<19:11,  1.30it/s]\u001b[A\n","Iteration:  19% 356/1851 [04:36<19:12,  1.30it/s]\u001b[A\n","Iteration:  19% 357/1851 [04:37<19:10,  1.30it/s]\u001b[A\n","Iteration:  19% 358/1851 [04:37<19:10,  1.30it/s]\u001b[A\n","Iteration:  19% 359/1851 [04:38<19:10,  1.30it/s]\u001b[A\n","Iteration:  19% 360/1851 [04:39<19:10,  1.30it/s]\u001b[A\n","Iteration:  20% 361/1851 [04:40<19:07,  1.30it/s]\u001b[A\n","Iteration:  20% 362/1851 [04:40<19:06,  1.30it/s]\u001b[A\n","Iteration:  20% 363/1851 [04:41<19:08,  1.30it/s]\u001b[A\n","Iteration:  20% 364/1851 [04:42<19:06,  1.30it/s]\u001b[A\n","Iteration:  20% 365/1851 [04:43<19:05,  1.30it/s]\u001b[A\n","Iteration:  20% 366/1851 [04:43<19:04,  1.30it/s]\u001b[A\n","Iteration:  20% 367/1851 [04:44<19:01,  1.30it/s]\u001b[A\n","Iteration:  20% 368/1851 [04:45<19:02,  1.30it/s]\u001b[A\n","Iteration:  20% 369/1851 [04:46<19:02,  1.30it/s]\u001b[A\n","Iteration:  20% 370/1851 [04:47<19:02,  1.30it/s]\u001b[A\n","Iteration:  20% 371/1851 [04:47<19:02,  1.30it/s]\u001b[A\n","Iteration:  20% 372/1851 [04:48<19:02,  1.29it/s]\u001b[A\n","Iteration:  20% 373/1851 [04:49<19:02,  1.29it/s]\u001b[A\n","Iteration:  20% 374/1851 [04:50<19:00,  1.29it/s]\u001b[A\n","Iteration:  20% 375/1851 [04:50<18:58,  1.30it/s]\u001b[A\n","Iteration:  20% 376/1851 [04:51<18:59,  1.29it/s]\u001b[A\n","Iteration:  20% 377/1851 [04:52<18:57,  1.30it/s]\u001b[A\n","Iteration:  20% 378/1851 [04:53<18:55,  1.30it/s]\u001b[A\n","Iteration:  20% 379/1851 [04:53<18:56,  1.30it/s]\u001b[A\n","Iteration:  21% 380/1851 [04:54<18:56,  1.29it/s]\u001b[A\n","Iteration:  21% 381/1851 [04:55<18:56,  1.29it/s]\u001b[A\n","Iteration:  21% 382/1851 [04:56<18:53,  1.30it/s]\u001b[A\n","Iteration:  21% 383/1851 [04:57<18:55,  1.29it/s]\u001b[A\n","Iteration:  21% 384/1851 [04:57<18:53,  1.29it/s]\u001b[A\n","Iteration:  21% 385/1851 [04:58<18:52,  1.30it/s]\u001b[A\n","Iteration:  21% 386/1851 [04:59<18:48,  1.30it/s]\u001b[A\n","Iteration:  21% 387/1851 [05:00<18:49,  1.30it/s]\u001b[A\n","Iteration:  21% 388/1851 [05:00<18:49,  1.30it/s]\u001b[A\n","Iteration:  21% 389/1851 [05:01<18:50,  1.29it/s]\u001b[A\n","Iteration:  21% 390/1851 [05:02<18:50,  1.29it/s]\u001b[A\n","Iteration:  21% 391/1851 [05:03<18:49,  1.29it/s]\u001b[A\n","Iteration:  21% 392/1851 [05:04<18:48,  1.29it/s]\u001b[A\n","Iteration:  21% 393/1851 [05:04<18:49,  1.29it/s]\u001b[A\n","Iteration:  21% 394/1851 [05:05<18:48,  1.29it/s]\u001b[A\n","Iteration:  21% 395/1851 [05:06<18:47,  1.29it/s]\u001b[A\n","Iteration:  21% 396/1851 [05:07<18:46,  1.29it/s]\u001b[A\n","Iteration:  21% 397/1851 [05:07<18:43,  1.29it/s]\u001b[A\n","Iteration:  22% 398/1851 [05:08<18:40,  1.30it/s]\u001b[A\n","Iteration:  22% 399/1851 [05:09<18:39,  1.30it/s]\u001b[A\n","Iteration:  22% 400/1851 [05:10<18:37,  1.30it/s]\u001b[A\n","Iteration:  22% 401/1851 [05:10<18:37,  1.30it/s]\u001b[A\n","Iteration:  22% 402/1851 [05:11<18:35,  1.30it/s]\u001b[A\n","Iteration:  22% 403/1851 [05:12<18:36,  1.30it/s]\u001b[A\n","Iteration:  22% 404/1851 [05:13<18:36,  1.30it/s]\u001b[A\n","Iteration:  22% 405/1851 [05:14<18:38,  1.29it/s]\u001b[A\n","Iteration:  22% 406/1851 [05:14<18:38,  1.29it/s]\u001b[A\n","Iteration:  22% 407/1851 [05:15<18:37,  1.29it/s]\u001b[A\n","Iteration:  22% 408/1851 [05:16<18:36,  1.29it/s]\u001b[A\n","Iteration:  22% 409/1851 [05:17<18:33,  1.29it/s]\u001b[A\n","Iteration:  22% 410/1851 [05:17<18:33,  1.29it/s]\u001b[A\n","Iteration:  22% 411/1851 [05:18<18:33,  1.29it/s]\u001b[A\n","Iteration:  22% 412/1851 [05:19<18:33,  1.29it/s]\u001b[A\n","Iteration:  22% 413/1851 [05:20<18:33,  1.29it/s]\u001b[A\n","Iteration:  22% 414/1851 [05:21<18:30,  1.29it/s]\u001b[A\n","Iteration:  22% 415/1851 [05:21<18:29,  1.29it/s]\u001b[A\n","Iteration:  22% 416/1851 [05:22<18:28,  1.29it/s]\u001b[A\n","Iteration:  23% 417/1851 [05:23<18:28,  1.29it/s]\u001b[A\n","Iteration:  23% 418/1851 [05:24<18:25,  1.30it/s]\u001b[A\n","Iteration:  23% 419/1851 [05:24<18:26,  1.29it/s]\u001b[A\n","Iteration:  23% 420/1851 [05:25<18:27,  1.29it/s]\u001b[A\n","Iteration:  23% 421/1851 [05:26<18:27,  1.29it/s]\u001b[A\n","Iteration:  23% 422/1851 [05:27<18:26,  1.29it/s]\u001b[A\n","Iteration:  23% 423/1851 [05:28<18:25,  1.29it/s]\u001b[A\n","Iteration:  23% 424/1851 [05:28<18:24,  1.29it/s]\u001b[A\n","Iteration:  23% 425/1851 [05:29<18:24,  1.29it/s]\u001b[A\n","Iteration:  23% 426/1851 [05:30<18:23,  1.29it/s]\u001b[A\n","Iteration:  23% 427/1851 [05:31<18:21,  1.29it/s]\u001b[A\n","Iteration:  23% 428/1851 [05:31<18:21,  1.29it/s]\u001b[A\n","Iteration:  23% 429/1851 [05:32<18:19,  1.29it/s]\u001b[A\n","Iteration:  23% 430/1851 [05:33<18:17,  1.29it/s]\u001b[A\n","Iteration:  23% 431/1851 [05:34<18:21,  1.29it/s]\u001b[A\n","Iteration:  23% 432/1851 [05:34<18:20,  1.29it/s]\u001b[A\n","Iteration:  23% 433/1851 [05:35<18:18,  1.29it/s]\u001b[A\n","Iteration:  23% 434/1851 [05:36<18:16,  1.29it/s]\u001b[A\n","Iteration:  24% 435/1851 [05:37<18:16,  1.29it/s]\u001b[A\n","Iteration:  24% 436/1851 [05:38<18:16,  1.29it/s]\u001b[A\n","Iteration:  24% 437/1851 [05:38<18:16,  1.29it/s]\u001b[A\n","Iteration:  24% 438/1851 [05:39<18:14,  1.29it/s]\u001b[A\n","Iteration:  24% 439/1851 [05:40<18:11,  1.29it/s]\u001b[A\n","Iteration:  24% 440/1851 [05:41<18:12,  1.29it/s]\u001b[A\n","Iteration:  24% 441/1851 [05:41<18:11,  1.29it/s]\u001b[A\n","Iteration:  24% 442/1851 [05:42<18:11,  1.29it/s]\u001b[A\n","Iteration:  24% 443/1851 [05:43<18:07,  1.30it/s]\u001b[A\n","Iteration:  24% 444/1851 [05:44<18:05,  1.30it/s]\u001b[A\n","Iteration:  24% 445/1851 [05:45<18:07,  1.29it/s]\u001b[A\n","Iteration:  24% 446/1851 [05:45<18:02,  1.30it/s]\u001b[A\n","Iteration:  24% 447/1851 [05:46<18:03,  1.30it/s]\u001b[A\n","Iteration:  24% 448/1851 [05:47<18:02,  1.30it/s]\u001b[A\n","Iteration:  24% 449/1851 [05:48<18:04,  1.29it/s]\u001b[A\n","Iteration:  24% 450/1851 [05:48<18:04,  1.29it/s]\u001b[A\n","Iteration:  24% 451/1851 [05:49<18:06,  1.29it/s]\u001b[A\n","Iteration:  24% 452/1851 [05:50<18:03,  1.29it/s]\u001b[A\n","Iteration:  24% 453/1851 [05:51<18:01,  1.29it/s]\u001b[A\n","Iteration:  25% 454/1851 [05:51<18:02,  1.29it/s]\u001b[A\n","Iteration:  25% 455/1851 [05:52<18:02,  1.29it/s]\u001b[A\n","Iteration:  25% 456/1851 [05:53<18:02,  1.29it/s]\u001b[A\n","Iteration:  25% 457/1851 [05:54<17:59,  1.29it/s]\u001b[A\n","Iteration:  25% 458/1851 [05:55<17:58,  1.29it/s]\u001b[A\n","Iteration:  25% 459/1851 [05:55<17:56,  1.29it/s]\u001b[A\n","Iteration:  25% 460/1851 [05:56<17:56,  1.29it/s]\u001b[A\n","Iteration:  25% 461/1851 [05:57<17:55,  1.29it/s]\u001b[A\n","Iteration:  25% 462/1851 [05:58<17:56,  1.29it/s]\u001b[A\n","Iteration:  25% 463/1851 [05:58<17:55,  1.29it/s]\u001b[A\n","Iteration:  25% 464/1851 [05:59<17:55,  1.29it/s]\u001b[A\n","Iteration:  25% 465/1851 [06:00<17:54,  1.29it/s]\u001b[A\n","Iteration:  25% 466/1851 [06:01<17:55,  1.29it/s]\u001b[A\n","Iteration:  25% 467/1851 [06:02<17:53,  1.29it/s]\u001b[A\n","Iteration:  25% 468/1851 [06:02<17:51,  1.29it/s]\u001b[A\n","Iteration:  25% 469/1851 [06:03<17:50,  1.29it/s]\u001b[A\n","Iteration:  25% 470/1851 [06:04<17:49,  1.29it/s]\u001b[A\n","Iteration:  25% 471/1851 [06:05<17:48,  1.29it/s]\u001b[A\n","Iteration:  25% 472/1851 [06:05<17:48,  1.29it/s]\u001b[A\n","Iteration:  26% 473/1851 [06:06<17:47,  1.29it/s]\u001b[A\n","Iteration:  26% 474/1851 [06:07<17:46,  1.29it/s]\u001b[A\n","Iteration:  26% 475/1851 [06:08<17:45,  1.29it/s]\u001b[A\n","Iteration:  26% 476/1851 [06:09<17:41,  1.29it/s]\u001b[A\n","Iteration:  26% 477/1851 [06:09<17:42,  1.29it/s]\u001b[A\n","Iteration:  26% 478/1851 [06:10<17:41,  1.29it/s]\u001b[A\n","Iteration:  26% 479/1851 [06:11<17:42,  1.29it/s]\u001b[A\n","Iteration:  26% 480/1851 [06:12<17:41,  1.29it/s]\u001b[A\n","Iteration:  26% 481/1851 [06:12<17:40,  1.29it/s]\u001b[A\n","Iteration:  26% 482/1851 [06:13<17:38,  1.29it/s]\u001b[A\n","Iteration:  26% 483/1851 [06:14<17:38,  1.29it/s]\u001b[A\n","Iteration:  26% 484/1851 [06:15<17:40,  1.29it/s]\u001b[A\n","Iteration:  26% 485/1851 [06:16<17:38,  1.29it/s]\u001b[A\n","Iteration:  26% 486/1851 [06:16<17:37,  1.29it/s]\u001b[A\n","Iteration:  26% 487/1851 [06:17<17:36,  1.29it/s]\u001b[A\n","Iteration:  26% 488/1851 [06:18<17:37,  1.29it/s]\u001b[A\n","Iteration:  26% 489/1851 [06:19<17:34,  1.29it/s]\u001b[A\n","Iteration:  26% 490/1851 [06:19<17:32,  1.29it/s]\u001b[A\n","Iteration:  27% 491/1851 [06:20<17:30,  1.29it/s]\u001b[A\n","Iteration:  27% 492/1851 [06:21<17:30,  1.29it/s]\u001b[A\n","Iteration:  27% 493/1851 [06:22<17:29,  1.29it/s]\u001b[A\n","Iteration:  27% 494/1851 [06:22<17:31,  1.29it/s]\u001b[A\n","Iteration:  27% 495/1851 [06:23<17:29,  1.29it/s]\u001b[A\n","Iteration:  27% 496/1851 [06:24<17:28,  1.29it/s]\u001b[A\n","Iteration:  27% 497/1851 [06:25<17:27,  1.29it/s]\u001b[A\n","Iteration:  27% 498/1851 [06:26<17:26,  1.29it/s]\u001b[A\n","Iteration:  27% 499/1851 [06:26<17:24,  1.29it/s]\u001b[A\n","Iteration:  27% 500/1851 [06:27<17:25,  1.29it/s]\u001b[A\n","Iteration:  27% 501/1851 [06:28<17:23,  1.29it/s]\u001b[A\n","Iteration:  27% 502/1851 [06:29<17:24,  1.29it/s]\u001b[A\n","Iteration:  27% 503/1851 [06:29<17:23,  1.29it/s]\u001b[A\n","Iteration:  27% 504/1851 [06:30<17:21,  1.29it/s]\u001b[A\n","Iteration:  27% 505/1851 [06:31<17:19,  1.29it/s]\u001b[A\n","Iteration:  27% 506/1851 [06:32<17:20,  1.29it/s]\u001b[A\n","Iteration:  27% 507/1851 [06:33<17:21,  1.29it/s]\u001b[A\n","Iteration:  27% 508/1851 [06:33<17:20,  1.29it/s]\u001b[A\n","Iteration:  27% 509/1851 [06:34<17:18,  1.29it/s]\u001b[A\n","Iteration:  28% 510/1851 [06:35<17:17,  1.29it/s]\u001b[A\n","Iteration:  28% 511/1851 [06:36<17:15,  1.29it/s]\u001b[A\n","Iteration:  28% 512/1851 [06:36<17:18,  1.29it/s]\u001b[A\n","Iteration:  28% 513/1851 [06:37<17:17,  1.29it/s]\u001b[A\n","Iteration:  28% 514/1851 [06:38<17:15,  1.29it/s]\u001b[A\n","Iteration:  28% 515/1851 [06:39<17:14,  1.29it/s]\u001b[A\n","Iteration:  28% 516/1851 [06:39<17:13,  1.29it/s]\u001b[A\n","Iteration:  28% 517/1851 [06:40<17:13,  1.29it/s]\u001b[A\n","Iteration:  28% 518/1851 [06:41<17:08,  1.30it/s]\u001b[A\n","Iteration:  28% 519/1851 [06:42<17:08,  1.29it/s]\u001b[A\n","Iteration:  28% 520/1851 [06:43<17:06,  1.30it/s]\u001b[A\n","Iteration:  28% 521/1851 [06:43<17:07,  1.29it/s]\u001b[A\n","Iteration:  28% 522/1851 [06:44<17:10,  1.29it/s]\u001b[A\n","Iteration:  28% 523/1851 [06:45<17:09,  1.29it/s]\u001b[A\n","Iteration:  28% 524/1851 [06:46<17:08,  1.29it/s]\u001b[A\n","Iteration:  28% 525/1851 [06:46<17:07,  1.29it/s]\u001b[A\n","Iteration:  28% 526/1851 [06:47<17:03,  1.29it/s]\u001b[A\n","Iteration:  28% 527/1851 [06:48<17:03,  1.29it/s]\u001b[A\n","Iteration:  29% 528/1851 [06:49<17:03,  1.29it/s]\u001b[A\n","Iteration:  29% 529/1851 [06:50<17:02,  1.29it/s]\u001b[A\n","Iteration:  29% 530/1851 [06:50<17:02,  1.29it/s]\u001b[A\n","Iteration:  29% 531/1851 [06:51<17:01,  1.29it/s]\u001b[A\n","Iteration:  29% 532/1851 [06:52<17:00,  1.29it/s]\u001b[A\n","Iteration:  29% 533/1851 [06:53<17:00,  1.29it/s]\u001b[A\n","Iteration:  29% 534/1851 [06:53<16:58,  1.29it/s]\u001b[A\n","Iteration:  29% 535/1851 [06:54<16:58,  1.29it/s]\u001b[A\n","Iteration:  29% 536/1851 [06:55<16:56,  1.29it/s]\u001b[A\n","Iteration:  29% 537/1851 [06:56<16:54,  1.29it/s]\u001b[A\n","Iteration:  29% 538/1851 [06:57<16:53,  1.30it/s]\u001b[A\n","Iteration:  29% 539/1851 [06:57<16:50,  1.30it/s]\u001b[A\n","Iteration:  29% 540/1851 [06:58<16:49,  1.30it/s]\u001b[A\n","Iteration:  29% 541/1851 [06:59<16:51,  1.30it/s]\u001b[A\n","Iteration:  29% 542/1851 [07:00<16:50,  1.30it/s]\u001b[A\n","Iteration:  29% 543/1851 [07:00<16:50,  1.30it/s]\u001b[A\n","Iteration:  29% 544/1851 [07:01<16:51,  1.29it/s]\u001b[A\n","Iteration:  29% 545/1851 [07:02<16:52,  1.29it/s]\u001b[A\n","Iteration:  29% 546/1851 [07:03<16:51,  1.29it/s]\u001b[A\n","Iteration:  30% 547/1851 [07:03<16:48,  1.29it/s]\u001b[A\n","Iteration:  30% 548/1851 [07:04<16:46,  1.29it/s]\u001b[A\n","Iteration:  30% 549/1851 [07:05<16:45,  1.29it/s]\u001b[A\n","Iteration:  30% 550/1851 [07:06<16:43,  1.30it/s]\u001b[A\n","Iteration:  30% 551/1851 [07:07<16:43,  1.29it/s]\u001b[A\n","Iteration:  30% 552/1851 [07:07<16:45,  1.29it/s]\u001b[A\n","Iteration:  30% 553/1851 [07:08<16:44,  1.29it/s]\u001b[A\n","Iteration:  30% 554/1851 [07:09<16:44,  1.29it/s]\u001b[A\n","Iteration:  30% 555/1851 [07:10<16:43,  1.29it/s]\u001b[A\n","Iteration:  30% 556/1851 [07:10<16:41,  1.29it/s]\u001b[A\n","Iteration:  30% 557/1851 [07:11<16:39,  1.29it/s]\u001b[A\n","Iteration:  30% 558/1851 [07:12<16:38,  1.29it/s]\u001b[A\n","Iteration:  30% 559/1851 [07:13<16:37,  1.29it/s]\u001b[A\n","Iteration:  30% 560/1851 [07:14<16:39,  1.29it/s]\u001b[A\n","Iteration:  30% 561/1851 [07:14<16:39,  1.29it/s]\u001b[A\n","Iteration:  30% 562/1851 [07:15<16:39,  1.29it/s]\u001b[A\n","Iteration:  30% 563/1851 [07:16<16:38,  1.29it/s]\u001b[A\n","Iteration:  30% 564/1851 [07:17<16:35,  1.29it/s]\u001b[A\n","Iteration:  31% 565/1851 [07:17<16:36,  1.29it/s]\u001b[A\n","Iteration:  31% 566/1851 [07:18<16:34,  1.29it/s]\u001b[A\n","Iteration:  31% 567/1851 [07:19<16:33,  1.29it/s]\u001b[A\n","Iteration:  31% 568/1851 [07:20<16:32,  1.29it/s]\u001b[A\n","Iteration:  31% 569/1851 [07:20<16:32,  1.29it/s]\u001b[A\n","Iteration:  31% 570/1851 [07:21<16:32,  1.29it/s]\u001b[A\n","Iteration:  31% 571/1851 [07:22<16:30,  1.29it/s]\u001b[A\n","Iteration:  31% 572/1851 [07:23<16:31,  1.29it/s]\u001b[A\n","Iteration:  31% 573/1851 [07:24<16:29,  1.29it/s]\u001b[A\n","Iteration:  31% 574/1851 [07:24<16:29,  1.29it/s]\u001b[A\n","Iteration:  31% 575/1851 [07:25<16:28,  1.29it/s]\u001b[A\n","Iteration:  31% 576/1851 [07:26<16:27,  1.29it/s]\u001b[A\n","Iteration:  31% 577/1851 [07:27<16:26,  1.29it/s]\u001b[A\n","Iteration:  31% 578/1851 [07:27<16:24,  1.29it/s]\u001b[A\n","Iteration:  31% 579/1851 [07:28<16:22,  1.29it/s]\u001b[A\n","Iteration:  31% 580/1851 [07:29<16:22,  1.29it/s]\u001b[A\n","Iteration:  31% 581/1851 [07:30<16:23,  1.29it/s]\u001b[A\n","Iteration:  31% 582/1851 [07:31<16:22,  1.29it/s]\u001b[A\n","Iteration:  31% 583/1851 [07:31<16:22,  1.29it/s]\u001b[A\n","Iteration:  32% 584/1851 [07:32<16:21,  1.29it/s]\u001b[A\n","Iteration:  32% 585/1851 [07:33<16:20,  1.29it/s]\u001b[A\n","Iteration:  32% 586/1851 [07:34<16:19,  1.29it/s]\u001b[A\n","Iteration:  32% 587/1851 [07:34<16:20,  1.29it/s]\u001b[A\n","Iteration:  32% 588/1851 [07:35<16:17,  1.29it/s]\u001b[A\n","Iteration:  32% 589/1851 [07:36<16:16,  1.29it/s]\u001b[A\n","Iteration:  32% 590/1851 [07:37<16:13,  1.29it/s]\u001b[A\n","Iteration:  32% 591/1851 [07:38<16:12,  1.30it/s]\u001b[A\n","Iteration:  32% 592/1851 [07:38<16:13,  1.29it/s]\u001b[A\n","Iteration:  32% 593/1851 [07:39<16:12,  1.29it/s]\u001b[A\n","Iteration:  32% 594/1851 [07:40<16:12,  1.29it/s]\u001b[A\n","Iteration:  32% 595/1851 [07:41<16:13,  1.29it/s]\u001b[A\n","Iteration:  32% 596/1851 [07:41<16:12,  1.29it/s]\u001b[A\n","Iteration:  32% 597/1851 [07:42<16:09,  1.29it/s]\u001b[A\n","Iteration:  32% 598/1851 [07:43<16:06,  1.30it/s]\u001b[A\n","Iteration:  32% 599/1851 [07:44<16:04,  1.30it/s]\u001b[A\n","Iteration:  32% 600/1851 [07:44<16:03,  1.30it/s]\u001b[A\n","Iteration:  32% 601/1851 [07:45<16:02,  1.30it/s]\u001b[A\n","Iteration:  33% 602/1851 [07:46<16:02,  1.30it/s]\u001b[A\n","Iteration:  33% 603/1851 [07:47<16:01,  1.30it/s]\u001b[A\n","Iteration:  33% 604/1851 [07:48<16:02,  1.30it/s]\u001b[A\n","Iteration:  33% 605/1851 [07:48<16:00,  1.30it/s]\u001b[A\n","Iteration:  33% 606/1851 [07:49<16:00,  1.30it/s]\u001b[A\n","Iteration:  33% 607/1851 [07:50<16:02,  1.29it/s]\u001b[A\n","Iteration:  33% 608/1851 [07:51<16:02,  1.29it/s]\u001b[A\n","Iteration:  33% 609/1851 [07:51<16:00,  1.29it/s]\u001b[A\n","Iteration:  33% 610/1851 [07:52<15:57,  1.30it/s]\u001b[A\n","Iteration:  33% 611/1851 [07:53<15:58,  1.29it/s]\u001b[A\n","Iteration:  33% 612/1851 [07:54<15:55,  1.30it/s]\u001b[A\n","Iteration:  33% 613/1851 [07:54<15:54,  1.30it/s]\u001b[A\n","Iteration:  33% 614/1851 [07:55<15:55,  1.29it/s]\u001b[A\n","Iteration:  33% 615/1851 [07:56<15:56,  1.29it/s]\u001b[A\n","Iteration:  33% 616/1851 [07:57<15:53,  1.30it/s]\u001b[A\n","Iteration:  33% 617/1851 [07:58<15:53,  1.29it/s]\u001b[A\n","Iteration:  33% 618/1851 [07:58<15:52,  1.29it/s]\u001b[A\n","Iteration:  33% 619/1851 [07:59<15:51,  1.30it/s]\u001b[A\n","Iteration:  33% 620/1851 [08:00<15:49,  1.30it/s]\u001b[A\n","Iteration:  34% 621/1851 [08:01<15:48,  1.30it/s]\u001b[A\n","Iteration:  34% 622/1851 [08:01<15:46,  1.30it/s]\u001b[A\n","Iteration:  34% 623/1851 [08:02<15:46,  1.30it/s]\u001b[A\n","Iteration:  34% 624/1851 [08:03<15:48,  1.29it/s]\u001b[A\n","Iteration:  34% 625/1851 [08:04<15:44,  1.30it/s]\u001b[A\n","Iteration:  34% 626/1851 [08:05<15:47,  1.29it/s]\u001b[A\n","Iteration:  34% 627/1851 [08:05<15:47,  1.29it/s]\u001b[A\n","Iteration:  34% 628/1851 [08:06<15:45,  1.29it/s]\u001b[A\n","Iteration:  34% 629/1851 [08:07<15:45,  1.29it/s]\u001b[A\n","Iteration:  34% 630/1851 [08:08<15:42,  1.30it/s]\u001b[A\n","Iteration:  34% 631/1851 [08:08<15:42,  1.29it/s]\u001b[A\n","Iteration:  34% 632/1851 [08:09<15:42,  1.29it/s]\u001b[A\n","Iteration:  34% 633/1851 [08:10<15:40,  1.30it/s]\u001b[A\n","Iteration:  34% 634/1851 [08:11<15:38,  1.30it/s]\u001b[A\n","Iteration:  34% 635/1851 [08:11<15:37,  1.30it/s]\u001b[A\n","Iteration:  34% 636/1851 [08:12<15:37,  1.30it/s]\u001b[A\n","Iteration:  34% 637/1851 [08:13<15:35,  1.30it/s]\u001b[A\n","Iteration:  34% 638/1851 [08:14<15:35,  1.30it/s]\u001b[A\n","Iteration:  35% 639/1851 [08:15<15:34,  1.30it/s]\u001b[A\n","Iteration:  35% 640/1851 [08:15<15:35,  1.29it/s]\u001b[A\n","Iteration:  35% 641/1851 [08:16<15:33,  1.30it/s]\u001b[A\n","Iteration:  35% 642/1851 [08:17<15:33,  1.29it/s]\u001b[A\n","Iteration:  35% 643/1851 [08:18<15:33,  1.29it/s]\u001b[A\n","Iteration:  35% 644/1851 [08:18<15:30,  1.30it/s]\u001b[A\n","Iteration:  35% 645/1851 [08:19<15:30,  1.30it/s]\u001b[A\n","Iteration:  35% 646/1851 [08:20<15:27,  1.30it/s]\u001b[A\n","Iteration:  35% 647/1851 [08:21<15:29,  1.30it/s]\u001b[A\n","Iteration:  35% 648/1851 [08:22<15:27,  1.30it/s]\u001b[A\n","Iteration:  35% 649/1851 [08:22<15:26,  1.30it/s]\u001b[A\n","Iteration:  35% 650/1851 [08:23<15:26,  1.30it/s]\u001b[A\n","Iteration:  35% 651/1851 [08:24<15:25,  1.30it/s]\u001b[A\n","Iteration:  35% 652/1851 [08:25<15:25,  1.30it/s]\u001b[A\n","Iteration:  35% 653/1851 [08:25<15:26,  1.29it/s]\u001b[A\n","Iteration:  35% 654/1851 [08:26<15:25,  1.29it/s]\u001b[A\n","Iteration:  35% 655/1851 [08:27<15:25,  1.29it/s]\u001b[A\n","Iteration:  35% 656/1851 [08:28<15:23,  1.29it/s]\u001b[A\n","Iteration:  35% 657/1851 [08:28<15:22,  1.29it/s]\u001b[A\n","Iteration:  36% 658/1851 [08:29<15:23,  1.29it/s]\u001b[A\n","Iteration:  36% 659/1851 [08:30<15:23,  1.29it/s]\u001b[A\n","Iteration:  36% 660/1851 [08:31<15:20,  1.29it/s]\u001b[A\n","Iteration:  36% 661/1851 [08:32<15:18,  1.30it/s]\u001b[A\n","Iteration:  36% 662/1851 [08:32<15:18,  1.29it/s]\u001b[A\n","Iteration:  36% 663/1851 [08:33<15:18,  1.29it/s]\u001b[A\n","Iteration:  36% 664/1851 [08:34<15:15,  1.30it/s]\u001b[A\n","Iteration:  36% 665/1851 [08:35<15:15,  1.30it/s]\u001b[A\n","Iteration:  36% 666/1851 [08:35<15:13,  1.30it/s]\u001b[A\n","Iteration:  36% 667/1851 [08:36<15:11,  1.30it/s]\u001b[A\n","Iteration:  36% 668/1851 [08:37<15:11,  1.30it/s]\u001b[A\n","Iteration:  36% 669/1851 [08:38<15:10,  1.30it/s]\u001b[A\n","Iteration:  36% 670/1851 [08:38<15:10,  1.30it/s]\u001b[A\n","Iteration:  36% 671/1851 [08:39<15:10,  1.30it/s]\u001b[A\n","Iteration:  36% 672/1851 [08:40<15:10,  1.29it/s]\u001b[A\n","Iteration:  36% 673/1851 [08:41<15:10,  1.29it/s]\u001b[A\n","Iteration:  36% 674/1851 [08:42<16:17,  1.20it/s]\u001b[A\n","Iteration:  36% 675/1851 [08:43<16:01,  1.22it/s]\u001b[A\n","Iteration:  37% 676/1851 [08:43<15:46,  1.24it/s]\u001b[A\n","Iteration:  37% 677/1851 [08:44<15:32,  1.26it/s]\u001b[A\n","Iteration:  37% 678/1851 [08:45<15:23,  1.27it/s]\u001b[A\n","Iteration:  37% 679/1851 [08:46<15:17,  1.28it/s]\u001b[A\n","Iteration:  37% 680/1851 [08:46<15:13,  1.28it/s]\u001b[A\n","Iteration:  37% 681/1851 [08:47<15:10,  1.28it/s]\u001b[A\n","Iteration:  37% 682/1851 [08:48<15:06,  1.29it/s]\u001b[A\n","Iteration:  37% 683/1851 [08:49<15:05,  1.29it/s]\u001b[A\n","Iteration:  37% 684/1851 [08:50<15:02,  1.29it/s]\u001b[A\n","Iteration:  37% 685/1851 [08:50<14:59,  1.30it/s]\u001b[A\n","Iteration:  37% 686/1851 [08:51<14:59,  1.30it/s]\u001b[A\n","Iteration:  37% 687/1851 [08:52<14:57,  1.30it/s]\u001b[A\n","Iteration:  37% 688/1851 [08:53<14:57,  1.30it/s]\u001b[A\n","Iteration:  37% 689/1851 [08:53<14:56,  1.30it/s]\u001b[A\n","Iteration:  37% 690/1851 [08:54<14:55,  1.30it/s]\u001b[A\n","Iteration:  37% 691/1851 [08:55<14:55,  1.30it/s]\u001b[A\n","Iteration:  37% 692/1851 [08:56<14:56,  1.29it/s]\u001b[A\n","Iteration:  37% 693/1851 [08:56<14:55,  1.29it/s]\u001b[A\n","Iteration:  37% 694/1851 [08:57<14:54,  1.29it/s]\u001b[A\n","Iteration:  38% 695/1851 [08:58<14:53,  1.29it/s]\u001b[A\n","Iteration:  38% 696/1851 [08:59<14:53,  1.29it/s]\u001b[A\n","Iteration:  38% 697/1851 [09:00<14:50,  1.30it/s]\u001b[A\n","Iteration:  38% 698/1851 [09:00<14:49,  1.30it/s]\u001b[A\n","Iteration:  38% 699/1851 [09:01<14:47,  1.30it/s]\u001b[A\n","Iteration:  38% 700/1851 [09:02<14:48,  1.30it/s]\u001b[A\n","Iteration:  38% 701/1851 [09:03<14:45,  1.30it/s]\u001b[A\n","Iteration:  38% 702/1851 [09:03<14:45,  1.30it/s]\u001b[A\n","Iteration:  38% 703/1851 [09:04<14:45,  1.30it/s]\u001b[A\n","Iteration:  38% 704/1851 [09:05<14:43,  1.30it/s]\u001b[A\n","Iteration:  38% 705/1851 [09:06<14:42,  1.30it/s]\u001b[A\n","Iteration:  38% 706/1851 [09:06<14:42,  1.30it/s]\u001b[A\n","Iteration:  38% 707/1851 [09:07<14:41,  1.30it/s]\u001b[A\n","Iteration:  38% 708/1851 [09:08<14:41,  1.30it/s]\u001b[A\n","Iteration:  38% 709/1851 [09:09<14:38,  1.30it/s]\u001b[A\n","Iteration:  38% 710/1851 [09:10<14:39,  1.30it/s]\u001b[A\n","Iteration:  38% 711/1851 [09:10<14:39,  1.30it/s]\u001b[A\n","Iteration:  38% 712/1851 [09:11<14:38,  1.30it/s]\u001b[A\n","Iteration:  39% 713/1851 [09:12<14:37,  1.30it/s]\u001b[A\n","Iteration:  39% 714/1851 [09:13<14:37,  1.30it/s]\u001b[A\n","Iteration:  39% 715/1851 [09:13<14:38,  1.29it/s]\u001b[A\n","Iteration:  39% 716/1851 [09:14<14:38,  1.29it/s]\u001b[A\n","Iteration:  39% 717/1851 [09:15<14:37,  1.29it/s]\u001b[A\n","Iteration:  39% 718/1851 [09:16<14:35,  1.29it/s]\u001b[A\n","Iteration:  39% 719/1851 [09:17<14:35,  1.29it/s]\u001b[A\n","Iteration:  39% 720/1851 [09:17<14:32,  1.30it/s]\u001b[A\n","Iteration:  39% 721/1851 [09:18<14:32,  1.30it/s]\u001b[A\n","Iteration:  39% 722/1851 [09:19<14:30,  1.30it/s]\u001b[A\n","Iteration:  39% 723/1851 [09:20<14:30,  1.30it/s]\u001b[A\n","Iteration:  39% 724/1851 [09:20<14:30,  1.29it/s]\u001b[A\n","Iteration:  39% 725/1851 [09:21<14:27,  1.30it/s]\u001b[A\n","Iteration:  39% 726/1851 [09:22<14:27,  1.30it/s]\u001b[A\n","Iteration:  39% 727/1851 [09:23<14:27,  1.30it/s]\u001b[A\n","Iteration:  39% 728/1851 [09:23<14:25,  1.30it/s]\u001b[A\n","Iteration:  39% 729/1851 [09:24<14:24,  1.30it/s]\u001b[A\n","Iteration:  39% 730/1851 [09:25<14:24,  1.30it/s]\u001b[A\n","Iteration:  39% 731/1851 [09:26<14:25,  1.29it/s]\u001b[A\n","Iteration:  40% 732/1851 [09:27<14:22,  1.30it/s]\u001b[A\n","Iteration:  40% 733/1851 [09:27<14:22,  1.30it/s]\u001b[A\n","Iteration:  40% 734/1851 [09:28<14:21,  1.30it/s]\u001b[A\n","Iteration:  40% 735/1851 [09:29<14:20,  1.30it/s]\u001b[A\n","Iteration:  40% 736/1851 [09:30<14:19,  1.30it/s]\u001b[A\n","Iteration:  40% 737/1851 [09:30<14:17,  1.30it/s]\u001b[A\n","Iteration:  40% 738/1851 [09:31<14:16,  1.30it/s]\u001b[A\n","Iteration:  40% 739/1851 [09:32<14:17,  1.30it/s]\u001b[A\n","Iteration:  40% 740/1851 [09:33<14:16,  1.30it/s]\u001b[A\n","Iteration:  40% 741/1851 [09:33<14:15,  1.30it/s]\u001b[A\n","Iteration:  40% 742/1851 [09:34<14:13,  1.30it/s]\u001b[A\n","Iteration:  40% 743/1851 [09:35<14:13,  1.30it/s]\u001b[A\n","Iteration:  40% 744/1851 [09:36<14:12,  1.30it/s]\u001b[A\n","Iteration:  40% 745/1851 [09:37<14:11,  1.30it/s]\u001b[A\n","Iteration:  40% 746/1851 [09:37<14:10,  1.30it/s]\u001b[A\n","Iteration:  40% 747/1851 [09:38<14:10,  1.30it/s]\u001b[A\n","Iteration:  40% 748/1851 [09:39<14:08,  1.30it/s]\u001b[A\n","Iteration:  40% 749/1851 [09:40<14:08,  1.30it/s]\u001b[A\n","Iteration:  41% 750/1851 [09:40<14:08,  1.30it/s]\u001b[A\n","Iteration:  41% 751/1851 [09:41<14:07,  1.30it/s]\u001b[A\n","Iteration:  41% 752/1851 [09:42<14:07,  1.30it/s]\u001b[A\n","Iteration:  41% 753/1851 [09:43<14:06,  1.30it/s]\u001b[A\n","Iteration:  41% 754/1851 [09:44<14:04,  1.30it/s]\u001b[A\n","Iteration:  41% 755/1851 [09:44<14:03,  1.30it/s]\u001b[A\n","Iteration:  41% 756/1851 [09:45<14:03,  1.30it/s]\u001b[A\n","Iteration:  41% 757/1851 [09:46<14:02,  1.30it/s]\u001b[A\n","Iteration:  41% 758/1851 [09:47<14:00,  1.30it/s]\u001b[A\n","Iteration:  41% 759/1851 [09:47<14:00,  1.30it/s]\u001b[A\n","Iteration:  41% 760/1851 [09:48<13:59,  1.30it/s]\u001b[A\n","Iteration:  41% 761/1851 [09:49<13:59,  1.30it/s]\u001b[A\n","Iteration:  41% 762/1851 [09:50<13:57,  1.30it/s]\u001b[A\n","Iteration:  41% 763/1851 [09:50<13:56,  1.30it/s]\u001b[A\n","Iteration:  41% 764/1851 [09:51<13:57,  1.30it/s]\u001b[A\n","Iteration:  41% 765/1851 [09:52<13:56,  1.30it/s]\u001b[A\n","Iteration:  41% 766/1851 [09:53<13:56,  1.30it/s]\u001b[A\n","Iteration:  41% 767/1851 [09:54<13:55,  1.30it/s]\u001b[A\n","Iteration:  41% 768/1851 [09:54<13:54,  1.30it/s]\u001b[A\n","Iteration:  42% 769/1851 [09:55<13:52,  1.30it/s]\u001b[A\n","Iteration:  42% 770/1851 [09:56<13:53,  1.30it/s]\u001b[A\n","Iteration:  42% 771/1851 [09:57<13:52,  1.30it/s]\u001b[A\n","Iteration:  42% 772/1851 [09:57<13:51,  1.30it/s]\u001b[A\n","Iteration:  42% 773/1851 [09:58<13:50,  1.30it/s]\u001b[A\n","Iteration:  42% 774/1851 [09:59<13:49,  1.30it/s]\u001b[A\n","Iteration:  42% 775/1851 [10:00<13:48,  1.30it/s]\u001b[A\n","Iteration:  42% 776/1851 [10:00<13:47,  1.30it/s]\u001b[A\n","Iteration:  42% 777/1851 [10:01<13:48,  1.30it/s]\u001b[A\n","Iteration:  42% 778/1851 [10:02<13:45,  1.30it/s]\u001b[A\n","Iteration:  42% 779/1851 [10:03<13:46,  1.30it/s]\u001b[A\n","Iteration:  42% 780/1851 [10:04<13:45,  1.30it/s]\u001b[A\n","Iteration:  42% 781/1851 [10:04<13:44,  1.30it/s]\u001b[A\n","Iteration:  42% 782/1851 [10:05<13:44,  1.30it/s]\u001b[A\n","Iteration:  42% 783/1851 [10:06<13:45,  1.29it/s]\u001b[A\n","Iteration:  42% 784/1851 [10:07<13:45,  1.29it/s]\u001b[A\n","Iteration:  42% 785/1851 [10:07<13:43,  1.29it/s]\u001b[A\n","Iteration:  42% 786/1851 [10:08<13:42,  1.29it/s]\u001b[A\n","Iteration:  43% 787/1851 [10:09<13:41,  1.30it/s]\u001b[A\n","Iteration:  43% 788/1851 [10:10<13:39,  1.30it/s]\u001b[A\n","Iteration:  43% 789/1851 [10:10<13:39,  1.30it/s]\u001b[A\n","Iteration:  43% 790/1851 [10:11<13:37,  1.30it/s]\u001b[A\n","Iteration:  43% 791/1851 [10:12<13:37,  1.30it/s]\u001b[A\n","Iteration:  43% 792/1851 [10:13<13:36,  1.30it/s]\u001b[A\n","Iteration:  43% 793/1851 [10:14<13:35,  1.30it/s]\u001b[A\n","Iteration:  43% 794/1851 [10:14<13:34,  1.30it/s]\u001b[A\n","Iteration:  43% 795/1851 [10:15<13:34,  1.30it/s]\u001b[A\n","Iteration:  43% 796/1851 [10:16<13:35,  1.29it/s]\u001b[A\n","Iteration:  43% 797/1851 [10:17<13:35,  1.29it/s]\u001b[A\n","Iteration:  43% 798/1851 [10:17<13:35,  1.29it/s]\u001b[A\n","Iteration:  43% 799/1851 [10:18<13:33,  1.29it/s]\u001b[A\n","Iteration:  43% 800/1851 [10:19<13:32,  1.29it/s]\u001b[A\n","Iteration:  43% 801/1851 [10:20<13:31,  1.29it/s]\u001b[A\n","Iteration:  43% 802/1851 [10:21<13:30,  1.29it/s]\u001b[A\n","Iteration:  43% 803/1851 [10:21<13:30,  1.29it/s]\u001b[A\n","Iteration:  43% 804/1851 [10:22<13:30,  1.29it/s]\u001b[A\n","Iteration:  43% 805/1851 [10:23<13:28,  1.29it/s]\u001b[A\n","Iteration:  44% 806/1851 [10:24<13:28,  1.29it/s]\u001b[A\n","Iteration:  44% 807/1851 [10:24<13:27,  1.29it/s]\u001b[A\n","Iteration:  44% 808/1851 [10:25<13:26,  1.29it/s]\u001b[A\n","Iteration:  44% 809/1851 [10:26<13:26,  1.29it/s]\u001b[A\n","Iteration:  44% 810/1851 [10:27<13:23,  1.30it/s]\u001b[A\n","Iteration:  44% 811/1851 [10:27<13:22,  1.30it/s]\u001b[A\n","Iteration:  44% 812/1851 [10:28<13:21,  1.30it/s]\u001b[A\n","Iteration:  44% 813/1851 [10:29<13:21,  1.30it/s]\u001b[A\n","Iteration:  44% 814/1851 [10:30<13:19,  1.30it/s]\u001b[A\n","Iteration:  44% 815/1851 [10:31<13:19,  1.30it/s]\u001b[A\n","Iteration:  44% 816/1851 [10:31<13:19,  1.29it/s]\u001b[A\n","Iteration:  44% 817/1851 [10:32<13:18,  1.29it/s]\u001b[A\n","Iteration:  44% 818/1851 [10:33<13:17,  1.29it/s]\u001b[A\n","Iteration:  44% 819/1851 [10:34<13:16,  1.30it/s]\u001b[A\n","Iteration:  44% 820/1851 [10:34<13:15,  1.30it/s]\u001b[A\n","Iteration:  44% 821/1851 [10:35<13:15,  1.29it/s]\u001b[A\n","Iteration:  44% 822/1851 [10:36<13:15,  1.29it/s]\u001b[A\n","Iteration:  44% 823/1851 [10:37<13:15,  1.29it/s]\u001b[A\n","Iteration:  45% 824/1851 [10:38<13:15,  1.29it/s]\u001b[A\n","Iteration:  45% 825/1851 [10:38<13:13,  1.29it/s]\u001b[A\n","Iteration:  45% 826/1851 [10:39<13:12,  1.29it/s]\u001b[A\n","Iteration:  45% 827/1851 [10:40<13:12,  1.29it/s]\u001b[A\n","Iteration:  45% 828/1851 [10:41<13:12,  1.29it/s]\u001b[A\n","Iteration:  45% 829/1851 [10:41<13:10,  1.29it/s]\u001b[A\n","Iteration:  45% 830/1851 [10:42<13:09,  1.29it/s]\u001b[A\n","Iteration:  45% 831/1851 [10:43<13:08,  1.29it/s]\u001b[A\n","Iteration:  45% 832/1851 [10:44<13:07,  1.29it/s]\u001b[A\n","Iteration:  45% 833/1851 [10:44<13:06,  1.29it/s]\u001b[A\n","Iteration:  45% 834/1851 [10:45<13:06,  1.29it/s]\u001b[A\n","Iteration:  45% 835/1851 [10:46<13:05,  1.29it/s]\u001b[A\n","Iteration:  45% 836/1851 [10:47<13:04,  1.29it/s]\u001b[A\n","Iteration:  45% 837/1851 [10:48<13:03,  1.29it/s]\u001b[A\n","Iteration:  45% 838/1851 [10:48<13:02,  1.30it/s]\u001b[A\n","Iteration:  45% 839/1851 [10:49<13:01,  1.30it/s]\u001b[A\n","Iteration:  45% 840/1851 [10:50<12:59,  1.30it/s]\u001b[A\n","Iteration:  45% 841/1851 [10:51<12:58,  1.30it/s]\u001b[A\n","Iteration:  45% 842/1851 [10:51<12:58,  1.30it/s]\u001b[A\n","Iteration:  46% 843/1851 [10:52<12:57,  1.30it/s]\u001b[A\n","Iteration:  46% 844/1851 [10:53<12:59,  1.29it/s]\u001b[A\n","Iteration:  46% 845/1851 [10:54<12:59,  1.29it/s]\u001b[A\n","Iteration:  46% 846/1851 [10:55<12:58,  1.29it/s]\u001b[A\n","Iteration:  46% 847/1851 [10:55<12:56,  1.29it/s]\u001b[A\n","Iteration:  46% 848/1851 [10:56<12:56,  1.29it/s]\u001b[A\n","Iteration:  46% 849/1851 [10:57<12:55,  1.29it/s]\u001b[A\n","Iteration:  46% 850/1851 [10:58<12:55,  1.29it/s]\u001b[A\n","Iteration:  46% 851/1851 [10:58<12:53,  1.29it/s]\u001b[A\n","Iteration:  46% 852/1851 [10:59<12:51,  1.29it/s]\u001b[A\n","Iteration:  46% 853/1851 [11:00<12:50,  1.30it/s]\u001b[A\n","Iteration:  46% 854/1851 [11:01<12:48,  1.30it/s]\u001b[A\n","Iteration:  46% 855/1851 [11:01<12:49,  1.29it/s]\u001b[A\n","Iteration:  46% 856/1851 [11:02<12:48,  1.29it/s]\u001b[A\n","Iteration:  46% 857/1851 [11:03<12:47,  1.29it/s]\u001b[A\n","Iteration:  46% 858/1851 [11:04<12:47,  1.29it/s]\u001b[A\n","Iteration:  46% 859/1851 [11:05<12:47,  1.29it/s]\u001b[A\n","Iteration:  46% 860/1851 [11:05<12:46,  1.29it/s]\u001b[A\n","Iteration:  47% 861/1851 [11:06<12:45,  1.29it/s]\u001b[A\n","Iteration:  47% 862/1851 [11:07<12:43,  1.30it/s]\u001b[A\n","Iteration:  47% 863/1851 [11:08<12:42,  1.30it/s]\u001b[A\n","Iteration:  47% 864/1851 [11:08<12:42,  1.29it/s]\u001b[A\n","Iteration:  47% 865/1851 [11:09<12:41,  1.30it/s]\u001b[A\n","Iteration:  47% 866/1851 [11:10<12:39,  1.30it/s]\u001b[A\n","Iteration:  47% 867/1851 [11:11<12:38,  1.30it/s]\u001b[A\n","Iteration:  47% 868/1851 [11:12<12:38,  1.30it/s]\u001b[A\n","Iteration:  47% 869/1851 [11:12<12:37,  1.30it/s]\u001b[A\n","Iteration:  47% 870/1851 [11:13<12:37,  1.30it/s]\u001b[A\n","Iteration:  47% 871/1851 [11:14<12:37,  1.29it/s]\u001b[A\n","Iteration:  47% 872/1851 [11:15<12:37,  1.29it/s]\u001b[A\n","Iteration:  47% 873/1851 [11:15<12:34,  1.30it/s]\u001b[A\n","Iteration:  47% 874/1851 [11:16<12:34,  1.29it/s]\u001b[A\n","Iteration:  47% 875/1851 [11:17<12:34,  1.29it/s]\u001b[A\n","Iteration:  47% 876/1851 [11:18<12:32,  1.30it/s]\u001b[A\n","Iteration:  47% 877/1851 [11:18<12:31,  1.30it/s]\u001b[A\n","Iteration:  47% 878/1851 [11:19<12:31,  1.30it/s]\u001b[A\n","Iteration:  47% 879/1851 [11:20<12:29,  1.30it/s]\u001b[A\n","Iteration:  48% 880/1851 [11:21<12:27,  1.30it/s]\u001b[A\n","Iteration:  48% 881/1851 [11:22<12:28,  1.30it/s]\u001b[A\n","Iteration:  48% 882/1851 [11:22<12:29,  1.29it/s]\u001b[A\n","Iteration:  48% 883/1851 [11:23<12:27,  1.29it/s]\u001b[A\n","Iteration:  48% 884/1851 [11:24<12:27,  1.29it/s]\u001b[A\n","Iteration:  48% 885/1851 [11:25<12:27,  1.29it/s]\u001b[A\n","Iteration:  48% 886/1851 [11:25<12:26,  1.29it/s]\u001b[A\n","Iteration:  48% 887/1851 [11:26<12:25,  1.29it/s]\u001b[A\n","Iteration:  48% 888/1851 [11:27<12:23,  1.30it/s]\u001b[A\n","Iteration:  48% 889/1851 [11:28<12:20,  1.30it/s]\u001b[A\n","Iteration:  48% 890/1851 [11:29<12:21,  1.30it/s]\u001b[A\n","Iteration:  48% 891/1851 [11:29<12:20,  1.30it/s]\u001b[A\n","Iteration:  48% 892/1851 [11:30<12:19,  1.30it/s]\u001b[A\n","Iteration:  48% 893/1851 [11:31<12:19,  1.29it/s]\u001b[A\n","Iteration:  48% 894/1851 [11:32<12:22,  1.29it/s]\u001b[A\n","Iteration:  48% 895/1851 [11:32<12:20,  1.29it/s]\u001b[A\n","Iteration:  48% 896/1851 [11:33<12:19,  1.29it/s]\u001b[A\n","Iteration:  48% 897/1851 [11:34<12:17,  1.29it/s]\u001b[A\n","Iteration:  49% 898/1851 [11:35<12:15,  1.30it/s]\u001b[A\n","Iteration:  49% 899/1851 [11:35<12:14,  1.30it/s]\u001b[A\n","Iteration:  49% 900/1851 [11:36<12:12,  1.30it/s]\u001b[A\n","Iteration:  49% 901/1851 [11:37<12:12,  1.30it/s]\u001b[A\n","Iteration:  49% 902/1851 [11:38<12:12,  1.30it/s]\u001b[A\n","Iteration:  49% 903/1851 [11:39<12:12,  1.29it/s]\u001b[A\n","Iteration:  49% 904/1851 [11:39<12:11,  1.29it/s]\u001b[A\n","Iteration:  49% 905/1851 [11:40<12:11,  1.29it/s]\u001b[A\n","Iteration:  49% 906/1851 [11:41<12:09,  1.29it/s]\u001b[A\n","Iteration:  49% 907/1851 [11:42<12:09,  1.29it/s]\u001b[A\n","Iteration:  49% 908/1851 [11:42<12:07,  1.30it/s]\u001b[A\n","Iteration:  49% 909/1851 [11:43<12:07,  1.29it/s]\u001b[A\n","Iteration:  49% 910/1851 [11:44<12:05,  1.30it/s]\u001b[A\n","Iteration:  49% 911/1851 [11:45<12:04,  1.30it/s]\u001b[A\n","Iteration:  49% 912/1851 [11:46<12:05,  1.29it/s]\u001b[A\n","Iteration:  49% 913/1851 [11:46<12:05,  1.29it/s]\u001b[A\n","Iteration:  49% 914/1851 [11:47<12:04,  1.29it/s]\u001b[A\n","Iteration:  49% 915/1851 [11:48<12:03,  1.29it/s]\u001b[A\n","Iteration:  49% 916/1851 [11:49<12:01,  1.30it/s]\u001b[A\n","Iteration:  50% 917/1851 [11:49<12:00,  1.30it/s]\u001b[A\n","Iteration:  50% 918/1851 [11:50<11:59,  1.30it/s]\u001b[A\n","Iteration:  50% 919/1851 [11:51<11:58,  1.30it/s]\u001b[A\n","Iteration:  50% 920/1851 [11:52<11:58,  1.30it/s]\u001b[A\n","Iteration:  50% 921/1851 [11:52<11:57,  1.30it/s]\u001b[A\n","Iteration:  50% 922/1851 [11:53<11:55,  1.30it/s]\u001b[A\n","Iteration:  50% 923/1851 [11:54<11:55,  1.30it/s]\u001b[A\n","Iteration:  50% 924/1851 [11:55<11:54,  1.30it/s]\u001b[A\n","Iteration:  50% 925/1851 [11:56<11:53,  1.30it/s]\u001b[A\n","Iteration:  50% 926/1851 [11:56<11:53,  1.30it/s]\u001b[A\n","Iteration:  50% 927/1851 [11:57<11:52,  1.30it/s]\u001b[A\n","Iteration:  50% 928/1851 [11:58<11:50,  1.30it/s]\u001b[A\n","Iteration:  50% 929/1851 [11:59<11:51,  1.30it/s]\u001b[A\n","Iteration:  50% 930/1851 [11:59<11:49,  1.30it/s]\u001b[A\n","Iteration:  50% 931/1851 [12:00<11:49,  1.30it/s]\u001b[A\n","Iteration:  50% 932/1851 [12:01<11:49,  1.29it/s]\u001b[A\n","Iteration:  50% 933/1851 [12:02<11:50,  1.29it/s]\u001b[A\n","Iteration:  50% 934/1851 [12:02<11:49,  1.29it/s]\u001b[A\n","Iteration:  51% 935/1851 [12:03<11:48,  1.29it/s]\u001b[A\n","Iteration:  51% 936/1851 [12:04<11:46,  1.29it/s]\u001b[A\n","Iteration:  51% 937/1851 [12:05<11:45,  1.30it/s]\u001b[A\n","Iteration:  51% 938/1851 [12:06<11:45,  1.29it/s]\u001b[A\n","Iteration:  51% 939/1851 [12:06<11:46,  1.29it/s]\u001b[A\n","Iteration:  51% 940/1851 [12:07<11:44,  1.29it/s]\u001b[A\n","Iteration:  51% 941/1851 [12:08<11:43,  1.29it/s]\u001b[A\n","Iteration:  51% 942/1851 [12:09<11:41,  1.30it/s]\u001b[A\n","Iteration:  51% 943/1851 [12:09<11:42,  1.29it/s]\u001b[A\n","Iteration:  51% 944/1851 [12:10<11:42,  1.29it/s]\u001b[A\n","Iteration:  51% 945/1851 [12:11<11:40,  1.29it/s]\u001b[A\n","Iteration:  51% 946/1851 [12:12<11:41,  1.29it/s]\u001b[A\n","Iteration:  51% 947/1851 [12:13<11:40,  1.29it/s]\u001b[A\n","Iteration:  51% 948/1851 [12:13<11:38,  1.29it/s]\u001b[A\n","Iteration:  51% 949/1851 [12:14<11:37,  1.29it/s]\u001b[A\n","Iteration:  51% 950/1851 [12:15<11:35,  1.30it/s]\u001b[A\n","Iteration:  51% 951/1851 [12:16<11:33,  1.30it/s]\u001b[A\n","Iteration:  51% 952/1851 [12:16<11:34,  1.30it/s]\u001b[A\n","Iteration:  51% 953/1851 [12:17<11:32,  1.30it/s]\u001b[A\n","Iteration:  52% 954/1851 [12:18<11:31,  1.30it/s]\u001b[A\n","Iteration:  52% 955/1851 [12:19<11:32,  1.29it/s]\u001b[A\n","Iteration:  52% 956/1851 [12:19<11:32,  1.29it/s]\u001b[A\n","Iteration:  52% 957/1851 [12:20<11:31,  1.29it/s]\u001b[A\n","Iteration:  52% 958/1851 [12:21<11:30,  1.29it/s]\u001b[A\n","Iteration:  52% 959/1851 [12:22<11:29,  1.29it/s]\u001b[A\n","Iteration:  52% 960/1851 [12:23<11:28,  1.29it/s]\u001b[A\n","Iteration:  52% 961/1851 [12:23<11:26,  1.30it/s]\u001b[A\n","Iteration:  52% 962/1851 [12:24<11:26,  1.29it/s]\u001b[A\n","Iteration:  52% 963/1851 [12:25<11:27,  1.29it/s]\u001b[A\n","Iteration:  52% 964/1851 [12:26<11:26,  1.29it/s]\u001b[A\n","Iteration:  52% 965/1851 [12:26<11:25,  1.29it/s]\u001b[A\n","Iteration:  52% 966/1851 [12:27<11:24,  1.29it/s]\u001b[A\n","Iteration:  52% 967/1851 [12:28<11:23,  1.29it/s]\u001b[A\n","Iteration:  52% 968/1851 [12:29<11:22,  1.29it/s]\u001b[A\n","Iteration:  52% 969/1851 [12:30<11:22,  1.29it/s]\u001b[A\n","Iteration:  52% 970/1851 [12:30<11:21,  1.29it/s]\u001b[A\n","Iteration:  52% 971/1851 [12:31<11:21,  1.29it/s]\u001b[A\n","Iteration:  53% 972/1851 [12:32<11:20,  1.29it/s]\u001b[A\n","Iteration:  53% 973/1851 [12:33<11:18,  1.29it/s]\u001b[A\n","Iteration:  53% 974/1851 [12:33<11:19,  1.29it/s]\u001b[A\n","Iteration:  53% 975/1851 [12:34<11:18,  1.29it/s]\u001b[A\n","Iteration:  53% 976/1851 [12:35<11:17,  1.29it/s]\u001b[A\n","Iteration:  53% 977/1851 [12:36<11:16,  1.29it/s]\u001b[A\n","Iteration:  53% 978/1851 [12:37<11:14,  1.29it/s]\u001b[A\n","Iteration:  53% 979/1851 [12:37<11:13,  1.29it/s]\u001b[A\n","Iteration:  53% 980/1851 [12:38<11:13,  1.29it/s]\u001b[A\n","Iteration:  53% 981/1851 [12:39<11:13,  1.29it/s]\u001b[A\n","Iteration:  53% 982/1851 [12:40<11:12,  1.29it/s]\u001b[A\n","Iteration:  53% 983/1851 [12:40<11:12,  1.29it/s]\u001b[A\n","Iteration:  53% 984/1851 [12:41<11:10,  1.29it/s]\u001b[A\n","Iteration:  53% 985/1851 [12:42<11:10,  1.29it/s]\u001b[A\n","Iteration:  53% 986/1851 [12:43<11:09,  1.29it/s]\u001b[A\n","Iteration:  53% 987/1851 [12:43<11:08,  1.29it/s]\u001b[A\n","Iteration:  53% 988/1851 [12:44<11:08,  1.29it/s]\u001b[A\n","Iteration:  53% 989/1851 [12:45<11:08,  1.29it/s]\u001b[A\n","Iteration:  53% 990/1851 [12:46<11:06,  1.29it/s]\u001b[A\n","Iteration:  54% 991/1851 [12:47<11:04,  1.29it/s]\u001b[A\n","Iteration:  54% 992/1851 [12:47<11:04,  1.29it/s]\u001b[A\n","Iteration:  54% 993/1851 [12:48<11:03,  1.29it/s]\u001b[A\n","Iteration:  54% 994/1851 [12:49<11:01,  1.30it/s]\u001b[A\n","Iteration:  54% 995/1851 [12:50<11:01,  1.29it/s]\u001b[A\n","Iteration:  54% 996/1851 [12:50<10:59,  1.30it/s]\u001b[A\n","Iteration:  54% 997/1851 [12:51<10:59,  1.30it/s]\u001b[A\n","Iteration:  54% 998/1851 [12:52<10:59,  1.29it/s]\u001b[A\n","Iteration:  54% 999/1851 [12:53<10:58,  1.29it/s]\u001b[A\n","Iteration:  54% 1000/1851 [12:54<10:56,  1.30it/s]\u001b[A\n","Iteration:  54% 1001/1851 [12:54<10:55,  1.30it/s]\u001b[A\n","Iteration:  54% 1002/1851 [12:55<10:56,  1.29it/s]\u001b[A\n","Iteration:  54% 1003/1851 [12:56<10:56,  1.29it/s]\u001b[A\n","Iteration:  54% 1004/1851 [12:57<10:55,  1.29it/s]\u001b[A\n","Iteration:  54% 1005/1851 [12:57<10:53,  1.29it/s]\u001b[A\n","Iteration:  54% 1006/1851 [12:58<10:53,  1.29it/s]\u001b[A\n","Iteration:  54% 1007/1851 [12:59<10:54,  1.29it/s]\u001b[A\n","Iteration:  54% 1008/1851 [13:00<10:53,  1.29it/s]\u001b[A\n","Iteration:  55% 1009/1851 [13:00<10:52,  1.29it/s]\u001b[A\n","Iteration:  55% 1010/1851 [13:01<10:50,  1.29it/s]\u001b[A\n","Iteration:  55% 1011/1851 [13:02<10:50,  1.29it/s]\u001b[A\n","Iteration:  55% 1012/1851 [13:03<10:49,  1.29it/s]\u001b[A\n","Iteration:  55% 1013/1851 [13:04<10:48,  1.29it/s]\u001b[A\n","Iteration:  55% 1014/1851 [13:04<10:47,  1.29it/s]\u001b[A\n","Iteration:  55% 1015/1851 [13:05<10:46,  1.29it/s]\u001b[A\n","Iteration:  55% 1016/1851 [13:06<10:45,  1.29it/s]\u001b[A\n","Iteration:  55% 1017/1851 [13:07<10:43,  1.30it/s]\u001b[A\n","Iteration:  55% 1018/1851 [13:07<10:42,  1.30it/s]\u001b[A\n","Iteration:  55% 1019/1851 [13:08<10:41,  1.30it/s]\u001b[A\n","Iteration:  55% 1020/1851 [13:09<10:41,  1.30it/s]\u001b[A\n","Iteration:  55% 1021/1851 [13:10<10:42,  1.29it/s]\u001b[A\n","Iteration:  55% 1022/1851 [13:11<10:41,  1.29it/s]\u001b[A\n","Iteration:  55% 1023/1851 [13:11<10:39,  1.29it/s]\u001b[A\n","Iteration:  55% 1024/1851 [13:12<10:38,  1.30it/s]\u001b[A\n","Iteration:  55% 1025/1851 [13:13<10:37,  1.30it/s]\u001b[A\n","Iteration:  55% 1026/1851 [13:14<10:36,  1.30it/s]\u001b[A\n","Iteration:  55% 1027/1851 [13:14<10:36,  1.29it/s]\u001b[A\n","Iteration:  56% 1028/1851 [13:15<10:34,  1.30it/s]\u001b[A\n","Iteration:  56% 1029/1851 [13:16<11:23,  1.20it/s]\u001b[A\n","Iteration:  56% 1030/1851 [13:17<11:12,  1.22it/s]\u001b[A\n","Iteration:  56% 1031/1851 [13:18<11:02,  1.24it/s]\u001b[A\n","Iteration:  56% 1032/1851 [13:18<10:52,  1.26it/s]\u001b[A\n","Iteration:  56% 1033/1851 [13:19<10:44,  1.27it/s]\u001b[A\n","Iteration:  56% 1034/1851 [13:20<10:40,  1.28it/s]\u001b[A\n","Iteration:  56% 1035/1851 [13:21<10:38,  1.28it/s]\u001b[A\n","Iteration:  56% 1036/1851 [13:22<10:35,  1.28it/s]\u001b[A\n","Iteration:  56% 1037/1851 [13:22<10:33,  1.28it/s]\u001b[A\n","Iteration:  56% 1038/1851 [13:23<10:32,  1.28it/s]\u001b[A\n","Iteration:  56% 1039/1851 [13:24<10:31,  1.29it/s]\u001b[A\n","Iteration:  56% 1040/1851 [13:25<10:29,  1.29it/s]\u001b[A\n","Iteration:  56% 1041/1851 [13:25<10:28,  1.29it/s]\u001b[A\n","Iteration:  56% 1042/1851 [13:26<10:26,  1.29it/s]\u001b[A\n","Iteration:  56% 1043/1851 [13:27<10:27,  1.29it/s]\u001b[A\n","Iteration:  56% 1044/1851 [13:28<10:26,  1.29it/s]\u001b[A\n","Iteration:  56% 1045/1851 [13:29<10:23,  1.29it/s]\u001b[A\n","Iteration:  57% 1046/1851 [13:29<10:21,  1.29it/s]\u001b[A\n","Iteration:  57% 1047/1851 [13:30<10:21,  1.29it/s]\u001b[A\n","Iteration:  57% 1048/1851 [13:31<10:20,  1.29it/s]\u001b[A\n","Iteration:  57% 1049/1851 [13:32<10:20,  1.29it/s]\u001b[A\n","Iteration:  57% 1050/1851 [13:32<10:19,  1.29it/s]\u001b[A\n","Iteration:  57% 1051/1851 [13:33<10:18,  1.29it/s]\u001b[A\n","Iteration:  57% 1052/1851 [13:34<10:17,  1.29it/s]\u001b[A\n","Iteration:  57% 1053/1851 [13:35<10:16,  1.29it/s]\u001b[A\n","Iteration:  57% 1054/1851 [13:35<10:15,  1.29it/s]\u001b[A\n","Iteration:  57% 1055/1851 [13:36<10:14,  1.30it/s]\u001b[A\n","Iteration:  57% 1056/1851 [13:37<10:14,  1.29it/s]\u001b[A\n","Iteration:  57% 1057/1851 [13:38<10:12,  1.30it/s]\u001b[A\n","Iteration:  57% 1058/1851 [13:39<10:11,  1.30it/s]\u001b[A\n","Iteration:  57% 1059/1851 [13:39<10:11,  1.30it/s]\u001b[A\n","Iteration:  57% 1060/1851 [13:40<10:09,  1.30it/s]\u001b[A\n","Iteration:  57% 1061/1851 [13:41<10:09,  1.30it/s]\u001b[A\n","Iteration:  57% 1062/1851 [13:42<10:09,  1.30it/s]\u001b[A\n","Iteration:  57% 1063/1851 [13:42<10:09,  1.29it/s]\u001b[A\n","Iteration:  57% 1064/1851 [13:43<10:07,  1.29it/s]\u001b[A\n","Iteration:  58% 1065/1851 [13:44<10:08,  1.29it/s]\u001b[A\n","Iteration:  58% 1066/1851 [13:45<10:07,  1.29it/s]\u001b[A\n","Iteration:  58% 1067/1851 [13:46<10:06,  1.29it/s]\u001b[A\n","Iteration:  58% 1068/1851 [13:46<10:04,  1.29it/s]\u001b[A\n","Iteration:  58% 1069/1851 [13:47<10:03,  1.30it/s]\u001b[A\n","Iteration:  58% 1070/1851 [13:48<10:03,  1.29it/s]\u001b[A\n","Iteration:  58% 1071/1851 [13:49<10:01,  1.30it/s]\u001b[A\n","Iteration:  58% 1072/1851 [13:49<10:01,  1.29it/s]\u001b[A\n","Iteration:  58% 1073/1851 [13:50<10:00,  1.30it/s]\u001b[A\n","Iteration:  58% 1074/1851 [13:51<09:59,  1.30it/s]\u001b[A\n","Iteration:  58% 1075/1851 [13:52<09:58,  1.30it/s]\u001b[A\n","Iteration:  58% 1076/1851 [13:52<09:58,  1.30it/s]\u001b[A\n","Iteration:  58% 1077/1851 [13:53<09:57,  1.30it/s]\u001b[A\n","Iteration:  58% 1078/1851 [13:54<09:56,  1.30it/s]\u001b[A\n","Iteration:  58% 1079/1851 [13:55<09:55,  1.30it/s]\u001b[A\n","Iteration:  58% 1080/1851 [13:56<09:54,  1.30it/s]\u001b[A\n","Iteration:  58% 1081/1851 [13:56<09:52,  1.30it/s]\u001b[A\n","Iteration:  58% 1082/1851 [13:57<09:53,  1.30it/s]\u001b[A\n","Iteration:  59% 1083/1851 [13:58<09:52,  1.30it/s]\u001b[A\n","Iteration:  59% 1084/1851 [13:59<09:51,  1.30it/s]\u001b[A\n","Iteration:  59% 1085/1851 [13:59<09:51,  1.30it/s]\u001b[A\n","Iteration:  59% 1086/1851 [14:00<09:51,  1.29it/s]\u001b[A\n","Iteration:  59% 1087/1851 [14:01<09:50,  1.29it/s]\u001b[A\n","Iteration:  59% 1088/1851 [14:02<09:50,  1.29it/s]\u001b[A\n","Iteration:  59% 1089/1851 [14:03<09:48,  1.29it/s]\u001b[A\n","Iteration:  59% 1090/1851 [14:03<09:46,  1.30it/s]\u001b[A\n","Iteration:  59% 1091/1851 [14:04<09:47,  1.29it/s]\u001b[A\n","Iteration:  59% 1092/1851 [14:05<09:44,  1.30it/s]\u001b[A\n","Iteration:  59% 1093/1851 [14:06<09:44,  1.30it/s]\u001b[A\n","Iteration:  59% 1094/1851 [14:06<09:44,  1.30it/s]\u001b[A\n","Iteration:  59% 1095/1851 [14:07<09:43,  1.30it/s]\u001b[A\n","Iteration:  59% 1096/1851 [14:08<09:43,  1.29it/s]\u001b[A\n","Iteration:  59% 1097/1851 [14:09<09:43,  1.29it/s]\u001b[A\n","Iteration:  59% 1098/1851 [14:09<09:42,  1.29it/s]\u001b[A\n","Iteration:  59% 1099/1851 [14:10<09:41,  1.29it/s]\u001b[A\n","Iteration:  59% 1100/1851 [14:11<09:40,  1.29it/s]\u001b[A\n","Iteration:  59% 1101/1851 [14:12<09:38,  1.30it/s]\u001b[A\n","Iteration:  60% 1102/1851 [14:13<09:38,  1.30it/s]\u001b[A\n","Iteration:  60% 1103/1851 [14:13<09:37,  1.29it/s]\u001b[A\n","Iteration:  60% 1104/1851 [14:14<09:38,  1.29it/s]\u001b[A\n","Iteration:  60% 1105/1851 [14:15<09:37,  1.29it/s]\u001b[A\n","Iteration:  60% 1106/1851 [14:16<09:36,  1.29it/s]\u001b[A\n","Iteration:  60% 1107/1851 [14:16<09:34,  1.29it/s]\u001b[A\n","Iteration:  60% 1108/1851 [14:17<09:34,  1.29it/s]\u001b[A\n","Iteration:  60% 1109/1851 [14:18<09:33,  1.29it/s]\u001b[A\n","Iteration:  60% 1110/1851 [14:19<09:33,  1.29it/s]\u001b[A\n","Iteration:  60% 1111/1851 [14:20<09:32,  1.29it/s]\u001b[A\n","Iteration:  60% 1112/1851 [14:20<09:31,  1.29it/s]\u001b[A\n","Iteration:  60% 1113/1851 [14:21<09:31,  1.29it/s]\u001b[A\n","Iteration:  60% 1114/1851 [14:22<09:29,  1.29it/s]\u001b[A\n","Iteration:  60% 1115/1851 [14:23<09:28,  1.30it/s]\u001b[A\n","Iteration:  60% 1116/1851 [14:23<09:27,  1.30it/s]\u001b[A\n","Iteration:  60% 1117/1851 [14:24<09:26,  1.30it/s]\u001b[A\n","Iteration:  60% 1118/1851 [14:25<09:26,  1.29it/s]\u001b[A\n","Iteration:  60% 1119/1851 [14:26<09:26,  1.29it/s]\u001b[A\n","Iteration:  61% 1120/1851 [14:26<09:25,  1.29it/s]\u001b[A\n","Iteration:  61% 1121/1851 [14:27<09:24,  1.29it/s]\u001b[A\n","Iteration:  61% 1122/1851 [14:28<09:23,  1.29it/s]\u001b[A\n","Iteration:  61% 1123/1851 [14:29<09:22,  1.30it/s]\u001b[A\n","Iteration:  61% 1124/1851 [14:30<09:20,  1.30it/s]\u001b[A\n","Iteration:  61% 1125/1851 [14:30<09:20,  1.29it/s]\u001b[A\n","Iteration:  61% 1126/1851 [14:31<09:19,  1.29it/s]\u001b[A\n","Iteration:  61% 1127/1851 [14:32<09:19,  1.30it/s]\u001b[A\n","Iteration:  61% 1128/1851 [14:33<09:18,  1.29it/s]\u001b[A\n","Iteration:  61% 1129/1851 [14:33<09:18,  1.29it/s]\u001b[A\n","Iteration:  61% 1130/1851 [14:34<09:16,  1.29it/s]\u001b[A\n","Iteration:  61% 1131/1851 [14:35<09:16,  1.29it/s]\u001b[A\n","Iteration:  61% 1132/1851 [14:36<09:15,  1.30it/s]\u001b[A\n","Iteration:  61% 1133/1851 [14:37<09:13,  1.30it/s]\u001b[A\n","Iteration:  61% 1134/1851 [14:37<09:12,  1.30it/s]\u001b[A\n","Iteration:  61% 1135/1851 [14:38<09:11,  1.30it/s]\u001b[A\n","Iteration:  61% 1136/1851 [14:39<09:11,  1.30it/s]\u001b[A\n","Iteration:  61% 1137/1851 [14:40<09:10,  1.30it/s]\u001b[A\n","Iteration:  61% 1138/1851 [14:40<09:11,  1.29it/s]\u001b[A\n","Iteration:  62% 1139/1851 [14:41<09:11,  1.29it/s]\u001b[A\n","Iteration:  62% 1140/1851 [14:42<09:10,  1.29it/s]\u001b[A\n","Iteration:  62% 1141/1851 [14:43<09:08,  1.29it/s]\u001b[A\n","Iteration:  62% 1142/1851 [14:43<09:08,  1.29it/s]\u001b[A\n","Iteration:  62% 1143/1851 [14:44<09:07,  1.29it/s]\u001b[A\n","Iteration:  62% 1144/1851 [14:45<09:07,  1.29it/s]\u001b[A\n","Iteration:  62% 1145/1851 [14:46<09:05,  1.29it/s]\u001b[A\n","Iteration:  62% 1146/1851 [14:47<09:04,  1.30it/s]\u001b[A\n","Iteration:  62% 1147/1851 [14:47<09:04,  1.29it/s]\u001b[A\n","Iteration:  62% 1148/1851 [14:48<09:03,  1.29it/s]\u001b[A\n","Iteration:  62% 1149/1851 [14:49<09:01,  1.30it/s]\u001b[A\n","Iteration:  62% 1150/1851 [14:50<09:01,  1.29it/s]\u001b[A\n","Iteration:  62% 1151/1851 [14:50<08:59,  1.30it/s]\u001b[A\n","Iteration:  62% 1152/1851 [14:51<08:59,  1.30it/s]\u001b[A\n","Iteration:  62% 1153/1851 [14:52<08:58,  1.30it/s]\u001b[A\n","Iteration:  62% 1154/1851 [14:53<08:58,  1.30it/s]\u001b[A\n","Iteration:  62% 1155/1851 [14:54<08:56,  1.30it/s]\u001b[A\n","Iteration:  62% 1156/1851 [14:54<08:55,  1.30it/s]\u001b[A\n","Iteration:  63% 1157/1851 [14:55<08:55,  1.30it/s]\u001b[A\n","Iteration:  63% 1158/1851 [14:56<08:54,  1.30it/s]\u001b[A\n","Iteration:  63% 1159/1851 [14:57<08:53,  1.30it/s]\u001b[A\n","Iteration:  63% 1160/1851 [14:57<08:52,  1.30it/s]\u001b[A\n","Iteration:  63% 1161/1851 [14:58<08:52,  1.30it/s]\u001b[A\n","Iteration:  63% 1162/1851 [14:59<08:51,  1.30it/s]\u001b[A\n","Iteration:  63% 1163/1851 [15:00<08:50,  1.30it/s]\u001b[A\n","Iteration:  63% 1164/1851 [15:00<08:49,  1.30it/s]\u001b[A\n","Iteration:  63% 1165/1851 [15:01<08:49,  1.30it/s]\u001b[A\n","Iteration:  63% 1166/1851 [15:02<08:47,  1.30it/s]\u001b[A\n","Iteration:  63% 1167/1851 [15:03<08:46,  1.30it/s]\u001b[A\n","Iteration:  63% 1168/1851 [15:04<08:47,  1.30it/s]\u001b[A\n","Iteration:  63% 1169/1851 [15:04<08:45,  1.30it/s]\u001b[A\n","Iteration:  63% 1170/1851 [15:05<08:45,  1.30it/s]\u001b[A\n","Iteration:  63% 1171/1851 [15:06<08:45,  1.29it/s]\u001b[A\n","Iteration:  63% 1172/1851 [15:07<08:43,  1.30it/s]\u001b[A\n","Iteration:  63% 1173/1851 [15:07<08:42,  1.30it/s]\u001b[A\n","Iteration:  63% 1174/1851 [15:08<08:40,  1.30it/s]\u001b[A\n","Iteration:  63% 1175/1851 [15:09<08:40,  1.30it/s]\u001b[A\n","Iteration:  64% 1176/1851 [15:10<08:40,  1.30it/s]\u001b[A\n","Iteration:  64% 1177/1851 [15:10<08:40,  1.30it/s]\u001b[A\n","Iteration:  64% 1178/1851 [15:11<08:40,  1.29it/s]\u001b[A\n","Iteration:  64% 1179/1851 [15:12<08:39,  1.29it/s]\u001b[A\n","Iteration:  64% 1180/1851 [15:13<08:39,  1.29it/s]\u001b[A\n","Iteration:  64% 1181/1851 [15:14<08:37,  1.29it/s]\u001b[A\n","Iteration:  64% 1182/1851 [15:14<08:36,  1.30it/s]\u001b[A\n","Iteration:  64% 1183/1851 [15:15<08:35,  1.30it/s]\u001b[A\n","Iteration:  64% 1184/1851 [15:16<08:35,  1.29it/s]\u001b[A\n","Iteration:  64% 1185/1851 [15:17<08:35,  1.29it/s]\u001b[A\n","Iteration:  64% 1186/1851 [15:17<08:34,  1.29it/s]\u001b[A\n","Iteration:  64% 1187/1851 [15:18<08:33,  1.29it/s]\u001b[A\n","Iteration:  64% 1188/1851 [15:19<08:32,  1.29it/s]\u001b[A\n","Iteration:  64% 1189/1851 [15:20<08:31,  1.29it/s]\u001b[A\n","Iteration:  64% 1190/1851 [15:21<08:31,  1.29it/s]\u001b[A\n","Iteration:  64% 1191/1851 [15:21<08:30,  1.29it/s]\u001b[A\n","Iteration:  64% 1192/1851 [15:22<08:29,  1.29it/s]\u001b[A\n","Iteration:  64% 1193/1851 [15:23<08:29,  1.29it/s]\u001b[A\n","Iteration:  65% 1194/1851 [15:24<08:28,  1.29it/s]\u001b[A\n","Iteration:  65% 1195/1851 [15:24<08:28,  1.29it/s]\u001b[A\n","Iteration:  65% 1196/1851 [15:25<08:27,  1.29it/s]\u001b[A\n","Iteration:  65% 1197/1851 [15:26<08:26,  1.29it/s]\u001b[A\n","Iteration:  65% 1198/1851 [15:27<08:25,  1.29it/s]\u001b[A\n","Iteration:  65% 1199/1851 [15:27<08:24,  1.29it/s]\u001b[A\n","Iteration:  65% 1200/1851 [15:28<08:23,  1.29it/s]\u001b[A\n","Iteration:  65% 1201/1851 [15:29<08:22,  1.29it/s]\u001b[A\n","Iteration:  65% 1202/1851 [15:30<08:21,  1.29it/s]\u001b[A\n","Iteration:  65% 1203/1851 [15:31<08:19,  1.30it/s]\u001b[A\n","Iteration:  65% 1204/1851 [15:31<08:19,  1.29it/s]\u001b[A\n","Iteration:  65% 1205/1851 [15:32<08:19,  1.29it/s]\u001b[A\n","Iteration:  65% 1206/1851 [15:33<08:18,  1.29it/s]\u001b[A\n","Iteration:  65% 1207/1851 [15:34<08:18,  1.29it/s]\u001b[A\n","Iteration:  65% 1208/1851 [15:34<08:17,  1.29it/s]\u001b[A\n","Iteration:  65% 1209/1851 [15:35<08:16,  1.29it/s]\u001b[A\n","Iteration:  65% 1210/1851 [15:36<08:14,  1.30it/s]\u001b[A\n","Iteration:  65% 1211/1851 [15:37<08:14,  1.29it/s]\u001b[A\n","Iteration:  65% 1212/1851 [15:38<08:13,  1.30it/s]\u001b[A\n","Iteration:  66% 1213/1851 [15:38<08:12,  1.30it/s]\u001b[A\n","Iteration:  66% 1214/1851 [15:39<08:11,  1.30it/s]\u001b[A\n","Iteration:  66% 1215/1851 [15:40<08:10,  1.30it/s]\u001b[A\n","Iteration:  66% 1216/1851 [15:41<08:09,  1.30it/s]\u001b[A\n","Iteration:  66% 1217/1851 [15:41<08:09,  1.30it/s]\u001b[A\n","Iteration:  66% 1218/1851 [15:42<08:08,  1.29it/s]\u001b[A\n","Iteration:  66% 1219/1851 [15:43<08:09,  1.29it/s]\u001b[A\n","Iteration:  66% 1220/1851 [15:44<08:08,  1.29it/s]\u001b[A\n","Iteration:  66% 1221/1851 [15:44<08:05,  1.30it/s]\u001b[A\n","Iteration:  66% 1222/1851 [15:45<08:05,  1.29it/s]\u001b[A\n","Iteration:  66% 1223/1851 [15:46<08:05,  1.29it/s]\u001b[A\n","Iteration:  66% 1224/1851 [15:47<08:04,  1.29it/s]\u001b[A\n","Iteration:  66% 1225/1851 [15:48<08:03,  1.29it/s]\u001b[A\n","Iteration:  66% 1226/1851 [15:48<08:02,  1.29it/s]\u001b[A\n","Iteration:  66% 1227/1851 [15:49<08:02,  1.29it/s]\u001b[A\n","Iteration:  66% 1228/1851 [15:50<08:01,  1.29it/s]\u001b[A\n","Iteration:  66% 1229/1851 [15:51<08:00,  1.29it/s]\u001b[A\n","Iteration:  66% 1230/1851 [15:51<08:00,  1.29it/s]\u001b[A\n","Iteration:  67% 1231/1851 [15:52<07:58,  1.30it/s]\u001b[A\n","Iteration:  67% 1232/1851 [15:53<07:59,  1.29it/s]\u001b[A\n","Iteration:  67% 1233/1851 [15:54<07:59,  1.29it/s]\u001b[A\n","Iteration:  67% 1234/1851 [15:55<07:57,  1.29it/s]\u001b[A\n","Iteration:  67% 1235/1851 [15:55<07:57,  1.29it/s]\u001b[A\n","Iteration:  67% 1236/1851 [15:56<07:55,  1.29it/s]\u001b[A\n","Iteration:  67% 1237/1851 [15:57<07:54,  1.29it/s]\u001b[A\n","Iteration:  67% 1238/1851 [15:58<07:53,  1.29it/s]\u001b[A\n","Iteration:  67% 1239/1851 [15:58<07:52,  1.30it/s]\u001b[A\n","Iteration:  67% 1240/1851 [15:59<07:51,  1.29it/s]\u001b[A\n","Iteration:  67% 1241/1851 [16:00<07:51,  1.29it/s]\u001b[A\n","Iteration:  67% 1242/1851 [16:01<07:51,  1.29it/s]\u001b[A\n","Iteration:  67% 1243/1851 [16:01<07:50,  1.29it/s]\u001b[A\n","Iteration:  67% 1244/1851 [16:02<07:49,  1.29it/s]\u001b[A\n","Iteration:  67% 1245/1851 [16:03<07:48,  1.29it/s]\u001b[A\n","Iteration:  67% 1246/1851 [16:04<07:47,  1.30it/s]\u001b[A\n","Iteration:  67% 1247/1851 [16:05<07:46,  1.30it/s]\u001b[A\n","Iteration:  67% 1248/1851 [16:05<07:45,  1.30it/s]\u001b[A\n","Iteration:  67% 1249/1851 [16:06<07:44,  1.30it/s]\u001b[A\n","Iteration:  68% 1250/1851 [16:07<07:43,  1.30it/s]\u001b[A\n","Iteration:  68% 1251/1851 [16:08<07:42,  1.30it/s]\u001b[A\n","Iteration:  68% 1252/1851 [16:08<07:42,  1.30it/s]\u001b[A\n","Iteration:  68% 1253/1851 [16:09<07:41,  1.30it/s]\u001b[A\n","Iteration:  68% 1254/1851 [16:10<07:40,  1.30it/s]\u001b[A\n","Iteration:  68% 1255/1851 [16:11<07:39,  1.30it/s]\u001b[A\n","Iteration:  68% 1256/1851 [16:12<07:38,  1.30it/s]\u001b[A\n","Iteration:  68% 1257/1851 [16:12<07:38,  1.30it/s]\u001b[A\n","Iteration:  68% 1258/1851 [16:13<07:37,  1.29it/s]\u001b[A\n","Iteration:  68% 1259/1851 [16:14<07:37,  1.30it/s]\u001b[A\n","Iteration:  68% 1260/1851 [16:15<07:37,  1.29it/s]\u001b[A\n","Iteration:  68% 1261/1851 [16:15<07:35,  1.29it/s]\u001b[A\n","Iteration:  68% 1262/1851 [16:16<07:35,  1.29it/s]\u001b[A\n","Iteration:  68% 1263/1851 [16:17<07:34,  1.29it/s]\u001b[A\n","Iteration:  68% 1264/1851 [16:18<07:33,  1.29it/s]\u001b[A\n","Iteration:  68% 1265/1851 [16:18<07:32,  1.30it/s]\u001b[A\n","Iteration:  68% 1266/1851 [16:19<07:31,  1.30it/s]\u001b[A\n","Iteration:  68% 1267/1851 [16:20<07:30,  1.30it/s]\u001b[A\n","Iteration:  69% 1268/1851 [16:21<07:29,  1.30it/s]\u001b[A\n","Iteration:  69% 1269/1851 [16:22<07:29,  1.29it/s]\u001b[A\n","Iteration:  69% 1270/1851 [16:22<07:29,  1.29it/s]\u001b[A\n","Iteration:  69% 1271/1851 [16:23<07:28,  1.29it/s]\u001b[A\n","Iteration:  69% 1272/1851 [16:24<07:28,  1.29it/s]\u001b[A\n","Iteration:  69% 1273/1851 [16:25<07:26,  1.29it/s]\u001b[A\n","Iteration:  69% 1274/1851 [16:25<07:25,  1.29it/s]\u001b[A\n","Iteration:  69% 1275/1851 [16:26<07:25,  1.29it/s]\u001b[A\n","Iteration:  69% 1276/1851 [16:27<07:24,  1.29it/s]\u001b[A\n","Iteration:  69% 1277/1851 [16:28<07:23,  1.29it/s]\u001b[A\n","Iteration:  69% 1278/1851 [16:29<07:22,  1.29it/s]\u001b[A\n","Iteration:  69% 1279/1851 [16:29<07:22,  1.29it/s]\u001b[A\n","Iteration:  69% 1280/1851 [16:30<07:21,  1.29it/s]\u001b[A\n","Iteration:  69% 1281/1851 [16:31<07:21,  1.29it/s]\u001b[A\n","Iteration:  69% 1282/1851 [16:32<07:19,  1.30it/s]\u001b[A\n","Iteration:  69% 1283/1851 [16:32<07:18,  1.30it/s]\u001b[A\n","Iteration:  69% 1284/1851 [16:33<07:17,  1.30it/s]\u001b[A\n","Iteration:  69% 1285/1851 [16:34<07:16,  1.30it/s]\u001b[A\n","Iteration:  69% 1286/1851 [16:35<07:14,  1.30it/s]\u001b[A\n","Iteration:  70% 1287/1851 [16:35<07:14,  1.30it/s]\u001b[A\n","Iteration:  70% 1288/1851 [16:36<07:14,  1.30it/s]\u001b[A\n","Iteration:  70% 1289/1851 [16:37<07:14,  1.29it/s]\u001b[A\n","Iteration:  70% 1290/1851 [16:38<07:13,  1.29it/s]\u001b[A\n","Iteration:  70% 1291/1851 [16:39<07:12,  1.29it/s]\u001b[A\n","Iteration:  70% 1292/1851 [16:39<07:11,  1.29it/s]\u001b[A\n","Iteration:  70% 1293/1851 [16:40<07:11,  1.29it/s]\u001b[A\n","Iteration:  70% 1294/1851 [16:41<07:10,  1.29it/s]\u001b[A\n","Iteration:  70% 1295/1851 [16:42<07:10,  1.29it/s]\u001b[A\n","Iteration:  70% 1296/1851 [16:42<07:09,  1.29it/s]\u001b[A\n","Iteration:  70% 1297/1851 [16:43<07:08,  1.29it/s]\u001b[A\n","Iteration:  70% 1298/1851 [16:44<07:07,  1.29it/s]\u001b[A\n","Iteration:  70% 1299/1851 [16:45<07:07,  1.29it/s]\u001b[A\n","Iteration:  70% 1300/1851 [16:46<07:05,  1.29it/s]\u001b[A\n","Iteration:  70% 1301/1851 [16:46<07:04,  1.30it/s]\u001b[A\n","Iteration:  70% 1302/1851 [16:47<07:03,  1.30it/s]\u001b[A\n","Iteration:  70% 1303/1851 [16:48<07:02,  1.30it/s]\u001b[A\n","Iteration:  70% 1304/1851 [16:49<07:01,  1.30it/s]\u001b[A\n","Iteration:  71% 1305/1851 [16:49<07:00,  1.30it/s]\u001b[A\n","Iteration:  71% 1306/1851 [16:50<06:59,  1.30it/s]\u001b[A\n","Iteration:  71% 1307/1851 [16:51<06:58,  1.30it/s]\u001b[A\n","Iteration:  71% 1308/1851 [16:52<06:58,  1.30it/s]\u001b[A\n","Iteration:  71% 1309/1851 [16:52<06:56,  1.30it/s]\u001b[A\n","Iteration:  71% 1310/1851 [16:53<06:56,  1.30it/s]\u001b[A\n","Iteration:  71% 1311/1851 [16:54<06:56,  1.30it/s]\u001b[A\n","Iteration:  71% 1312/1851 [16:55<06:55,  1.30it/s]\u001b[A\n","Iteration:  71% 1313/1851 [16:56<06:55,  1.30it/s]\u001b[A\n","Iteration:  71% 1314/1851 [16:56<06:54,  1.29it/s]\u001b[A\n","Iteration:  71% 1315/1851 [16:57<06:54,  1.29it/s]\u001b[A\n","Iteration:  71% 1316/1851 [16:58<06:52,  1.30it/s]\u001b[A\n","Iteration:  71% 1317/1851 [16:59<06:52,  1.29it/s]\u001b[A\n","Iteration:  71% 1318/1851 [16:59<06:52,  1.29it/s]\u001b[A\n","Iteration:  71% 1319/1851 [17:00<06:50,  1.30it/s]\u001b[A\n","Iteration:  71% 1320/1851 [17:01<06:49,  1.30it/s]\u001b[A\n","Iteration:  71% 1321/1851 [17:02<06:49,  1.30it/s]\u001b[A\n","Iteration:  71% 1322/1851 [17:02<06:48,  1.30it/s]\u001b[A\n","Iteration:  71% 1323/1851 [17:03<06:46,  1.30it/s]\u001b[A\n","Iteration:  72% 1324/1851 [17:04<06:46,  1.30it/s]\u001b[A\n","Iteration:  72% 1325/1851 [17:05<06:45,  1.30it/s]\u001b[A\n","Iteration:  72% 1326/1851 [17:06<06:45,  1.30it/s]\u001b[A\n","Iteration:  72% 1327/1851 [17:06<06:43,  1.30it/s]\u001b[A\n","Iteration:  72% 1328/1851 [17:07<06:43,  1.30it/s]\u001b[A\n","Iteration:  72% 1329/1851 [17:08<06:42,  1.30it/s]\u001b[A\n","Iteration:  72% 1330/1851 [17:09<06:41,  1.30it/s]\u001b[A\n","Iteration:  72% 1331/1851 [17:09<06:40,  1.30it/s]\u001b[A\n","Iteration:  72% 1332/1851 [17:10<06:40,  1.30it/s]\u001b[A\n","Iteration:  72% 1333/1851 [17:11<06:40,  1.29it/s]\u001b[A\n","Iteration:  72% 1334/1851 [17:12<06:40,  1.29it/s]\u001b[A\n","Iteration:  72% 1335/1851 [17:13<06:39,  1.29it/s]\u001b[A\n","Iteration:  72% 1336/1851 [17:13<06:38,  1.29it/s]\u001b[A\n","Iteration:  72% 1337/1851 [17:14<06:38,  1.29it/s]\u001b[A\n","Iteration:  72% 1338/1851 [17:15<06:36,  1.29it/s]\u001b[A\n","Iteration:  72% 1339/1851 [17:16<06:35,  1.29it/s]\u001b[A\n","Iteration:  72% 1340/1851 [17:16<06:34,  1.30it/s]\u001b[A\n","Iteration:  72% 1341/1851 [17:17<06:33,  1.30it/s]\u001b[A\n","Iteration:  73% 1342/1851 [17:18<06:33,  1.30it/s]\u001b[A\n","Iteration:  73% 1343/1851 [17:19<06:32,  1.29it/s]\u001b[A\n","Iteration:  73% 1344/1851 [17:19<06:32,  1.29it/s]\u001b[A\n","Iteration:  73% 1345/1851 [17:20<06:31,  1.29it/s]\u001b[A\n","Iteration:  73% 1346/1851 [17:21<06:31,  1.29it/s]\u001b[A\n","Iteration:  73% 1347/1851 [17:22<06:30,  1.29it/s]\u001b[A\n","Iteration:  73% 1348/1851 [17:23<06:29,  1.29it/s]\u001b[A\n","Iteration:  73% 1349/1851 [17:23<06:28,  1.29it/s]\u001b[A\n","Iteration:  73% 1350/1851 [17:24<06:26,  1.29it/s]\u001b[A\n","Iteration:  73% 1351/1851 [17:25<06:25,  1.30it/s]\u001b[A\n","Iteration:  73% 1352/1851 [17:26<06:24,  1.30it/s]\u001b[A\n","Iteration:  73% 1353/1851 [17:26<06:24,  1.30it/s]\u001b[A\n","Iteration:  73% 1354/1851 [17:27<06:22,  1.30it/s]\u001b[A\n","Iteration:  73% 1355/1851 [17:28<06:21,  1.30it/s]\u001b[A\n","Iteration:  73% 1356/1851 [17:29<06:21,  1.30it/s]\u001b[A\n","Iteration:  73% 1357/1851 [17:30<06:20,  1.30it/s]\u001b[A\n","Iteration:  73% 1358/1851 [17:30<06:20,  1.30it/s]\u001b[A\n","Iteration:  73% 1359/1851 [17:31<06:19,  1.30it/s]\u001b[A\n","Iteration:  73% 1360/1851 [17:32<06:18,  1.30it/s]\u001b[A\n","Iteration:  74% 1361/1851 [17:33<06:18,  1.30it/s]\u001b[A\n","Iteration:  74% 1362/1851 [17:33<06:17,  1.29it/s]\u001b[A\n","Iteration:  74% 1363/1851 [17:34<06:17,  1.29it/s]\u001b[A\n","Iteration:  74% 1364/1851 [17:35<06:16,  1.29it/s]\u001b[A\n","Iteration:  74% 1365/1851 [17:36<06:15,  1.29it/s]\u001b[A\n","Iteration:  74% 1366/1851 [17:36<06:15,  1.29it/s]\u001b[A\n","Iteration:  74% 1367/1851 [17:37<06:14,  1.29it/s]\u001b[A\n","Iteration:  74% 1368/1851 [17:38<06:13,  1.29it/s]\u001b[A\n","Iteration:  74% 1369/1851 [17:39<06:13,  1.29it/s]\u001b[A\n","Iteration:  74% 1370/1851 [17:40<06:12,  1.29it/s]\u001b[A\n","Iteration:  74% 1371/1851 [17:40<06:11,  1.29it/s]\u001b[A\n","Iteration:  74% 1372/1851 [17:41<06:09,  1.29it/s]\u001b[A\n","Iteration:  74% 1373/1851 [17:42<06:08,  1.30it/s]\u001b[A\n","Iteration:  74% 1374/1851 [17:43<06:08,  1.30it/s]\u001b[A\n","Iteration:  74% 1375/1851 [17:43<06:07,  1.30it/s]\u001b[A\n","Iteration:  74% 1376/1851 [17:44<06:06,  1.30it/s]\u001b[A\n","Iteration:  74% 1377/1851 [17:45<06:05,  1.30it/s]\u001b[A\n","Iteration:  74% 1378/1851 [17:46<06:04,  1.30it/s]\u001b[A\n","Iteration:  75% 1379/1851 [17:46<06:04,  1.30it/s]\u001b[A\n","Iteration:  75% 1380/1851 [17:47<06:03,  1.30it/s]\u001b[A\n","Iteration:  75% 1381/1851 [17:48<06:02,  1.30it/s]\u001b[A\n","Iteration:  75% 1382/1851 [17:49<06:02,  1.29it/s]\u001b[A\n","Iteration:  75% 1383/1851 [17:50<06:01,  1.29it/s]\u001b[A\n","Iteration:  75% 1384/1851 [17:50<06:00,  1.29it/s]\u001b[A\n","Iteration:  75% 1385/1851 [17:51<06:00,  1.29it/s]\u001b[A\n","Iteration:  75% 1386/1851 [17:52<05:59,  1.29it/s]\u001b[A\n","Iteration:  75% 1387/1851 [17:53<05:58,  1.29it/s]\u001b[A\n","Iteration:  75% 1388/1851 [17:53<05:58,  1.29it/s]\u001b[A\n","Iteration:  75% 1389/1851 [17:54<05:57,  1.29it/s]\u001b[A\n","Iteration:  75% 1390/1851 [17:55<05:56,  1.29it/s]\u001b[A\n","Iteration:  75% 1391/1851 [17:56<05:55,  1.29it/s]\u001b[A\n","Iteration:  75% 1392/1851 [17:57<05:54,  1.29it/s]\u001b[A\n","Iteration:  75% 1393/1851 [17:57<05:53,  1.30it/s]\u001b[A\n","Iteration:  75% 1394/1851 [17:58<05:53,  1.29it/s]\u001b[A\n","Iteration:  75% 1395/1851 [17:59<05:52,  1.29it/s]\u001b[A\n","Iteration:  75% 1396/1851 [18:00<05:52,  1.29it/s]\u001b[A\n","Iteration:  75% 1397/1851 [18:00<05:51,  1.29it/s]\u001b[A\n","Iteration:  76% 1398/1851 [18:01<05:50,  1.29it/s]\u001b[A\n","Iteration:  76% 1399/1851 [18:02<05:49,  1.29it/s]\u001b[A\n","Iteration:  76% 1400/1851 [18:03<05:48,  1.29it/s]\u001b[A\n","Iteration:  76% 1401/1851 [18:04<05:48,  1.29it/s]\u001b[A\n","Iteration:  76% 1402/1851 [18:04<05:47,  1.29it/s]\u001b[A\n","Iteration:  76% 1403/1851 [18:05<05:46,  1.29it/s]\u001b[A\n","Iteration:  76% 1404/1851 [18:06<05:45,  1.29it/s]\u001b[A\n","Iteration:  76% 1405/1851 [18:07<05:44,  1.30it/s]\u001b[A\n","Iteration:  76% 1406/1851 [18:07<05:43,  1.30it/s]\u001b[A\n","Iteration:  76% 1407/1851 [18:08<05:42,  1.29it/s]\u001b[A\n","Iteration:  76% 1408/1851 [18:09<05:42,  1.29it/s]\u001b[A\n","Iteration:  76% 1409/1851 [18:10<05:41,  1.29it/s]\u001b[A\n","Iteration:  76% 1410/1851 [18:10<05:41,  1.29it/s]\u001b[A\n","Iteration:  76% 1411/1851 [18:11<05:40,  1.29it/s]\u001b[A\n","Iteration:  76% 1412/1851 [18:12<05:39,  1.29it/s]\u001b[A\n","Iteration:  76% 1413/1851 [18:13<05:38,  1.29it/s]\u001b[A\n","Iteration:  76% 1414/1851 [18:14<05:37,  1.29it/s]\u001b[A\n","Iteration:  76% 1415/1851 [18:14<05:36,  1.30it/s]\u001b[A\n","Iteration:  76% 1416/1851 [18:15<05:35,  1.30it/s]\u001b[A\n","Iteration:  77% 1417/1851 [18:16<05:34,  1.30it/s]\u001b[A\n","Iteration:  77% 1418/1851 [18:17<05:33,  1.30it/s]\u001b[A\n","Iteration:  77% 1419/1851 [18:17<05:33,  1.29it/s]\u001b[A\n","Iteration:  77% 1420/1851 [18:18<05:33,  1.29it/s]\u001b[A\n","Iteration:  77% 1421/1851 [18:19<05:32,  1.29it/s]\u001b[A\n","Iteration:  77% 1422/1851 [18:20<05:31,  1.29it/s]\u001b[A\n","Iteration:  77% 1423/1851 [18:21<05:31,  1.29it/s]\u001b[A\n","Iteration:  77% 1424/1851 [18:21<05:30,  1.29it/s]\u001b[A\n","Iteration:  77% 1425/1851 [18:22<05:29,  1.29it/s]\u001b[A\n","Iteration:  77% 1426/1851 [18:23<05:28,  1.29it/s]\u001b[A\n","Iteration:  77% 1427/1851 [18:24<05:28,  1.29it/s]\u001b[A\n","Iteration:  77% 1428/1851 [18:24<05:27,  1.29it/s]\u001b[A\n","Iteration:  77% 1429/1851 [18:25<05:27,  1.29it/s]\u001b[A\n","Iteration:  77% 1430/1851 [18:26<05:26,  1.29it/s]\u001b[A\n","Iteration:  77% 1431/1851 [18:27<05:25,  1.29it/s]\u001b[A\n","Iteration:  77% 1432/1851 [18:27<05:23,  1.29it/s]\u001b[A\n","Iteration:  77% 1433/1851 [18:28<05:23,  1.29it/s]\u001b[A\n","Iteration:  77% 1434/1851 [18:29<05:21,  1.30it/s]\u001b[A\n","Iteration:  78% 1435/1851 [18:30<05:21,  1.29it/s]\u001b[A\n","Iteration:  78% 1436/1851 [18:31<05:21,  1.29it/s]\u001b[A\n","Iteration:  78% 1437/1851 [18:31<05:20,  1.29it/s]\u001b[A\n","Iteration:  78% 1438/1851 [18:32<05:19,  1.29it/s]\u001b[A\n","Iteration:  78% 1439/1851 [18:33<05:18,  1.29it/s]\u001b[A\n","Iteration:  78% 1440/1851 [18:34<05:17,  1.29it/s]\u001b[A\n","Iteration:  78% 1441/1851 [18:34<05:17,  1.29it/s]\u001b[A\n","Iteration:  78% 1442/1851 [18:35<05:16,  1.29it/s]\u001b[A\n","Iteration:  78% 1443/1851 [18:36<05:16,  1.29it/s]\u001b[A\n","Iteration:  78% 1444/1851 [18:37<05:15,  1.29it/s]\u001b[A\n","Iteration:  78% 1445/1851 [18:38<05:14,  1.29it/s]\u001b[A\n","Iteration:  78% 1446/1851 [18:38<05:13,  1.29it/s]\u001b[A\n","Iteration:  78% 1447/1851 [18:39<05:13,  1.29it/s]\u001b[A\n","Iteration:  78% 1448/1851 [18:40<05:11,  1.29it/s]\u001b[A\n","Iteration:  78% 1449/1851 [18:41<05:11,  1.29it/s]\u001b[A\n","Iteration:  78% 1450/1851 [18:41<05:11,  1.29it/s]\u001b[A\n","Iteration:  78% 1451/1851 [18:42<05:10,  1.29it/s]\u001b[A\n","Iteration:  78% 1452/1851 [18:43<05:08,  1.29it/s]\u001b[A\n","Iteration:  78% 1453/1851 [18:44<05:07,  1.29it/s]\u001b[A\n","Iteration:  79% 1454/1851 [18:45<05:06,  1.29it/s]\u001b[A\n","Iteration:  79% 1455/1851 [18:45<05:05,  1.30it/s]\u001b[A\n","Iteration:  79% 1456/1851 [18:46<05:04,  1.30it/s]\u001b[A\n","Iteration:  79% 1457/1851 [18:47<05:04,  1.30it/s]\u001b[A\n","Iteration:  79% 1458/1851 [18:48<05:02,  1.30it/s]\u001b[A\n","Iteration:  79% 1459/1851 [18:48<05:02,  1.30it/s]\u001b[A\n","Iteration:  79% 1460/1851 [18:49<05:01,  1.30it/s]\u001b[A\n","Iteration:  79% 1461/1851 [18:50<05:01,  1.29it/s]\u001b[A\n","Iteration:  79% 1462/1851 [18:51<05:00,  1.29it/s]\u001b[A\n","Iteration:  79% 1463/1851 [18:51<05:00,  1.29it/s]\u001b[A\n","Iteration:  79% 1464/1851 [18:52<04:58,  1.29it/s]\u001b[A\n","Iteration:  79% 1465/1851 [18:53<04:58,  1.29it/s]\u001b[A\n","Iteration:  79% 1466/1851 [18:54<04:58,  1.29it/s]\u001b[A\n","Iteration:  79% 1467/1851 [18:55<04:57,  1.29it/s]\u001b[A\n","Iteration:  79% 1468/1851 [18:55<04:56,  1.29it/s]\u001b[A\n","Iteration:  79% 1469/1851 [18:56<04:56,  1.29it/s]\u001b[A\n","Iteration:  79% 1470/1851 [18:57<04:54,  1.29it/s]\u001b[A\n","Iteration:  79% 1471/1851 [18:58<04:53,  1.29it/s]\u001b[A\n","Iteration:  80% 1472/1851 [18:58<04:53,  1.29it/s]\u001b[A\n","Iteration:  80% 1473/1851 [18:59<04:52,  1.29it/s]\u001b[A\n","Iteration:  80% 1474/1851 [19:00<04:51,  1.29it/s]\u001b[A\n","Iteration:  80% 1475/1851 [19:01<04:51,  1.29it/s]\u001b[A\n","Iteration:  80% 1476/1851 [19:02<04:50,  1.29it/s]\u001b[A\n","Iteration:  80% 1477/1851 [19:02<04:49,  1.29it/s]\u001b[A\n","Iteration:  80% 1478/1851 [19:03<04:49,  1.29it/s]\u001b[A\n","Iteration:  80% 1479/1851 [19:04<04:48,  1.29it/s]\u001b[A\n","Iteration:  80% 1480/1851 [19:05<04:46,  1.29it/s]\u001b[A\n","Iteration:  80% 1481/1851 [19:05<04:46,  1.29it/s]\u001b[A\n","Iteration:  80% 1482/1851 [19:06<04:44,  1.29it/s]\u001b[A\n","Iteration:  80% 1483/1851 [19:07<04:44,  1.30it/s]\u001b[A\n","Iteration:  80% 1484/1851 [19:08<04:43,  1.29it/s]\u001b[A\n","Iteration:  80% 1485/1851 [19:08<04:42,  1.29it/s]\u001b[A\n","Iteration:  80% 1486/1851 [19:09<04:42,  1.29it/s]\u001b[A\n","Iteration:  80% 1487/1851 [19:10<04:41,  1.29it/s]\u001b[A\n","Iteration:  80% 1488/1851 [19:11<04:40,  1.29it/s]\u001b[A\n","Iteration:  80% 1489/1851 [19:12<04:40,  1.29it/s]\u001b[A\n","Iteration:  80% 1490/1851 [19:12<04:39,  1.29it/s]\u001b[A\n","Iteration:  81% 1491/1851 [19:13<04:38,  1.29it/s]\u001b[A\n","Iteration:  81% 1492/1851 [19:14<04:37,  1.29it/s]\u001b[A\n","Iteration:  81% 1493/1851 [19:15<04:36,  1.30it/s]\u001b[A\n","Iteration:  81% 1494/1851 [19:15<04:35,  1.30it/s]\u001b[A\n","Iteration:  81% 1495/1851 [19:16<04:34,  1.30it/s]\u001b[A\n","Iteration:  81% 1496/1851 [19:17<04:33,  1.30it/s]\u001b[A\n","Iteration:  81% 1497/1851 [19:18<04:33,  1.30it/s]\u001b[A\n","Iteration:  81% 1498/1851 [19:19<04:32,  1.29it/s]\u001b[A\n","Iteration:  81% 1499/1851 [19:19<04:32,  1.29it/s]\u001b[A\n","Iteration:  81% 1500/1851 [19:20<04:31,  1.29it/s]\u001b[A\n","Iteration:  81% 1501/1851 [19:21<04:30,  1.29it/s]\u001b[A\n","Iteration:  81% 1502/1851 [19:22<04:29,  1.29it/s]\u001b[A\n","Iteration:  81% 1503/1851 [19:22<04:29,  1.29it/s]\u001b[A\n","Iteration:  81% 1504/1851 [19:23<04:28,  1.29it/s]\u001b[A\n","Iteration:  81% 1505/1851 [19:24<04:27,  1.29it/s]\u001b[A\n","Iteration:  81% 1506/1851 [19:25<04:26,  1.29it/s]\u001b[A\n","Iteration:  81% 1507/1851 [19:25<04:25,  1.29it/s]\u001b[A\n","Iteration:  81% 1508/1851 [19:26<04:25,  1.29it/s]\u001b[A\n","Iteration:  82% 1509/1851 [19:27<04:24,  1.29it/s]\u001b[A\n","Iteration:  82% 1510/1851 [19:28<04:23,  1.29it/s]\u001b[A\n","Iteration:  82% 1511/1851 [19:29<04:22,  1.29it/s]\u001b[A\n","Iteration:  82% 1512/1851 [19:29<04:22,  1.29it/s]\u001b[A\n","Iteration:  82% 1513/1851 [19:30<04:21,  1.29it/s]\u001b[A\n","Iteration:  82% 1514/1851 [19:31<04:20,  1.29it/s]\u001b[A\n","Iteration:  82% 1515/1851 [19:32<04:20,  1.29it/s]\u001b[A\n","Iteration:  82% 1516/1851 [19:32<04:19,  1.29it/s]\u001b[A\n","Iteration:  82% 1517/1851 [19:33<04:17,  1.30it/s]\u001b[A\n","Iteration:  82% 1518/1851 [19:34<04:17,  1.29it/s]\u001b[A\n","Iteration:  82% 1519/1851 [19:35<04:16,  1.29it/s]\u001b[A\n","Iteration:  82% 1520/1851 [19:36<04:15,  1.30it/s]\u001b[A\n","Iteration:  82% 1521/1851 [19:36<04:14,  1.30it/s]\u001b[A\n","Iteration:  82% 1522/1851 [19:37<04:13,  1.30it/s]\u001b[A\n","Iteration:  82% 1523/1851 [19:38<04:12,  1.30it/s]\u001b[A\n","Iteration:  82% 1524/1851 [19:39<04:13,  1.29it/s]\u001b[A\n","Iteration:  82% 1525/1851 [19:39<04:12,  1.29it/s]\u001b[A\n","Iteration:  82% 1526/1851 [19:40<04:11,  1.29it/s]\u001b[A\n","Iteration:  82% 1527/1851 [19:41<04:10,  1.29it/s]\u001b[A\n","Iteration:  83% 1528/1851 [19:42<04:09,  1.29it/s]\u001b[A\n","Iteration:  83% 1529/1851 [19:42<04:08,  1.29it/s]\u001b[A\n","Iteration:  83% 1530/1851 [19:43<04:08,  1.29it/s]\u001b[A\n","Iteration:  83% 1531/1851 [19:44<04:07,  1.29it/s]\u001b[A\n","Iteration:  83% 1532/1851 [19:45<04:07,  1.29it/s]\u001b[A\n","Iteration:  83% 1533/1851 [19:46<04:05,  1.29it/s]\u001b[A\n","Iteration:  83% 1534/1851 [19:46<04:05,  1.29it/s]\u001b[A\n","Iteration:  83% 1535/1851 [19:47<04:03,  1.30it/s]\u001b[A\n","Iteration:  83% 1536/1851 [19:48<04:02,  1.30it/s]\u001b[A\n","Iteration:  83% 1537/1851 [19:49<04:02,  1.29it/s]\u001b[A\n","Iteration:  83% 1538/1851 [19:49<04:02,  1.29it/s]\u001b[A\n","Iteration:  83% 1539/1851 [19:50<04:01,  1.29it/s]\u001b[A\n","Iteration:  83% 1540/1851 [19:51<04:00,  1.29it/s]\u001b[A\n","Iteration:  83% 1541/1851 [19:52<03:59,  1.29it/s]\u001b[A\n","Iteration:  83% 1542/1851 [19:53<03:58,  1.30it/s]\u001b[A\n","Iteration:  83% 1543/1851 [19:53<03:57,  1.30it/s]\u001b[A\n","Iteration:  83% 1544/1851 [19:54<03:56,  1.30it/s]\u001b[A\n","Iteration:  83% 1545/1851 [19:55<03:56,  1.30it/s]\u001b[A\n","Iteration:  84% 1546/1851 [19:56<03:55,  1.30it/s]\u001b[A\n","Iteration:  84% 1547/1851 [19:56<03:54,  1.30it/s]\u001b[A\n","Iteration:  84% 1548/1851 [19:57<03:54,  1.29it/s]\u001b[A\n","Iteration:  84% 1549/1851 [19:58<03:53,  1.29it/s]\u001b[A\n","Iteration:  84% 1550/1851 [19:59<03:52,  1.29it/s]\u001b[A\n","Iteration:  84% 1551/1851 [19:59<03:51,  1.29it/s]\u001b[A\n","Iteration:  84% 1552/1851 [20:00<03:50,  1.30it/s]\u001b[A\n","Iteration:  84% 1553/1851 [20:01<03:49,  1.30it/s]\u001b[A\n","Iteration:  84% 1554/1851 [20:02<03:48,  1.30it/s]\u001b[A\n","Iteration:  84% 1555/1851 [20:03<03:48,  1.30it/s]\u001b[A\n","Iteration:  84% 1556/1851 [20:03<03:47,  1.30it/s]\u001b[A\n","Iteration:  84% 1557/1851 [20:04<03:47,  1.29it/s]\u001b[A\n","Iteration:  84% 1558/1851 [20:05<03:46,  1.29it/s]\u001b[A\n","Iteration:  84% 1559/1851 [20:06<03:45,  1.29it/s]\u001b[A\n","Iteration:  84% 1560/1851 [20:06<03:45,  1.29it/s]\u001b[A\n","Iteration:  84% 1561/1851 [20:07<03:44,  1.29it/s]\u001b[A\n","Iteration:  84% 1562/1851 [20:08<03:43,  1.30it/s]\u001b[A\n","Iteration:  84% 1563/1851 [20:09<03:42,  1.30it/s]\u001b[A\n","Iteration:  84% 1564/1851 [20:10<03:41,  1.30it/s]\u001b[A\n","Iteration:  85% 1565/1851 [20:10<03:40,  1.29it/s]\u001b[A\n","Iteration:  85% 1566/1851 [20:11<03:40,  1.29it/s]\u001b[A\n","Iteration:  85% 1567/1851 [20:12<03:39,  1.29it/s]\u001b[A\n","Iteration:  85% 1568/1851 [20:13<03:38,  1.29it/s]\u001b[A\n","Iteration:  85% 1569/1851 [20:13<03:37,  1.29it/s]\u001b[A\n","Iteration:  85% 1570/1851 [20:14<03:36,  1.30it/s]\u001b[A\n","Iteration:  85% 1571/1851 [20:15<03:36,  1.30it/s]\u001b[A\n","Iteration:  85% 1572/1851 [20:16<03:35,  1.30it/s]\u001b[A\n","Iteration:  85% 1573/1851 [20:16<03:34,  1.30it/s]\u001b[A\n","Iteration:  85% 1574/1851 [20:17<03:33,  1.30it/s]\u001b[A\n","Iteration:  85% 1575/1851 [20:18<03:32,  1.30it/s]\u001b[A\n","Iteration:  85% 1576/1851 [20:19<03:32,  1.30it/s]\u001b[A\n","Iteration:  85% 1577/1851 [20:20<03:31,  1.30it/s]\u001b[A\n","Iteration:  85% 1578/1851 [20:20<03:30,  1.30it/s]\u001b[A\n","Iteration:  85% 1579/1851 [20:21<03:29,  1.30it/s]\u001b[A\n","Iteration:  85% 1580/1851 [20:22<03:28,  1.30it/s]\u001b[A\n","Iteration:  85% 1581/1851 [20:23<03:27,  1.30it/s]\u001b[A\n","Iteration:  85% 1582/1851 [20:23<03:26,  1.30it/s]\u001b[A\n","Iteration:  86% 1583/1851 [20:24<03:26,  1.30it/s]\u001b[A\n","Iteration:  86% 1584/1851 [20:25<03:26,  1.30it/s]\u001b[A\n","Iteration:  86% 1585/1851 [20:26<03:25,  1.29it/s]\u001b[A\n","Iteration:  86% 1586/1851 [20:27<03:25,  1.29it/s]\u001b[A\n","Iteration:  86% 1587/1851 [20:27<03:24,  1.29it/s]\u001b[A\n","Iteration:  86% 1588/1851 [20:28<03:23,  1.29it/s]\u001b[A\n","Iteration:  86% 1589/1851 [20:29<03:23,  1.29it/s]\u001b[A\n","Iteration:  86% 1590/1851 [20:30<03:22,  1.29it/s]\u001b[A\n","Iteration:  86% 1591/1851 [20:30<03:21,  1.29it/s]\u001b[A\n","Iteration:  86% 1592/1851 [20:31<03:20,  1.29it/s]\u001b[A\n","Iteration:  86% 1593/1851 [20:32<03:19,  1.29it/s]\u001b[A\n","Iteration:  86% 1594/1851 [20:33<03:18,  1.29it/s]\u001b[A\n","Iteration:  86% 1595/1851 [20:33<03:17,  1.30it/s]\u001b[A\n","Iteration:  86% 1596/1851 [20:34<03:16,  1.30it/s]\u001b[A\n","Iteration:  86% 1597/1851 [20:35<03:16,  1.30it/s]\u001b[A\n","Iteration:  86% 1598/1851 [20:36<03:15,  1.29it/s]\u001b[A\n","Iteration:  86% 1599/1851 [20:37<03:14,  1.29it/s]\u001b[A\n","Iteration:  86% 1600/1851 [20:37<03:14,  1.29it/s]\u001b[A\n","Iteration:  86% 1601/1851 [20:38<03:13,  1.29it/s]\u001b[A\n","Iteration:  87% 1602/1851 [20:39<03:12,  1.29it/s]\u001b[A\n","Iteration:  87% 1603/1851 [20:40<03:11,  1.29it/s]\u001b[A\n","Iteration:  87% 1604/1851 [20:40<03:10,  1.29it/s]\u001b[A\n","Iteration:  87% 1605/1851 [20:41<03:10,  1.29it/s]\u001b[A\n","Iteration:  87% 1606/1851 [20:42<03:09,  1.29it/s]\u001b[A\n","Iteration:  87% 1607/1851 [20:43<03:08,  1.29it/s]\u001b[A\n","Iteration:  87% 1608/1851 [20:44<03:07,  1.29it/s]\u001b[A\n","Iteration:  87% 1609/1851 [20:44<03:07,  1.29it/s]\u001b[A\n","Iteration:  87% 1610/1851 [20:45<03:06,  1.29it/s]\u001b[A\n","Iteration:  87% 1611/1851 [20:46<03:05,  1.29it/s]\u001b[A\n","Iteration:  87% 1612/1851 [20:47<03:04,  1.29it/s]\u001b[A\n","Iteration:  87% 1613/1851 [20:47<03:03,  1.30it/s]\u001b[A\n","Iteration:  87% 1614/1851 [20:48<03:02,  1.30it/s]\u001b[A\n","Iteration:  87% 1615/1851 [20:49<03:02,  1.30it/s]\u001b[A\n","Iteration:  87% 1616/1851 [20:50<03:00,  1.30it/s]\u001b[A\n","Iteration:  87% 1617/1851 [20:50<03:00,  1.30it/s]\u001b[A\n","Iteration:  87% 1618/1851 [20:51<02:59,  1.30it/s]\u001b[A\n","Iteration:  87% 1619/1851 [20:52<02:58,  1.30it/s]\u001b[A\n","Iteration:  88% 1620/1851 [20:53<02:57,  1.30it/s]\u001b[A\n","Iteration:  88% 1621/1851 [20:54<02:57,  1.30it/s]\u001b[A\n","Iteration:  88% 1622/1851 [20:54<02:56,  1.30it/s]\u001b[A\n","Iteration:  88% 1623/1851 [20:55<02:55,  1.30it/s]\u001b[A\n","Iteration:  88% 1624/1851 [20:56<02:55,  1.30it/s]\u001b[A\n","Iteration:  88% 1625/1851 [20:57<02:54,  1.30it/s]\u001b[A\n","Iteration:  88% 1626/1851 [20:57<02:53,  1.29it/s]\u001b[A\n","Iteration:  88% 1627/1851 [20:58<02:53,  1.29it/s]\u001b[A\n","Iteration:  88% 1628/1851 [20:59<02:52,  1.29it/s]\u001b[A\n","Iteration:  88% 1629/1851 [21:00<02:51,  1.29it/s]\u001b[A\n","Iteration:  88% 1630/1851 [21:01<02:50,  1.29it/s]\u001b[A\n","Iteration:  88% 1631/1851 [21:01<02:50,  1.29it/s]\u001b[A\n","Iteration:  88% 1632/1851 [21:02<02:49,  1.29it/s]\u001b[A\n","Iteration:  88% 1633/1851 [21:03<02:48,  1.29it/s]\u001b[A\n","Iteration:  88% 1634/1851 [21:04<02:47,  1.29it/s]\u001b[A\n","Iteration:  88% 1635/1851 [21:04<02:47,  1.29it/s]\u001b[A\n","Iteration:  88% 1636/1851 [21:05<02:46,  1.29it/s]\u001b[A\n","Iteration:  88% 1637/1851 [21:06<02:45,  1.29it/s]\u001b[A\n","Iteration:  88% 1638/1851 [21:07<02:45,  1.29it/s]\u001b[A\n","Iteration:  89% 1639/1851 [21:07<02:44,  1.29it/s]\u001b[A\n","Iteration:  89% 1640/1851 [21:08<02:43,  1.29it/s]\u001b[A\n","Iteration:  89% 1641/1851 [21:09<02:42,  1.29it/s]\u001b[A\n","Iteration:  89% 1642/1851 [21:10<02:41,  1.29it/s]\u001b[A\n","Iteration:  89% 1643/1851 [21:11<02:40,  1.29it/s]\u001b[A\n","Iteration:  89% 1644/1851 [21:11<02:40,  1.29it/s]\u001b[A\n","Iteration:  89% 1645/1851 [21:12<02:39,  1.29it/s]\u001b[A\n","Iteration:  89% 1646/1851 [21:13<02:38,  1.29it/s]\u001b[A\n","Iteration:  89% 1647/1851 [21:14<02:37,  1.29it/s]\u001b[A\n","Iteration:  89% 1648/1851 [21:14<02:36,  1.30it/s]\u001b[A\n","Iteration:  89% 1649/1851 [21:15<02:35,  1.30it/s]\u001b[A\n","Iteration:  89% 1650/1851 [21:16<02:34,  1.30it/s]\u001b[A\n","Iteration:  89% 1651/1851 [21:17<02:34,  1.30it/s]\u001b[A\n","Iteration:  89% 1652/1851 [21:18<02:32,  1.30it/s]\u001b[A\n","Iteration:  89% 1653/1851 [21:18<02:32,  1.30it/s]\u001b[A\n","Iteration:  89% 1654/1851 [21:19<02:31,  1.30it/s]\u001b[A\n","Iteration:  89% 1655/1851 [21:20<02:31,  1.29it/s]\u001b[A\n","Iteration:  89% 1656/1851 [21:21<02:30,  1.29it/s]\u001b[A\n","Iteration:  90% 1657/1851 [21:21<02:30,  1.29it/s]\u001b[A\n","Iteration:  90% 1658/1851 [21:22<02:29,  1.29it/s]\u001b[A\n","Iteration:  90% 1659/1851 [21:23<02:28,  1.29it/s]\u001b[A\n","Iteration:  90% 1660/1851 [21:24<02:27,  1.29it/s]\u001b[A\n","Iteration:  90% 1661/1851 [21:24<02:26,  1.30it/s]\u001b[A\n","Iteration:  90% 1662/1851 [21:25<02:25,  1.30it/s]\u001b[A\n","Iteration:  90% 1663/1851 [21:26<02:24,  1.30it/s]\u001b[A\n","Iteration:  90% 1664/1851 [21:27<02:24,  1.30it/s]\u001b[A\n","Iteration:  90% 1665/1851 [21:28<02:23,  1.30it/s]\u001b[A\n","Iteration:  90% 1666/1851 [21:28<02:22,  1.30it/s]\u001b[A\n","Iteration:  90% 1667/1851 [21:29<02:21,  1.30it/s]\u001b[A\n","Iteration:  90% 1668/1851 [21:30<02:21,  1.30it/s]\u001b[A\n","Iteration:  90% 1669/1851 [21:31<02:20,  1.30it/s]\u001b[A\n","Iteration:  90% 1670/1851 [21:31<02:19,  1.30it/s]\u001b[A\n","Iteration:  90% 1671/1851 [21:32<02:18,  1.30it/s]\u001b[A\n","Iteration:  90% 1672/1851 [21:33<02:18,  1.29it/s]\u001b[A\n","Iteration:  90% 1673/1851 [21:34<02:17,  1.29it/s]\u001b[A\n","Iteration:  90% 1674/1851 [21:34<02:16,  1.29it/s]\u001b[A\n","Iteration:  90% 1675/1851 [21:35<02:16,  1.29it/s]\u001b[A\n","Iteration:  91% 1676/1851 [21:36<02:15,  1.29it/s]\u001b[A\n","Iteration:  91% 1677/1851 [21:37<02:14,  1.29it/s]\u001b[A\n","Iteration:  91% 1678/1851 [21:38<02:13,  1.29it/s]\u001b[A\n","Iteration:  91% 1679/1851 [21:38<02:12,  1.29it/s]\u001b[A\n","Iteration:  91% 1680/1851 [21:39<02:12,  1.29it/s]\u001b[A\n","Iteration:  91% 1681/1851 [21:40<02:11,  1.29it/s]\u001b[A\n","Iteration:  91% 1682/1851 [21:41<02:10,  1.29it/s]\u001b[A\n","Iteration:  91% 1683/1851 [21:41<02:10,  1.29it/s]\u001b[A\n","Iteration:  91% 1684/1851 [21:42<02:09,  1.29it/s]\u001b[A\n","Iteration:  91% 1685/1851 [21:43<02:08,  1.30it/s]\u001b[A\n","Iteration:  91% 1686/1851 [21:44<02:07,  1.30it/s]\u001b[A\n","Iteration:  91% 1687/1851 [21:45<02:06,  1.29it/s]\u001b[A\n","Iteration:  91% 1688/1851 [21:45<02:05,  1.30it/s]\u001b[A\n","Iteration:  91% 1689/1851 [21:46<02:04,  1.30it/s]\u001b[A\n","Iteration:  91% 1690/1851 [21:47<02:04,  1.29it/s]\u001b[A\n","Iteration:  91% 1691/1851 [21:48<02:03,  1.30it/s]\u001b[A\n","Iteration:  91% 1692/1851 [21:48<02:02,  1.30it/s]\u001b[A\n","Iteration:  91% 1693/1851 [21:49<02:01,  1.30it/s]\u001b[A\n","Iteration:  92% 1694/1851 [21:50<02:01,  1.30it/s]\u001b[A\n","Iteration:  92% 1695/1851 [21:51<02:00,  1.30it/s]\u001b[A\n","Iteration:  92% 1696/1851 [21:51<01:59,  1.30it/s]\u001b[A\n","Iteration:  92% 1697/1851 [21:52<01:58,  1.30it/s]\u001b[A\n","Iteration:  92% 1698/1851 [21:53<01:58,  1.29it/s]\u001b[A\n","Iteration:  92% 1699/1851 [21:54<01:57,  1.30it/s]\u001b[A\n","Iteration:  92% 1700/1851 [21:55<01:56,  1.30it/s]\u001b[A\n","Iteration:  92% 1701/1851 [21:55<01:55,  1.29it/s]\u001b[A\n","Iteration:  92% 1702/1851 [21:56<01:54,  1.30it/s]\u001b[A\n","Iteration:  92% 1703/1851 [21:57<01:54,  1.29it/s]\u001b[A\n","Iteration:  92% 1704/1851 [21:58<01:53,  1.29it/s]\u001b[A\n","Iteration:  92% 1705/1851 [21:58<01:52,  1.29it/s]\u001b[A\n","Iteration:  92% 1706/1851 [21:59<01:51,  1.30it/s]\u001b[A\n","Iteration:  92% 1707/1851 [22:00<01:51,  1.30it/s]\u001b[A\n","Iteration:  92% 1708/1851 [22:01<01:50,  1.30it/s]\u001b[A\n","Iteration:  92% 1709/1851 [22:02<01:49,  1.30it/s]\u001b[A\n","Iteration:  92% 1710/1851 [22:02<01:48,  1.29it/s]\u001b[A\n","Iteration:  92% 1711/1851 [22:03<01:48,  1.29it/s]\u001b[A\n","Iteration:  92% 1712/1851 [22:04<01:47,  1.29it/s]\u001b[A\n","Iteration:  93% 1713/1851 [22:05<01:46,  1.29it/s]\u001b[A\n","Iteration:  93% 1714/1851 [22:05<01:45,  1.29it/s]\u001b[A\n","Iteration:  93% 1715/1851 [22:06<01:45,  1.29it/s]\u001b[A\n","Iteration:  93% 1716/1851 [22:07<01:44,  1.29it/s]\u001b[A\n","Iteration:  93% 1717/1851 [22:08<01:43,  1.29it/s]\u001b[A\n","Iteration:  93% 1718/1851 [22:08<01:42,  1.29it/s]\u001b[A\n","Iteration:  93% 1719/1851 [22:09<01:42,  1.29it/s]\u001b[A\n","Iteration:  93% 1720/1851 [22:10<01:41,  1.29it/s]\u001b[A\n","Iteration:  93% 1721/1851 [22:11<01:40,  1.29it/s]\u001b[A\n","Iteration:  93% 1722/1851 [22:12<01:39,  1.29it/s]\u001b[A\n","Iteration:  93% 1723/1851 [22:12<01:39,  1.29it/s]\u001b[A\n","Iteration:  93% 1724/1851 [22:13<01:38,  1.29it/s]\u001b[A\n","Iteration:  93% 1725/1851 [22:14<01:37,  1.29it/s]\u001b[A\n","Iteration:  93% 1726/1851 [22:15<01:36,  1.29it/s]\u001b[A\n","Iteration:  93% 1727/1851 [22:15<01:35,  1.29it/s]\u001b[A\n","Iteration:  93% 1728/1851 [22:16<01:35,  1.29it/s]\u001b[A\n","Iteration:  93% 1729/1851 [22:17<01:34,  1.29it/s]\u001b[A\n","Iteration:  93% 1730/1851 [22:18<01:33,  1.29it/s]\u001b[A\n","Iteration:  94% 1731/1851 [22:19<01:32,  1.30it/s]\u001b[A\n","Iteration:  94% 1732/1851 [22:19<01:31,  1.29it/s]\u001b[A\n","Iteration:  94% 1733/1851 [22:20<01:31,  1.29it/s]\u001b[A\n","Iteration:  94% 1734/1851 [22:21<01:30,  1.29it/s]\u001b[A\n","Iteration:  94% 1735/1851 [22:22<01:29,  1.29it/s]\u001b[A\n","Iteration:  94% 1736/1851 [22:22<01:28,  1.30it/s]\u001b[A\n","Iteration:  94% 1737/1851 [22:23<01:28,  1.29it/s]\u001b[A\n","Iteration:  94% 1738/1851 [22:24<01:27,  1.29it/s]\u001b[A\n","Iteration:  94% 1739/1851 [22:25<01:26,  1.29it/s]\u001b[A\n","Iteration:  94% 1740/1851 [22:25<01:25,  1.29it/s]\u001b[A\n","Iteration:  94% 1741/1851 [22:26<01:25,  1.29it/s]\u001b[A\n","Iteration:  94% 1742/1851 [22:27<01:24,  1.29it/s]\u001b[A\n","Iteration:  94% 1743/1851 [22:28<01:23,  1.29it/s]\u001b[A\n","Iteration:  94% 1744/1851 [22:29<01:22,  1.30it/s]\u001b[A\n","Iteration:  94% 1745/1851 [22:29<01:21,  1.29it/s]\u001b[A\n","Iteration:  94% 1746/1851 [22:30<01:21,  1.29it/s]\u001b[A\n","Iteration:  94% 1747/1851 [22:31<01:20,  1.29it/s]\u001b[A\n","Iteration:  94% 1748/1851 [22:32<01:19,  1.29it/s]\u001b[A\n","Iteration:  94% 1749/1851 [22:32<01:18,  1.29it/s]\u001b[A\n","Iteration:  95% 1750/1851 [22:33<01:18,  1.29it/s]\u001b[A\n","Iteration:  95% 1751/1851 [22:34<01:17,  1.29it/s]\u001b[A\n","Iteration:  95% 1752/1851 [22:35<01:16,  1.29it/s]\u001b[A\n","Iteration:  95% 1753/1851 [22:36<01:15,  1.29it/s]\u001b[A\n","Iteration:  95% 1754/1851 [22:36<01:14,  1.29it/s]\u001b[A\n","Iteration:  95% 1755/1851 [22:37<01:14,  1.29it/s]\u001b[A\n","Iteration:  95% 1756/1851 [22:38<01:13,  1.29it/s]\u001b[A\n","Iteration:  95% 1757/1851 [22:39<01:12,  1.29it/s]\u001b[A\n","Iteration:  95% 1758/1851 [22:39<01:11,  1.30it/s]\u001b[A\n","Iteration:  95% 1759/1851 [22:40<01:10,  1.30it/s]\u001b[A\n","Iteration:  95% 1760/1851 [22:41<01:10,  1.30it/s]\u001b[A\n","Iteration:  95% 1761/1851 [22:42<01:09,  1.29it/s]\u001b[A\n","Iteration:  95% 1762/1851 [22:43<01:08,  1.29it/s]\u001b[A\n","Iteration:  95% 1763/1851 [22:43<01:08,  1.29it/s]\u001b[A\n","Iteration:  95% 1764/1851 [22:44<01:07,  1.29it/s]\u001b[A\n","Iteration:  95% 1765/1851 [22:45<01:06,  1.29it/s]\u001b[A\n","Iteration:  95% 1766/1851 [22:46<01:05,  1.29it/s]\u001b[A\n","Iteration:  95% 1767/1851 [22:46<01:05,  1.29it/s]\u001b[A\n","Iteration:  96% 1768/1851 [22:47<01:04,  1.29it/s]\u001b[A\n","Iteration:  96% 1769/1851 [22:48<01:03,  1.29it/s]\u001b[A\n","Iteration:  96% 1770/1851 [22:49<01:02,  1.29it/s]\u001b[A\n","Iteration:  96% 1771/1851 [22:49<01:01,  1.29it/s]\u001b[A\n","Iteration:  96% 1772/1851 [22:50<01:01,  1.29it/s]\u001b[A\n","Iteration:  96% 1773/1851 [22:51<01:00,  1.29it/s]\u001b[A\n","Iteration:  96% 1774/1851 [22:52<00:59,  1.30it/s]\u001b[A\n","Iteration:  96% 1775/1851 [22:53<00:58,  1.30it/s]\u001b[A\n","Iteration:  96% 1776/1851 [22:53<00:57,  1.30it/s]\u001b[A\n","Iteration:  96% 1777/1851 [22:54<00:56,  1.30it/s]\u001b[A\n","Iteration:  96% 1778/1851 [22:55<00:56,  1.30it/s]\u001b[A\n","Iteration:  96% 1779/1851 [22:56<00:55,  1.30it/s]\u001b[A\n","Iteration:  96% 1780/1851 [22:56<00:54,  1.29it/s]\u001b[A\n","Iteration:  96% 1781/1851 [22:57<00:54,  1.30it/s]\u001b[A\n","Iteration:  96% 1782/1851 [22:58<00:53,  1.29it/s]\u001b[A\n","Iteration:  96% 1783/1851 [22:59<00:52,  1.30it/s]\u001b[A\n","Iteration:  96% 1784/1851 [22:59<00:51,  1.30it/s]\u001b[A\n","Iteration:  96% 1785/1851 [23:00<00:50,  1.29it/s]\u001b[A\n","Iteration:  96% 1786/1851 [23:01<00:50,  1.29it/s]\u001b[A\n","Iteration:  97% 1787/1851 [23:02<00:49,  1.30it/s]\u001b[A\n","Iteration:  97% 1788/1851 [23:03<00:48,  1.30it/s]\u001b[A\n","Iteration:  97% 1789/1851 [23:03<00:47,  1.30it/s]\u001b[A\n","Iteration:  97% 1790/1851 [23:04<00:47,  1.30it/s]\u001b[A\n","Iteration:  97% 1791/1851 [23:05<00:46,  1.29it/s]\u001b[A\n","Iteration:  97% 1792/1851 [23:06<00:45,  1.29it/s]\u001b[A\n","Iteration:  97% 1793/1851 [23:06<00:44,  1.29it/s]\u001b[A\n","Iteration:  97% 1794/1851 [23:07<00:43,  1.30it/s]\u001b[A\n","Iteration:  97% 1795/1851 [23:08<00:43,  1.30it/s]\u001b[A\n","Iteration:  97% 1796/1851 [23:09<00:42,  1.30it/s]\u001b[A\n","Iteration:  97% 1797/1851 [23:10<00:41,  1.30it/s]\u001b[A\n","Iteration:  97% 1798/1851 [23:10<00:40,  1.30it/s]\u001b[A\n","Iteration:  97% 1799/1851 [23:11<00:40,  1.30it/s]\u001b[A\n","Iteration:  97% 1800/1851 [23:12<00:39,  1.30it/s]\u001b[A\n","Iteration:  97% 1801/1851 [23:13<00:38,  1.30it/s]\u001b[A\n","Iteration:  97% 1802/1851 [23:13<00:37,  1.30it/s]\u001b[A\n","Iteration:  97% 1803/1851 [23:14<00:37,  1.30it/s]\u001b[A\n","Iteration:  97% 1804/1851 [23:15<00:36,  1.29it/s]\u001b[A\n","Iteration:  98% 1805/1851 [23:16<00:35,  1.29it/s]\u001b[A\n","Iteration:  98% 1806/1851 [23:16<00:34,  1.29it/s]\u001b[A\n","Iteration:  98% 1807/1851 [23:17<00:34,  1.29it/s]\u001b[A\n","Iteration:  98% 1808/1851 [23:18<00:33,  1.29it/s]\u001b[A\n","Iteration:  98% 1809/1851 [23:19<00:32,  1.29it/s]\u001b[A\n","Iteration:  98% 1810/1851 [23:20<00:31,  1.29it/s]\u001b[A\n","Iteration:  98% 1811/1851 [23:20<00:30,  1.29it/s]\u001b[A\n","Iteration:  98% 1812/1851 [23:21<00:30,  1.29it/s]\u001b[A\n","Iteration:  98% 1813/1851 [23:22<00:29,  1.29it/s]\u001b[A\n","Iteration:  98% 1814/1851 [23:23<00:28,  1.29it/s]\u001b[A\n","Iteration:  98% 1815/1851 [23:23<00:27,  1.29it/s]\u001b[A\n","Iteration:  98% 1816/1851 [23:24<00:27,  1.30it/s]\u001b[A\n","Iteration:  98% 1817/1851 [23:25<00:26,  1.29it/s]\u001b[A\n","Iteration:  98% 1818/1851 [23:26<00:25,  1.30it/s]\u001b[A\n","Iteration:  98% 1819/1851 [23:27<00:24,  1.30it/s]\u001b[A\n","Iteration:  98% 1820/1851 [23:27<00:23,  1.29it/s]\u001b[A\n","Iteration:  98% 1821/1851 [23:28<00:23,  1.29it/s]\u001b[A\n","Iteration:  98% 1822/1851 [23:29<00:22,  1.29it/s]\u001b[A\n","Iteration:  98% 1823/1851 [23:30<00:21,  1.29it/s]\u001b[A\n","Iteration:  99% 1824/1851 [23:30<00:20,  1.29it/s]\u001b[A\n","Iteration:  99% 1825/1851 [23:31<00:20,  1.29it/s]\u001b[A\n","Iteration:  99% 1826/1851 [23:32<00:19,  1.29it/s]\u001b[A\n","Iteration:  99% 1827/1851 [23:33<00:18,  1.29it/s]\u001b[A\n","Iteration:  99% 1828/1851 [23:33<00:17,  1.29it/s]\u001b[A\n","Iteration:  99% 1829/1851 [23:34<00:17,  1.29it/s]\u001b[A\n","Iteration:  99% 1830/1851 [23:35<00:16,  1.29it/s]\u001b[A\n","Iteration:  99% 1831/1851 [23:36<00:15,  1.30it/s]\u001b[A\n","Iteration:  99% 1832/1851 [23:37<00:14,  1.30it/s]\u001b[A\n","Iteration:  99% 1833/1851 [23:37<00:13,  1.30it/s]\u001b[A\n","Iteration:  99% 1834/1851 [23:38<00:13,  1.30it/s]\u001b[A\n","Iteration:  99% 1835/1851 [23:39<00:12,  1.29it/s]\u001b[A\n","Iteration:  99% 1836/1851 [23:40<00:11,  1.29it/s]\u001b[A\n","Iteration:  99% 1837/1851 [23:40<00:10,  1.29it/s]\u001b[A\n","Iteration:  99% 1838/1851 [23:41<00:10,  1.29it/s]\u001b[A\n","Iteration:  99% 1839/1851 [23:42<00:09,  1.30it/s]\u001b[A\n","Iteration:  99% 1840/1851 [23:43<00:08,  1.30it/s]\u001b[A\n","Iteration:  99% 1841/1851 [23:44<00:07,  1.30it/s]\u001b[A\n","Iteration: 100% 1842/1851 [23:44<00:06,  1.30it/s]\u001b[A\n","Iteration: 100% 1843/1851 [23:45<00:06,  1.30it/s]\u001b[A\n","Iteration: 100% 1844/1851 [23:46<00:05,  1.30it/s]\u001b[A\n","Iteration: 100% 1845/1851 [23:47<00:04,  1.30it/s]\u001b[A\n","Iteration: 100% 1846/1851 [23:47<00:03,  1.30it/s]\u001b[A\n","Iteration: 100% 1847/1851 [23:48<00:03,  1.30it/s]\u001b[A\n","Iteration: 100% 1848/1851 [23:49<00:02,  1.30it/s]\u001b[A\n","Iteration: 100% 1849/1851 [23:50<00:01,  1.30it/s]\u001b[A\n","Iteration: 100% 1850/1851 [23:50<00:00,  1.29it/s]\u001b[A\n","Iteration: 100% 1851/1851 [23:51<00:00,  1.29it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-16 05:39:10,894][__main__][DEBUG] - early stop\n","Epoch:   1% 1/100 [56:49<93:45:18, 3409.27s/it]\n"]}],"source":["!HYDRA_FULL_ERROR=1 python run.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"w7sdHHb0uFV-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660634108749,"user_tz":-540,"elapsed":5619064,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"445bade1-26ee-4afa-c0c3-06c4776e128f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","eval.py:21: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-16 05:39:18,343][HYDRA] Hydra 1.2.0\n","[2022-08-16 05:39:18,344][HYDRA] ===========\n","[2022-08-16 05:39:18,344][HYDRA] Installed Hydra Plugins\n","[2022-08-16 05:39:18,344][HYDRA] ***********************\n","[2022-08-16 05:39:18,344][HYDRA] \tConfigSource:\n","[2022-08-16 05:39:18,344][HYDRA] \t-------------\n","[2022-08-16 05:39:18,344][HYDRA] \t\tFileConfigSource\n","[2022-08-16 05:39:18,344][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-16 05:39:18,344][HYDRA] \t\tStructuredConfigSource\n","[2022-08-16 05:39:18,344][HYDRA] \tCompletionPlugin:\n","[2022-08-16 05:39:18,344][HYDRA] \t-----------------\n","[2022-08-16 05:39:18,344][HYDRA] \t\tBashCompletion\n","[2022-08-16 05:39:18,344][HYDRA] \t\tFishCompletion\n","[2022-08-16 05:39:18,344][HYDRA] \t\tZshCompletion\n","[2022-08-16 05:39:18,344][HYDRA] \tLauncher:\n","[2022-08-16 05:39:18,344][HYDRA] \t---------\n","[2022-08-16 05:39:18,344][HYDRA] \t\tBasicLauncher\n","[2022-08-16 05:39:18,344][HYDRA] \tSweeper:\n","[2022-08-16 05:39:18,344][HYDRA] \t--------\n","[2022-08-16 05:39:18,344][HYDRA] \t\tBasicSweeper\n","[2022-08-16 05:39:18,344][HYDRA] \n","[2022-08-16 05:39:18,344][HYDRA] Config search path\n","[2022-08-16 05:39:18,344][HYDRA] ******************\n","[2022-08-16 05:39:18,622][HYDRA] | Provider | Search path                                                           |\n","[2022-08-16 05:39:18,622][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-16 05:39:18,622][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-16 05:39:18,622][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-16 05:39:18,623][HYDRA] | schema   | structured://                                                         |\n","[2022-08-16 05:39:18,623][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-16 05:39:18,691][HYDRA] \n","[2022-08-16 05:39:18,691][HYDRA] Defaults Tree\n","[2022-08-16 05:39:18,691][HYDRA] *************\n","[2022-08-16 05:39:18,691][HYDRA] <root>:\n","[2022-08-16 05:39:18,692][HYDRA]   hydra/config:\n","[2022-08-16 05:39:18,692][HYDRA]     hydra/output: default\n","[2022-08-16 05:39:18,692][HYDRA]     hydra/launcher: basic\n","[2022-08-16 05:39:18,692][HYDRA]     hydra/sweeper: basic\n","[2022-08-16 05:39:18,692][HYDRA]     hydra/help: default\n","[2022-08-16 05:39:18,692][HYDRA]     hydra/hydra_help: default\n","[2022-08-16 05:39:18,692][HYDRA]     hydra/hydra_logging: default\n","[2022-08-16 05:39:18,692][HYDRA]     hydra/job_logging: default\n","[2022-08-16 05:39:18,692][HYDRA]     hydra/callbacks: null\n","[2022-08-16 05:39:18,692][HYDRA]     hydra/env: default\n","[2022-08-16 05:39:18,692][HYDRA]     _self_\n","[2022-08-16 05:39:18,692][HYDRA]   config:\n","[2022-08-16 05:39:18,692][HYDRA]     data/FB15kET\n","[2022-08-16 05:39:18,693][HYDRA]     model/T5\n","[2022-08-16 05:39:18,693][HYDRA]     _self_\n","[2022-08-16 05:39:18,760][HYDRA] \n","[2022-08-16 05:39:18,760][HYDRA] Defaults List\n","[2022-08-16 05:39:18,760][HYDRA] *************\n","[2022-08-16 05:39:18,760][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-16 05:39:18,760][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-16 05:39:18,760][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-16 05:39:18,760][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-16 05:39:18,760][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-16 05:39:18,760][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-16 05:39:18,760][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-16 05:39:18,760][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-16 05:39:18,760][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-16 05:39:18,760][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-16 05:39:18,760][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-16 05:39:18,760][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-08-16 05:39:18,760][HYDRA] | model/T5                    | model               | False  | config       |\n","[2022-08-16 05:39:18,760][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-16 05:39:18,760][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-16 05:39:18,877][HYDRA] Config\n","[2022-08-16 05:39:18,877][HYDRA] ******\n","[2022-08-16 05:39:18,881][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: false\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: T5\n","  train_dataset: ET_train.txt\n","  pretrained_model: t5-base\n","  append_another_bos: false\n","  append_sep_token: true\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 128\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 128\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_test.txt\n","    save_outputs: true\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: Exp/Exp19/save/ET_1_1_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-16 05:39:18,961][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 05:39:18,961 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 05:39:19,726][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 0\n","2022-08-16 05:39:19,726 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 0\n","[2022-08-16 05:39:19,727][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","2022-08-16 05:39:19,727 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-16 05:39:27,219][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 05:39:27,219 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 05:39:28,020][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 0\n","2022-08-16 05:39:28,020 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 0\n","[2022-08-16 05:39:28,022][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","2022-08-16 05:39:28,022 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-16 05:39:28,023][transformers.configuration_utils][INFO] - Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","2022-08-16 05:39:28,023 INFO     Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[2022-08-16 05:39:28,025][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-16 05:39:28,025 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-16 05:39:28,140][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /t5-base-pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-16 05:39:28,140 DEBUG    https://cdn.huggingface.co:443 \"HEAD /t5-base-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-16 05:39:28,142][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","2022-08-16 05:39:28,142 INFO     loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-16 05:39:33,749][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","2022-08-16 05:39:33,749 INFO     All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","[2022-08-16 05:39:33,750][transformers.modeling_utils][WARNING] - Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2022-08-16 05:39:33,750 WARNING  Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[2022-08-16 05:39:38,737][root][DEBUG] - Parameter model.shared.weight: torch.Size([32128, 768]), require_grad=True\n","2022-08-16 05:39:38,737 DEBUG    Parameter model.shared.weight: torch.Size([32128, 768]), require_grad=True\n","[2022-08-16 05:39:38,737][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,737 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,738][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,738 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,738][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,738 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,738][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,738 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,738][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","2022-08-16 05:39:38,738 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-16 05:39:38,738][root][DEBUG] - Parameter model.encoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,738 DEBUG    Parameter model.encoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,739][root][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,739 DEBUG    Parameter model.encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,739][root][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,739 DEBUG    Parameter model.encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,739][root][DEBUG] - Parameter model.encoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,739 DEBUG    Parameter model.encoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,739][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,739 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,740][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,740 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,740][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,740 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,740][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,740 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,740][root][DEBUG] - Parameter model.encoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,740 DEBUG    Parameter model.encoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,740][root][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,740 DEBUG    Parameter model.encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,741][root][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,741 DEBUG    Parameter model.encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,741][root][DEBUG] - Parameter model.encoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,741 DEBUG    Parameter model.encoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,741][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,741 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,741][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,741 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,741][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,741 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,741][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,741 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,742][root][DEBUG] - Parameter model.encoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,742 DEBUG    Parameter model.encoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,742][root][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,742 DEBUG    Parameter model.encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,742][root][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,742 DEBUG    Parameter model.encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,742][root][DEBUG] - Parameter model.encoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,742 DEBUG    Parameter model.encoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,742][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,742 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,743][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,743 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,743][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,743 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,743][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,743 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,743][root][DEBUG] - Parameter model.encoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,743 DEBUG    Parameter model.encoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,743][root][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,743 DEBUG    Parameter model.encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,744][root][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,744 DEBUG    Parameter model.encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,744][root][DEBUG] - Parameter model.encoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,744 DEBUG    Parameter model.encoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,744][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,744 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,744][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,744 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,744][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,744 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,744][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,744 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,745][root][DEBUG] - Parameter model.encoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,745 DEBUG    Parameter model.encoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,745][root][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,745 DEBUG    Parameter model.encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,745][root][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,745 DEBUG    Parameter model.encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,745][root][DEBUG] - Parameter model.encoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,745 DEBUG    Parameter model.encoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,745][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,745 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,746][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,746 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,746][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,746 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,746][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,746 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,746][root][DEBUG] - Parameter model.encoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,746 DEBUG    Parameter model.encoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,746][root][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,746 DEBUG    Parameter model.encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,746][root][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,746 DEBUG    Parameter model.encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,747][root][DEBUG] - Parameter model.encoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,747 DEBUG    Parameter model.encoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,747][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,747 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,747][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,747 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,747][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,747 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,747][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,747 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,747][root][DEBUG] - Parameter model.encoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,747 DEBUG    Parameter model.encoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,748][root][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,748 DEBUG    Parameter model.encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,748][root][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,748 DEBUG    Parameter model.encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,748][root][DEBUG] - Parameter model.encoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,748 DEBUG    Parameter model.encoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,748][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,748 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,748][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,748 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,748][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,748 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,748][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,748 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,821][root][DEBUG] - Parameter model.encoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,821 DEBUG    Parameter model.encoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,822][root][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,822 DEBUG    Parameter model.encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,822][root][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,822 DEBUG    Parameter model.encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,822][root][DEBUG] - Parameter model.encoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,822 DEBUG    Parameter model.encoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,822][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,822 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,823][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,823 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,823][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,823 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,823][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,823 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,823][root][DEBUG] - Parameter model.encoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,823 DEBUG    Parameter model.encoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,823][root][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,823 DEBUG    Parameter model.encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,824][root][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,824 DEBUG    Parameter model.encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,824][root][DEBUG] - Parameter model.encoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,824 DEBUG    Parameter model.encoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,824][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,824 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,824][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,824 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,825][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,825 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,825][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,825 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,825][root][DEBUG] - Parameter model.encoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,825 DEBUG    Parameter model.encoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,825][root][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,825 DEBUG    Parameter model.encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,825][root][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,825 DEBUG    Parameter model.encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,826][root][DEBUG] - Parameter model.encoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,826 DEBUG    Parameter model.encoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,826][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,826 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,826][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,826 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,826][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,826 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,826][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,826 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,827][root][DEBUG] - Parameter model.encoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,827 DEBUG    Parameter model.encoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,827][root][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,827 DEBUG    Parameter model.encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,827][root][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,827 DEBUG    Parameter model.encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,827][root][DEBUG] - Parameter model.encoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,827 DEBUG    Parameter model.encoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,828][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,828 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,828][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,828 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,828][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,828 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,828][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,828 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,828][root][DEBUG] - Parameter model.encoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,828 DEBUG    Parameter model.encoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,828][root][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,828 DEBUG    Parameter model.encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,829][root][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,829 DEBUG    Parameter model.encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,829][root][DEBUG] - Parameter model.encoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,829 DEBUG    Parameter model.encoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,829][root][DEBUG] - Parameter model.encoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,829 DEBUG    Parameter model.encoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,829][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,829 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,829][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,829 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,830][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,830 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,830][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,830 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,830][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","2022-08-16 05:39:38,830 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-16 05:39:38,830][root][DEBUG] - Parameter model.decoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,830 DEBUG    Parameter model.decoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,831][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,831 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,831][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,831 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,831][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,831 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,831][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,831 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,831][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","2022-08-16 05:39:38,831 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-16 05:39:38,832][root][DEBUG] - Parameter model.decoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,832 DEBUG    Parameter model.decoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,832][root][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,832 DEBUG    Parameter model.decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,832][root][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,832 DEBUG    Parameter model.decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,832][root][DEBUG] - Parameter model.decoder.block.0.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,832 DEBUG    Parameter model.decoder.block.0.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,832][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,832 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,832][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,832 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,833][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,833 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,833][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,833 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,833][root][DEBUG] - Parameter model.decoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,833 DEBUG    Parameter model.decoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,833][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,833 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,833][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,833 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,834][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,834 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,834][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,834 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,834][root][DEBUG] - Parameter model.decoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,834 DEBUG    Parameter model.decoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,834][root][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,834 DEBUG    Parameter model.decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,834][root][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,834 DEBUG    Parameter model.decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,834][root][DEBUG] - Parameter model.decoder.block.1.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,834 DEBUG    Parameter model.decoder.block.1.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,835][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,835 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,835][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,835 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,835][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,835 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,835][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,835 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,835][root][DEBUG] - Parameter model.decoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,835 DEBUG    Parameter model.decoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,835][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,835 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,835][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,835 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,836][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,836 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,836][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,836 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,836][root][DEBUG] - Parameter model.decoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,836 DEBUG    Parameter model.decoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,836][root][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,836 DEBUG    Parameter model.decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,836][root][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,836 DEBUG    Parameter model.decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,836][root][DEBUG] - Parameter model.decoder.block.2.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,836 DEBUG    Parameter model.decoder.block.2.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,836][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,836 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,837][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,837 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,837][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,837 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,837][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,837 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,837][root][DEBUG] - Parameter model.decoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,837 DEBUG    Parameter model.decoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,837][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,837 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,837][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,837 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,838][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,838 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,838][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,838 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,838][root][DEBUG] - Parameter model.decoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,838 DEBUG    Parameter model.decoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,838][root][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,838 DEBUG    Parameter model.decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,838][root][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,838 DEBUG    Parameter model.decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,838][root][DEBUG] - Parameter model.decoder.block.3.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,838 DEBUG    Parameter model.decoder.block.3.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,839][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,839 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,839][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,839 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,839][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,839 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,839][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,839 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,839][root][DEBUG] - Parameter model.decoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,839 DEBUG    Parameter model.decoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,839][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,839 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,839][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,839 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,840][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,840 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,840][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,840 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,840][root][DEBUG] - Parameter model.decoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,840 DEBUG    Parameter model.decoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,840][root][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,840 DEBUG    Parameter model.decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,840][root][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,840 DEBUG    Parameter model.decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,840][root][DEBUG] - Parameter model.decoder.block.4.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,840 DEBUG    Parameter model.decoder.block.4.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,932][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,932 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,932][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,932 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,932][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,932 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,932][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,932 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,933][root][DEBUG] - Parameter model.decoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,933 DEBUG    Parameter model.decoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,933][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,933 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,933][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,933 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,933][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,933 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,933][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,933 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,934][root][DEBUG] - Parameter model.decoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,934 DEBUG    Parameter model.decoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,934][root][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,934 DEBUG    Parameter model.decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,934][root][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,934 DEBUG    Parameter model.decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,934][root][DEBUG] - Parameter model.decoder.block.5.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,934 DEBUG    Parameter model.decoder.block.5.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,934][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,934 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,935][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,935 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,935][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,935 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,935][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,935 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,935][root][DEBUG] - Parameter model.decoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,935 DEBUG    Parameter model.decoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,935][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,935 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,936][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,936 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,936][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,936 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,936][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,936 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,936][root][DEBUG] - Parameter model.decoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,936 DEBUG    Parameter model.decoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,936][root][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,936 DEBUG    Parameter model.decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,936][root][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,936 DEBUG    Parameter model.decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,937][root][DEBUG] - Parameter model.decoder.block.6.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,937 DEBUG    Parameter model.decoder.block.6.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,937][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,937 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,937][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,937 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,937][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,937 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,937][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,937 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,938][root][DEBUG] - Parameter model.decoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,938 DEBUG    Parameter model.decoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,938][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,938 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,938][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,938 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,938][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,938 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,938][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,938 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,939][root][DEBUG] - Parameter model.decoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,939 DEBUG    Parameter model.decoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,939][root][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,939 DEBUG    Parameter model.decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,939][root][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,939 DEBUG    Parameter model.decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,939][root][DEBUG] - Parameter model.decoder.block.7.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,939 DEBUG    Parameter model.decoder.block.7.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,939][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,939 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,940][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,940 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,940][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,940 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,940][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,940 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,940][root][DEBUG] - Parameter model.decoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,940 DEBUG    Parameter model.decoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,941][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,941 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,941][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,941 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,941][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,941 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,941][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,941 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,941][root][DEBUG] - Parameter model.decoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,941 DEBUG    Parameter model.decoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,941][root][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,941 DEBUG    Parameter model.decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,942][root][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,942 DEBUG    Parameter model.decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,942][root][DEBUG] - Parameter model.decoder.block.8.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,942 DEBUG    Parameter model.decoder.block.8.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,942][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,942 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,942][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,942 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,942][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,942 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,943][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,943 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,943][root][DEBUG] - Parameter model.decoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,943 DEBUG    Parameter model.decoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,943][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,943 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,943][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,943 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,943][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,943 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,943][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,943 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,944][root][DEBUG] - Parameter model.decoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,944 DEBUG    Parameter model.decoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,944][root][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:38,944 DEBUG    Parameter model.decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:38,944][root][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:38,944 DEBUG    Parameter model.decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:38,944][root][DEBUG] - Parameter model.decoder.block.9.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:38,944 DEBUG    Parameter model.decoder.block.9.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:38,945][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,945 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:38,945][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:38,945 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,035][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,035 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,036][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,036 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,036][root][DEBUG] - Parameter model.decoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:39,036 DEBUG    Parameter model.decoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:39,036][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,036 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,036][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,036 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,036][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,036 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,037][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,037 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,037][root][DEBUG] - Parameter model.decoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:39,037 DEBUG    Parameter model.decoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:39,037][root][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:39,037 DEBUG    Parameter model.decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:39,037][root][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:39,037 DEBUG    Parameter model.decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:39,037][root][DEBUG] - Parameter model.decoder.block.10.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:39,037 DEBUG    Parameter model.decoder.block.10.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:39,038][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,038 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,038][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,038 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,038][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,038 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,038][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,038 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,038][root][DEBUG] - Parameter model.decoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:39,038 DEBUG    Parameter model.decoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:39,039][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,039 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,039][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,039 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,039][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,039 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,039][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-16 05:39:39,039 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-16 05:39:39,039][root][DEBUG] - Parameter model.decoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:39,039 DEBUG    Parameter model.decoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:39,040][root][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-16 05:39:39,040 DEBUG    Parameter model.decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-16 05:39:39,040][root][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-16 05:39:39,040 DEBUG    Parameter model.decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-16 05:39:39,040][root][DEBUG] - Parameter model.decoder.block.11.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:39,040 DEBUG    Parameter model.decoder.block.11.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-16 05:39:39,040][root][DEBUG] - Parameter model.decoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-16 05:39:39,040 DEBUG    Parameter model.decoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","Iteration:   0% 0/1082 [00:00<?, ?it/s]The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","Iteration: 100% 1082/1082 [1:31:56<00:00,  5.10s/it]\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","[2022-08-16 07:11:40,691][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 07:11:40,691 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 07:11:41,458][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-16 07:11:41,458 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-16 07:11:41,460][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-16 07:11:41,460 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-16 07:11:41,460][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-16 07:11:41,460 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-16 07:11:41,462][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 07:11:41,462 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 07:11:42,261][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","2022-08-16 07:11:42,261 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-16 07:11:42,264][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 07:11:42,264 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 07:11:43,035][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","2022-08-16 07:11:43,035 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-16 07:11:43,036][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-16 07:11:43,036 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-16 07:11:43,037][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-16 07:11:43,037 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-16 07:11:43,121][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-16 07:11:43,121 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-16 07:11:43,878][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-16 07:11:43,878 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-16 07:11:43,880][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-16 07:11:43,880 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-16 07:11:43,880][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-16 07:11:43,880 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-16 07:11:43,882][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-16 07:11:43,882 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-16 07:11:43,991][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-16 07:11:43,991 DEBUG    https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-16 07:11:43,993][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","2022-08-16 07:11:43,993 INFO     loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","[2022-08-16 07:11:54,280][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing RobertaModel.\n","\n","2022-08-16 07:11:54,280 INFO     All model checkpoint weights were used when initializing RobertaModel.\n","\n","[2022-08-16 07:11:54,281][transformers.modeling_utils][INFO] - All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","2022-08-16 07:11:54,281 INFO     All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","calculating scores...\n","computing bert embedding.\n","100% 92/92 [00:54<00:00,  1.70it/s]\n","computing greedy matching.\n","100% 136/136 [00:02<00:00, 65.74it/s]\n","done in 56.26 seconds, 153.85 sentences/sec\n","[2022-08-16 07:12:50,955][root][INFO] - test data set : ET_test.txt\n","2022-08-16 07:12:50,955 INFO     test data set : ET_test.txt\n","[2022-08-16 07:12:50,956][root][INFO] - N-grams: 1-0.20196722173641665, 2-0.09454249074303181, 3-0.052860768854588985, 4-0.021759188107491487\n","2022-08-16 07:12:50,956 INFO     N-grams: 1-0.20196722173641665, 2-0.09454249074303181, 3-0.052860768854588985, 4-0.021759188107491487\n","[2022-08-16 07:12:50,956][root][INFO] - BERT-P:0.851417, BERT-R:0.887069, BERT-F1:0.868635\n","2022-08-16 07:12:50,956 INFO     BERT-P:0.851417, BERT-R:0.887069, BERT-F1:0.868635\n"]}],"source":["!HYDRA_FULL_ERROR=1 python eval.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiRHm4nruPw9"},"outputs":[],"source":["!kill $(ps aux | awk '{print $2}')"]},{"cell_type":"code","source":[""],"metadata":{"id":"WPTZiAzwc_WZ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"cmd_train.ipynb","provenance":[],"mount_file_id":"1Mrwlgkjv2G7LOLpOtCehzWxaTRu9sXPA","authorship_tag":"ABX9TyM2dd7XQjK7MtzbhdCWkdas"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}