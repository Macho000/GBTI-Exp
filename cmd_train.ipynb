{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1660518735241,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"dymDs0Po0aES","outputId":"1ed5c133-14b8-4739-989d-2766a7d16a70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Aug 14 23:10:00 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1376,"status":"ok","timestamp":1660518736611,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"EfCxDoEXuzgg","outputId":"bec78ba1-8aa3-4c78-bb25-6fea4d630fa2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","source":["!python -m pip install bert-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bOeGCnRF9Cs","executionInfo":{"status":"ok","timestamp":1660518747683,"user_tz":-540,"elapsed":11080,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"4add62b4-0f88-4081-f015-d7ad8a6c43df"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bert-score\n","  Downloading bert_score-0.3.11-py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 3.1 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.3.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert-score) (3.2.2)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert-score) (1.12.1+cu113)\n","Collecting transformers>=3.0.0numpy\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 8.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert-score) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert-score) (2.23.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert-score) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert-score) (3.0.9)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert-score) (4.1.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (3.7.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 57.2 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 14.3 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 58.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert-score) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert-score) (3.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score) (0.11.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score) (2022.6.15)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, bert-score\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed bert-score-0.3.11 huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":449624,"status":"ok","timestamp":1660519197296,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"mshVPsrku0kd","outputId":"25c3368c-4f2d-43dc-a9ba-152ccbd47005"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 12 kB/s \n","\u001b[?25hCollecting transformers==3.0.0\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[K     |████████████████████████████████| 754 kB 72.3 MB/s \n","\u001b[?25hCollecting torch_scatter==2.0.4\n","  Downloading torch_scatter-2.0.4.tar.gz (20 kB)\n","Collecting dgl==0.5.3\n","  Downloading dgl-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 66.9 MB/s \n","\u001b[?25hCollecting hydra==2.4\n","  Downloading Hydra-2.4.tar.gz (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 11.1 MB/s \n","\u001b[?25hCollecting omegaconf==2.2.2\n","  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.2)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 50.1 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 62.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 80.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (3.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (2.6.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.5.3->-r requirements.txt (line 5)) (1.7.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.2.2->-r requirements.txt (line 7)) (6.0)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 86.4 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0->-r requirements.txt (line 3)) (1.1.0)\n","Building wheels for collected packages: torch-scatter, hydra, antlr4-python3-runtime, sacremoses\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-scatter: filename=torch_scatter-2.0.4-cp37-cp37m-linux_x86_64.whl size=14800976 sha256=e6afc1679cdc58046b3d1d85c933fd365264187e16ee342915da4af350ffd81b\n","  Stored in directory: /root/.cache/pip/wheels/4a/3d/01/e408ecc11389070cbacee91b70c978bf3557130e9aaa18a95b\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.4-cp37-cp37m-linux_x86_64.whl size=219225 sha256=b1ca69dc939b45eaede7e4c79e74e1722a32afe55138e3d9023184c317eef8a1\n","  Stored in directory: /root/.cache/pip/wheels/f5/65/98/3603b340344bd22dfe1c809365013fc4d425d83d89c3e2cd17\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=8fe240abaee15179b44ee4be6ea72d2f0a4f28630845017b5fb217981822a6cf\n","  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=19a24ea986d6f50319929fb9f6d1b5728ec33c7293f7bff50e69397054b7b697\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built torch-scatter hydra antlr4-python3-runtime sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, antlr4-python3-runtime, transformers, torch-scatter, torch, omegaconf, hydra, dgl\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.21.1\n","    Uninstalling transformers-4.21.1:\n","      Successfully uninstalled transformers-4.21.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed antlr4-python3-runtime-4.9.3 dgl-0.5.3 hydra-2.4 omegaconf-2.2.2 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.0rc4 torch-1.8.0 torch-scatter-2.0.4 transformers-3.0.0\n"]}],"source":["!python -m pip install -r requirements.txt"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126530,"status":"ok","timestamp":1660519323817,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"G8LmQt_jcvSZ","outputId":"ba1cb521-8f3b-42d1-ef13-a0dd7f7cc815"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 74.5 MB/s eta 0:00:17tcmalloc: large alloc 1147494400 bytes == 0x3a276000 @  0x7f391337d615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:13tcmalloc: large alloc 1434370048 bytes == 0x7e8cc000 @  0x7f391337d615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:10:08tcmalloc: large alloc 1792966656 bytes == 0x36fe000 @  0x7f391337d615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:48tcmalloc: large alloc 2241208320 bytes == 0x6e4e6000 @  0x7f391337d615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf3e48000 @  0x7f391337c1e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2551685120 bytes == 0x1e1dc8000 @  0x7f391337d615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 2041.3 MB 7.2 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 34.0 MB/s \n","\u001b[?25hCollecting torchaudio===0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.8.0\n","    Uninstalling torch-1.8.0:\n","      Successfully uninstalled torch-1.8.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\n","bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 3.0.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}],"source":["!python -m pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":563,"status":"ok","timestamp":1660519324368,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"JJqgY88ou7Qp","outputId":"9a4bc12b-608d-4860-a49c-d30b0816a081"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch-scatter 2.0.4\n","Uninstalling torch-scatter-2.0.4:\n","  Successfully uninstalled torch-scatter-2.0.4\n"]}],"source":["!python -m pip uninstall torch-scatter -y"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6595,"status":"ok","timestamp":1660519330955,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"7c7V5B7yc9Cc","outputId":"6ad372ff-9a47-4aac-a38c-ad424dbd43eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 1.1 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.9\n"]}],"source":["!python -m pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.1+cu111.html"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1068,"status":"ok","timestamp":1660519332003,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"l2wm30u-c-i0","outputId":"a7d7ae01-dae4-4eeb-adb0-771b0d914679"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.9\n"]}],"source":["!python -c \"import torch_scatter; print(torch_scatter.__version__)\""]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4552,"status":"ok","timestamp":1660519336551,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"GgPMOQSL4HVZ","outputId":"2ec2c80f-3b44-4db4-f9c4-214b414af27b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.2.2)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.9.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core) (21.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core) (3.0.9)\n","Installing collected packages: hydra-core\n","Successfully installed hydra-core-1.2.0\n"]}],"source":["!pip install hydra-core --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1660203016899,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"FT5vluqcNpey","outputId":"fb6b583e-b039-4cef-cbf9-2bf97cee58d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZROa2w4NUfm"},"outputs":[],"source":["!python preprocess.py --dataset FB15kET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDB7erFzN4St"},"outputs":[],"source":["!python preprocess.py --dataset YAGO43kET"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1660520159140,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"},"user_tz":-540},"id":"hsnRA4_pUSzk","outputId":"82db6c40-8789-441d-9fea-9c2d0960f508"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp\n"]}],"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"586hjT34u-VB","outputId":"f446283e-12f7-410e-e04a-610e01568603","executionInfo":{"status":"ok","timestamp":1660522284195,"user_tz":-540,"elapsed":2125061,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n","Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n","Using backend: pytorch\n","run.py:18: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-14 23:33:58,767][HYDRA] Hydra 1.2.0\n","[2022-08-14 23:33:58,767][HYDRA] ===========\n","[2022-08-14 23:33:58,767][HYDRA] Installed Hydra Plugins\n","[2022-08-14 23:33:58,767][HYDRA] ***********************\n","[2022-08-14 23:33:58,767][HYDRA] \tConfigSource:\n","[2022-08-14 23:33:58,767][HYDRA] \t-------------\n","[2022-08-14 23:33:58,767][HYDRA] \t\tFileConfigSource\n","[2022-08-14 23:33:58,767][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-14 23:33:58,767][HYDRA] \t\tStructuredConfigSource\n","[2022-08-14 23:33:58,768][HYDRA] \tCompletionPlugin:\n","[2022-08-14 23:33:58,768][HYDRA] \t-----------------\n","[2022-08-14 23:33:58,768][HYDRA] \t\tBashCompletion\n","[2022-08-14 23:33:58,768][HYDRA] \t\tFishCompletion\n","[2022-08-14 23:33:58,768][HYDRA] \t\tZshCompletion\n","[2022-08-14 23:33:58,768][HYDRA] \tLauncher:\n","[2022-08-14 23:33:58,768][HYDRA] \t---------\n","[2022-08-14 23:33:58,768][HYDRA] \t\tBasicLauncher\n","[2022-08-14 23:33:58,768][HYDRA] \tSweeper:\n","[2022-08-14 23:33:58,768][HYDRA] \t--------\n","[2022-08-14 23:33:58,768][HYDRA] \t\tBasicSweeper\n","[2022-08-14 23:33:58,768][HYDRA] \n","[2022-08-14 23:33:58,768][HYDRA] Config search path\n","[2022-08-14 23:33:58,768][HYDRA] ******************\n","[2022-08-14 23:33:58,890][HYDRA] | Provider | Search path                                                           |\n","[2022-08-14 23:33:58,890][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-14 23:33:58,890][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-14 23:33:58,891][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-14 23:33:58,891][HYDRA] | schema   | structured://                                                         |\n","[2022-08-14 23:33:58,891][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-14 23:33:58,957][HYDRA] \n","[2022-08-14 23:33:58,957][HYDRA] Defaults Tree\n","[2022-08-14 23:33:58,957][HYDRA] *************\n","[2022-08-14 23:33:58,957][HYDRA] <root>:\n","[2022-08-14 23:33:58,957][HYDRA]   hydra/config:\n","[2022-08-14 23:33:58,957][HYDRA]     hydra/output: default\n","[2022-08-14 23:33:58,957][HYDRA]     hydra/launcher: basic\n","[2022-08-14 23:33:58,958][HYDRA]     hydra/sweeper: basic\n","[2022-08-14 23:33:58,958][HYDRA]     hydra/help: default\n","[2022-08-14 23:33:58,958][HYDRA]     hydra/hydra_help: default\n","[2022-08-14 23:33:58,958][HYDRA]     hydra/hydra_logging: default\n","[2022-08-14 23:33:58,958][HYDRA]     hydra/job_logging: default\n","[2022-08-14 23:33:58,958][HYDRA]     hydra/callbacks: null\n","[2022-08-14 23:33:58,958][HYDRA]     hydra/env: default\n","[2022-08-14 23:33:58,958][HYDRA]     _self_\n","[2022-08-14 23:33:58,958][HYDRA]   config:\n","[2022-08-14 23:33:58,958][HYDRA]     data/FB15kET\n","[2022-08-14 23:33:58,958][HYDRA]     model/T5\n","[2022-08-14 23:33:58,958][HYDRA]     _self_\n","[2022-08-14 23:33:59,024][HYDRA] \n","[2022-08-14 23:33:59,024][HYDRA] Defaults List\n","[2022-08-14 23:33:59,024][HYDRA] *************\n","[2022-08-14 23:33:59,024][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-14 23:33:59,024][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-14 23:33:59,024][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-14 23:33:59,024][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-14 23:33:59,024][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-14 23:33:59,024][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-14 23:33:59,025][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-14 23:33:59,025][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-14 23:33:59,025][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-14 23:33:59,025][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-14 23:33:59,025][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-14 23:33:59,025][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-08-14 23:33:59,025][HYDRA] | model/T5                    | model               | False  | config       |\n","[2022-08-14 23:33:59,025][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-14 23:33:59,025][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-14 23:33:59,140][HYDRA] Config\n","[2022-08-14 23:33:59,140][HYDRA] ******\n","[2022-08-14 23:33:59,144][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: true\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: T5\n","  train_dataset: ET_train.txt\n","  pretrained_model: t5-base\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 128\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 128\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_test.txt\n","    save_outputs: true\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: Exp/Exp19/save/ET_1_1_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-14 23:33:59,216][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-14 23:33:59,991][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 0\n","[2022-08-14 23:33:59,993][filelock][DEBUG] - Attempting to acquire lock 140551255246544 on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-14 23:33:59,993][filelock][DEBUG] - Lock 140551255246544 acquired on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-14 23:33:59,993][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp437fgxtn\n","[2022-08-14 23:33:59,995][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-14 23:34:00,779][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 791656\n","Downloading: 100% 792k/792k [00:00<00:00, 855kB/s]\n","[2022-08-14 23:34:01,706][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model in cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-14 23:34:01,706][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-14 23:34:01,707][filelock][DEBUG] - Attempting to release lock 140551255246544 on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-14 23:34:01,707][filelock][DEBUG] - Lock 140551255246544 released on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n","[2022-08-14 23:34:01,707][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-14 23:34:24,149][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-14 23:34:24,916][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 0\n","[2022-08-14 23:34:24,918][filelock][DEBUG] - Attempting to acquire lock 140549996890896 on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-14 23:34:24,918][filelock][DEBUG] - Lock 140549996890896 acquired on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-14 23:34:24,919][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpspq67_i7\n","[2022-08-14 23:34:24,920][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-14 23:34:25,704][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 1199\n","Downloading: 100% 1.20k/1.20k [00:00<00:00, 1.06MB/s]\n","[2022-08-14 23:34:25,706][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json in cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-14 23:34:25,707][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-14 23:34:25,707][filelock][DEBUG] - Attempting to release lock 140549996890896 on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-14 23:34:25,707][filelock][DEBUG] - Lock 140549996890896 released on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n","[2022-08-14 23:34:25,707][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-14 23:34:25,708][transformers.configuration_utils][INFO] - Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[2022-08-14 23:34:25,709][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-14 23:34:26,610][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /t5-base-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-14 23:34:26,612][filelock][DEBUG] - Attempting to acquire lock 140549996889872 on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-14 23:34:26,612][filelock][DEBUG] - Lock 140549996889872 acquired on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-14 23:34:26,613][transformers.file_utils][INFO] - https://cdn.huggingface.co/t5-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpm3zt78wm\n","[2022-08-14 23:34:26,614][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-14 23:34:26,998][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"GET /t5-base-pytorch_model.bin HTTP/1.1\" 200 891691430\n","Downloading: 100% 892M/892M [00:43<00:00, 20.3MB/s]\n","[2022-08-14 23:35:10,947][transformers.file_utils][INFO] - storing https://cdn.huggingface.co/t5-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-14 23:35:10,947][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-14 23:35:10,947][filelock][DEBUG] - Attempting to release lock 140549996889872 on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-14 23:35:10,948][filelock][DEBUG] - Lock 140549996889872 released on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n","[2022-08-14 23:35:10,948][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-14 23:35:16,356][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","[2022-08-14 23:35:16,356][transformers.modeling_utils][WARNING] - Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[2022-08-14 23:35:21,868][__main__][DEBUG] - Parameter model.shared.weight: torch.Size([32128, 768]), require_grad=True\n","[2022-08-14 23:35:21,868][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,868][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,869][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,869][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,869][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-14 23:35:21,869][__main__][DEBUG] - Parameter model.encoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,869][__main__][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,869][__main__][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,869][__main__][DEBUG] - Parameter model.encoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,869][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,870][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,870][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,870][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,870][__main__][DEBUG] - Parameter model.encoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,870][__main__][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,870][__main__][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,870][__main__][DEBUG] - Parameter model.encoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,870][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,871][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,871][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,871][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,871][__main__][DEBUG] - Parameter model.encoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,871][__main__][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,871][__main__][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,871][__main__][DEBUG] - Parameter model.encoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,871][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,872][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,872][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,872][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,872][__main__][DEBUG] - Parameter model.encoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,872][__main__][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,872][__main__][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,872][__main__][DEBUG] - Parameter model.encoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,872][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,872][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,873][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,873][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,873][__main__][DEBUG] - Parameter model.encoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,873][__main__][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,873][__main__][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,873][__main__][DEBUG] - Parameter model.encoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,873][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,873][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,874][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,874][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,874][__main__][DEBUG] - Parameter model.encoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,874][__main__][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,874][__main__][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,874][__main__][DEBUG] - Parameter model.encoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,874][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,874][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,874][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,875][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,875][__main__][DEBUG] - Parameter model.encoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,875][__main__][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,875][__main__][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,875][__main__][DEBUG] - Parameter model.encoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,875][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,875][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,875][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,875][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,876][__main__][DEBUG] - Parameter model.encoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,876][__main__][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,876][__main__][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,876][__main__][DEBUG] - Parameter model.encoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,876][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,876][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,876][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,876][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,877][__main__][DEBUG] - Parameter model.encoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,877][__main__][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,877][__main__][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,877][__main__][DEBUG] - Parameter model.encoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,877][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,877][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,877][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,877][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,877][__main__][DEBUG] - Parameter model.encoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,878][__main__][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,878][__main__][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,878][__main__][DEBUG] - Parameter model.encoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,878][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,878][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,878][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,878][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,878][__main__][DEBUG] - Parameter model.encoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,878][__main__][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,879][__main__][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,879][__main__][DEBUG] - Parameter model.encoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,879][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,879][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,879][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,879][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,879][__main__][DEBUG] - Parameter model.encoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,879][__main__][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,879][__main__][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,880][__main__][DEBUG] - Parameter model.encoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,880][__main__][DEBUG] - Parameter model.encoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,880][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,880][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,880][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,880][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,880][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-14 23:35:21,881][__main__][DEBUG] - Parameter model.decoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,881][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,881][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,881][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,881][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,881][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-14 23:35:21,881][__main__][DEBUG] - Parameter model.decoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,881][__main__][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,882][__main__][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,882][__main__][DEBUG] - Parameter model.decoder.block.0.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,882][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,882][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,882][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,882][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,882][__main__][DEBUG] - Parameter model.decoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,882][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,938][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,938][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,938][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,938][__main__][DEBUG] - Parameter model.decoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,938][__main__][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,938][__main__][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,939][__main__][DEBUG] - Parameter model.decoder.block.1.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,939][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,939][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,939][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,939][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,940][__main__][DEBUG] - Parameter model.decoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,940][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,940][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,940][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,940][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,941][__main__][DEBUG] - Parameter model.decoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,941][__main__][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,941][__main__][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,941][__main__][DEBUG] - Parameter model.decoder.block.2.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,941][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,942][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,942][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,942][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,942][__main__][DEBUG] - Parameter model.decoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,942][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,942][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,943][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,943][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,943][__main__][DEBUG] - Parameter model.decoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,943][__main__][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,943][__main__][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,943][__main__][DEBUG] - Parameter model.decoder.block.3.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,943][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,943][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,944][__main__][DEBUG] - Parameter model.decoder.block.4.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,945][__main__][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.5.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,946][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,947][__main__][DEBUG] - Parameter model.decoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,947][__main__][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,947][__main__][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,947][__main__][DEBUG] - Parameter model.decoder.block.6.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,947][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,947][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,947][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,947][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,947][__main__][DEBUG] - Parameter model.decoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,948][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,948][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,948][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,948][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,948][__main__][DEBUG] - Parameter model.decoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,948][__main__][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,948][__main__][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,948][__main__][DEBUG] - Parameter model.decoder.block.7.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,948][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,949][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,949][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,949][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,949][__main__][DEBUG] - Parameter model.decoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,949][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,949][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,949][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,949][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,949][__main__][DEBUG] - Parameter model.decoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.8.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,950][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,951][__main__][DEBUG] - Parameter model.decoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,951][__main__][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,951][__main__][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,951][__main__][DEBUG] - Parameter model.decoder.block.9.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,951][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,951][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,951][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,951][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,951][__main__][DEBUG] - Parameter model.decoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.10.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,952][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,953][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,953][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,953][__main__][DEBUG] - Parameter model.decoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,953][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,953][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,954][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,954][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-14 23:35:21,954][__main__][DEBUG] - Parameter model.decoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,954][__main__][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-14 23:35:21,954][__main__][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-14 23:35:21,954][__main__][DEBUG] - Parameter model.decoder.block.11.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-14 23:35:21,955][__main__][DEBUG] - Parameter model.decoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","Epoch:   0% 0/100 [00:00<?, ?it/s][2022-08-14 23:35:21,957][__main__][DEBUG] - Starting training!\n","\n","Iteration:   0% 0/1851 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-14 23:35:22,904][__main__][DEBUG] - batch 0: tensor([[ 784, 9413,  908,  ..., 6327,  908,    1],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1],\n","        ...,\n","        [ 784, 9413,  908,  ..., 6327,  908,    1],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1],\n","        [ 784, 9413,  908,  ..., 6327,  908,    1]], device='cuda:0') \n","[2022-08-14 23:35:22,914][__main__][DEBUG] - batch 1: tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') \n","[2022-08-14 23:35:22,922][__main__][DEBUG] - batch 2: tensor([[   3,   17,  208,  ...,    0,    0,    0],\n","        [5349,    1,    0,  ...,    0,    0,    0],\n","        [2600,    3,   32,  ...,    0,    0,    0],\n","        ...,\n","        [2772,   49,    3,  ...,    0,    0,    0],\n","        [2100,  372, 2859,  ...,    0,    0,    0],\n","        [2859, 1128,    3,  ...,    0,    0,    0]], device='cuda:0') \n","[2022-08-14 23:35:22,924][__main__][DEBUG] - batch 3: tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 0,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0') \n","\n","Iteration:   0% 1/1851 [00:01<46:48,  1.52s/it]\u001b[A\n","Iteration:   0% 2/1851 [00:01<27:19,  1.13it/s]\u001b[A\n","Iteration:   0% 3/1851 [00:02<21:00,  1.47it/s]\u001b[A\n","Iteration:   0% 4/1851 [00:02<18:00,  1.71it/s]\u001b[A\n","Iteration:   0% 5/1851 [00:03<16:21,  1.88it/s]\u001b[A\n","Iteration:   0% 6/1851 [00:03<15:22,  2.00it/s]\u001b[A\n","Iteration:   0% 7/1851 [00:04<14:44,  2.08it/s]\u001b[A\n","Iteration:   0% 8/1851 [00:04<14:19,  2.14it/s]\u001b[A\n","Iteration:   0% 9/1851 [00:05<14:03,  2.18it/s]\u001b[A\n","Iteration:   1% 10/1851 [00:05<13:51,  2.21it/s]\u001b[A\n","Iteration:   1% 11/1851 [00:05<13:43,  2.23it/s]\u001b[A\n","Iteration:   1% 12/1851 [00:06<13:37,  2.25it/s]\u001b[A\n","Iteration:   1% 13/1851 [00:06<13:33,  2.26it/s]\u001b[A\n","Iteration:   1% 14/1851 [00:07<13:30,  2.27it/s]\u001b[A\n","Iteration:   1% 15/1851 [00:07<13:28,  2.27it/s]\u001b[A\n","Iteration:   1% 16/1851 [00:08<13:27,  2.27it/s]\u001b[A\n","Iteration:   1% 17/1851 [00:08<13:26,  2.28it/s]\u001b[A\n","Iteration:   1% 18/1851 [00:08<13:24,  2.28it/s]\u001b[A\n","Iteration:   1% 19/1851 [00:09<13:23,  2.28it/s]\u001b[A\n","Iteration:   1% 20/1851 [00:09<13:22,  2.28it/s]\u001b[A\n","Iteration:   1% 21/1851 [00:10<13:22,  2.28it/s]\u001b[A\n","Iteration:   1% 22/1851 [00:10<13:21,  2.28it/s]\u001b[A\n","Iteration:   1% 23/1851 [00:11<13:21,  2.28it/s]\u001b[A\n","Iteration:   1% 24/1851 [00:11<13:21,  2.28it/s]\u001b[A\n","Iteration:   1% 25/1851 [00:12<13:20,  2.28it/s]\u001b[A\n","Iteration:   1% 26/1851 [00:12<13:20,  2.28it/s]\u001b[A\n","Iteration:   1% 27/1851 [00:12<13:20,  2.28it/s]\u001b[A\n","Iteration:   2% 28/1851 [00:13<13:19,  2.28it/s]\u001b[A\n","Iteration:   2% 29/1851 [00:13<13:19,  2.28it/s]\u001b[A\n","Iteration:   2% 30/1851 [00:14<13:18,  2.28it/s]\u001b[A\n","Iteration:   2% 31/1851 [00:14<13:17,  2.28it/s]\u001b[A\n","Iteration:   2% 32/1851 [00:15<13:17,  2.28it/s]\u001b[A\n","Iteration:   2% 33/1851 [00:15<13:17,  2.28it/s]\u001b[A\n","Iteration:   2% 34/1851 [00:15<13:17,  2.28it/s]\u001b[A\n","Iteration:   2% 35/1851 [00:16<13:16,  2.28it/s]\u001b[A\n","Iteration:   2% 36/1851 [00:16<13:16,  2.28it/s]\u001b[A\n","Iteration:   2% 37/1851 [00:17<13:15,  2.28it/s]\u001b[A\n","Iteration:   2% 38/1851 [00:17<13:14,  2.28it/s]\u001b[A\n","Iteration:   2% 39/1851 [00:18<13:14,  2.28it/s]\u001b[A\n","Iteration:   2% 40/1851 [00:18<13:13,  2.28it/s]\u001b[A\n","Iteration:   2% 41/1851 [00:19<13:12,  2.28it/s]\u001b[A\n","Iteration:   2% 42/1851 [00:19<13:11,  2.28it/s]\u001b[A\n","Iteration:   2% 43/1851 [00:19<13:11,  2.28it/s]\u001b[A\n","Iteration:   2% 44/1851 [00:20<13:11,  2.28it/s]\u001b[A\n","Iteration:   2% 45/1851 [00:20<13:10,  2.29it/s]\u001b[A\n","Iteration:   2% 46/1851 [00:21<13:10,  2.28it/s]\u001b[A\n","Iteration:   3% 47/1851 [00:21<13:09,  2.28it/s]\u001b[A\n","Iteration:   3% 48/1851 [00:22<13:10,  2.28it/s]\u001b[A\n","Iteration:   3% 49/1851 [00:22<13:09,  2.28it/s]\u001b[A\n","Iteration:   3% 50/1851 [00:22<13:09,  2.28it/s]\u001b[A\n","Iteration:   3% 51/1851 [00:23<13:08,  2.28it/s]\u001b[A\n","Iteration:   3% 52/1851 [00:23<13:10,  2.28it/s]\u001b[A\n","Iteration:   3% 53/1851 [00:24<13:09,  2.28it/s]\u001b[A\n","Iteration:   3% 54/1851 [00:24<13:08,  2.28it/s]\u001b[A\n","Iteration:   3% 55/1851 [00:25<13:06,  2.28it/s]\u001b[A\n","Iteration:   3% 56/1851 [00:25<13:06,  2.28it/s]\u001b[A\n","Iteration:   3% 57/1851 [00:26<13:05,  2.28it/s]\u001b[A\n","Iteration:   3% 58/1851 [00:26<13:05,  2.28it/s]\u001b[A\n","Iteration:   3% 59/1851 [00:26<13:04,  2.28it/s]\u001b[A\n","Iteration:   3% 60/1851 [00:27<13:04,  2.28it/s]\u001b[A\n","Iteration:   3% 61/1851 [00:27<13:03,  2.28it/s]\u001b[A\n","Iteration:   3% 62/1851 [00:28<13:03,  2.28it/s]\u001b[A\n","Iteration:   3% 63/1851 [00:28<13:03,  2.28it/s]\u001b[A\n","Iteration:   3% 64/1851 [00:29<13:04,  2.28it/s]\u001b[A\n","Iteration:   4% 65/1851 [00:29<13:04,  2.28it/s]\u001b[A\n","Iteration:   4% 66/1851 [00:30<13:04,  2.27it/s]\u001b[A\n","Iteration:   4% 67/1851 [00:30<13:03,  2.28it/s]\u001b[A\n","Iteration:   4% 68/1851 [00:30<13:02,  2.28it/s]\u001b[A\n","Iteration:   4% 69/1851 [00:31<13:01,  2.28it/s]\u001b[A\n","Iteration:   4% 70/1851 [00:31<13:00,  2.28it/s]\u001b[A\n","Iteration:   4% 71/1851 [00:32<13:01,  2.28it/s]\u001b[A\n","Iteration:   4% 72/1851 [00:32<12:59,  2.28it/s]\u001b[A\n","Iteration:   4% 73/1851 [00:33<12:59,  2.28it/s]\u001b[A\n","Iteration:   4% 74/1851 [00:33<12:58,  2.28it/s]\u001b[A\n","Iteration:   4% 75/1851 [00:33<12:57,  2.28it/s]\u001b[A\n","Iteration:   4% 76/1851 [00:34<12:57,  2.28it/s]\u001b[A\n","Iteration:   4% 77/1851 [00:34<12:56,  2.28it/s]\u001b[A\n","Iteration:   4% 78/1851 [00:35<12:56,  2.28it/s]\u001b[A\n","Iteration:   4% 79/1851 [00:35<12:55,  2.28it/s]\u001b[A\n","Iteration:   4% 80/1851 [00:36<12:55,  2.28it/s]\u001b[A\n","Iteration:   4% 81/1851 [00:36<12:54,  2.29it/s]\u001b[A\n","Iteration:   4% 82/1851 [00:37<12:54,  2.28it/s]\u001b[A\n","Iteration:   4% 83/1851 [00:37<12:53,  2.28it/s]\u001b[A\n","Iteration:   5% 84/1851 [00:37<12:53,  2.28it/s]\u001b[A\n","Iteration:   5% 85/1851 [00:38<12:53,  2.28it/s]\u001b[A\n","Iteration:   5% 86/1851 [00:38<12:53,  2.28it/s]\u001b[A\n","Iteration:   5% 87/1851 [00:39<12:53,  2.28it/s]\u001b[A\n","Iteration:   5% 88/1851 [00:39<12:52,  2.28it/s]\u001b[A\n","Iteration:   5% 89/1851 [00:40<12:51,  2.28it/s]\u001b[A\n","Iteration:   5% 90/1851 [00:40<12:50,  2.28it/s]\u001b[A\n","Iteration:   5% 91/1851 [00:40<12:50,  2.28it/s]\u001b[A\n","Iteration:   5% 92/1851 [00:41<12:50,  2.28it/s]\u001b[A\n","Iteration:   5% 93/1851 [00:41<12:50,  2.28it/s]\u001b[A\n","Iteration:   5% 94/1851 [00:42<12:49,  2.28it/s]\u001b[A\n","Iteration:   5% 95/1851 [00:42<12:48,  2.28it/s]\u001b[A\n","Iteration:   5% 96/1851 [00:43<12:48,  2.28it/s]\u001b[A\n","Iteration:   5% 97/1851 [00:43<12:50,  2.28it/s]\u001b[A\n","Iteration:   5% 98/1851 [00:44<12:49,  2.28it/s]\u001b[A\n","Iteration:   5% 99/1851 [00:44<12:48,  2.28it/s]\u001b[A\n","Iteration:   5% 100/1851 [00:44<12:47,  2.28it/s]\u001b[A\n","Iteration:   5% 101/1851 [00:45<12:46,  2.28it/s]\u001b[A\n","Iteration:   6% 102/1851 [00:45<12:45,  2.28it/s]\u001b[A\n","Iteration:   6% 103/1851 [00:46<12:45,  2.28it/s]\u001b[A\n","Iteration:   6% 104/1851 [00:46<12:45,  2.28it/s]\u001b[A\n","Iteration:   6% 105/1851 [00:47<12:45,  2.28it/s]\u001b[A\n","Iteration:   6% 106/1851 [00:47<12:44,  2.28it/s]\u001b[A\n","Iteration:   6% 107/1851 [00:47<12:43,  2.28it/s]\u001b[A\n","Iteration:   6% 108/1851 [00:48<12:44,  2.28it/s]\u001b[A\n","Iteration:   6% 109/1851 [00:48<12:43,  2.28it/s]\u001b[A\n","Iteration:   6% 110/1851 [00:49<12:42,  2.28it/s]\u001b[A\n","Iteration:   6% 111/1851 [00:49<12:42,  2.28it/s]\u001b[A\n","Iteration:   6% 112/1851 [00:50<12:41,  2.28it/s]\u001b[A\n","Iteration:   6% 113/1851 [00:50<12:40,  2.28it/s]\u001b[A\n","Iteration:   6% 114/1851 [00:51<12:40,  2.28it/s]\u001b[A\n","Iteration:   6% 115/1851 [00:51<12:40,  2.28it/s]\u001b[A\n","Iteration:   6% 116/1851 [00:51<12:40,  2.28it/s]\u001b[A\n","Iteration:   6% 117/1851 [00:52<12:40,  2.28it/s]\u001b[A\n","Iteration:   6% 118/1851 [00:52<12:39,  2.28it/s]\u001b[A\n","Iteration:   6% 119/1851 [00:53<12:38,  2.28it/s]\u001b[A\n","Iteration:   6% 120/1851 [00:53<12:37,  2.28it/s]\u001b[A\n","Iteration:   7% 121/1851 [00:54<12:36,  2.29it/s]\u001b[A\n","Iteration:   7% 122/1851 [00:54<12:36,  2.28it/s]\u001b[A\n","Iteration:   7% 123/1851 [00:54<12:36,  2.28it/s]\u001b[A\n","Iteration:   7% 124/1851 [00:55<12:35,  2.29it/s]\u001b[A\n","Iteration:   7% 125/1851 [00:55<12:35,  2.29it/s]\u001b[A\n","Iteration:   7% 126/1851 [00:56<12:38,  2.27it/s]\u001b[A\n","Iteration:   7% 127/1851 [00:56<12:37,  2.28it/s]\u001b[A\n","Iteration:   7% 128/1851 [00:57<12:38,  2.27it/s]\u001b[A\n","Iteration:   7% 129/1851 [00:57<12:37,  2.27it/s]\u001b[A\n","Iteration:   7% 130/1851 [00:58<12:36,  2.28it/s]\u001b[A\n","Iteration:   7% 131/1851 [00:58<12:35,  2.28it/s]\u001b[A\n","Iteration:   7% 132/1851 [00:58<12:33,  2.28it/s]\u001b[A\n","Iteration:   7% 133/1851 [00:59<12:33,  2.28it/s]\u001b[A\n","Iteration:   7% 134/1851 [00:59<12:32,  2.28it/s]\u001b[A\n","Iteration:   7% 135/1851 [01:00<12:32,  2.28it/s]\u001b[A\n","Iteration:   7% 136/1851 [01:00<12:31,  2.28it/s]\u001b[A\n","Iteration:   7% 137/1851 [01:01<12:30,  2.28it/s]\u001b[A\n","Iteration:   7% 138/1851 [01:01<12:30,  2.28it/s]\u001b[A\n","Iteration:   8% 139/1851 [01:02<12:29,  2.28it/s]\u001b[A\n","Iteration:   8% 140/1851 [01:02<12:29,  2.28it/s]\u001b[A\n","Iteration:   8% 141/1851 [01:02<12:28,  2.29it/s]\u001b[A\n","Iteration:   8% 142/1851 [01:03<12:28,  2.28it/s]\u001b[A\n","Iteration:   8% 143/1851 [01:03<12:27,  2.28it/s]\u001b[A\n","Iteration:   8% 144/1851 [01:04<12:27,  2.28it/s]\u001b[A\n","Iteration:   8% 145/1851 [01:04<12:32,  2.27it/s]\u001b[A\n","Iteration:   8% 146/1851 [01:05<12:32,  2.27it/s]\u001b[A\n","Iteration:   8% 147/1851 [01:05<12:31,  2.27it/s]\u001b[A\n","Iteration:   8% 148/1851 [01:05<12:31,  2.27it/s]\u001b[A\n","Iteration:   8% 149/1851 [01:06<12:30,  2.27it/s]\u001b[A\n","Iteration:   8% 150/1851 [01:06<12:28,  2.27it/s]\u001b[A\n","Iteration:   8% 151/1851 [01:07<12:29,  2.27it/s]\u001b[A\n","Iteration:   8% 152/1851 [01:07<12:29,  2.27it/s]\u001b[A\n","Iteration:   8% 153/1851 [01:08<12:29,  2.27it/s]\u001b[A\n","Iteration:   8% 154/1851 [01:08<12:28,  2.27it/s]\u001b[A\n","Iteration:   8% 155/1851 [01:09<12:25,  2.27it/s]\u001b[A\n","Iteration:   8% 156/1851 [01:09<12:24,  2.28it/s]\u001b[A\n","Iteration:   8% 157/1851 [01:09<12:22,  2.28it/s]\u001b[A\n","Iteration:   9% 158/1851 [01:10<12:22,  2.28it/s]\u001b[A\n","Iteration:   9% 159/1851 [01:10<12:21,  2.28it/s]\u001b[A\n","Iteration:   9% 160/1851 [01:11<12:20,  2.28it/s]\u001b[A\n","Iteration:   9% 161/1851 [01:11<12:19,  2.28it/s]\u001b[A\n","Iteration:   9% 162/1851 [01:12<12:20,  2.28it/s]\u001b[A\n","Iteration:   9% 163/1851 [01:12<12:19,  2.28it/s]\u001b[A\n","Iteration:   9% 164/1851 [01:12<12:19,  2.28it/s]\u001b[A\n","Iteration:   9% 165/1851 [01:13<12:18,  2.28it/s]\u001b[A\n","Iteration:   9% 166/1851 [01:13<12:17,  2.28it/s]\u001b[A\n","Iteration:   9% 167/1851 [01:14<12:17,  2.28it/s]\u001b[A\n","Iteration:   9% 168/1851 [01:14<12:17,  2.28it/s]\u001b[A\n","Iteration:   9% 169/1851 [01:15<12:17,  2.28it/s]\u001b[A\n","Iteration:   9% 170/1851 [01:15<12:16,  2.28it/s]\u001b[A\n","Iteration:   9% 171/1851 [01:16<12:17,  2.28it/s]\u001b[A\n","Iteration:   9% 172/1851 [01:16<12:19,  2.27it/s]\u001b[A\n","Iteration:   9% 173/1851 [01:16<12:18,  2.27it/s]\u001b[A\n","Iteration:   9% 174/1851 [01:17<12:16,  2.28it/s]\u001b[A\n","Iteration:   9% 175/1851 [01:17<12:15,  2.28it/s]\u001b[A\n","Iteration:  10% 176/1851 [01:18<12:15,  2.28it/s]\u001b[A\n","Iteration:  10% 177/1851 [01:18<12:13,  2.28it/s]\u001b[A\n","Iteration:  10% 178/1851 [01:19<12:13,  2.28it/s]\u001b[A\n","Iteration:  10% 179/1851 [01:19<12:12,  2.28it/s]\u001b[A\n","Iteration:  10% 180/1851 [01:20<12:11,  2.28it/s]\u001b[A\n","Iteration:  10% 181/1851 [01:20<12:11,  2.28it/s]\u001b[A\n","Iteration:  10% 182/1851 [01:20<12:10,  2.29it/s]\u001b[A\n","Iteration:  10% 183/1851 [01:21<12:10,  2.28it/s]\u001b[A\n","Iteration:  10% 184/1851 [01:21<12:09,  2.29it/s]\u001b[A\n","Iteration:  10% 185/1851 [01:22<12:09,  2.28it/s]\u001b[A\n","Iteration:  10% 186/1851 [01:22<12:08,  2.28it/s]\u001b[A\n","Iteration:  10% 187/1851 [01:23<12:08,  2.28it/s]\u001b[A\n","Iteration:  10% 188/1851 [01:23<12:10,  2.28it/s]\u001b[A\n","Iteration:  10% 189/1851 [01:23<12:09,  2.28it/s]\u001b[A\n","Iteration:  10% 190/1851 [01:24<12:07,  2.28it/s]\u001b[A\n","Iteration:  10% 191/1851 [01:24<12:07,  2.28it/s]\u001b[A\n","Iteration:  10% 192/1851 [01:25<12:07,  2.28it/s]\u001b[A\n","Iteration:  10% 193/1851 [01:25<12:06,  2.28it/s]\u001b[A\n","Iteration:  10% 194/1851 [01:26<12:06,  2.28it/s]\u001b[A\n","Iteration:  11% 195/1851 [01:26<12:05,  2.28it/s]\u001b[A\n","Iteration:  11% 196/1851 [01:27<12:05,  2.28it/s]\u001b[A\n","Iteration:  11% 197/1851 [01:27<12:04,  2.28it/s]\u001b[A\n","Iteration:  11% 198/1851 [01:27<12:04,  2.28it/s]\u001b[A\n","Iteration:  11% 199/1851 [01:28<12:03,  2.28it/s]\u001b[A\n","Iteration:  11% 200/1851 [01:28<12:02,  2.28it/s]\u001b[A\n","Iteration:  11% 201/1851 [01:29<12:02,  2.28it/s]\u001b[A\n","Iteration:  11% 202/1851 [01:29<12:02,  2.28it/s]\u001b[A\n","Iteration:  11% 203/1851 [01:30<12:02,  2.28it/s]\u001b[A\n","Iteration:  11% 204/1851 [01:30<12:01,  2.28it/s]\u001b[A\n","Iteration:  11% 205/1851 [01:30<12:00,  2.28it/s]\u001b[A\n","Iteration:  11% 206/1851 [01:31<12:00,  2.28it/s]\u001b[A\n","Iteration:  11% 207/1851 [01:31<12:00,  2.28it/s]\u001b[A\n","Iteration:  11% 208/1851 [01:32<11:59,  2.28it/s]\u001b[A\n","Iteration:  11% 209/1851 [01:32<11:59,  2.28it/s]\u001b[A\n","Iteration:  11% 210/1851 [01:33<11:59,  2.28it/s]\u001b[A\n","Iteration:  11% 211/1851 [01:33<11:58,  2.28it/s]\u001b[A\n","Iteration:  11% 212/1851 [01:34<11:57,  2.28it/s]\u001b[A\n","Iteration:  12% 213/1851 [01:34<11:57,  2.28it/s]\u001b[A\n","Iteration:  12% 214/1851 [01:34<11:56,  2.28it/s]\u001b[A\n","Iteration:  12% 215/1851 [01:35<11:56,  2.28it/s]\u001b[A\n","Iteration:  12% 216/1851 [01:35<11:56,  2.28it/s]\u001b[A\n","Iteration:  12% 217/1851 [01:36<11:55,  2.28it/s]\u001b[A\n","Iteration:  12% 218/1851 [01:36<11:55,  2.28it/s]\u001b[A\n","Iteration:  12% 219/1851 [01:37<11:55,  2.28it/s]\u001b[A\n","Iteration:  12% 220/1851 [01:37<11:54,  2.28it/s]\u001b[A\n","Iteration:  12% 221/1851 [01:37<11:53,  2.28it/s]\u001b[A\n","Iteration:  12% 222/1851 [01:38<11:53,  2.28it/s]\u001b[A\n","Iteration:  12% 223/1851 [01:38<11:54,  2.28it/s]\u001b[A\n","Iteration:  12% 224/1851 [01:39<11:53,  2.28it/s]\u001b[A\n","Iteration:  12% 225/1851 [01:39<11:52,  2.28it/s]\u001b[A\n","Iteration:  12% 226/1851 [01:40<11:51,  2.28it/s]\u001b[A\n","Iteration:  12% 227/1851 [01:40<11:51,  2.28it/s]\u001b[A\n","Iteration:  12% 228/1851 [01:41<11:50,  2.28it/s]\u001b[A\n","Iteration:  12% 229/1851 [01:41<11:50,  2.28it/s]\u001b[A\n","Iteration:  12% 230/1851 [01:41<11:49,  2.28it/s]\u001b[A\n","Iteration:  12% 231/1851 [01:42<11:49,  2.28it/s]\u001b[A\n","Iteration:  13% 232/1851 [01:42<11:49,  2.28it/s]\u001b[A\n","Iteration:  13% 233/1851 [01:43<11:48,  2.28it/s]\u001b[A\n","Iteration:  13% 234/1851 [01:43<11:47,  2.28it/s]\u001b[A\n","Iteration:  13% 235/1851 [01:44<11:48,  2.28it/s]\u001b[A\n","Iteration:  13% 236/1851 [01:44<11:47,  2.28it/s]\u001b[A\n","Iteration:  13% 237/1851 [01:44<11:46,  2.28it/s]\u001b[A\n","Iteration:  13% 238/1851 [01:45<11:46,  2.28it/s]\u001b[A\n","Iteration:  13% 239/1851 [01:45<11:45,  2.28it/s]\u001b[A\n","Iteration:  13% 240/1851 [01:46<11:45,  2.28it/s]\u001b[A\n","Iteration:  13% 241/1851 [01:46<11:45,  2.28it/s]\u001b[A\n","Iteration:  13% 242/1851 [01:47<11:45,  2.28it/s]\u001b[A\n","Iteration:  13% 243/1851 [01:47<11:45,  2.28it/s]\u001b[A\n","Iteration:  13% 244/1851 [01:48<11:45,  2.28it/s]\u001b[A\n","Iteration:  13% 245/1851 [01:48<11:44,  2.28it/s]\u001b[A\n","Iteration:  13% 246/1851 [01:48<11:43,  2.28it/s]\u001b[A\n","Iteration:  13% 247/1851 [01:49<11:43,  2.28it/s]\u001b[A\n","Iteration:  13% 248/1851 [01:49<11:42,  2.28it/s]\u001b[A\n","Iteration:  13% 249/1851 [01:50<11:41,  2.28it/s]\u001b[A\n","Iteration:  14% 250/1851 [01:50<11:41,  2.28it/s]\u001b[A\n","Iteration:  14% 251/1851 [01:51<11:41,  2.28it/s]\u001b[A\n","Iteration:  14% 252/1851 [01:51<11:41,  2.28it/s]\u001b[A\n","Iteration:  14% 253/1851 [01:51<11:42,  2.28it/s]\u001b[A\n","Iteration:  14% 254/1851 [01:52<11:41,  2.28it/s]\u001b[A\n","Iteration:  14% 255/1851 [01:52<11:40,  2.28it/s]\u001b[A\n","Iteration:  14% 256/1851 [01:53<11:40,  2.28it/s]\u001b[A\n","Iteration:  14% 257/1851 [01:53<11:39,  2.28it/s]\u001b[A\n","Iteration:  14% 258/1851 [01:54<11:38,  2.28it/s]\u001b[A\n","Iteration:  14% 259/1851 [01:54<11:37,  2.28it/s]\u001b[A\n","Iteration:  14% 260/1851 [01:55<11:37,  2.28it/s]\u001b[A\n","Iteration:  14% 261/1851 [01:55<11:36,  2.28it/s]\u001b[A\n","Iteration:  14% 262/1851 [01:55<11:36,  2.28it/s]\u001b[A\n","Iteration:  14% 263/1851 [01:56<11:34,  2.28it/s]\u001b[A\n","Iteration:  14% 264/1851 [01:56<11:34,  2.28it/s]\u001b[A\n","Iteration:  14% 265/1851 [01:57<11:34,  2.28it/s]\u001b[A\n","Iteration:  14% 266/1851 [01:57<11:34,  2.28it/s]\u001b[A\n","Iteration:  14% 267/1851 [01:58<11:33,  2.28it/s]\u001b[A\n","Iteration:  14% 268/1851 [01:58<11:32,  2.28it/s]\u001b[A\n","Iteration:  15% 269/1851 [01:59<11:32,  2.28it/s]\u001b[A\n","Iteration:  15% 270/1851 [01:59<11:32,  2.28it/s]\u001b[A\n","Iteration:  15% 271/1851 [01:59<11:32,  2.28it/s]\u001b[A\n","Iteration:  15% 272/1851 [02:00<11:32,  2.28it/s]\u001b[A\n","Iteration:  15% 273/1851 [02:00<11:32,  2.28it/s]\u001b[A\n","Iteration:  15% 274/1851 [02:01<11:31,  2.28it/s]\u001b[A\n","Iteration:  15% 275/1851 [02:01<11:30,  2.28it/s]\u001b[A\n","Iteration:  15% 276/1851 [02:02<11:29,  2.28it/s]\u001b[A\n","Iteration:  15% 277/1851 [02:02<11:29,  2.28it/s]\u001b[A\n","Iteration:  15% 278/1851 [02:02<11:28,  2.28it/s]\u001b[A\n","Iteration:  15% 279/1851 [02:03<11:27,  2.28it/s]\u001b[A\n","Iteration:  15% 280/1851 [02:03<11:27,  2.28it/s]\u001b[A\n","Iteration:  15% 281/1851 [02:04<11:27,  2.28it/s]\u001b[A\n","Iteration:  15% 282/1851 [02:04<11:26,  2.28it/s]\u001b[A\n","Iteration:  15% 283/1851 [02:05<11:26,  2.29it/s]\u001b[A\n","Iteration:  15% 284/1851 [02:05<11:25,  2.29it/s]\u001b[A\n","Iteration:  15% 285/1851 [02:06<11:25,  2.28it/s]\u001b[A\n","Iteration:  15% 286/1851 [02:06<11:25,  2.28it/s]\u001b[A\n","Iteration:  16% 287/1851 [02:06<11:24,  2.28it/s]\u001b[A\n","Iteration:  16% 288/1851 [02:07<11:24,  2.28it/s]\u001b[A\n","Iteration:  16% 289/1851 [02:07<11:25,  2.28it/s]\u001b[A\n","Iteration:  16% 290/1851 [02:08<11:27,  2.27it/s]\u001b[A\n","Iteration:  16% 291/1851 [02:08<11:25,  2.28it/s]\u001b[A\n","Iteration:  16% 292/1851 [02:09<11:24,  2.28it/s]\u001b[A\n","Iteration:  16% 293/1851 [02:09<11:24,  2.28it/s]\u001b[A\n","Iteration:  16% 294/1851 [02:09<11:22,  2.28it/s]\u001b[A\n","Iteration:  16% 295/1851 [02:10<11:21,  2.28it/s]\u001b[A\n","Iteration:  16% 296/1851 [02:10<11:21,  2.28it/s]\u001b[A\n","Iteration:  16% 297/1851 [02:11<11:20,  2.28it/s]\u001b[A\n","Iteration:  16% 298/1851 [02:11<11:21,  2.28it/s]\u001b[A\n","Iteration:  16% 299/1851 [02:12<11:20,  2.28it/s]\u001b[A\n","Iteration:  16% 300/1851 [02:12<11:20,  2.28it/s]\u001b[A\n","Iteration:  16% 301/1851 [02:13<11:19,  2.28it/s]\u001b[A\n","Iteration:  16% 302/1851 [02:13<11:18,  2.28it/s]\u001b[A\n","Iteration:  16% 303/1851 [02:13<11:19,  2.28it/s]\u001b[A\n","Iteration:  16% 304/1851 [02:14<11:18,  2.28it/s]\u001b[A\n","Iteration:  16% 305/1851 [02:14<11:17,  2.28it/s]\u001b[A\n","Iteration:  17% 306/1851 [02:15<11:16,  2.28it/s]\u001b[A\n","Iteration:  17% 307/1851 [02:15<11:17,  2.28it/s]\u001b[A\n","Iteration:  17% 308/1851 [02:16<11:17,  2.28it/s]\u001b[A\n","Iteration:  17% 309/1851 [02:16<11:16,  2.28it/s]\u001b[A\n","Iteration:  17% 310/1851 [02:16<11:15,  2.28it/s]\u001b[A\n","Iteration:  17% 311/1851 [02:17<11:15,  2.28it/s]\u001b[A\n","Iteration:  17% 312/1851 [02:17<11:14,  2.28it/s]\u001b[A\n","Iteration:  17% 313/1851 [02:18<11:13,  2.28it/s]\u001b[A\n","Iteration:  17% 314/1851 [02:18<11:13,  2.28it/s]\u001b[A\n","Iteration:  17% 315/1851 [02:19<11:12,  2.28it/s]\u001b[A\n","Iteration:  17% 316/1851 [02:19<11:12,  2.28it/s]\u001b[A\n","Iteration:  17% 317/1851 [02:20<11:11,  2.28it/s]\u001b[A\n","Iteration:  17% 318/1851 [02:20<11:10,  2.28it/s]\u001b[A\n","Iteration:  17% 319/1851 [02:20<11:10,  2.28it/s]\u001b[A\n","Iteration:  17% 320/1851 [02:21<11:10,  2.28it/s]\u001b[A\n","Iteration:  17% 321/1851 [02:21<11:09,  2.28it/s]\u001b[A\n","Iteration:  17% 322/1851 [02:22<11:09,  2.28it/s]\u001b[A\n","Iteration:  17% 323/1851 [02:22<11:08,  2.28it/s]\u001b[A\n","Iteration:  18% 324/1851 [02:23<11:08,  2.29it/s]\u001b[A\n","Iteration:  18% 325/1851 [02:23<11:07,  2.29it/s]\u001b[A\n","Iteration:  18% 326/1851 [02:23<11:07,  2.29it/s]\u001b[A\n","Iteration:  18% 327/1851 [02:24<11:06,  2.29it/s]\u001b[A\n","Iteration:  18% 328/1851 [02:24<11:07,  2.28it/s]\u001b[A\n","Iteration:  18% 329/1851 [02:25<11:06,  2.28it/s]\u001b[A\n","Iteration:  18% 330/1851 [02:25<11:06,  2.28it/s]\u001b[A\n","Iteration:  18% 331/1851 [02:26<11:05,  2.28it/s]\u001b[A\n","Iteration:  18% 332/1851 [02:26<11:04,  2.28it/s]\u001b[A\n","Iteration:  18% 333/1851 [02:27<11:04,  2.29it/s]\u001b[A\n","Iteration:  18% 334/1851 [02:27<11:04,  2.28it/s]\u001b[A\n","Iteration:  18% 335/1851 [02:27<11:03,  2.28it/s]\u001b[A\n","Iteration:  18% 336/1851 [02:28<11:02,  2.29it/s]\u001b[A\n","Iteration:  18% 337/1851 [02:28<11:02,  2.28it/s]\u001b[A\n","Iteration:  18% 338/1851 [02:29<11:02,  2.28it/s]\u001b[A\n","Iteration:  18% 339/1851 [02:29<11:01,  2.28it/s]\u001b[A\n","Iteration:  18% 340/1851 [02:30<11:01,  2.28it/s]\u001b[A\n","Iteration:  18% 341/1851 [02:30<11:01,  2.28it/s]\u001b[A\n","Iteration:  18% 342/1851 [02:30<11:00,  2.29it/s]\u001b[A\n","Iteration:  19% 343/1851 [02:31<11:00,  2.28it/s]\u001b[A\n","Iteration:  19% 344/1851 [02:31<11:00,  2.28it/s]\u001b[A\n","Iteration:  19% 345/1851 [02:32<11:00,  2.28it/s]\u001b[A\n","Iteration:  19% 346/1851 [02:32<10:59,  2.28it/s]\u001b[A\n","Iteration:  19% 347/1851 [02:33<10:59,  2.28it/s]\u001b[A\n","Iteration:  19% 348/1851 [02:33<10:58,  2.28it/s]\u001b[A\n","Iteration:  19% 349/1851 [02:34<10:58,  2.28it/s]\u001b[A\n","Iteration:  19% 350/1851 [02:34<10:57,  2.28it/s]\u001b[A\n","Iteration:  19% 351/1851 [02:34<10:57,  2.28it/s]\u001b[A\n","Iteration:  19% 352/1851 [02:35<10:56,  2.28it/s]\u001b[A\n","Iteration:  19% 353/1851 [02:35<10:55,  2.28it/s]\u001b[A\n","Iteration:  19% 354/1851 [02:36<10:55,  2.28it/s]\u001b[A\n","Iteration:  19% 355/1851 [02:36<10:54,  2.28it/s]\u001b[A\n","Iteration:  19% 356/1851 [02:37<10:54,  2.29it/s]\u001b[A\n","Iteration:  19% 357/1851 [02:37<10:54,  2.28it/s]\u001b[A\n","Iteration:  19% 358/1851 [02:37<10:53,  2.28it/s]\u001b[A\n","Iteration:  19% 359/1851 [02:38<10:53,  2.28it/s]\u001b[A\n","Iteration:  19% 360/1851 [02:38<10:52,  2.28it/s]\u001b[A\n","Iteration:  20% 361/1851 [02:39<10:52,  2.28it/s]\u001b[A\n","Iteration:  20% 362/1851 [02:39<10:52,  2.28it/s]\u001b[A\n","Iteration:  20% 363/1851 [02:40<10:53,  2.28it/s]\u001b[A\n","Iteration:  20% 364/1851 [02:40<10:52,  2.28it/s]\u001b[A\n","Iteration:  20% 365/1851 [02:41<10:53,  2.27it/s]\u001b[A\n","Iteration:  20% 366/1851 [02:41<10:53,  2.27it/s]\u001b[A\n","Iteration:  20% 367/1851 [02:41<10:53,  2.27it/s]\u001b[A\n","Iteration:  20% 368/1851 [02:42<10:54,  2.27it/s]\u001b[A\n","Iteration:  20% 369/1851 [02:42<10:53,  2.27it/s]\u001b[A\n","Iteration:  20% 370/1851 [02:43<10:52,  2.27it/s]\u001b[A\n","Iteration:  20% 371/1851 [02:43<10:51,  2.27it/s]\u001b[A\n","Iteration:  20% 372/1851 [02:44<10:49,  2.28it/s]\u001b[A\n","Iteration:  20% 373/1851 [02:44<10:49,  2.28it/s]\u001b[A\n","Iteration:  20% 374/1851 [02:45<10:47,  2.28it/s]\u001b[A\n","Iteration:  20% 375/1851 [02:45<10:47,  2.28it/s]\u001b[A\n","Iteration:  20% 376/1851 [02:45<10:46,  2.28it/s]\u001b[A\n","Iteration:  20% 377/1851 [02:46<10:46,  2.28it/s]\u001b[A\n","Iteration:  20% 378/1851 [02:46<10:45,  2.28it/s]\u001b[A\n","Iteration:  20% 379/1851 [02:47<10:45,  2.28it/s]\u001b[A\n","Iteration:  21% 380/1851 [02:47<10:44,  2.28it/s]\u001b[A\n","Iteration:  21% 381/1851 [02:48<10:44,  2.28it/s]\u001b[A\n","Iteration:  21% 382/1851 [02:48<10:44,  2.28it/s]\u001b[A\n","Iteration:  21% 383/1851 [02:48<10:43,  2.28it/s]\u001b[A\n","Iteration:  21% 384/1851 [02:49<10:43,  2.28it/s]\u001b[A\n","Iteration:  21% 385/1851 [02:49<10:43,  2.28it/s]\u001b[A\n","Iteration:  21% 386/1851 [02:50<10:42,  2.28it/s]\u001b[A\n","Iteration:  21% 387/1851 [02:50<10:41,  2.28it/s]\u001b[A\n","Iteration:  21% 388/1851 [02:51<10:41,  2.28it/s]\u001b[A\n","Iteration:  21% 389/1851 [02:51<10:40,  2.28it/s]\u001b[A\n","Iteration:  21% 390/1851 [02:52<10:40,  2.28it/s]\u001b[A\n","Iteration:  21% 391/1851 [02:52<10:39,  2.28it/s]\u001b[A\n","Iteration:  21% 392/1851 [02:52<10:39,  2.28it/s]\u001b[A\n","Iteration:  21% 393/1851 [02:53<10:39,  2.28it/s]\u001b[A\n","Iteration:  21% 394/1851 [02:53<10:38,  2.28it/s]\u001b[A\n","Iteration:  21% 395/1851 [02:54<10:38,  2.28it/s]\u001b[A\n","Iteration:  21% 396/1851 [02:54<10:38,  2.28it/s]\u001b[A\n","Iteration:  21% 397/1851 [02:55<10:38,  2.28it/s]\u001b[A\n","Iteration:  22% 398/1851 [02:55<10:38,  2.28it/s]\u001b[A\n","Iteration:  22% 399/1851 [02:55<10:36,  2.28it/s]\u001b[A\n","Iteration:  22% 400/1851 [02:56<10:36,  2.28it/s]\u001b[A\n","Iteration:  22% 401/1851 [02:56<10:35,  2.28it/s]\u001b[A\n","Iteration:  22% 402/1851 [02:57<10:35,  2.28it/s]\u001b[A\n","Iteration:  22% 403/1851 [02:57<10:34,  2.28it/s]\u001b[A\n","Iteration:  22% 404/1851 [02:58<10:34,  2.28it/s]\u001b[A\n","Iteration:  22% 405/1851 [02:58<10:33,  2.28it/s]\u001b[A\n","Iteration:  22% 406/1851 [02:59<10:33,  2.28it/s]\u001b[A\n","Iteration:  22% 407/1851 [02:59<10:33,  2.28it/s]\u001b[A\n","Iteration:  22% 408/1851 [02:59<10:33,  2.28it/s]\u001b[A\n","Iteration:  22% 409/1851 [03:00<10:32,  2.28it/s]\u001b[A\n","Iteration:  22% 410/1851 [03:00<10:32,  2.28it/s]\u001b[A\n","Iteration:  22% 411/1851 [03:01<10:31,  2.28it/s]\u001b[A\n","Iteration:  22% 412/1851 [03:01<10:31,  2.28it/s]\u001b[A\n","Iteration:  22% 413/1851 [03:02<10:30,  2.28it/s]\u001b[A\n","Iteration:  22% 414/1851 [03:02<10:31,  2.28it/s]\u001b[A\n","Iteration:  22% 415/1851 [03:03<10:30,  2.28it/s]\u001b[A\n","Iteration:  22% 416/1851 [03:03<10:29,  2.28it/s]\u001b[A\n","Iteration:  23% 417/1851 [03:03<10:29,  2.28it/s]\u001b[A\n","Iteration:  23% 418/1851 [03:04<10:28,  2.28it/s]\u001b[A\n","Iteration:  23% 419/1851 [03:04<10:28,  2.28it/s]\u001b[A\n","Iteration:  23% 420/1851 [03:05<10:27,  2.28it/s]\u001b[A\n","Iteration:  23% 421/1851 [03:05<10:26,  2.28it/s]\u001b[A\n","Iteration:  23% 422/1851 [03:06<10:26,  2.28it/s]\u001b[A\n","Iteration:  23% 423/1851 [03:06<10:25,  2.28it/s]\u001b[A\n","Iteration:  23% 424/1851 [03:06<10:24,  2.28it/s]\u001b[A\n","Iteration:  23% 425/1851 [03:07<10:24,  2.28it/s]\u001b[A\n","Iteration:  23% 426/1851 [03:07<10:24,  2.28it/s]\u001b[A\n","Iteration:  23% 427/1851 [03:08<10:24,  2.28it/s]\u001b[A\n","Iteration:  23% 428/1851 [03:08<10:23,  2.28it/s]\u001b[A\n","Iteration:  23% 429/1851 [03:09<10:23,  2.28it/s]\u001b[A\n","Iteration:  23% 430/1851 [03:09<10:23,  2.28it/s]\u001b[A\n","Iteration:  23% 431/1851 [03:10<10:22,  2.28it/s]\u001b[A\n","Iteration:  23% 432/1851 [03:10<10:22,  2.28it/s]\u001b[A\n","Iteration:  23% 433/1851 [03:10<10:21,  2.28it/s]\u001b[A\n","Iteration:  23% 434/1851 [03:11<10:21,  2.28it/s]\u001b[A\n","Iteration:  24% 435/1851 [03:11<10:20,  2.28it/s]\u001b[A\n","Iteration:  24% 436/1851 [03:12<10:19,  2.28it/s]\u001b[A\n","Iteration:  24% 437/1851 [03:12<10:19,  2.28it/s]\u001b[A\n","Iteration:  24% 438/1851 [03:13<10:18,  2.28it/s]\u001b[A\n","Iteration:  24% 439/1851 [03:13<10:18,  2.28it/s]\u001b[A\n","Iteration:  24% 440/1851 [03:13<10:17,  2.28it/s]\u001b[A\n","Iteration:  24% 441/1851 [03:14<10:17,  2.28it/s]\u001b[A\n","Iteration:  24% 442/1851 [03:14<10:17,  2.28it/s]\u001b[A\n","Iteration:  24% 443/1851 [03:15<10:16,  2.28it/s]\u001b[A\n","Iteration:  24% 444/1851 [03:15<10:17,  2.28it/s]\u001b[A\n","Iteration:  24% 445/1851 [03:16<10:16,  2.28it/s]\u001b[A\n","Iteration:  24% 446/1851 [03:16<10:15,  2.28it/s]\u001b[A\n","Iteration:  24% 447/1851 [03:17<10:15,  2.28it/s]\u001b[A\n","Iteration:  24% 448/1851 [03:17<10:15,  2.28it/s]\u001b[A\n","Iteration:  24% 449/1851 [03:17<10:14,  2.28it/s]\u001b[A\n","Iteration:  24% 450/1851 [03:18<10:15,  2.28it/s]\u001b[A\n","Iteration:  24% 451/1851 [03:18<10:15,  2.28it/s]\u001b[A\n","Iteration:  24% 452/1851 [03:19<10:13,  2.28it/s]\u001b[A\n","Iteration:  24% 453/1851 [03:19<10:12,  2.28it/s]\u001b[A\n","Iteration:  25% 454/1851 [03:20<10:12,  2.28it/s]\u001b[A\n","Iteration:  25% 455/1851 [03:20<10:12,  2.28it/s]\u001b[A\n","Iteration:  25% 456/1851 [03:20<10:11,  2.28it/s]\u001b[A\n","Iteration:  25% 457/1851 [03:21<10:10,  2.28it/s]\u001b[A\n","Iteration:  25% 458/1851 [03:21<10:25,  2.23it/s]\u001b[A\n","Iteration:  25% 459/1851 [03:22<10:20,  2.24it/s]\u001b[A\n","Iteration:  25% 460/1851 [03:22<11:44,  1.97it/s]\u001b[A\n","Iteration:  25% 461/1851 [03:23<11:15,  2.06it/s]\u001b[A\n","Iteration:  25% 462/1851 [03:23<10:54,  2.12it/s]\u001b[A\n","Iteration:  25% 463/1851 [03:24<10:40,  2.17it/s]\u001b[A\n","Iteration:  25% 464/1851 [03:24<10:30,  2.20it/s]\u001b[A\n","Iteration:  25% 465/1851 [03:25<10:23,  2.22it/s]\u001b[A\n","Iteration:  25% 466/1851 [03:25<10:18,  2.24it/s]\u001b[A\n","Iteration:  25% 467/1851 [03:26<10:14,  2.25it/s]\u001b[A\n","Iteration:  25% 468/1851 [03:26<10:12,  2.26it/s]\u001b[A\n","Iteration:  25% 469/1851 [03:26<10:10,  2.26it/s]\u001b[A\n","Iteration:  25% 470/1851 [03:27<10:08,  2.27it/s]\u001b[A\n","Iteration:  25% 471/1851 [03:27<10:07,  2.27it/s]\u001b[A\n","Iteration:  25% 472/1851 [03:28<10:06,  2.27it/s]\u001b[A\n","Iteration:  26% 473/1851 [03:28<10:05,  2.28it/s]\u001b[A\n","Iteration:  26% 474/1851 [03:29<10:04,  2.28it/s]\u001b[A\n","Iteration:  26% 475/1851 [03:29<10:03,  2.28it/s]\u001b[A\n","Iteration:  26% 476/1851 [03:29<10:02,  2.28it/s]\u001b[A\n","Iteration:  26% 477/1851 [03:30<10:02,  2.28it/s]\u001b[A\n","Iteration:  26% 478/1851 [03:30<10:03,  2.27it/s]\u001b[A\n","Iteration:  26% 479/1851 [03:31<11:20,  2.02it/s]\u001b[A\n","Iteration:  26% 480/1851 [03:31<10:55,  2.09it/s]\u001b[A\n","Iteration:  26% 481/1851 [03:32<10:38,  2.14it/s]\u001b[A\n","Iteration:  26% 482/1851 [03:32<10:26,  2.18it/s]\u001b[A\n","Iteration:  26% 483/1851 [03:33<10:19,  2.21it/s]\u001b[A\n","Iteration:  26% 484/1851 [03:33<10:13,  2.23it/s]\u001b[A\n","Iteration:  26% 485/1851 [03:34<10:08,  2.25it/s]\u001b[A\n","Iteration:  26% 486/1851 [03:34<10:05,  2.26it/s]\u001b[A\n","Iteration:  26% 487/1851 [03:35<10:02,  2.26it/s]\u001b[A\n","Iteration:  26% 488/1851 [03:35<10:01,  2.27it/s]\u001b[A\n","Iteration:  26% 489/1851 [03:35<09:59,  2.27it/s]\u001b[A\n","Iteration:  26% 490/1851 [03:36<09:58,  2.28it/s]\u001b[A\n","Iteration:  27% 491/1851 [03:36<09:57,  2.28it/s]\u001b[A\n","Iteration:  27% 492/1851 [03:37<09:56,  2.28it/s]\u001b[A\n","Iteration:  27% 493/1851 [03:37<09:56,  2.28it/s]\u001b[A\n","Iteration:  27% 494/1851 [03:38<09:56,  2.28it/s]\u001b[A\n","Iteration:  27% 495/1851 [03:38<09:55,  2.28it/s]\u001b[A\n","Iteration:  27% 496/1851 [03:38<09:56,  2.27it/s]\u001b[A\n","Iteration:  27% 497/1851 [03:39<09:54,  2.28it/s]\u001b[A\n","Iteration:  27% 498/1851 [03:39<09:53,  2.28it/s]\u001b[A\n","Iteration:  27% 499/1851 [03:40<09:53,  2.28it/s]\u001b[A\n","Iteration:  27% 500/1851 [03:40<09:54,  2.27it/s]\u001b[A\n","Iteration:  27% 501/1851 [03:41<09:53,  2.27it/s]\u001b[A\n","Iteration:  27% 502/1851 [03:41<09:52,  2.28it/s]\u001b[A\n","Iteration:  27% 503/1851 [03:42<09:52,  2.28it/s]\u001b[A\n","Iteration:  27% 504/1851 [03:42<09:51,  2.28it/s]\u001b[A\n","Iteration:  27% 505/1851 [03:42<09:50,  2.28it/s]\u001b[A\n","Iteration:  27% 506/1851 [03:43<09:50,  2.28it/s]\u001b[A\n","Iteration:  27% 507/1851 [03:43<09:49,  2.28it/s]\u001b[A\n","Iteration:  27% 508/1851 [03:44<09:49,  2.28it/s]\u001b[A\n","Iteration:  27% 509/1851 [03:44<09:48,  2.28it/s]\u001b[A\n","Iteration:  28% 510/1851 [03:45<09:47,  2.28it/s]\u001b[A\n","Iteration:  28% 511/1851 [03:45<09:46,  2.28it/s]\u001b[A\n","Iteration:  28% 512/1851 [03:45<09:46,  2.28it/s]\u001b[A\n","Iteration:  28% 513/1851 [03:46<09:46,  2.28it/s]\u001b[A\n","Iteration:  28% 514/1851 [03:46<09:45,  2.28it/s]\u001b[A\n","Iteration:  28% 515/1851 [03:47<09:45,  2.28it/s]\u001b[A\n","Iteration:  28% 516/1851 [03:47<09:45,  2.28it/s]\u001b[A\n","Iteration:  28% 517/1851 [03:48<09:44,  2.28it/s]\u001b[A\n","Iteration:  28% 518/1851 [03:48<09:44,  2.28it/s]\u001b[A\n","Iteration:  28% 519/1851 [03:49<09:43,  2.28it/s]\u001b[A\n","Iteration:  28% 520/1851 [03:49<09:43,  2.28it/s]\u001b[A\n","Iteration:  28% 521/1851 [03:49<09:43,  2.28it/s]\u001b[A\n","Iteration:  28% 522/1851 [03:50<09:42,  2.28it/s]\u001b[A\n","Iteration:  28% 523/1851 [03:50<09:42,  2.28it/s]\u001b[A\n","Iteration:  28% 524/1851 [03:51<09:41,  2.28it/s]\u001b[A\n","Iteration:  28% 525/1851 [03:51<09:41,  2.28it/s]\u001b[A\n","Iteration:  28% 526/1851 [03:52<09:41,  2.28it/s]\u001b[A\n","Iteration:  28% 527/1851 [03:52<09:40,  2.28it/s]\u001b[A\n","Iteration:  29% 528/1851 [03:52<09:39,  2.28it/s]\u001b[A\n","Iteration:  29% 529/1851 [03:53<09:39,  2.28it/s]\u001b[A\n","Iteration:  29% 530/1851 [03:53<09:39,  2.28it/s]\u001b[A\n","Iteration:  29% 531/1851 [03:54<09:39,  2.28it/s]\u001b[A\n","Iteration:  29% 532/1851 [03:54<09:38,  2.28it/s]\u001b[A\n","Iteration:  29% 533/1851 [03:55<09:37,  2.28it/s]\u001b[A\n","Iteration:  29% 534/1851 [03:55<09:36,  2.28it/s]\u001b[A\n","Iteration:  29% 535/1851 [03:56<09:36,  2.28it/s]\u001b[A\n","Iteration:  29% 536/1851 [03:56<09:36,  2.28it/s]\u001b[A\n","Iteration:  29% 537/1851 [03:56<09:36,  2.28it/s]\u001b[A\n","Iteration:  29% 538/1851 [03:57<09:36,  2.28it/s]\u001b[A\n","Iteration:  29% 539/1851 [03:57<09:36,  2.28it/s]\u001b[A\n","Iteration:  29% 540/1851 [03:58<09:34,  2.28it/s]\u001b[A\n","Iteration:  29% 541/1851 [03:58<09:34,  2.28it/s]\u001b[A\n","Iteration:  29% 542/1851 [03:59<09:33,  2.28it/s]\u001b[A\n","Iteration:  29% 543/1851 [03:59<09:33,  2.28it/s]\u001b[A\n","Iteration:  29% 544/1851 [04:00<09:32,  2.28it/s]\u001b[A\n","Iteration:  29% 545/1851 [04:00<09:32,  2.28it/s]\u001b[A\n","Iteration:  29% 546/1851 [04:00<09:31,  2.28it/s]\u001b[A\n","Iteration:  30% 547/1851 [04:01<09:31,  2.28it/s]\u001b[A\n","Iteration:  30% 548/1851 [04:01<09:30,  2.28it/s]\u001b[A\n","Iteration:  30% 549/1851 [04:02<09:30,  2.28it/s]\u001b[A\n","Iteration:  30% 550/1851 [04:02<09:29,  2.28it/s]\u001b[A\n","Iteration:  30% 551/1851 [04:03<09:29,  2.28it/s]\u001b[A\n","Iteration:  30% 552/1851 [04:03<09:28,  2.28it/s]\u001b[A\n","Iteration:  30% 553/1851 [04:03<09:28,  2.28it/s]\u001b[A\n","Iteration:  30% 554/1851 [04:04<09:27,  2.28it/s]\u001b[A\n","Iteration:  30% 555/1851 [04:04<09:27,  2.28it/s]\u001b[A\n","Iteration:  30% 556/1851 [04:05<09:26,  2.28it/s]\u001b[A\n","Iteration:  30% 557/1851 [04:05<09:26,  2.28it/s]\u001b[A\n","Iteration:  30% 558/1851 [04:06<09:25,  2.29it/s]\u001b[A\n","Iteration:  30% 559/1851 [04:06<09:25,  2.29it/s]\u001b[A\n","Iteration:  30% 560/1851 [04:07<09:25,  2.28it/s]\u001b[A\n","Iteration:  30% 561/1851 [04:07<09:24,  2.28it/s]\u001b[A\n","Iteration:  30% 562/1851 [04:07<09:24,  2.28it/s]\u001b[A\n","Iteration:  30% 563/1851 [04:08<09:24,  2.28it/s]\u001b[A\n","Iteration:  30% 564/1851 [04:08<09:24,  2.28it/s]\u001b[A\n","Iteration:  31% 565/1851 [04:09<09:23,  2.28it/s]\u001b[A\n","Iteration:  31% 566/1851 [04:09<09:23,  2.28it/s]\u001b[A\n","Iteration:  31% 567/1851 [04:10<09:23,  2.28it/s]\u001b[A\n","Iteration:  31% 568/1851 [04:10<09:22,  2.28it/s]\u001b[A\n","Iteration:  31% 569/1851 [04:10<09:22,  2.28it/s]\u001b[A\n","Iteration:  31% 570/1851 [04:11<09:21,  2.28it/s]\u001b[A\n","Iteration:  31% 571/1851 [04:11<09:20,  2.28it/s]\u001b[A\n","Iteration:  31% 572/1851 [04:12<09:20,  2.28it/s]\u001b[A\n","Iteration:  31% 573/1851 [04:12<09:20,  2.28it/s]\u001b[A\n","Iteration:  31% 574/1851 [04:13<09:20,  2.28it/s]\u001b[A\n","Iteration:  31% 575/1851 [04:13<09:19,  2.28it/s]\u001b[A\n","Iteration:  31% 576/1851 [04:14<09:19,  2.28it/s]\u001b[A\n","Iteration:  31% 577/1851 [04:14<09:18,  2.28it/s]\u001b[A\n","Iteration:  31% 578/1851 [04:14<09:22,  2.26it/s]\u001b[A\n","Iteration:  31% 579/1851 [04:15<09:21,  2.26it/s]\u001b[A\n","Iteration:  31% 580/1851 [04:15<09:21,  2.26it/s]\u001b[A\n","Iteration:  31% 581/1851 [04:16<09:24,  2.25it/s]\u001b[A\n","Iteration:  31% 582/1851 [04:16<09:22,  2.26it/s]\u001b[A\n","Iteration:  31% 583/1851 [04:17<09:20,  2.26it/s]\u001b[A\n","Iteration:  32% 584/1851 [04:17<09:18,  2.27it/s]\u001b[A\n","Iteration:  32% 585/1851 [04:18<09:17,  2.27it/s]\u001b[A\n","Iteration:  32% 586/1851 [04:18<09:16,  2.27it/s]\u001b[A\n","Iteration:  32% 587/1851 [04:18<09:15,  2.28it/s]\u001b[A\n","Iteration:  32% 588/1851 [04:19<09:14,  2.28it/s]\u001b[A\n","Iteration:  32% 589/1851 [04:19<09:13,  2.28it/s]\u001b[A\n","Iteration:  32% 590/1851 [04:20<09:13,  2.28it/s]\u001b[A\n","Iteration:  32% 591/1851 [04:20<09:13,  2.28it/s]\u001b[A\n","Iteration:  32% 592/1851 [04:21<09:12,  2.28it/s]\u001b[A\n","Iteration:  32% 593/1851 [04:21<09:11,  2.28it/s]\u001b[A\n","Iteration:  32% 594/1851 [04:21<09:11,  2.28it/s]\u001b[A\n","Iteration:  32% 595/1851 [04:22<09:10,  2.28it/s]\u001b[A\n","Iteration:  32% 596/1851 [04:22<09:09,  2.28it/s]\u001b[A\n","Iteration:  32% 597/1851 [04:23<09:09,  2.28it/s]\u001b[A\n","Iteration:  32% 598/1851 [04:23<09:08,  2.28it/s]\u001b[A\n","Iteration:  32% 599/1851 [04:24<09:08,  2.28it/s]\u001b[A\n","Iteration:  32% 600/1851 [04:24<09:08,  2.28it/s]\u001b[A\n","Iteration:  32% 601/1851 [04:25<09:07,  2.28it/s]\u001b[A\n","Iteration:  33% 602/1851 [04:25<09:07,  2.28it/s]\u001b[A\n","Iteration:  33% 603/1851 [04:25<09:07,  2.28it/s]\u001b[A\n","Iteration:  33% 604/1851 [04:26<09:06,  2.28it/s]\u001b[A\n","Iteration:  33% 605/1851 [04:26<09:06,  2.28it/s]\u001b[A\n","Iteration:  33% 606/1851 [04:27<09:05,  2.28it/s]\u001b[A\n","Iteration:  33% 607/1851 [04:27<09:05,  2.28it/s]\u001b[A\n","Iteration:  33% 608/1851 [04:28<09:04,  2.28it/s]\u001b[A\n","Iteration:  33% 609/1851 [04:28<09:03,  2.28it/s]\u001b[A\n","Iteration:  33% 610/1851 [04:28<09:04,  2.28it/s]\u001b[A\n","Iteration:  33% 611/1851 [04:29<09:05,  2.27it/s]\u001b[A\n","Iteration:  33% 612/1851 [04:29<09:05,  2.27it/s]\u001b[A\n","Iteration:  33% 613/1851 [04:30<09:06,  2.27it/s]\u001b[A\n","Iteration:  33% 614/1851 [04:30<09:04,  2.27it/s]\u001b[A\n","Iteration:  33% 615/1851 [04:31<09:04,  2.27it/s]\u001b[A\n","Iteration:  33% 616/1851 [04:31<09:05,  2.27it/s]\u001b[A\n","Iteration:  33% 617/1851 [04:32<09:05,  2.26it/s]\u001b[A\n","Iteration:  33% 618/1851 [04:34<18:40,  1.10it/s]\u001b[A\n","Iteration:  33% 619/1851 [04:34<15:45,  1.30it/s]\u001b[A\n","Iteration:  33% 620/1851 [04:34<13:45,  1.49it/s]\u001b[A\n","Iteration:  34% 621/1851 [04:35<12:18,  1.66it/s]\u001b[A\n","Iteration:  34% 622/1851 [04:35<11:18,  1.81it/s]\u001b[A\n","Iteration:  34% 623/1851 [04:36<10:36,  1.93it/s]\u001b[A\n","Iteration:  34% 624/1851 [04:36<10:06,  2.02it/s]\u001b[A\n","Iteration:  34% 625/1851 [04:37<09:45,  2.09it/s]\u001b[A\n","Iteration:  34% 626/1851 [04:37<09:30,  2.15it/s]\u001b[A\n","Iteration:  34% 627/1851 [04:38<09:19,  2.19it/s]\u001b[A\n","Iteration:  34% 628/1851 [04:38<09:12,  2.21it/s]\u001b[A\n","Iteration:  34% 629/1851 [04:38<09:06,  2.23it/s]\u001b[A\n","Iteration:  34% 630/1851 [04:39<09:03,  2.25it/s]\u001b[A\n","Iteration:  34% 631/1851 [04:39<09:00,  2.26it/s]\u001b[A\n","Iteration:  34% 632/1851 [04:40<08:58,  2.26it/s]\u001b[A\n","Iteration:  34% 633/1851 [04:40<08:56,  2.27it/s]\u001b[A\n","Iteration:  34% 634/1851 [04:41<08:55,  2.27it/s]\u001b[A\n","Iteration:  34% 635/1851 [04:41<08:54,  2.28it/s]\u001b[A\n","Iteration:  34% 636/1851 [04:41<08:53,  2.28it/s]\u001b[A\n","Iteration:  34% 637/1851 [04:42<08:52,  2.28it/s]\u001b[A\n","Iteration:  34% 638/1851 [04:42<08:52,  2.28it/s]\u001b[A\n","Iteration:  35% 639/1851 [04:43<08:51,  2.28it/s]\u001b[A\n","Iteration:  35% 640/1851 [04:43<08:50,  2.28it/s]\u001b[A\n","Iteration:  35% 641/1851 [04:44<08:50,  2.28it/s]\u001b[A\n","Iteration:  35% 642/1851 [04:44<08:49,  2.28it/s]\u001b[A\n","Iteration:  35% 643/1851 [04:45<08:49,  2.28it/s]\u001b[A\n","Iteration:  35% 644/1851 [04:45<08:48,  2.28it/s]\u001b[A\n","Iteration:  35% 645/1851 [04:45<08:48,  2.28it/s]\u001b[A\n","Iteration:  35% 646/1851 [04:46<08:47,  2.28it/s]\u001b[A\n","Iteration:  35% 647/1851 [04:46<08:47,  2.28it/s]\u001b[A\n","Iteration:  35% 648/1851 [04:47<08:46,  2.28it/s]\u001b[A\n","Iteration:  35% 649/1851 [04:47<08:46,  2.28it/s]\u001b[A\n","Iteration:  35% 650/1851 [04:48<08:46,  2.28it/s]\u001b[A\n","Iteration:  35% 651/1851 [04:48<08:45,  2.28it/s]\u001b[A\n","Iteration:  35% 652/1851 [04:48<08:45,  2.28it/s]\u001b[A\n","Iteration:  35% 653/1851 [04:49<08:46,  2.28it/s]\u001b[A\n","Iteration:  35% 654/1851 [04:49<08:50,  2.25it/s]\u001b[A\n","Iteration:  35% 655/1851 [04:50<08:46,  2.27it/s]\u001b[A\n","Iteration:  35% 656/1851 [04:50<08:44,  2.28it/s]\u001b[A\n","Iteration:  35% 657/1851 [04:51<08:44,  2.28it/s]\u001b[A\n","Iteration:  36% 658/1851 [04:51<08:43,  2.28it/s]\u001b[A\n","Iteration:  36% 659/1851 [04:52<08:48,  2.25it/s]\u001b[A\n","Iteration:  36% 660/1851 [04:53<13:00,  1.53it/s]\u001b[A\n","Iteration:  36% 661/1851 [04:53<12:26,  1.59it/s]\u001b[A\n","Iteration:  36% 662/1851 [04:54<11:17,  1.75it/s]\u001b[A\n","Iteration:  36% 663/1851 [04:54<10:30,  1.89it/s]\u001b[A\n","Iteration:  36% 664/1851 [04:55<09:56,  1.99it/s]\u001b[A\n","Iteration:  36% 665/1851 [04:55<09:33,  2.07it/s]\u001b[A\n","Iteration:  36% 666/1851 [04:55<09:16,  2.13it/s]\u001b[A\n","Iteration:  36% 667/1851 [04:56<09:05,  2.17it/s]\u001b[A\n","Iteration:  36% 668/1851 [04:56<08:57,  2.20it/s]\u001b[A\n","Iteration:  36% 669/1851 [04:57<08:50,  2.23it/s]\u001b[A\n","Iteration:  36% 670/1851 [04:57<08:47,  2.24it/s]\u001b[A\n","Iteration:  36% 671/1851 [04:58<08:45,  2.24it/s]\u001b[A\n","Iteration:  36% 672/1851 [04:58<08:42,  2.26it/s]\u001b[A\n","Iteration:  36% 673/1851 [04:59<09:58,  1.97it/s]\u001b[A\n","Iteration:  36% 674/1851 [04:59<09:34,  2.05it/s]\u001b[A\n","Iteration:  36% 675/1851 [05:00<09:18,  2.11it/s]\u001b[A\n","Iteration:  37% 676/1851 [05:00<09:05,  2.15it/s]\u001b[A\n","Iteration:  37% 677/1851 [05:01<08:56,  2.19it/s]\u001b[A\n","Iteration:  37% 678/1851 [05:01<08:49,  2.22it/s]\u001b[A\n","Iteration:  37% 679/1851 [05:01<08:44,  2.23it/s]\u001b[A\n","Iteration:  37% 680/1851 [05:02<08:41,  2.25it/s]\u001b[A\n","Iteration:  37% 681/1851 [05:02<08:38,  2.26it/s]\u001b[A\n","Iteration:  37% 682/1851 [05:03<08:35,  2.27it/s]\u001b[A\n","Iteration:  37% 683/1851 [05:03<08:34,  2.27it/s]\u001b[A\n","Iteration:  37% 684/1851 [05:04<08:33,  2.27it/s]\u001b[A\n","Iteration:  37% 685/1851 [05:04<08:32,  2.28it/s]\u001b[A\n","Iteration:  37% 686/1851 [05:04<08:31,  2.28it/s]\u001b[A\n","Iteration:  37% 687/1851 [05:05<08:31,  2.28it/s]\u001b[A\n","Iteration:  37% 688/1851 [05:05<08:30,  2.28it/s]\u001b[A\n","Iteration:  37% 689/1851 [05:06<08:29,  2.28it/s]\u001b[A\n","Iteration:  37% 690/1851 [05:06<08:29,  2.28it/s]\u001b[A\n","Iteration:  37% 691/1851 [05:07<08:28,  2.28it/s]\u001b[A\n","Iteration:  37% 692/1851 [05:07<08:28,  2.28it/s]\u001b[A\n","Iteration:  37% 693/1851 [05:08<08:27,  2.28it/s]\u001b[A\n","Iteration:  37% 694/1851 [05:08<08:27,  2.28it/s]\u001b[A\n","Iteration:  38% 695/1851 [05:08<08:26,  2.28it/s]\u001b[A\n","Iteration:  38% 696/1851 [05:09<08:26,  2.28it/s]\u001b[A\n","Iteration:  38% 697/1851 [05:09<08:25,  2.28it/s]\u001b[A\n","Iteration:  38% 698/1851 [05:10<08:25,  2.28it/s]\u001b[A\n","Iteration:  38% 699/1851 [05:10<08:24,  2.28it/s]\u001b[A\n","Iteration:  38% 700/1851 [05:11<08:25,  2.28it/s]\u001b[A\n","Iteration:  38% 701/1851 [05:11<08:25,  2.28it/s]\u001b[A\n","Iteration:  38% 702/1851 [05:11<08:24,  2.28it/s]\u001b[A\n","Iteration:  38% 703/1851 [05:12<08:24,  2.28it/s]\u001b[A\n","Iteration:  38% 704/1851 [05:12<08:23,  2.28it/s]\u001b[A\n","Iteration:  38% 705/1851 [05:13<08:23,  2.28it/s]\u001b[A\n","Iteration:  38% 706/1851 [05:13<08:22,  2.28it/s]\u001b[A\n","Iteration:  38% 707/1851 [05:14<08:21,  2.28it/s]\u001b[A\n","Iteration:  38% 708/1851 [05:14<08:20,  2.28it/s]\u001b[A\n","Iteration:  38% 709/1851 [05:15<08:20,  2.28it/s]\u001b[A\n","Iteration:  38% 710/1851 [05:15<08:20,  2.28it/s]\u001b[A\n","Iteration:  38% 711/1851 [05:15<08:20,  2.28it/s]\u001b[A\n","Iteration:  38% 712/1851 [05:16<08:21,  2.27it/s]\u001b[A\n","Iteration:  39% 713/1851 [05:16<08:19,  2.28it/s]\u001b[A\n","Iteration:  39% 714/1851 [05:17<08:19,  2.28it/s]\u001b[A\n","Iteration:  39% 715/1851 [05:17<08:18,  2.28it/s]\u001b[A\n","Iteration:  39% 716/1851 [05:18<08:17,  2.28it/s]\u001b[A\n","Iteration:  39% 717/1851 [05:18<08:17,  2.28it/s]\u001b[A\n","Iteration:  39% 718/1851 [05:19<08:16,  2.28it/s]\u001b[A\n","Iteration:  39% 719/1851 [05:19<08:16,  2.28it/s]\u001b[A\n","Iteration:  39% 720/1851 [05:19<08:15,  2.28it/s]\u001b[A\n","Iteration:  39% 721/1851 [05:20<08:14,  2.28it/s]\u001b[A\n","Iteration:  39% 722/1851 [05:20<08:14,  2.28it/s]\u001b[A\n","Iteration:  39% 723/1851 [05:21<08:14,  2.28it/s]\u001b[A\n","Iteration:  39% 724/1851 [05:21<08:14,  2.28it/s]\u001b[A\n","Iteration:  39% 725/1851 [05:22<08:13,  2.28it/s]\u001b[A\n","Iteration:  39% 726/1851 [05:22<08:13,  2.28it/s]\u001b[A\n","Iteration:  39% 727/1851 [05:22<08:12,  2.28it/s]\u001b[A\n","Iteration:  39% 728/1851 [05:23<08:12,  2.28it/s]\u001b[A\n","Iteration:  39% 729/1851 [05:23<08:11,  2.28it/s]\u001b[A\n","Iteration:  39% 730/1851 [05:24<08:14,  2.27it/s]\u001b[A\n","Iteration:  39% 731/1851 [05:24<08:11,  2.28it/s]\u001b[A\n","Iteration:  40% 732/1851 [05:25<08:10,  2.28it/s]\u001b[A\n","Iteration:  40% 733/1851 [05:25<08:10,  2.28it/s]\u001b[A\n","Iteration:  40% 734/1851 [05:26<08:09,  2.28it/s]\u001b[A\n","Iteration:  40% 735/1851 [05:26<08:09,  2.28it/s]\u001b[A\n","Iteration:  40% 736/1851 [05:26<08:10,  2.27it/s]\u001b[A\n","Iteration:  40% 737/1851 [05:27<08:09,  2.27it/s]\u001b[A\n","Iteration:  40% 738/1851 [05:27<08:09,  2.28it/s]\u001b[A\n","Iteration:  40% 739/1851 [05:28<08:08,  2.28it/s]\u001b[A\n","Iteration:  40% 740/1851 [05:28<08:07,  2.28it/s]\u001b[A\n","Iteration:  40% 741/1851 [05:29<08:06,  2.28it/s]\u001b[A\n","Iteration:  40% 742/1851 [05:29<08:06,  2.28it/s]\u001b[A\n","Iteration:  40% 743/1851 [05:29<08:05,  2.28it/s]\u001b[A\n","Iteration:  40% 744/1851 [05:30<08:05,  2.28it/s]\u001b[A\n","Iteration:  40% 745/1851 [05:30<08:05,  2.28it/s]\u001b[A\n","Iteration:  40% 746/1851 [05:31<08:04,  2.28it/s]\u001b[A\n","Iteration:  40% 747/1851 [05:31<08:04,  2.28it/s]\u001b[A\n","Iteration:  40% 748/1851 [05:32<08:03,  2.28it/s]\u001b[A\n","Iteration:  40% 749/1851 [05:32<08:03,  2.28it/s]\u001b[A\n","Iteration:  41% 750/1851 [05:33<08:02,  2.28it/s]\u001b[A\n","Iteration:  41% 751/1851 [05:33<08:02,  2.28it/s]\u001b[A\n","Iteration:  41% 752/1851 [05:33<08:01,  2.28it/s]\u001b[A\n","Iteration:  41% 753/1851 [05:34<08:01,  2.28it/s]\u001b[A\n","Iteration:  41% 754/1851 [05:34<08:00,  2.28it/s]\u001b[A\n","Iteration:  41% 755/1851 [05:35<08:00,  2.28it/s]\u001b[A\n","Iteration:  41% 756/1851 [05:35<08:00,  2.28it/s]\u001b[A\n","Iteration:  41% 757/1851 [05:36<07:59,  2.28it/s]\u001b[A\n","Iteration:  41% 758/1851 [05:36<07:59,  2.28it/s]\u001b[A\n","Iteration:  41% 759/1851 [05:36<07:59,  2.28it/s]\u001b[A\n","Iteration:  41% 760/1851 [05:37<07:58,  2.28it/s]\u001b[A\n","Iteration:  41% 761/1851 [05:37<07:57,  2.28it/s]\u001b[A\n","Iteration:  41% 762/1851 [05:38<07:57,  2.28it/s]\u001b[A\n","Iteration:  41% 763/1851 [05:38<07:56,  2.28it/s]\u001b[A\n","Iteration:  41% 764/1851 [05:39<07:57,  2.28it/s]\u001b[A\n","Iteration:  41% 765/1851 [05:39<07:57,  2.28it/s]\u001b[A\n","Iteration:  41% 766/1851 [05:40<07:56,  2.28it/s]\u001b[A\n","Iteration:  41% 767/1851 [05:40<07:55,  2.28it/s]\u001b[A\n","Iteration:  41% 768/1851 [05:40<07:54,  2.28it/s]\u001b[A\n","Iteration:  42% 769/1851 [05:41<07:54,  2.28it/s]\u001b[A\n","Iteration:  42% 770/1851 [05:41<07:53,  2.28it/s]\u001b[A\n","Iteration:  42% 771/1851 [05:42<07:53,  2.28it/s]\u001b[A\n","Iteration:  42% 772/1851 [05:42<07:53,  2.28it/s]\u001b[A\n","Iteration:  42% 773/1851 [05:43<07:52,  2.28it/s]\u001b[A\n","Iteration:  42% 774/1851 [05:43<07:51,  2.28it/s]\u001b[A\n","Iteration:  42% 775/1851 [05:44<07:51,  2.28it/s]\u001b[A\n","Iteration:  42% 776/1851 [05:44<07:50,  2.28it/s]\u001b[A\n","Iteration:  42% 777/1851 [05:44<07:50,  2.28it/s]\u001b[A\n","Iteration:  42% 778/1851 [05:45<07:50,  2.28it/s]\u001b[A\n","Iteration:  42% 779/1851 [05:45<07:49,  2.28it/s]\u001b[A\n","Iteration:  42% 780/1851 [05:46<07:49,  2.28it/s]\u001b[A\n","Iteration:  42% 781/1851 [05:46<07:48,  2.28it/s]\u001b[A\n","Iteration:  42% 782/1851 [05:47<07:48,  2.28it/s]\u001b[A\n","Iteration:  42% 783/1851 [05:47<07:48,  2.28it/s]\u001b[A\n","Iteration:  42% 784/1851 [05:47<07:47,  2.28it/s]\u001b[A\n","Iteration:  42% 785/1851 [05:48<07:47,  2.28it/s]\u001b[A\n","Iteration:  42% 786/1851 [05:48<07:47,  2.28it/s]\u001b[A\n","Iteration:  43% 787/1851 [05:49<07:46,  2.28it/s]\u001b[A\n","Iteration:  43% 788/1851 [05:49<07:48,  2.27it/s]\u001b[A\n","Iteration:  43% 789/1851 [05:50<07:47,  2.27it/s]\u001b[A\n","Iteration:  43% 790/1851 [05:50<07:47,  2.27it/s]\u001b[A\n","Iteration:  43% 791/1851 [05:51<07:46,  2.27it/s]\u001b[A\n","Iteration:  43% 792/1851 [05:51<07:46,  2.27it/s]\u001b[A\n","Iteration:  43% 793/1851 [05:52<08:26,  2.09it/s]\u001b[A\n","Iteration:  43% 794/1851 [05:52<08:12,  2.14it/s]\u001b[A\n","Iteration:  43% 795/1851 [05:52<08:03,  2.18it/s]\u001b[A\n","Iteration:  43% 796/1851 [05:53<07:56,  2.21it/s]\u001b[A\n","Iteration:  43% 797/1851 [05:53<07:52,  2.23it/s]\u001b[A\n","Iteration:  43% 798/1851 [05:54<07:48,  2.25it/s]\u001b[A\n","Iteration:  43% 799/1851 [05:54<07:45,  2.26it/s]\u001b[A\n","Iteration:  43% 800/1851 [05:55<07:43,  2.27it/s]\u001b[A\n","Iteration:  43% 801/1851 [05:55<07:42,  2.27it/s]\u001b[A\n","Iteration:  43% 802/1851 [05:55<07:41,  2.27it/s]\u001b[A\n","Iteration:  43% 803/1851 [05:56<07:40,  2.28it/s]\u001b[A\n","Iteration:  43% 804/1851 [05:56<07:39,  2.28it/s]\u001b[A\n","Iteration:  43% 805/1851 [05:57<07:38,  2.28it/s]\u001b[A\n","Iteration:  44% 806/1851 [05:57<07:37,  2.28it/s]\u001b[A\n","Iteration:  44% 807/1851 [05:58<07:37,  2.28it/s]\u001b[A\n","Iteration:  44% 808/1851 [05:58<07:37,  2.28it/s]\u001b[A\n","Iteration:  44% 809/1851 [05:59<07:37,  2.28it/s]\u001b[A\n","Iteration:  44% 810/1851 [05:59<07:36,  2.28it/s]\u001b[A\n","Iteration:  44% 811/1851 [05:59<07:35,  2.28it/s]\u001b[A\n","Iteration:  44% 812/1851 [06:00<07:35,  2.28it/s]\u001b[A\n","Iteration:  44% 813/1851 [06:00<07:35,  2.28it/s]\u001b[A\n","Iteration:  44% 814/1851 [06:01<07:35,  2.28it/s]\u001b[A\n","Iteration:  44% 815/1851 [06:01<07:34,  2.28it/s]\u001b[A\n","Iteration:  44% 816/1851 [06:02<07:33,  2.28it/s]\u001b[A\n","Iteration:  44% 817/1851 [06:02<07:33,  2.28it/s]\u001b[A\n","Iteration:  44% 818/1851 [06:02<07:32,  2.28it/s]\u001b[A\n","Iteration:  44% 819/1851 [06:03<07:32,  2.28it/s]\u001b[A\n","Iteration:  44% 820/1851 [06:03<07:31,  2.28it/s]\u001b[A\n","Iteration:  44% 821/1851 [06:04<07:31,  2.28it/s]\u001b[A\n","Iteration:  44% 822/1851 [06:04<07:30,  2.28it/s]\u001b[A\n","Iteration:  44% 823/1851 [06:05<07:30,  2.28it/s]\u001b[A\n","Iteration:  45% 824/1851 [06:05<07:29,  2.28it/s]\u001b[A\n","Iteration:  45% 825/1851 [06:06<07:29,  2.28it/s]\u001b[A\n","Iteration:  45% 826/1851 [06:06<07:29,  2.28it/s]\u001b[A\n","Iteration:  45% 827/1851 [06:06<07:28,  2.28it/s]\u001b[A\n","Iteration:  45% 828/1851 [06:07<07:28,  2.28it/s]\u001b[A\n","Iteration:  45% 829/1851 [06:07<07:29,  2.27it/s]\u001b[A\n","Iteration:  45% 830/1851 [06:08<07:28,  2.27it/s]\u001b[A\n","Iteration:  45% 831/1851 [06:08<07:27,  2.28it/s]\u001b[A\n","Iteration:  45% 832/1851 [06:09<07:27,  2.28it/s]\u001b[A\n","Iteration:  45% 833/1851 [06:09<07:27,  2.27it/s]\u001b[A\n","Iteration:  45% 834/1851 [06:10<07:27,  2.27it/s]\u001b[A\n","Iteration:  45% 835/1851 [06:10<07:27,  2.27it/s]\u001b[A\n","Iteration:  45% 836/1851 [06:10<07:26,  2.27it/s]\u001b[A\n","Iteration:  45% 837/1851 [06:11<07:27,  2.27it/s]\u001b[A\n","Iteration:  45% 838/1851 [06:11<07:26,  2.27it/s]\u001b[A\n","Iteration:  45% 839/1851 [06:12<07:26,  2.27it/s]\u001b[A\n","Iteration:  45% 840/1851 [06:12<07:29,  2.25it/s]\u001b[A\n","Iteration:  45% 841/1851 [06:13<07:27,  2.26it/s]\u001b[A\n","Iteration:  45% 842/1851 [06:13<07:25,  2.27it/s]\u001b[A\n","Iteration:  46% 843/1851 [06:13<07:23,  2.27it/s]\u001b[A\n","Iteration:  46% 844/1851 [06:14<07:22,  2.28it/s]\u001b[A\n","Iteration:  46% 845/1851 [06:14<07:21,  2.28it/s]\u001b[A\n","Iteration:  46% 846/1851 [06:15<07:20,  2.28it/s]\u001b[A\n","Iteration:  46% 847/1851 [06:15<07:20,  2.28it/s]\u001b[A\n","Iteration:  46% 848/1851 [06:16<07:20,  2.28it/s]\u001b[A\n","Iteration:  46% 849/1851 [06:16<07:19,  2.28it/s]\u001b[A\n","Iteration:  46% 850/1851 [06:17<07:18,  2.28it/s]\u001b[A\n","Iteration:  46% 851/1851 [06:17<07:18,  2.28it/s]\u001b[A\n","Iteration:  46% 852/1851 [06:17<07:19,  2.27it/s]\u001b[A\n","Iteration:  46% 853/1851 [06:18<07:18,  2.27it/s]\u001b[A\n","Iteration:  46% 854/1851 [06:18<07:17,  2.28it/s]\u001b[A\n","Iteration:  46% 855/1851 [06:19<07:17,  2.28it/s]\u001b[A\n","Iteration:  46% 856/1851 [06:19<07:16,  2.28it/s]\u001b[A\n","Iteration:  46% 857/1851 [06:20<07:15,  2.28it/s]\u001b[A\n","Iteration:  46% 858/1851 [06:20<07:15,  2.28it/s]\u001b[A\n","Iteration:  46% 859/1851 [06:21<07:14,  2.28it/s]\u001b[A\n","Iteration:  46% 860/1851 [06:21<07:14,  2.28it/s]\u001b[A\n","Iteration:  47% 861/1851 [06:21<07:14,  2.28it/s]\u001b[A\n","Iteration:  47% 862/1851 [06:22<07:13,  2.28it/s]\u001b[A\n","Iteration:  47% 863/1851 [06:22<07:13,  2.28it/s]\u001b[A\n","Iteration:  47% 864/1851 [06:23<07:12,  2.28it/s]\u001b[A\n","Iteration:  47% 865/1851 [06:23<07:12,  2.28it/s]\u001b[A\n","Iteration:  47% 866/1851 [06:24<07:11,  2.28it/s]\u001b[A\n","Iteration:  47% 867/1851 [06:24<07:11,  2.28it/s]\u001b[A\n","Iteration:  47% 868/1851 [06:24<07:11,  2.28it/s]\u001b[A\n","Iteration:  47% 869/1851 [06:25<07:10,  2.28it/s]\u001b[A\n","Iteration:  47% 870/1851 [06:25<07:10,  2.28it/s]\u001b[A\n","Iteration:  47% 871/1851 [06:26<07:09,  2.28it/s]\u001b[A\n","Iteration:  47% 872/1851 [06:26<07:09,  2.28it/s]\u001b[A\n","Iteration:  47% 873/1851 [06:27<07:08,  2.28it/s]\u001b[A\n","Iteration:  47% 874/1851 [06:27<07:08,  2.28it/s]\u001b[A\n","Iteration:  47% 875/1851 [06:28<07:08,  2.28it/s]\u001b[A\n","Iteration:  47% 876/1851 [06:28<07:07,  2.28it/s]\u001b[A\n","Iteration:  47% 877/1851 [06:28<07:06,  2.28it/s]\u001b[A\n","Iteration:  47% 878/1851 [06:29<07:06,  2.28it/s]\u001b[A\n","Iteration:  47% 879/1851 [06:29<07:06,  2.28it/s]\u001b[A\n","Iteration:  48% 880/1851 [06:30<07:05,  2.28it/s]\u001b[A\n","Iteration:  48% 881/1851 [06:30<07:05,  2.28it/s]\u001b[A\n","Iteration:  48% 882/1851 [06:31<07:04,  2.28it/s]\u001b[A\n","Iteration:  48% 883/1851 [06:31<07:04,  2.28it/s]\u001b[A\n","Iteration:  48% 884/1851 [06:31<07:03,  2.28it/s]\u001b[A\n","Iteration:  48% 885/1851 [06:32<07:03,  2.28it/s]\u001b[A\n","Iteration:  48% 886/1851 [06:32<07:03,  2.28it/s]\u001b[A\n","Iteration:  48% 887/1851 [06:33<07:02,  2.28it/s]\u001b[A\n","Iteration:  48% 888/1851 [06:33<07:02,  2.28it/s]\u001b[A\n","Iteration:  48% 889/1851 [06:34<07:01,  2.28it/s]\u001b[A\n","Iteration:  48% 890/1851 [06:34<07:01,  2.28it/s]\u001b[A\n","Iteration:  48% 891/1851 [06:35<07:00,  2.28it/s]\u001b[A\n","Iteration:  48% 892/1851 [06:35<07:00,  2.28it/s]\u001b[A\n","Iteration:  48% 893/1851 [06:35<06:59,  2.28it/s]\u001b[A\n","Iteration:  48% 894/1851 [06:36<06:59,  2.28it/s]\u001b[A\n","Iteration:  48% 895/1851 [06:36<06:59,  2.28it/s]\u001b[A\n","Iteration:  48% 896/1851 [06:37<06:58,  2.28it/s]\u001b[A\n","Iteration:  48% 897/1851 [06:37<06:58,  2.28it/s]\u001b[A\n","Iteration:  49% 898/1851 [06:38<06:58,  2.28it/s]\u001b[A\n","Iteration:  49% 899/1851 [06:38<06:57,  2.28it/s]\u001b[A\n","Iteration:  49% 900/1851 [06:38<06:57,  2.28it/s]\u001b[A\n","Iteration:  49% 901/1851 [06:39<06:56,  2.28it/s]\u001b[A\n","Iteration:  49% 902/1851 [06:39<06:55,  2.28it/s]\u001b[A\n","Iteration:  49% 903/1851 [06:40<06:55,  2.28it/s]\u001b[A\n","Iteration:  49% 904/1851 [06:40<06:56,  2.27it/s]\u001b[A\n","Iteration:  49% 905/1851 [06:41<06:55,  2.28it/s]\u001b[A\n","Iteration:  49% 906/1851 [06:41<06:55,  2.28it/s]\u001b[A\n","Iteration:  49% 907/1851 [06:42<06:54,  2.28it/s]\u001b[A\n","Iteration:  49% 908/1851 [06:42<06:53,  2.28it/s]\u001b[A\n","Iteration:  49% 909/1851 [06:42<06:53,  2.28it/s]\u001b[A\n","Iteration:  49% 910/1851 [06:43<06:53,  2.27it/s]\u001b[A\n","Iteration:  49% 911/1851 [06:43<06:52,  2.28it/s]\u001b[A\n","Iteration:  49% 912/1851 [06:44<06:52,  2.28it/s]\u001b[A\n","Iteration:  49% 913/1851 [06:44<06:51,  2.28it/s]\u001b[A\n","Iteration:  49% 914/1851 [06:45<06:50,  2.28it/s]\u001b[A\n","Iteration:  49% 915/1851 [06:45<06:50,  2.28it/s]\u001b[A\n","Iteration:  49% 916/1851 [06:46<06:49,  2.28it/s]\u001b[A\n","Iteration:  50% 917/1851 [06:46<06:49,  2.28it/s]\u001b[A\n","Iteration:  50% 918/1851 [06:46<06:48,  2.28it/s]\u001b[A\n","Iteration:  50% 919/1851 [06:47<06:48,  2.28it/s]\u001b[A\n","Iteration:  50% 920/1851 [06:47<06:48,  2.28it/s]\u001b[A\n","Iteration:  50% 921/1851 [06:48<06:47,  2.28it/s]\u001b[A\n","Iteration:  50% 922/1851 [06:48<06:47,  2.28it/s]\u001b[A\n","Iteration:  50% 923/1851 [06:49<06:46,  2.28it/s]\u001b[A\n","Iteration:  50% 924/1851 [06:49<06:46,  2.28it/s]\u001b[A\n","Iteration:  50% 925/1851 [06:49<06:45,  2.28it/s]\u001b[A\n","Iteration:  50% 926/1851 [06:50<06:45,  2.28it/s]\u001b[A\n","Iteration:  50% 927/1851 [06:50<06:45,  2.28it/s]\u001b[A\n","Iteration:  50% 928/1851 [06:51<06:44,  2.28it/s]\u001b[A\n","Iteration:  50% 929/1851 [06:51<06:44,  2.28it/s]\u001b[A\n","Iteration:  50% 930/1851 [06:52<06:44,  2.28it/s]\u001b[A\n","Iteration:  50% 931/1851 [06:52<06:43,  2.28it/s]\u001b[A\n","Iteration:  50% 932/1851 [06:53<06:45,  2.27it/s]\u001b[A\n","Iteration:  50% 933/1851 [06:53<06:53,  2.22it/s]\u001b[A\n","Iteration:  50% 934/1851 [06:53<06:49,  2.24it/s]\u001b[A\n","Iteration:  51% 935/1851 [06:54<06:46,  2.25it/s]\u001b[A\n","Iteration:  51% 936/1851 [06:54<06:44,  2.26it/s]\u001b[A\n","Iteration:  51% 937/1851 [06:55<06:43,  2.27it/s]\u001b[A\n","Iteration:  51% 938/1851 [06:55<06:41,  2.27it/s]\u001b[A\n","Iteration:  51% 939/1851 [06:56<06:40,  2.28it/s]\u001b[A\n","Iteration:  51% 940/1851 [06:56<06:40,  2.28it/s]\u001b[A\n","Iteration:  51% 941/1851 [06:57<06:39,  2.28it/s]\u001b[A\n","Iteration:  51% 942/1851 [06:57<06:38,  2.28it/s]\u001b[A\n","Iteration:  51% 943/1851 [06:57<06:38,  2.28it/s]\u001b[A\n","Iteration:  51% 944/1851 [06:58<06:38,  2.28it/s]\u001b[A\n","Iteration:  51% 945/1851 [06:58<06:37,  2.28it/s]\u001b[A\n","Iteration:  51% 946/1851 [06:59<06:37,  2.28it/s]\u001b[A\n","Iteration:  51% 947/1851 [06:59<06:36,  2.28it/s]\u001b[A\n","Iteration:  51% 948/1851 [07:00<06:35,  2.28it/s]\u001b[A\n","Iteration:  51% 949/1851 [07:00<06:35,  2.28it/s]\u001b[A\n","Iteration:  51% 950/1851 [07:00<06:34,  2.28it/s]\u001b[A\n","Iteration:  51% 951/1851 [07:01<06:34,  2.28it/s]\u001b[A\n","Iteration:  51% 952/1851 [07:01<06:34,  2.28it/s]\u001b[A\n","Iteration:  51% 953/1851 [07:02<06:33,  2.28it/s]\u001b[A\n","Iteration:  52% 954/1851 [07:02<06:33,  2.28it/s]\u001b[A\n","Iteration:  52% 955/1851 [07:03<06:32,  2.28it/s]\u001b[A\n","Iteration:  52% 956/1851 [07:03<06:32,  2.28it/s]\u001b[A\n","Iteration:  52% 957/1851 [07:04<06:31,  2.28it/s]\u001b[A\n","Iteration:  52% 958/1851 [07:04<06:31,  2.28it/s]\u001b[A\n","Iteration:  52% 959/1851 [07:04<06:30,  2.28it/s]\u001b[A\n","Iteration:  52% 960/1851 [07:05<06:30,  2.28it/s]\u001b[A\n","Iteration:  52% 961/1851 [07:05<06:30,  2.28it/s]\u001b[A\n","Iteration:  52% 962/1851 [07:06<06:29,  2.28it/s]\u001b[A\n","Iteration:  52% 963/1851 [07:06<06:29,  2.28it/s]\u001b[A\n","Iteration:  52% 964/1851 [07:07<06:28,  2.28it/s]\u001b[A\n","Iteration:  52% 965/1851 [07:07<06:28,  2.28it/s]\u001b[A\n","Iteration:  52% 966/1851 [07:07<06:27,  2.28it/s]\u001b[A\n","Iteration:  52% 967/1851 [07:08<06:27,  2.28it/s]\u001b[A\n","Iteration:  52% 968/1851 [07:08<06:26,  2.28it/s]\u001b[A\n","Iteration:  52% 969/1851 [07:09<06:26,  2.28it/s]\u001b[A\n","Iteration:  52% 970/1851 [07:09<06:25,  2.28it/s]\u001b[A\n","Iteration:  52% 971/1851 [07:10<06:25,  2.28it/s]\u001b[A\n","Iteration:  53% 972/1851 [07:10<06:24,  2.28it/s]\u001b[A\n","Iteration:  53% 973/1851 [07:11<06:24,  2.28it/s]\u001b[A\n","Iteration:  53% 974/1851 [07:11<06:23,  2.28it/s]\u001b[A\n","Iteration:  53% 975/1851 [07:11<06:23,  2.28it/s]\u001b[A\n","Iteration:  53% 976/1851 [07:12<06:22,  2.28it/s]\u001b[A\n","Iteration:  53% 977/1851 [07:12<06:22,  2.28it/s]\u001b[A\n","Iteration:  53% 978/1851 [07:13<06:22,  2.28it/s]\u001b[A\n","Iteration:  53% 979/1851 [07:13<06:23,  2.28it/s]\u001b[A\n","Iteration:  53% 980/1851 [07:14<06:22,  2.28it/s]\u001b[A\n","Iteration:  53% 981/1851 [07:14<06:22,  2.28it/s]\u001b[A\n","Iteration:  53% 982/1851 [07:14<06:21,  2.28it/s]\u001b[A\n","Iteration:  53% 983/1851 [07:15<06:20,  2.28it/s]\u001b[A\n","Iteration:  53% 984/1851 [07:15<06:19,  2.28it/s]\u001b[A\n","Iteration:  53% 985/1851 [07:16<06:19,  2.28it/s]\u001b[A\n","Iteration:  53% 986/1851 [07:16<06:19,  2.28it/s]\u001b[A\n","Iteration:  53% 987/1851 [07:17<06:18,  2.28it/s]\u001b[A\n","Iteration:  53% 988/1851 [07:17<06:18,  2.28it/s]\u001b[A\n","Iteration:  53% 989/1851 [07:18<06:17,  2.28it/s]\u001b[A\n","Iteration:  53% 990/1851 [07:18<06:17,  2.28it/s]\u001b[A\n","Iteration:  54% 991/1851 [07:18<06:16,  2.28it/s]\u001b[A\n","Iteration:  54% 992/1851 [07:19<06:16,  2.28it/s]\u001b[A\n","Iteration:  54% 993/1851 [07:19<06:15,  2.28it/s]\u001b[A\n","Iteration:  54% 994/1851 [07:20<06:15,  2.28it/s]\u001b[A\n","Iteration:  54% 995/1851 [07:20<06:15,  2.28it/s]\u001b[A\n","Iteration:  54% 996/1851 [07:21<06:14,  2.28it/s]\u001b[A\n","Iteration:  54% 997/1851 [07:21<06:14,  2.28it/s]\u001b[A\n","Iteration:  54% 998/1851 [07:21<06:13,  2.28it/s]\u001b[A\n","Iteration:  54% 999/1851 [07:22<06:13,  2.28it/s]\u001b[A\n","Iteration:  54% 1000/1851 [07:22<06:13,  2.28it/s]\u001b[A\n","Iteration:  54% 1001/1851 [07:23<06:12,  2.28it/s]\u001b[A\n","Iteration:  54% 1002/1851 [07:23<06:13,  2.27it/s]\u001b[A\n","Iteration:  54% 1003/1851 [07:24<06:12,  2.27it/s]\u001b[A\n","Iteration:  54% 1004/1851 [07:24<06:14,  2.26it/s]\u001b[A\n","Iteration:  54% 1005/1851 [07:25<06:12,  2.27it/s]\u001b[A\n","Iteration:  54% 1006/1851 [07:25<06:12,  2.27it/s]\u001b[A\n","Iteration:  54% 1007/1851 [07:25<06:11,  2.27it/s]\u001b[A\n","Iteration:  54% 1008/1851 [07:26<06:10,  2.28it/s]\u001b[A\n","Iteration:  55% 1009/1851 [07:26<06:09,  2.28it/s]\u001b[A\n","Iteration:  55% 1010/1851 [07:27<06:09,  2.28it/s]\u001b[A\n","Iteration:  55% 1011/1851 [07:27<06:08,  2.28it/s]\u001b[A\n","Iteration:  55% 1012/1851 [07:28<06:08,  2.28it/s]\u001b[A\n","Iteration:  55% 1013/1851 [07:28<06:07,  2.28it/s]\u001b[A\n","Iteration:  55% 1014/1851 [07:29<06:07,  2.28it/s]\u001b[A\n","Iteration:  55% 1015/1851 [07:29<06:06,  2.28it/s]\u001b[A\n","Iteration:  55% 1016/1851 [07:29<06:05,  2.28it/s]\u001b[A\n","Iteration:  55% 1017/1851 [07:30<06:05,  2.28it/s]\u001b[A\n","Iteration:  55% 1018/1851 [07:30<06:04,  2.28it/s]\u001b[A\n","Iteration:  55% 1019/1851 [07:31<06:04,  2.28it/s]\u001b[A\n","Iteration:  55% 1020/1851 [07:31<06:04,  2.28it/s]\u001b[A\n","Iteration:  55% 1021/1851 [07:32<06:03,  2.28it/s]\u001b[A\n","Iteration:  55% 1022/1851 [07:32<06:03,  2.28it/s]\u001b[A\n","Iteration:  55% 1023/1851 [07:32<06:04,  2.27it/s]\u001b[A\n","Iteration:  55% 1024/1851 [07:33<06:03,  2.27it/s]\u001b[A\n","Iteration:  55% 1025/1851 [07:33<06:02,  2.28it/s]\u001b[A\n","Iteration:  55% 1026/1851 [07:34<06:02,  2.28it/s]\u001b[A\n","Iteration:  55% 1027/1851 [07:34<06:01,  2.28it/s]\u001b[A\n","Iteration:  56% 1028/1851 [07:35<06:01,  2.28it/s]\u001b[A\n","Iteration:  56% 1029/1851 [07:35<06:00,  2.28it/s]\u001b[A\n","Iteration:  56% 1030/1851 [07:36<06:00,  2.28it/s]\u001b[A\n","Iteration:  56% 1031/1851 [07:36<05:59,  2.28it/s]\u001b[A\n","Iteration:  56% 1032/1851 [07:36<05:59,  2.28it/s]\u001b[A\n","Iteration:  56% 1033/1851 [07:37<05:58,  2.28it/s]\u001b[A\n","Iteration:  56% 1034/1851 [07:37<05:58,  2.28it/s]\u001b[A\n","Iteration:  56% 1035/1851 [07:38<05:57,  2.28it/s]\u001b[A\n","Iteration:  56% 1036/1851 [07:38<05:57,  2.28it/s]\u001b[A\n","Iteration:  56% 1037/1851 [07:39<05:56,  2.28it/s]\u001b[A\n","Iteration:  56% 1038/1851 [07:39<05:56,  2.28it/s]\u001b[A\n","Iteration:  56% 1039/1851 [07:39<05:55,  2.28it/s]\u001b[A\n","Iteration:  56% 1040/1851 [07:40<05:55,  2.28it/s]\u001b[A\n","Iteration:  56% 1041/1851 [07:40<05:55,  2.28it/s]\u001b[A\n","Iteration:  56% 1042/1851 [07:41<05:54,  2.28it/s]\u001b[A\n","Iteration:  56% 1043/1851 [07:41<05:54,  2.28it/s]\u001b[A\n","Iteration:  56% 1044/1851 [07:42<05:53,  2.28it/s]\u001b[A\n","Iteration:  56% 1045/1851 [07:42<05:53,  2.28it/s]\u001b[A\n","Iteration:  57% 1046/1851 [07:43<05:52,  2.28it/s]\u001b[A\n","Iteration:  57% 1047/1851 [07:43<05:52,  2.28it/s]\u001b[A\n","Iteration:  57% 1048/1851 [07:43<05:51,  2.28it/s]\u001b[A\n","Iteration:  57% 1049/1851 [07:44<05:51,  2.28it/s]\u001b[A\n","Iteration:  57% 1050/1851 [07:44<05:50,  2.28it/s]\u001b[A\n","Iteration:  57% 1051/1851 [07:45<05:50,  2.28it/s]\u001b[A\n","Iteration:  57% 1052/1851 [07:45<05:49,  2.28it/s]\u001b[A\n","Iteration:  57% 1053/1851 [07:46<05:49,  2.28it/s]\u001b[A\n","Iteration:  57% 1054/1851 [07:46<05:49,  2.28it/s]\u001b[A\n","Iteration:  57% 1055/1851 [07:46<05:48,  2.28it/s]\u001b[A\n","Iteration:  57% 1056/1851 [07:47<05:48,  2.28it/s]\u001b[A\n","Iteration:  57% 1057/1851 [07:47<05:48,  2.28it/s]\u001b[A\n","Iteration:  57% 1058/1851 [07:48<05:47,  2.28it/s]\u001b[A\n","Iteration:  57% 1059/1851 [07:48<05:47,  2.28it/s]\u001b[A\n","Iteration:  57% 1060/1851 [07:49<05:46,  2.28it/s]\u001b[A\n","Iteration:  57% 1061/1851 [07:49<05:46,  2.28it/s]\u001b[A\n","Iteration:  57% 1062/1851 [07:50<05:45,  2.28it/s]\u001b[A\n","Iteration:  57% 1063/1851 [07:50<05:45,  2.28it/s]\u001b[A\n","Iteration:  57% 1064/1851 [07:50<05:44,  2.28it/s]\u001b[A\n","Iteration:  58% 1065/1851 [07:51<05:44,  2.28it/s]\u001b[A\n","Iteration:  58% 1066/1851 [07:51<05:43,  2.28it/s]\u001b[A\n","Iteration:  58% 1067/1851 [07:52<05:43,  2.28it/s]\u001b[A\n","Iteration:  58% 1068/1851 [07:52<05:42,  2.28it/s]\u001b[A\n","Iteration:  58% 1069/1851 [07:53<05:42,  2.28it/s]\u001b[A\n","Iteration:  58% 1070/1851 [07:53<05:41,  2.28it/s]\u001b[A\n","Iteration:  58% 1071/1851 [07:54<05:41,  2.28it/s]\u001b[A\n","Iteration:  58% 1072/1851 [07:54<05:41,  2.28it/s]\u001b[A\n","Iteration:  58% 1073/1851 [07:54<05:41,  2.28it/s]\u001b[A\n","Iteration:  58% 1074/1851 [07:55<05:40,  2.28it/s]\u001b[A\n","Iteration:  58% 1075/1851 [07:55<05:40,  2.28it/s]\u001b[A\n","Iteration:  58% 1076/1851 [07:56<05:39,  2.28it/s]\u001b[A\n","Iteration:  58% 1077/1851 [07:56<05:39,  2.28it/s]\u001b[A\n","Iteration:  58% 1078/1851 [07:57<05:38,  2.28it/s]\u001b[A\n","Iteration:  58% 1079/1851 [07:57<05:38,  2.28it/s]\u001b[A\n","Iteration:  58% 1080/1851 [07:57<05:37,  2.28it/s]\u001b[A\n","Iteration:  58% 1081/1851 [07:58<05:37,  2.28it/s]\u001b[A\n","Iteration:  58% 1082/1851 [07:58<05:38,  2.27it/s]\u001b[A\n","Iteration:  59% 1083/1851 [07:59<05:37,  2.28it/s]\u001b[A\n","Iteration:  59% 1084/1851 [07:59<05:36,  2.28it/s]\u001b[A\n","Iteration:  59% 1085/1851 [08:00<05:35,  2.28it/s]\u001b[A\n","Iteration:  59% 1086/1851 [08:00<05:35,  2.28it/s]\u001b[A\n","Iteration:  59% 1087/1851 [08:01<05:35,  2.28it/s]\u001b[A\n","Iteration:  59% 1088/1851 [08:01<05:34,  2.28it/s]\u001b[A\n","Iteration:  59% 1089/1851 [08:01<05:34,  2.28it/s]\u001b[A\n","Iteration:  59% 1090/1851 [08:02<05:33,  2.28it/s]\u001b[A\n","Iteration:  59% 1091/1851 [08:02<05:32,  2.28it/s]\u001b[A\n","Iteration:  59% 1092/1851 [08:03<05:32,  2.28it/s]\u001b[A\n","Iteration:  59% 1093/1851 [08:03<05:32,  2.28it/s]\u001b[A\n","Iteration:  59% 1094/1851 [08:04<05:31,  2.28it/s]\u001b[A\n","Iteration:  59% 1095/1851 [08:04<05:31,  2.28it/s]\u001b[A\n","Iteration:  59% 1096/1851 [08:04<05:30,  2.28it/s]\u001b[A\n","Iteration:  59% 1097/1851 [08:05<05:30,  2.28it/s]\u001b[A\n","Iteration:  59% 1098/1851 [08:05<05:30,  2.28it/s]\u001b[A\n","Iteration:  59% 1099/1851 [08:06<05:29,  2.28it/s]\u001b[A\n","Iteration:  59% 1100/1851 [08:06<05:29,  2.28it/s]\u001b[A\n","Iteration:  59% 1101/1851 [08:07<05:28,  2.28it/s]\u001b[A\n","Iteration:  60% 1102/1851 [08:07<05:28,  2.28it/s]\u001b[A\n","Iteration:  60% 1103/1851 [08:08<05:27,  2.28it/s]\u001b[A\n","Iteration:  60% 1104/1851 [08:08<05:27,  2.28it/s]\u001b[A\n","Iteration:  60% 1105/1851 [08:08<05:27,  2.28it/s]\u001b[A\n","Iteration:  60% 1106/1851 [08:09<05:26,  2.28it/s]\u001b[A\n","Iteration:  60% 1107/1851 [08:09<05:26,  2.28it/s]\u001b[A\n","Iteration:  60% 1108/1851 [08:10<05:25,  2.28it/s]\u001b[A\n","Iteration:  60% 1109/1851 [08:10<05:25,  2.28it/s]\u001b[A\n","Iteration:  60% 1110/1851 [08:11<05:24,  2.28it/s]\u001b[A\n","Iteration:  60% 1111/1851 [08:11<05:24,  2.28it/s]\u001b[A\n","Iteration:  60% 1112/1851 [08:11<05:24,  2.28it/s]\u001b[A\n","Iteration:  60% 1113/1851 [08:12<05:23,  2.28it/s]\u001b[A\n","Iteration:  60% 1114/1851 [08:12<05:23,  2.28it/s]\u001b[A\n","Iteration:  60% 1115/1851 [08:13<05:22,  2.28it/s]\u001b[A\n","Iteration:  60% 1116/1851 [08:13<05:22,  2.28it/s]\u001b[A\n","Iteration:  60% 1117/1851 [08:14<05:21,  2.28it/s]\u001b[A\n","Iteration:  60% 1118/1851 [08:14<05:21,  2.28it/s]\u001b[A\n","Iteration:  60% 1119/1851 [08:15<05:20,  2.28it/s]\u001b[A\n","Iteration:  61% 1120/1851 [08:15<05:20,  2.28it/s]\u001b[A\n","Iteration:  61% 1121/1851 [08:15<05:20,  2.28it/s]\u001b[A\n","Iteration:  61% 1122/1851 [08:16<05:19,  2.28it/s]\u001b[A\n","Iteration:  61% 1123/1851 [08:16<05:18,  2.28it/s]\u001b[A\n","Iteration:  61% 1124/1851 [08:17<05:18,  2.28it/s]\u001b[A\n","Iteration:  61% 1125/1851 [08:17<05:18,  2.28it/s]\u001b[A\n","Iteration:  61% 1126/1851 [08:18<05:17,  2.28it/s]\u001b[A\n","Iteration:  61% 1127/1851 [08:18<05:17,  2.28it/s]\u001b[A\n","Iteration:  61% 1128/1851 [08:18<05:16,  2.28it/s]\u001b[A\n","Iteration:  61% 1129/1851 [08:19<05:16,  2.28it/s]\u001b[A\n","Iteration:  61% 1130/1851 [08:19<05:15,  2.28it/s]\u001b[A\n","Iteration:  61% 1131/1851 [08:20<05:15,  2.28it/s]\u001b[A\n","Iteration:  61% 1132/1851 [08:20<05:14,  2.28it/s]\u001b[A\n","Iteration:  61% 1133/1851 [08:21<05:14,  2.28it/s]\u001b[A\n","Iteration:  61% 1134/1851 [08:21<05:13,  2.28it/s]\u001b[A\n","Iteration:  61% 1135/1851 [08:22<05:13,  2.28it/s]\u001b[A\n","Iteration:  61% 1136/1851 [08:22<05:13,  2.28it/s]\u001b[A\n","Iteration:  61% 1137/1851 [08:22<05:12,  2.28it/s]\u001b[A\n","Iteration:  61% 1138/1851 [08:23<05:12,  2.28it/s]\u001b[A\n","Iteration:  62% 1139/1851 [08:23<05:11,  2.28it/s]\u001b[A\n","Iteration:  62% 1140/1851 [08:24<05:11,  2.28it/s]\u001b[A\n","Iteration:  62% 1141/1851 [08:24<05:11,  2.28it/s]\u001b[A\n","Iteration:  62% 1142/1851 [08:25<05:10,  2.28it/s]\u001b[A\n","Iteration:  62% 1143/1851 [08:25<05:10,  2.28it/s]\u001b[A\n","Iteration:  62% 1144/1851 [08:26<05:09,  2.28it/s]\u001b[A\n","Iteration:  62% 1145/1851 [08:26<05:09,  2.28it/s]\u001b[A\n","Iteration:  62% 1146/1851 [08:26<05:08,  2.28it/s]\u001b[A\n","Iteration:  62% 1147/1851 [08:27<05:08,  2.28it/s]\u001b[A\n","Iteration:  62% 1148/1851 [08:27<05:09,  2.27it/s]\u001b[A\n","Iteration:  62% 1149/1851 [08:28<05:08,  2.28it/s]\u001b[A\n","Iteration:  62% 1150/1851 [08:28<05:07,  2.28it/s]\u001b[A\n","Iteration:  62% 1151/1851 [08:29<05:07,  2.28it/s]\u001b[A\n","Iteration:  62% 1152/1851 [08:29<05:06,  2.28it/s]\u001b[A\n","Iteration:  62% 1153/1851 [08:29<05:06,  2.28it/s]\u001b[A\n","Iteration:  62% 1154/1851 [08:30<05:05,  2.28it/s]\u001b[A\n","Iteration:  62% 1155/1851 [08:30<05:05,  2.28it/s]\u001b[A\n","Iteration:  62% 1156/1851 [08:31<05:04,  2.28it/s]\u001b[A\n","Iteration:  63% 1157/1851 [08:31<05:04,  2.28it/s]\u001b[A\n","Iteration:  63% 1158/1851 [08:32<05:03,  2.28it/s]\u001b[A\n","Iteration:  63% 1159/1851 [08:32<05:03,  2.28it/s]\u001b[A\n","Iteration:  63% 1160/1851 [08:33<05:02,  2.28it/s]\u001b[A\n","Iteration:  63% 1161/1851 [08:33<05:02,  2.28it/s]\u001b[A\n","Iteration:  63% 1162/1851 [08:33<05:02,  2.28it/s]\u001b[A\n","Iteration:  63% 1163/1851 [08:34<05:01,  2.28it/s]\u001b[A\n","Iteration:  63% 1164/1851 [08:34<05:01,  2.28it/s]\u001b[A\n","Iteration:  63% 1165/1851 [08:35<05:00,  2.28it/s]\u001b[A\n","Iteration:  63% 1166/1851 [08:35<05:00,  2.28it/s]\u001b[A\n","Iteration:  63% 1167/1851 [08:36<04:59,  2.28it/s]\u001b[A\n","Iteration:  63% 1168/1851 [08:36<04:59,  2.28it/s]\u001b[A\n","Iteration:  63% 1169/1851 [08:36<04:58,  2.28it/s]\u001b[A\n","Iteration:  63% 1170/1851 [08:37<04:58,  2.28it/s]\u001b[A\n","Iteration:  63% 1171/1851 [08:37<04:57,  2.28it/s]\u001b[A\n","Iteration:  63% 1172/1851 [08:38<04:57,  2.28it/s]\u001b[A\n","Iteration:  63% 1173/1851 [08:38<04:57,  2.28it/s]\u001b[A\n","Iteration:  63% 1174/1851 [08:39<04:56,  2.28it/s]\u001b[A\n","Iteration:  63% 1175/1851 [08:39<04:56,  2.28it/s]\u001b[A\n","Iteration:  64% 1176/1851 [08:40<04:56,  2.28it/s]\u001b[A\n","Iteration:  64% 1177/1851 [08:40<04:55,  2.28it/s]\u001b[A\n","Iteration:  64% 1178/1851 [08:40<04:55,  2.28it/s]\u001b[A\n","Iteration:  64% 1179/1851 [08:41<04:54,  2.28it/s]\u001b[A\n","Iteration:  64% 1180/1851 [08:41<04:53,  2.28it/s]\u001b[A\n","Iteration:  64% 1181/1851 [08:42<04:53,  2.28it/s]\u001b[A\n","Iteration:  64% 1182/1851 [08:42<04:53,  2.28it/s]\u001b[A\n","Iteration:  64% 1183/1851 [08:43<04:52,  2.28it/s]\u001b[A\n","Iteration:  64% 1184/1851 [08:43<04:52,  2.28it/s]\u001b[A\n","Iteration:  64% 1185/1851 [08:43<04:51,  2.28it/s]\u001b[A\n","Iteration:  64% 1186/1851 [08:44<04:51,  2.28it/s]\u001b[A\n","Iteration:  64% 1187/1851 [08:44<04:50,  2.28it/s]\u001b[A\n","Iteration:  64% 1188/1851 [08:45<04:50,  2.28it/s]\u001b[A\n","Iteration:  64% 1189/1851 [08:45<04:50,  2.28it/s]\u001b[A\n","Iteration:  64% 1190/1851 [08:46<04:49,  2.28it/s]\u001b[A\n","Iteration:  64% 1191/1851 [08:46<04:49,  2.28it/s]\u001b[A\n","Iteration:  64% 1192/1851 [08:47<04:48,  2.28it/s]\u001b[A\n","Iteration:  64% 1193/1851 [08:47<04:48,  2.28it/s]\u001b[A\n","Iteration:  65% 1194/1851 [08:47<04:47,  2.28it/s]\u001b[A\n","Iteration:  65% 1195/1851 [08:48<04:47,  2.28it/s]\u001b[A\n","Iteration:  65% 1196/1851 [08:48<04:47,  2.27it/s]\u001b[A\n","Iteration:  65% 1197/1851 [08:49<04:47,  2.28it/s]\u001b[A\n","Iteration:  65% 1198/1851 [08:49<04:46,  2.28it/s]\u001b[A\n","Iteration:  65% 1199/1851 [08:50<04:46,  2.27it/s]\u001b[A\n","Iteration:  65% 1200/1851 [08:50<04:46,  2.27it/s]\u001b[A\n","Iteration:  65% 1201/1851 [08:51<04:46,  2.27it/s]\u001b[A\n","Iteration:  65% 1202/1851 [08:51<04:45,  2.27it/s]\u001b[A\n","Iteration:  65% 1203/1851 [08:51<04:44,  2.28it/s]\u001b[A\n","Iteration:  65% 1204/1851 [08:52<04:43,  2.28it/s]\u001b[A\n","Iteration:  65% 1205/1851 [08:52<04:43,  2.28it/s]\u001b[A\n","Iteration:  65% 1206/1851 [08:53<04:42,  2.28it/s]\u001b[A\n","Iteration:  65% 1207/1851 [08:53<04:42,  2.28it/s]\u001b[A\n","Iteration:  65% 1208/1851 [08:54<04:41,  2.28it/s]\u001b[A\n","Iteration:  65% 1209/1851 [08:54<04:41,  2.28it/s]\u001b[A\n","Iteration:  65% 1210/1851 [08:54<04:40,  2.28it/s]\u001b[A\n","Iteration:  65% 1211/1851 [08:55<04:40,  2.28it/s]\u001b[A\n","Iteration:  65% 1212/1851 [08:55<04:40,  2.28it/s]\u001b[A\n","Iteration:  66% 1213/1851 [08:56<04:39,  2.28it/s]\u001b[A\n","Iteration:  66% 1214/1851 [08:56<04:39,  2.28it/s]\u001b[A\n","Iteration:  66% 1215/1851 [08:57<04:40,  2.27it/s]\u001b[A\n","Iteration:  66% 1216/1851 [08:57<04:40,  2.27it/s]\u001b[A\n","Iteration:  66% 1217/1851 [08:58<04:39,  2.27it/s]\u001b[A\n","Iteration:  66% 1218/1851 [08:58<04:39,  2.26it/s]\u001b[A\n","Iteration:  66% 1219/1851 [08:58<04:38,  2.27it/s]\u001b[A\n","Iteration:  66% 1220/1851 [08:59<04:37,  2.27it/s]\u001b[A\n","Iteration:  66% 1221/1851 [08:59<04:37,  2.27it/s]\u001b[A\n","Iteration:  66% 1222/1851 [09:00<04:36,  2.28it/s]\u001b[A\n","Iteration:  66% 1223/1851 [09:00<04:35,  2.28it/s]\u001b[A\n","Iteration:  66% 1224/1851 [09:01<04:35,  2.28it/s]\u001b[A\n","Iteration:  66% 1225/1851 [09:01<04:34,  2.28it/s]\u001b[A\n","Iteration:  66% 1226/1851 [09:01<04:34,  2.28it/s]\u001b[A\n","Iteration:  66% 1227/1851 [09:02<04:33,  2.28it/s]\u001b[A\n","Iteration:  66% 1228/1851 [09:02<04:32,  2.28it/s]\u001b[A\n","Iteration:  66% 1229/1851 [09:03<04:32,  2.28it/s]\u001b[A\n","Iteration:  66% 1230/1851 [09:03<04:32,  2.28it/s]\u001b[A\n","Iteration:  67% 1231/1851 [09:04<04:31,  2.28it/s]\u001b[A\n","Iteration:  67% 1232/1851 [09:04<04:31,  2.28it/s]\u001b[A\n","Iteration:  67% 1233/1851 [09:05<04:30,  2.28it/s]\u001b[A\n","Iteration:  67% 1234/1851 [09:05<04:30,  2.28it/s]\u001b[A\n","Iteration:  67% 1235/1851 [09:05<04:30,  2.28it/s]\u001b[A\n","Iteration:  67% 1236/1851 [09:06<04:29,  2.28it/s]\u001b[A\n","Iteration:  67% 1237/1851 [09:06<04:29,  2.28it/s]\u001b[A\n","Iteration:  67% 1238/1851 [09:07<04:28,  2.28it/s]\u001b[A\n","Iteration:  67% 1239/1851 [09:07<04:28,  2.28it/s]\u001b[A\n","Iteration:  67% 1240/1851 [09:08<04:27,  2.28it/s]\u001b[A\n","Iteration:  67% 1241/1851 [09:08<04:27,  2.28it/s]\u001b[A\n","Iteration:  67% 1242/1851 [09:08<04:26,  2.28it/s]\u001b[A\n","Iteration:  67% 1243/1851 [09:09<04:26,  2.28it/s]\u001b[A\n","Iteration:  67% 1244/1851 [09:09<04:26,  2.28it/s]\u001b[A\n","Iteration:  67% 1245/1851 [09:10<04:25,  2.28it/s]\u001b[A\n","Iteration:  67% 1246/1851 [09:10<04:25,  2.28it/s]\u001b[A\n","Iteration:  67% 1247/1851 [09:11<04:24,  2.28it/s]\u001b[A\n","Iteration:  67% 1248/1851 [09:11<04:24,  2.28it/s]\u001b[A\n","Iteration:  67% 1249/1851 [09:12<04:23,  2.28it/s]\u001b[A\n","Iteration:  68% 1250/1851 [09:12<04:23,  2.28it/s]\u001b[A\n","Iteration:  68% 1251/1851 [09:12<04:23,  2.28it/s]\u001b[A\n","Iteration:  68% 1252/1851 [09:13<04:22,  2.28it/s]\u001b[A\n","Iteration:  68% 1253/1851 [09:13<04:22,  2.28it/s]\u001b[A\n","Iteration:  68% 1254/1851 [09:14<04:21,  2.28it/s]\u001b[A\n","Iteration:  68% 1255/1851 [09:14<04:21,  2.28it/s]\u001b[A\n","Iteration:  68% 1256/1851 [09:15<04:20,  2.28it/s]\u001b[A\n","Iteration:  68% 1257/1851 [09:15<04:20,  2.28it/s]\u001b[A\n","Iteration:  68% 1258/1851 [09:16<04:19,  2.28it/s]\u001b[A\n","Iteration:  68% 1259/1851 [09:16<04:19,  2.28it/s]\u001b[A\n","Iteration:  68% 1260/1851 [09:16<04:18,  2.28it/s]\u001b[A\n","Iteration:  68% 1261/1851 [09:17<04:18,  2.28it/s]\u001b[A\n","Iteration:  68% 1262/1851 [09:17<04:18,  2.28it/s]\u001b[A\n","Iteration:  68% 1263/1851 [09:18<04:17,  2.28it/s]\u001b[A\n","Iteration:  68% 1264/1851 [09:18<04:17,  2.28it/s]\u001b[A\n","Iteration:  68% 1265/1851 [09:19<04:16,  2.28it/s]\u001b[A\n","Iteration:  68% 1266/1851 [09:19<04:16,  2.28it/s]\u001b[A\n","Iteration:  68% 1267/1851 [09:19<04:15,  2.28it/s]\u001b[A\n","Iteration:  69% 1268/1851 [09:20<04:16,  2.27it/s]\u001b[A\n","Iteration:  69% 1269/1851 [09:20<04:15,  2.28it/s]\u001b[A\n","Iteration:  69% 1270/1851 [09:21<04:15,  2.28it/s]\u001b[A\n","Iteration:  69% 1271/1851 [09:21<04:14,  2.28it/s]\u001b[A\n","Iteration:  69% 1272/1851 [09:22<04:14,  2.28it/s]\u001b[A\n","Iteration:  69% 1273/1851 [09:22<04:13,  2.28it/s]\u001b[A\n","Iteration:  69% 1274/1851 [09:23<04:13,  2.28it/s]\u001b[A\n","Iteration:  69% 1275/1851 [09:23<04:12,  2.28it/s]\u001b[A\n","Iteration:  69% 1276/1851 [09:23<04:12,  2.28it/s]\u001b[A\n","Iteration:  69% 1277/1851 [09:24<04:11,  2.28it/s]\u001b[A\n","Iteration:  69% 1278/1851 [09:24<04:11,  2.28it/s]\u001b[A\n","Iteration:  69% 1279/1851 [09:25<04:10,  2.28it/s]\u001b[A\n","Iteration:  69% 1280/1851 [09:25<04:10,  2.28it/s]\u001b[A\n","Iteration:  69% 1281/1851 [09:26<04:09,  2.28it/s]\u001b[A\n","Iteration:  69% 1282/1851 [09:26<04:09,  2.28it/s]\u001b[A\n","Iteration:  69% 1283/1851 [09:26<04:09,  2.28it/s]\u001b[A\n","Iteration:  69% 1284/1851 [09:27<04:08,  2.28it/s]\u001b[A\n","Iteration:  69% 1285/1851 [09:27<04:08,  2.28it/s]\u001b[A\n","Iteration:  69% 1286/1851 [09:28<04:07,  2.28it/s]\u001b[A\n","Iteration:  70% 1287/1851 [09:28<04:07,  2.28it/s]\u001b[A\n","Iteration:  70% 1288/1851 [09:29<04:07,  2.27it/s]\u001b[A\n","Iteration:  70% 1289/1851 [09:29<04:06,  2.28it/s]\u001b[A\n","Iteration:  70% 1290/1851 [09:30<04:06,  2.27it/s]\u001b[A\n","Iteration:  70% 1291/1851 [09:30<04:19,  2.16it/s]\u001b[A\n","Iteration:  70% 1292/1851 [09:31<04:14,  2.19it/s]\u001b[A\n","Iteration:  70% 1293/1851 [09:31<04:11,  2.22it/s]\u001b[A\n","Iteration:  70% 1294/1851 [09:31<04:08,  2.24it/s]\u001b[A\n","Iteration:  70% 1295/1851 [09:32<04:07,  2.25it/s]\u001b[A\n","Iteration:  70% 1296/1851 [09:32<04:05,  2.26it/s]\u001b[A\n","Iteration:  70% 1297/1851 [09:33<04:04,  2.27it/s]\u001b[A\n","Iteration:  70% 1298/1851 [09:33<04:03,  2.27it/s]\u001b[A\n","Iteration:  70% 1299/1851 [09:34<04:02,  2.27it/s]\u001b[A\n","Iteration:  70% 1300/1851 [09:34<04:02,  2.28it/s]\u001b[A\n","Iteration:  70% 1301/1851 [09:34<04:01,  2.28it/s]\u001b[A\n","Iteration:  70% 1302/1851 [09:35<04:00,  2.28it/s]\u001b[A\n","Iteration:  70% 1303/1851 [09:35<04:00,  2.28it/s]\u001b[A\n","Iteration:  70% 1304/1851 [09:36<04:00,  2.28it/s]\u001b[A\n","Iteration:  71% 1305/1851 [09:36<03:59,  2.28it/s]\u001b[A\n","Iteration:  71% 1306/1851 [09:37<03:59,  2.28it/s]\u001b[A\n","Iteration:  71% 1307/1851 [09:37<03:58,  2.28it/s]\u001b[A\n","Iteration:  71% 1308/1851 [09:38<03:58,  2.28it/s]\u001b[A\n","Iteration:  71% 1309/1851 [09:38<03:57,  2.28it/s]\u001b[A\n","Iteration:  71% 1310/1851 [09:38<03:57,  2.28it/s]\u001b[A\n","Iteration:  71% 1311/1851 [09:39<03:56,  2.28it/s]\u001b[A\n","Iteration:  71% 1312/1851 [09:39<03:56,  2.28it/s]\u001b[A\n","Iteration:  71% 1313/1851 [09:40<03:55,  2.28it/s]\u001b[A\n","Iteration:  71% 1314/1851 [09:40<03:55,  2.28it/s]\u001b[A\n","Iteration:  71% 1315/1851 [09:41<03:55,  2.28it/s]\u001b[A\n","Iteration:  71% 1316/1851 [09:41<03:54,  2.28it/s]\u001b[A\n","Iteration:  71% 1317/1851 [09:41<03:54,  2.28it/s]\u001b[A\n","Iteration:  71% 1318/1851 [09:42<03:53,  2.28it/s]\u001b[A\n","Iteration:  71% 1319/1851 [09:42<03:53,  2.28it/s]\u001b[A\n","Iteration:  71% 1320/1851 [09:43<03:52,  2.28it/s]\u001b[A\n","Iteration:  71% 1321/1851 [09:43<03:52,  2.28it/s]\u001b[A\n","Iteration:  71% 1322/1851 [09:44<03:51,  2.28it/s]\u001b[A\n","Iteration:  71% 1323/1851 [09:44<03:51,  2.28it/s]\u001b[A\n","Iteration:  72% 1324/1851 [09:45<03:50,  2.28it/s]\u001b[A\n","Iteration:  72% 1325/1851 [09:45<03:50,  2.28it/s]\u001b[A\n","Iteration:  72% 1326/1851 [09:45<03:50,  2.28it/s]\u001b[A\n","Iteration:  72% 1327/1851 [09:46<03:49,  2.28it/s]\u001b[A\n","Iteration:  72% 1328/1851 [09:46<03:49,  2.28it/s]\u001b[A\n","Iteration:  72% 1329/1851 [09:47<03:48,  2.28it/s]\u001b[A\n","Iteration:  72% 1330/1851 [09:47<03:48,  2.28it/s]\u001b[A\n","Iteration:  72% 1331/1851 [09:48<03:48,  2.28it/s]\u001b[A\n","Iteration:  72% 1332/1851 [09:48<03:47,  2.28it/s]\u001b[A\n","Iteration:  72% 1333/1851 [09:48<03:47,  2.28it/s]\u001b[A\n","Iteration:  72% 1334/1851 [09:49<03:46,  2.28it/s]\u001b[A\n","Iteration:  72% 1335/1851 [09:49<03:46,  2.28it/s]\u001b[A\n","Iteration:  72% 1336/1851 [09:50<03:45,  2.28it/s]\u001b[A\n","Iteration:  72% 1337/1851 [09:50<03:45,  2.28it/s]\u001b[A\n","Iteration:  72% 1338/1851 [09:51<03:44,  2.28it/s]\u001b[A\n","Iteration:  72% 1339/1851 [09:51<03:44,  2.28it/s]\u001b[A\n","Iteration:  72% 1340/1851 [09:52<03:43,  2.28it/s]\u001b[A\n","Iteration:  72% 1341/1851 [09:52<03:43,  2.28it/s]\u001b[A\n","Iteration:  73% 1342/1851 [09:52<03:43,  2.28it/s]\u001b[A\n","Iteration:  73% 1343/1851 [09:53<03:42,  2.28it/s]\u001b[A\n","Iteration:  73% 1344/1851 [09:53<03:42,  2.28it/s]\u001b[A\n","Iteration:  73% 1345/1851 [09:54<03:41,  2.28it/s]\u001b[A\n","Iteration:  73% 1346/1851 [09:54<03:41,  2.28it/s]\u001b[A\n","Iteration:  73% 1347/1851 [09:55<03:40,  2.28it/s]\u001b[A\n","Iteration:  73% 1348/1851 [09:55<03:40,  2.28it/s]\u001b[A\n","Iteration:  73% 1349/1851 [09:55<03:40,  2.28it/s]\u001b[A\n","Iteration:  73% 1350/1851 [09:56<03:39,  2.28it/s]\u001b[A\n","Iteration:  73% 1351/1851 [09:56<03:39,  2.28it/s]\u001b[A\n","Iteration:  73% 1352/1851 [09:57<03:39,  2.28it/s]\u001b[A\n","Iteration:  73% 1353/1851 [09:57<03:39,  2.27it/s]\u001b[A\n","Iteration:  73% 1354/1851 [09:58<03:39,  2.27it/s]\u001b[A\n","Iteration:  73% 1355/1851 [09:58<03:40,  2.25it/s]\u001b[A\n","Iteration:  73% 1356/1851 [09:59<03:40,  2.25it/s]\u001b[A\n","Iteration:  73% 1357/1851 [09:59<03:39,  2.25it/s]\u001b[A\n","Iteration:  73% 1358/1851 [09:59<03:38,  2.26it/s]\u001b[A\n","Iteration:  73% 1359/1851 [10:00<03:37,  2.26it/s]\u001b[A\n","Iteration:  73% 1360/1851 [10:00<03:36,  2.27it/s]\u001b[A\n","Iteration:  74% 1361/1851 [10:01<03:35,  2.28it/s]\u001b[A\n","Iteration:  74% 1362/1851 [10:01<03:34,  2.28it/s]\u001b[A\n","Iteration:  74% 1363/1851 [10:02<03:34,  2.28it/s]\u001b[A\n","Iteration:  74% 1364/1851 [10:02<03:34,  2.27it/s]\u001b[A\n","Iteration:  74% 1365/1851 [10:03<03:33,  2.27it/s]\u001b[A\n","Iteration:  74% 1366/1851 [10:03<03:33,  2.28it/s]\u001b[A\n","Iteration:  74% 1367/1851 [10:03<03:32,  2.28it/s]\u001b[A\n","Iteration:  74% 1368/1851 [10:04<03:31,  2.28it/s]\u001b[A\n","Iteration:  74% 1369/1851 [10:04<03:31,  2.28it/s]\u001b[A\n","Iteration:  74% 1370/1851 [10:05<03:31,  2.28it/s]\u001b[A\n","Iteration:  74% 1371/1851 [10:05<03:30,  2.28it/s]\u001b[A\n","Iteration:  74% 1372/1851 [10:06<03:30,  2.28it/s]\u001b[A\n","Iteration:  74% 1373/1851 [10:06<03:29,  2.28it/s]\u001b[A\n","Iteration:  74% 1374/1851 [10:07<03:29,  2.28it/s]\u001b[A\n","Iteration:  74% 1375/1851 [10:07<03:28,  2.28it/s]\u001b[A\n","Iteration:  74% 1376/1851 [10:07<03:28,  2.28it/s]\u001b[A\n","Iteration:  74% 1377/1851 [10:08<03:27,  2.28it/s]\u001b[A\n","Iteration:  74% 1378/1851 [10:08<03:27,  2.28it/s]\u001b[A\n","Iteration:  75% 1379/1851 [10:09<03:26,  2.28it/s]\u001b[A\n","Iteration:  75% 1380/1851 [10:09<03:26,  2.28it/s]\u001b[A\n","Iteration:  75% 1381/1851 [10:10<03:25,  2.28it/s]\u001b[A\n","Iteration:  75% 1382/1851 [10:10<03:25,  2.28it/s]\u001b[A\n","Iteration:  75% 1383/1851 [10:10<03:24,  2.28it/s]\u001b[A\n","Iteration:  75% 1384/1851 [10:11<03:24,  2.28it/s]\u001b[A\n","Iteration:  75% 1385/1851 [10:11<03:24,  2.28it/s]\u001b[A\n","Iteration:  75% 1386/1851 [10:12<03:23,  2.28it/s]\u001b[A\n","Iteration:  75% 1387/1851 [10:12<03:23,  2.28it/s]\u001b[A\n","Iteration:  75% 1388/1851 [10:13<03:22,  2.28it/s]\u001b[A\n","Iteration:  75% 1389/1851 [10:13<03:22,  2.28it/s]\u001b[A\n","Iteration:  75% 1390/1851 [10:14<03:21,  2.28it/s]\u001b[A\n","Iteration:  75% 1391/1851 [10:14<03:21,  2.28it/s]\u001b[A\n","Iteration:  75% 1392/1851 [10:14<03:21,  2.28it/s]\u001b[A\n","Iteration:  75% 1393/1851 [10:15<03:20,  2.28it/s]\u001b[A\n","Iteration:  75% 1394/1851 [10:15<03:20,  2.28it/s]\u001b[A\n","Iteration:  75% 1395/1851 [10:16<03:19,  2.28it/s]\u001b[A\n","Iteration:  75% 1396/1851 [10:16<03:19,  2.28it/s]\u001b[A\n","Iteration:  75% 1397/1851 [10:17<03:19,  2.28it/s]\u001b[A\n","Iteration:  76% 1398/1851 [10:17<03:18,  2.28it/s]\u001b[A\n","Iteration:  76% 1399/1851 [10:17<03:18,  2.28it/s]\u001b[A\n","Iteration:  76% 1400/1851 [10:18<03:17,  2.28it/s]\u001b[A\n","Iteration:  76% 1401/1851 [10:18<03:17,  2.28it/s]\u001b[A\n","Iteration:  76% 1402/1851 [10:19<03:16,  2.28it/s]\u001b[A\n","Iteration:  76% 1403/1851 [10:19<03:16,  2.28it/s]\u001b[A\n","Iteration:  76% 1404/1851 [10:20<03:15,  2.28it/s]\u001b[A\n","Iteration:  76% 1405/1851 [10:20<03:15,  2.28it/s]\u001b[A\n","Iteration:  76% 1406/1851 [10:21<03:14,  2.28it/s]\u001b[A\n","Iteration:  76% 1407/1851 [10:21<03:14,  2.28it/s]\u001b[A\n","Iteration:  76% 1408/1851 [10:21<03:14,  2.28it/s]\u001b[A\n","Iteration:  76% 1409/1851 [10:22<03:13,  2.28it/s]\u001b[A\n","Iteration:  76% 1410/1851 [10:22<03:13,  2.28it/s]\u001b[A\n","Iteration:  76% 1411/1851 [10:23<03:13,  2.28it/s]\u001b[A\n","Iteration:  76% 1412/1851 [10:23<03:12,  2.28it/s]\u001b[A\n","Iteration:  76% 1413/1851 [10:24<03:11,  2.28it/s]\u001b[A\n","Iteration:  76% 1414/1851 [10:24<03:11,  2.28it/s]\u001b[A\n","Iteration:  76% 1415/1851 [10:24<03:11,  2.28it/s]\u001b[A\n","Iteration:  76% 1416/1851 [10:25<03:10,  2.28it/s]\u001b[A\n","Iteration:  77% 1417/1851 [10:25<03:10,  2.28it/s]\u001b[A\n","Iteration:  77% 1418/1851 [10:26<03:09,  2.28it/s]\u001b[A\n","Iteration:  77% 1419/1851 [10:26<03:09,  2.28it/s]\u001b[A\n","Iteration:  77% 1420/1851 [10:27<03:08,  2.28it/s]\u001b[A\n","Iteration:  77% 1421/1851 [10:27<03:08,  2.28it/s]\u001b[A\n","Iteration:  77% 1422/1851 [10:28<03:07,  2.28it/s]\u001b[A\n","Iteration:  77% 1423/1851 [10:28<03:07,  2.28it/s]\u001b[A\n","Iteration:  77% 1424/1851 [10:28<03:07,  2.28it/s]\u001b[A\n","Iteration:  77% 1425/1851 [10:29<03:06,  2.28it/s]\u001b[A\n","Iteration:  77% 1426/1851 [10:29<03:06,  2.28it/s]\u001b[A\n","Iteration:  77% 1427/1851 [10:30<03:06,  2.28it/s]\u001b[A\n","Iteration:  77% 1428/1851 [10:30<03:05,  2.28it/s]\u001b[A\n","Iteration:  77% 1429/1851 [10:31<03:06,  2.26it/s]\u001b[A\n","Iteration:  77% 1430/1851 [10:31<03:05,  2.27it/s]\u001b[A\n","Iteration:  77% 1431/1851 [10:31<03:05,  2.27it/s]\u001b[A\n","Iteration:  77% 1432/1851 [10:32<03:04,  2.27it/s]\u001b[A\n","Iteration:  77% 1433/1851 [10:32<03:04,  2.26it/s]\u001b[A\n","Iteration:  77% 1434/1851 [10:33<03:03,  2.27it/s]\u001b[A\n","Iteration:  78% 1435/1851 [10:33<03:03,  2.27it/s]\u001b[A\n","Iteration:  78% 1436/1851 [10:34<03:03,  2.26it/s]\u001b[A\n","Iteration:  78% 1437/1851 [10:34<03:02,  2.27it/s]\u001b[A\n","Iteration:  78% 1438/1851 [10:35<03:01,  2.27it/s]\u001b[A\n","Iteration:  78% 1439/1851 [10:35<03:01,  2.27it/s]\u001b[A\n","Iteration:  78% 1440/1851 [10:35<03:00,  2.28it/s]\u001b[A\n","Iteration:  78% 1441/1851 [10:36<02:59,  2.28it/s]\u001b[A\n","Iteration:  78% 1442/1851 [10:36<02:59,  2.28it/s]\u001b[A\n","Iteration:  78% 1443/1851 [10:37<02:59,  2.28it/s]\u001b[A\n","Iteration:  78% 1444/1851 [10:37<02:58,  2.28it/s]\u001b[A\n","Iteration:  78% 1445/1851 [10:38<02:58,  2.28it/s]\u001b[A\n","Iteration:  78% 1446/1851 [10:38<02:57,  2.28it/s]\u001b[A\n","Iteration:  78% 1447/1851 [10:39<02:57,  2.28it/s]\u001b[A\n","Iteration:  78% 1448/1851 [10:39<02:56,  2.28it/s]\u001b[A\n","Iteration:  78% 1449/1851 [10:39<02:56,  2.28it/s]\u001b[A\n","Iteration:  78% 1450/1851 [10:40<02:55,  2.28it/s]\u001b[A\n","Iteration:  78% 1451/1851 [10:40<02:55,  2.28it/s]\u001b[A\n","Iteration:  78% 1452/1851 [10:41<02:54,  2.28it/s]\u001b[A\n","Iteration:  78% 1453/1851 [10:41<02:54,  2.28it/s]\u001b[A\n","Iteration:  79% 1454/1851 [10:42<02:53,  2.28it/s]\u001b[A\n","Iteration:  79% 1455/1851 [10:42<02:53,  2.28it/s]\u001b[A\n","Iteration:  79% 1456/1851 [10:42<02:53,  2.28it/s]\u001b[A\n","Iteration:  79% 1457/1851 [10:43<02:52,  2.28it/s]\u001b[A\n","Iteration:  79% 1458/1851 [10:43<02:52,  2.28it/s]\u001b[A\n","Iteration:  79% 1459/1851 [10:44<02:51,  2.28it/s]\u001b[A\n","Iteration:  79% 1460/1851 [10:44<02:51,  2.28it/s]\u001b[A\n","Iteration:  79% 1461/1851 [10:45<02:50,  2.28it/s]\u001b[A\n","Iteration:  79% 1462/1851 [10:45<02:50,  2.28it/s]\u001b[A\n","Iteration:  79% 1463/1851 [10:46<02:50,  2.28it/s]\u001b[A\n","Iteration:  79% 1464/1851 [10:46<02:49,  2.28it/s]\u001b[A\n","Iteration:  79% 1465/1851 [10:46<02:49,  2.28it/s]\u001b[A\n","Iteration:  79% 1466/1851 [10:47<02:48,  2.28it/s]\u001b[A\n","Iteration:  79% 1467/1851 [10:47<02:48,  2.28it/s]\u001b[A\n","Iteration:  79% 1468/1851 [10:48<02:48,  2.28it/s]\u001b[A\n","Iteration:  79% 1469/1851 [10:48<02:47,  2.28it/s]\u001b[A\n","Iteration:  79% 1470/1851 [10:49<02:47,  2.28it/s]\u001b[A\n","Iteration:  79% 1471/1851 [10:49<02:46,  2.28it/s]\u001b[A\n","Iteration:  80% 1472/1851 [10:49<02:46,  2.28it/s]\u001b[A\n","Iteration:  80% 1473/1851 [10:50<02:45,  2.28it/s]\u001b[A\n","Iteration:  80% 1474/1851 [10:50<02:45,  2.28it/s]\u001b[A\n","Iteration:  80% 1475/1851 [10:51<02:44,  2.28it/s]\u001b[A\n","Iteration:  80% 1476/1851 [10:51<02:44,  2.28it/s]\u001b[A\n","Iteration:  80% 1477/1851 [10:52<02:44,  2.28it/s]\u001b[A\n","Iteration:  80% 1478/1851 [10:52<02:43,  2.28it/s]\u001b[A\n","Iteration:  80% 1479/1851 [10:53<02:43,  2.28it/s]\u001b[A\n","Iteration:  80% 1480/1851 [10:53<02:42,  2.28it/s]\u001b[A\n","Iteration:  80% 1481/1851 [10:53<02:42,  2.28it/s]\u001b[A\n","Iteration:  80% 1482/1851 [10:54<02:41,  2.28it/s]\u001b[A\n","Iteration:  80% 1483/1851 [10:54<02:41,  2.28it/s]\u001b[A\n","Iteration:  80% 1484/1851 [10:55<02:40,  2.28it/s]\u001b[A\n","Iteration:  80% 1485/1851 [10:55<02:40,  2.28it/s]\u001b[A\n","Iteration:  80% 1486/1851 [10:56<02:39,  2.28it/s]\u001b[A\n","Iteration:  80% 1487/1851 [10:56<02:39,  2.28it/s]\u001b[A\n","Iteration:  80% 1488/1851 [10:57<02:39,  2.28it/s]\u001b[A\n","Iteration:  80% 1489/1851 [10:57<02:38,  2.28it/s]\u001b[A\n","Iteration:  80% 1490/1851 [10:57<02:38,  2.28it/s]\u001b[A\n","Iteration:  81% 1491/1851 [10:58<02:37,  2.28it/s]\u001b[A\n","Iteration:  81% 1492/1851 [10:58<02:37,  2.28it/s]\u001b[A\n","Iteration:  81% 1493/1851 [10:59<02:36,  2.28it/s]\u001b[A\n","Iteration:  81% 1494/1851 [10:59<02:36,  2.28it/s]\u001b[A\n","Iteration:  81% 1495/1851 [11:00<02:35,  2.28it/s]\u001b[A\n","Iteration:  81% 1496/1851 [11:00<02:35,  2.28it/s]\u001b[A\n","Iteration:  81% 1497/1851 [11:00<02:35,  2.28it/s]\u001b[A\n","Iteration:  81% 1498/1851 [11:01<02:34,  2.28it/s]\u001b[A\n","Iteration:  81% 1499/1851 [11:01<02:34,  2.28it/s]\u001b[A\n","Iteration:  81% 1500/1851 [11:02<02:33,  2.28it/s]\u001b[A\n","Iteration:  81% 1501/1851 [11:02<02:33,  2.28it/s]\u001b[A\n","Iteration:  81% 1502/1851 [11:03<02:33,  2.28it/s]\u001b[A\n","Iteration:  81% 1503/1851 [11:03<02:32,  2.28it/s]\u001b[A\n","Iteration:  81% 1504/1851 [11:04<02:32,  2.28it/s]\u001b[A\n","Iteration:  81% 1505/1851 [11:04<02:31,  2.28it/s]\u001b[A\n","Iteration:  81% 1506/1851 [11:04<02:31,  2.28it/s]\u001b[A\n","Iteration:  81% 1507/1851 [11:05<02:30,  2.28it/s]\u001b[A\n","Iteration:  81% 1508/1851 [11:05<02:30,  2.28it/s]\u001b[A\n","Iteration:  82% 1509/1851 [11:06<02:29,  2.28it/s]\u001b[A\n","Iteration:  82% 1510/1851 [11:06<02:29,  2.28it/s]\u001b[A\n","Iteration:  82% 1511/1851 [11:07<02:29,  2.28it/s]\u001b[A\n","Iteration:  82% 1512/1851 [11:07<02:28,  2.28it/s]\u001b[A\n","Iteration:  82% 1513/1851 [11:07<02:28,  2.28it/s]\u001b[A\n","Iteration:  82% 1514/1851 [11:08<02:27,  2.28it/s]\u001b[A\n","Iteration:  82% 1515/1851 [11:08<02:27,  2.28it/s]\u001b[A\n","Iteration:  82% 1516/1851 [11:09<02:26,  2.28it/s]\u001b[A\n","Iteration:  82% 1517/1851 [11:09<02:26,  2.28it/s]\u001b[A\n","Iteration:  82% 1518/1851 [11:10<02:25,  2.28it/s]\u001b[A\n","Iteration:  82% 1519/1851 [11:10<02:25,  2.28it/s]\u001b[A\n","Iteration:  82% 1520/1851 [11:11<02:25,  2.28it/s]\u001b[A\n","Iteration:  82% 1521/1851 [11:11<02:24,  2.28it/s]\u001b[A\n","Iteration:  82% 1522/1851 [11:11<02:24,  2.28it/s]\u001b[A\n","Iteration:  82% 1523/1851 [11:12<02:23,  2.28it/s]\u001b[A\n","Iteration:  82% 1524/1851 [11:12<02:23,  2.28it/s]\u001b[A\n","Iteration:  82% 1525/1851 [11:13<02:22,  2.28it/s]\u001b[A\n","Iteration:  82% 1526/1851 [11:13<02:22,  2.28it/s]\u001b[A\n","Iteration:  82% 1527/1851 [11:14<02:21,  2.28it/s]\u001b[A\n","Iteration:  83% 1528/1851 [11:14<02:21,  2.28it/s]\u001b[A\n","Iteration:  83% 1529/1851 [11:14<02:21,  2.28it/s]\u001b[A\n","Iteration:  83% 1530/1851 [11:15<02:20,  2.28it/s]\u001b[A\n","Iteration:  83% 1531/1851 [11:15<02:20,  2.28it/s]\u001b[A\n","Iteration:  83% 1532/1851 [11:16<02:19,  2.28it/s]\u001b[A\n","Iteration:  83% 1533/1851 [11:16<02:19,  2.28it/s]\u001b[A\n","Iteration:  83% 1534/1851 [11:17<02:18,  2.28it/s]\u001b[A\n","Iteration:  83% 1535/1851 [11:17<02:18,  2.28it/s]\u001b[A\n","Iteration:  83% 1536/1851 [11:18<02:17,  2.29it/s]\u001b[A\n","Iteration:  83% 1537/1851 [11:18<02:17,  2.28it/s]\u001b[A\n","Iteration:  83% 1538/1851 [11:18<02:17,  2.28it/s]\u001b[A\n","Iteration:  83% 1539/1851 [11:19<02:16,  2.28it/s]\u001b[A\n","Iteration:  83% 1540/1851 [11:19<02:16,  2.28it/s]\u001b[A\n","Iteration:  83% 1541/1851 [11:20<02:15,  2.28it/s]\u001b[A\n","Iteration:  83% 1542/1851 [11:20<02:15,  2.28it/s]\u001b[A\n","Iteration:  83% 1543/1851 [11:21<02:15,  2.28it/s]\u001b[A\n","Iteration:  83% 1544/1851 [11:21<02:14,  2.28it/s]\u001b[A\n","Iteration:  83% 1545/1851 [11:21<02:14,  2.28it/s]\u001b[A\n","Iteration:  84% 1546/1851 [11:22<02:13,  2.28it/s]\u001b[A\n","Iteration:  84% 1547/1851 [11:22<02:13,  2.28it/s]\u001b[A\n","Iteration:  84% 1548/1851 [11:23<02:12,  2.28it/s]\u001b[A\n","Iteration:  84% 1549/1851 [11:23<02:12,  2.28it/s]\u001b[A\n","Iteration:  84% 1550/1851 [11:24<02:11,  2.28it/s]\u001b[A\n","Iteration:  84% 1551/1851 [11:24<02:12,  2.27it/s]\u001b[A\n","Iteration:  84% 1552/1851 [11:25<02:11,  2.27it/s]\u001b[A\n","Iteration:  84% 1553/1851 [11:25<02:11,  2.27it/s]\u001b[A\n","Iteration:  84% 1554/1851 [11:25<02:10,  2.28it/s]\u001b[A\n","Iteration:  84% 1555/1851 [11:26<02:09,  2.28it/s]\u001b[A\n","Iteration:  84% 1556/1851 [11:26<02:09,  2.28it/s]\u001b[A\n","Iteration:  84% 1557/1851 [11:27<02:08,  2.28it/s]\u001b[A\n","Iteration:  84% 1558/1851 [11:27<02:08,  2.28it/s]\u001b[A\n","Iteration:  84% 1559/1851 [11:28<02:08,  2.28it/s]\u001b[A\n","Iteration:  84% 1560/1851 [11:28<02:07,  2.28it/s]\u001b[A\n","Iteration:  84% 1561/1851 [11:29<02:07,  2.28it/s]\u001b[A\n","Iteration:  84% 1562/1851 [11:29<02:07,  2.27it/s]\u001b[A\n","Iteration:  84% 1563/1851 [11:29<02:06,  2.27it/s]\u001b[A\n","Iteration:  84% 1564/1851 [11:30<02:06,  2.27it/s]\u001b[A\n","Iteration:  85% 1565/1851 [11:30<02:06,  2.26it/s]\u001b[A\n","Iteration:  85% 1566/1851 [11:31<02:05,  2.27it/s]\u001b[A\n","Iteration:  85% 1567/1851 [11:31<02:05,  2.26it/s]\u001b[A\n","Iteration:  85% 1568/1851 [11:32<02:15,  2.08it/s]\u001b[A\n","Iteration:  85% 1569/1851 [11:32<02:11,  2.14it/s]\u001b[A\n","Iteration:  85% 1570/1851 [11:33<02:09,  2.17it/s]\u001b[A\n","Iteration:  85% 1571/1851 [11:33<02:07,  2.20it/s]\u001b[A\n","Iteration:  85% 1572/1851 [11:33<02:05,  2.23it/s]\u001b[A\n","Iteration:  85% 1573/1851 [11:34<02:03,  2.24it/s]\u001b[A\n","Iteration:  85% 1574/1851 [11:34<02:02,  2.25it/s]\u001b[A\n","Iteration:  85% 1575/1851 [11:35<02:02,  2.26it/s]\u001b[A\n","Iteration:  85% 1576/1851 [11:35<02:01,  2.27it/s]\u001b[A\n","Iteration:  85% 1577/1851 [11:36<02:00,  2.27it/s]\u001b[A\n","Iteration:  85% 1578/1851 [11:36<02:00,  2.27it/s]\u001b[A\n","Iteration:  85% 1579/1851 [11:37<01:59,  2.28it/s]\u001b[A\n","Iteration:  85% 1580/1851 [11:37<01:58,  2.28it/s]\u001b[A\n","Iteration:  85% 1581/1851 [11:37<01:58,  2.28it/s]\u001b[A\n","Iteration:  85% 1582/1851 [11:38<01:57,  2.28it/s]\u001b[A\n","Iteration:  86% 1583/1851 [11:38<01:57,  2.28it/s]\u001b[A\n","Iteration:  86% 1584/1851 [11:39<01:57,  2.28it/s]\u001b[A\n","Iteration:  86% 1585/1851 [11:39<01:56,  2.28it/s]\u001b[A\n","Iteration:  86% 1586/1851 [11:40<01:56,  2.28it/s]\u001b[A\n","Iteration:  86% 1587/1851 [11:40<01:55,  2.28it/s]\u001b[A\n","Iteration:  86% 1588/1851 [11:40<01:55,  2.28it/s]\u001b[A\n","Iteration:  86% 1589/1851 [11:41<01:54,  2.28it/s]\u001b[A\n","Iteration:  86% 1590/1851 [11:41<01:54,  2.28it/s]\u001b[A\n","Iteration:  86% 1591/1851 [11:42<01:53,  2.28it/s]\u001b[A\n","Iteration:  86% 1592/1851 [11:42<01:53,  2.28it/s]\u001b[A\n","Iteration:  86% 1593/1851 [11:43<01:53,  2.28it/s]\u001b[A\n","Iteration:  86% 1594/1851 [11:43<01:52,  2.28it/s]\u001b[A\n","Iteration:  86% 1595/1851 [11:44<01:52,  2.28it/s]\u001b[A\n","Iteration:  86% 1596/1851 [11:44<01:51,  2.28it/s]\u001b[A\n","Iteration:  86% 1597/1851 [11:44<01:51,  2.28it/s]\u001b[A\n","Iteration:  86% 1598/1851 [11:45<01:50,  2.28it/s]\u001b[A\n","Iteration:  86% 1599/1851 [11:45<01:51,  2.27it/s]\u001b[A\n","Iteration:  86% 1600/1851 [11:46<01:50,  2.27it/s]\u001b[A\n","Iteration:  86% 1601/1851 [11:46<01:49,  2.28it/s]\u001b[A\n","Iteration:  87% 1602/1851 [11:47<01:49,  2.27it/s]\u001b[A\n","Iteration:  87% 1603/1851 [11:47<01:48,  2.28it/s]\u001b[A\n","Iteration:  87% 1604/1851 [11:48<01:48,  2.28it/s]\u001b[A\n","Iteration:  87% 1605/1851 [11:48<01:47,  2.28it/s]\u001b[A\n","Iteration:  87% 1606/1851 [11:48<01:47,  2.28it/s]\u001b[A\n","Iteration:  87% 1607/1851 [11:49<01:47,  2.28it/s]\u001b[A\n","Iteration:  87% 1608/1851 [11:49<01:46,  2.28it/s]\u001b[A\n","Iteration:  87% 1609/1851 [11:50<01:46,  2.28it/s]\u001b[A\n","Iteration:  87% 1610/1851 [11:50<01:45,  2.28it/s]\u001b[A\n","Iteration:  87% 1611/1851 [11:51<01:45,  2.28it/s]\u001b[A\n","Iteration:  87% 1612/1851 [11:51<01:44,  2.28it/s]\u001b[A\n","Iteration:  87% 1613/1851 [11:51<01:44,  2.28it/s]\u001b[A\n","Iteration:  87% 1614/1851 [11:52<01:43,  2.28it/s]\u001b[A\n","Iteration:  87% 1615/1851 [11:52<01:43,  2.28it/s]\u001b[A\n","Iteration:  87% 1616/1851 [11:53<01:43,  2.28it/s]\u001b[A\n","Iteration:  87% 1617/1851 [11:53<01:42,  2.28it/s]\u001b[A\n","Iteration:  87% 1618/1851 [11:54<01:42,  2.28it/s]\u001b[A\n","Iteration:  87% 1619/1851 [11:54<01:41,  2.28it/s]\u001b[A\n","Iteration:  88% 1620/1851 [11:55<01:41,  2.28it/s]\u001b[A\n","Iteration:  88% 1621/1851 [11:55<01:40,  2.28it/s]\u001b[A\n","Iteration:  88% 1622/1851 [11:55<01:40,  2.28it/s]\u001b[A\n","Iteration:  88% 1623/1851 [11:56<01:40,  2.28it/s]\u001b[A\n","Iteration:  88% 1624/1851 [11:56<01:39,  2.28it/s]\u001b[A\n","Iteration:  88% 1625/1851 [11:57<01:39,  2.28it/s]\u001b[A\n","Iteration:  88% 1626/1851 [11:57<01:38,  2.28it/s]\u001b[A\n","Iteration:  88% 1627/1851 [11:58<01:38,  2.28it/s]\u001b[A\n","Iteration:  88% 1628/1851 [11:58<01:37,  2.28it/s]\u001b[A\n","Iteration:  88% 1629/1851 [11:58<01:37,  2.28it/s]\u001b[A\n","Iteration:  88% 1630/1851 [11:59<01:36,  2.28it/s]\u001b[A\n","Iteration:  88% 1631/1851 [11:59<01:36,  2.28it/s]\u001b[A\n","Iteration:  88% 1632/1851 [12:00<01:36,  2.28it/s]\u001b[A\n","Iteration:  88% 1633/1851 [12:00<01:35,  2.28it/s]\u001b[A\n","Iteration:  88% 1634/1851 [12:01<01:35,  2.28it/s]\u001b[A\n","Iteration:  88% 1635/1851 [12:01<01:34,  2.28it/s]\u001b[A\n","Iteration:  88% 1636/1851 [12:02<01:34,  2.28it/s]\u001b[A\n","Iteration:  88% 1637/1851 [12:02<01:33,  2.28it/s]\u001b[A\n","Iteration:  88% 1638/1851 [12:02<01:33,  2.28it/s]\u001b[A\n","Iteration:  89% 1639/1851 [12:03<01:33,  2.28it/s]\u001b[A\n","Iteration:  89% 1640/1851 [12:03<01:32,  2.28it/s]\u001b[A\n","Iteration:  89% 1641/1851 [12:04<01:32,  2.28it/s]\u001b[A\n","Iteration:  89% 1642/1851 [12:04<01:32,  2.27it/s]\u001b[A\n","Iteration:  89% 1643/1851 [12:05<01:31,  2.28it/s]\u001b[A\n","Iteration:  89% 1644/1851 [12:05<01:31,  2.27it/s]\u001b[A\n","Iteration:  89% 1645/1851 [12:06<01:30,  2.27it/s]\u001b[A\n","Iteration:  89% 1646/1851 [12:06<01:30,  2.27it/s]\u001b[A\n","Iteration:  89% 1647/1851 [12:07<01:45,  1.93it/s]\u001b[A\n","Iteration:  89% 1648/1851 [12:07<01:40,  2.03it/s]\u001b[A\n","Iteration:  89% 1649/1851 [12:08<01:36,  2.10it/s]\u001b[A\n","Iteration:  89% 1650/1851 [12:08<01:33,  2.15it/s]\u001b[A\n","Iteration:  89% 1651/1851 [12:08<01:31,  2.19it/s]\u001b[A\n","Iteration:  89% 1652/1851 [12:09<01:29,  2.21it/s]\u001b[A\n","Iteration:  89% 1653/1851 [12:09<01:28,  2.23it/s]\u001b[A\n","Iteration:  89% 1654/1851 [12:10<01:27,  2.25it/s]\u001b[A\n","Iteration:  89% 1655/1851 [12:10<01:26,  2.26it/s]\u001b[A\n","Iteration:  89% 1656/1851 [12:11<01:26,  2.26it/s]\u001b[A\n","Iteration:  90% 1657/1851 [12:11<01:25,  2.27it/s]\u001b[A\n","Iteration:  90% 1658/1851 [12:11<01:24,  2.27it/s]\u001b[A\n","Iteration:  90% 1659/1851 [12:12<01:24,  2.28it/s]\u001b[A\n","Iteration:  90% 1660/1851 [12:12<01:23,  2.28it/s]\u001b[A\n","Iteration:  90% 1661/1851 [12:13<01:23,  2.28it/s]\u001b[A\n","Iteration:  90% 1662/1851 [12:13<01:23,  2.27it/s]\u001b[A\n","Iteration:  90% 1663/1851 [12:14<01:22,  2.28it/s]\u001b[A\n","Iteration:  90% 1664/1851 [12:14<01:22,  2.28it/s]\u001b[A\n","Iteration:  90% 1665/1851 [12:15<01:21,  2.28it/s]\u001b[A\n","Iteration:  90% 1666/1851 [12:15<01:21,  2.27it/s]\u001b[A\n","Iteration:  90% 1667/1851 [12:15<01:20,  2.28it/s]\u001b[A\n","Iteration:  90% 1668/1851 [12:16<01:20,  2.28it/s]\u001b[A\n","Iteration:  90% 1669/1851 [12:16<01:19,  2.28it/s]\u001b[A\n","Iteration:  90% 1670/1851 [12:17<01:19,  2.27it/s]\u001b[A\n","Iteration:  90% 1671/1851 [12:17<01:19,  2.28it/s]\u001b[A\n","Iteration:  90% 1672/1851 [12:18<01:18,  2.28it/s]\u001b[A\n","Iteration:  90% 1673/1851 [12:18<01:18,  2.28it/s]\u001b[A\n","Iteration:  90% 1674/1851 [12:19<01:17,  2.28it/s]\u001b[A\n","Iteration:  90% 1675/1851 [12:19<01:17,  2.28it/s]\u001b[A\n","Iteration:  91% 1676/1851 [12:19<01:16,  2.28it/s]\u001b[A\n","Iteration:  91% 1677/1851 [12:20<01:16,  2.28it/s]\u001b[A\n","Iteration:  91% 1678/1851 [12:20<01:15,  2.28it/s]\u001b[A\n","Iteration:  91% 1679/1851 [12:21<01:15,  2.28it/s]\u001b[A\n","Iteration:  91% 1680/1851 [12:21<01:15,  2.28it/s]\u001b[A\n","Iteration:  91% 1681/1851 [12:22<01:14,  2.28it/s]\u001b[A\n","Iteration:  91% 1682/1851 [12:22<01:14,  2.28it/s]\u001b[A\n","Iteration:  91% 1683/1851 [12:22<01:13,  2.28it/s]\u001b[A\n","Iteration:  91% 1684/1851 [12:23<01:13,  2.28it/s]\u001b[A\n","Iteration:  91% 1685/1851 [12:23<01:12,  2.28it/s]\u001b[A\n","Iteration:  91% 1686/1851 [12:24<01:12,  2.28it/s]\u001b[A\n","Iteration:  91% 1687/1851 [12:24<01:11,  2.28it/s]\u001b[A\n","Iteration:  91% 1688/1851 [12:25<01:11,  2.28it/s]\u001b[A\n","Iteration:  91% 1689/1851 [12:25<01:10,  2.28it/s]\u001b[A\n","Iteration:  91% 1690/1851 [12:26<01:10,  2.28it/s]\u001b[A\n","Iteration:  91% 1691/1851 [12:26<01:10,  2.28it/s]\u001b[A\n","Iteration:  91% 1692/1851 [12:26<01:09,  2.28it/s]\u001b[A\n","Iteration:  91% 1693/1851 [12:27<01:09,  2.28it/s]\u001b[A\n","Iteration:  92% 1694/1851 [12:27<01:08,  2.28it/s]\u001b[A\n","Iteration:  92% 1695/1851 [12:28<01:08,  2.28it/s]\u001b[A\n","Iteration:  92% 1696/1851 [12:28<01:08,  2.27it/s]\u001b[A\n","Iteration:  92% 1697/1851 [12:29<01:07,  2.27it/s]\u001b[A\n","Iteration:  92% 1698/1851 [12:29<01:07,  2.27it/s]\u001b[A\n","Iteration:  92% 1699/1851 [12:29<01:06,  2.28it/s]\u001b[A\n","Iteration:  92% 1700/1851 [12:30<01:06,  2.28it/s]\u001b[A\n","Iteration:  92% 1701/1851 [12:30<01:05,  2.28it/s]\u001b[A\n","Iteration:  92% 1702/1851 [12:31<01:05,  2.28it/s]\u001b[A\n","Iteration:  92% 1703/1851 [12:31<01:04,  2.28it/s]\u001b[A\n","Iteration:  92% 1704/1851 [12:32<01:04,  2.27it/s]\u001b[A\n","Iteration:  92% 1705/1851 [12:32<01:04,  2.28it/s]\u001b[A\n","Iteration:  92% 1706/1851 [12:33<01:03,  2.28it/s]\u001b[A\n","Iteration:  92% 1707/1851 [12:33<01:03,  2.28it/s]\u001b[A\n","Iteration:  92% 1708/1851 [12:33<01:02,  2.28it/s]\u001b[A\n","Iteration:  92% 1709/1851 [12:34<01:02,  2.28it/s]\u001b[A\n","Iteration:  92% 1710/1851 [12:34<01:01,  2.28it/s]\u001b[A\n","Iteration:  92% 1711/1851 [12:35<01:01,  2.28it/s]\u001b[A\n","Iteration:  92% 1712/1851 [12:35<01:00,  2.28it/s]\u001b[A\n","Iteration:  93% 1713/1851 [12:36<01:00,  2.28it/s]\u001b[A\n","Iteration:  93% 1714/1851 [12:36<01:00,  2.28it/s]\u001b[A\n","Iteration:  93% 1715/1851 [12:36<00:59,  2.28it/s]\u001b[A\n","Iteration:  93% 1716/1851 [12:37<00:59,  2.28it/s]\u001b[A\n","Iteration:  93% 1717/1851 [12:37<00:58,  2.28it/s]\u001b[A\n","Iteration:  93% 1718/1851 [12:38<00:58,  2.28it/s]\u001b[A\n","Iteration:  93% 1719/1851 [12:38<00:57,  2.28it/s]\u001b[A\n","Iteration:  93% 1720/1851 [12:39<00:57,  2.28it/s]\u001b[A\n","Iteration:  93% 1721/1851 [12:39<00:57,  2.28it/s]\u001b[A\n","Iteration:  93% 1722/1851 [12:40<00:56,  2.28it/s]\u001b[A\n","Iteration:  93% 1723/1851 [12:40<00:56,  2.28it/s]\u001b[A\n","Iteration:  93% 1724/1851 [12:40<00:55,  2.28it/s]\u001b[A\n","Iteration:  93% 1725/1851 [12:41<00:55,  2.28it/s]\u001b[A\n","Iteration:  93% 1726/1851 [12:41<00:54,  2.28it/s]\u001b[A\n","Iteration:  93% 1727/1851 [12:42<00:54,  2.28it/s]\u001b[A\n","Iteration:  93% 1728/1851 [12:42<00:53,  2.28it/s]\u001b[A\n","Iteration:  93% 1729/1851 [12:43<00:53,  2.28it/s]\u001b[A\n","Iteration:  93% 1730/1851 [12:43<00:53,  2.28it/s]\u001b[A\n","Iteration:  94% 1731/1851 [12:44<00:52,  2.28it/s]\u001b[A\n","Iteration:  94% 1732/1851 [12:44<00:52,  2.28it/s]\u001b[A\n","Iteration:  94% 1733/1851 [12:44<00:51,  2.28it/s]\u001b[A\n","Iteration:  94% 1734/1851 [12:45<00:51,  2.28it/s]\u001b[A\n","Iteration:  94% 1735/1851 [12:45<00:50,  2.28it/s]\u001b[A\n","Iteration:  94% 1736/1851 [12:46<00:50,  2.28it/s]\u001b[A\n","Iteration:  94% 1737/1851 [12:46<00:49,  2.28it/s]\u001b[A\n","Iteration:  94% 1738/1851 [12:47<00:49,  2.28it/s]\u001b[A\n","Iteration:  94% 1739/1851 [12:47<00:49,  2.28it/s]\u001b[A\n","Iteration:  94% 1740/1851 [12:47<00:48,  2.28it/s]\u001b[A\n","Iteration:  94% 1741/1851 [12:48<00:48,  2.28it/s]\u001b[A\n","Iteration:  94% 1742/1851 [12:48<00:47,  2.28it/s]\u001b[A\n","Iteration:  94% 1743/1851 [12:49<00:47,  2.28it/s]\u001b[A\n","Iteration:  94% 1744/1851 [12:49<00:46,  2.28it/s]\u001b[A\n","Iteration:  94% 1745/1851 [12:50<00:46,  2.28it/s]\u001b[A\n","Iteration:  94% 1746/1851 [12:50<00:46,  2.28it/s]\u001b[A\n","Iteration:  94% 1747/1851 [12:51<00:45,  2.28it/s]\u001b[A\n","Iteration:  94% 1748/1851 [12:51<00:45,  2.28it/s]\u001b[A\n","Iteration:  94% 1749/1851 [12:51<00:44,  2.28it/s]\u001b[A\n","Iteration:  95% 1750/1851 [12:52<00:44,  2.28it/s]\u001b[A\n","Iteration:  95% 1751/1851 [12:52<00:43,  2.28it/s]\u001b[A\n","Iteration:  95% 1752/1851 [12:53<00:43,  2.28it/s]\u001b[A\n","Iteration:  95% 1753/1851 [12:53<00:42,  2.28it/s]\u001b[A\n","Iteration:  95% 1754/1851 [12:54<00:42,  2.28it/s]\u001b[A\n","Iteration:  95% 1755/1851 [12:54<00:42,  2.28it/s]\u001b[A\n","Iteration:  95% 1756/1851 [12:54<00:41,  2.28it/s]\u001b[A\n","Iteration:  95% 1757/1851 [12:55<00:41,  2.28it/s]\u001b[A\n","Iteration:  95% 1758/1851 [12:55<00:40,  2.28it/s]\u001b[A\n","Iteration:  95% 1759/1851 [12:56<00:40,  2.28it/s]\u001b[A\n","Iteration:  95% 1760/1851 [12:56<00:39,  2.28it/s]\u001b[A\n","Iteration:  95% 1761/1851 [12:57<00:39,  2.28it/s]\u001b[A\n","Iteration:  95% 1762/1851 [12:57<00:39,  2.28it/s]\u001b[A\n","Iteration:  95% 1763/1851 [12:58<00:38,  2.28it/s]\u001b[A\n","Iteration:  95% 1764/1851 [12:58<00:38,  2.28it/s]\u001b[A\n","Iteration:  95% 1765/1851 [12:58<00:37,  2.28it/s]\u001b[A\n","Iteration:  95% 1766/1851 [12:59<00:37,  2.28it/s]\u001b[A\n","Iteration:  95% 1767/1851 [12:59<00:36,  2.28it/s]\u001b[A\n","Iteration:  96% 1768/1851 [13:00<00:36,  2.28it/s]\u001b[A\n","Iteration:  96% 1769/1851 [13:00<00:35,  2.28it/s]\u001b[A\n","Iteration:  96% 1770/1851 [13:01<00:35,  2.28it/s]\u001b[A\n","Iteration:  96% 1771/1851 [13:01<00:35,  2.28it/s]\u001b[A\n","Iteration:  96% 1772/1851 [13:01<00:34,  2.28it/s]\u001b[A\n","Iteration:  96% 1773/1851 [13:02<00:34,  2.28it/s]\u001b[A\n","Iteration:  96% 1774/1851 [13:02<00:33,  2.28it/s]\u001b[A\n","Iteration:  96% 1775/1851 [13:03<00:33,  2.28it/s]\u001b[A\n","Iteration:  96% 1776/1851 [13:03<00:32,  2.28it/s]\u001b[A\n","Iteration:  96% 1777/1851 [13:04<00:32,  2.28it/s]\u001b[A\n","Iteration:  96% 1778/1851 [13:04<00:32,  2.28it/s]\u001b[A\n","Iteration:  96% 1779/1851 [13:05<00:31,  2.28it/s]\u001b[A\n","Iteration:  96% 1780/1851 [13:05<00:31,  2.28it/s]\u001b[A\n","Iteration:  96% 1781/1851 [13:05<00:30,  2.28it/s]\u001b[A\n","Iteration:  96% 1782/1851 [13:06<00:30,  2.28it/s]\u001b[A\n","Iteration:  96% 1783/1851 [13:06<00:29,  2.28it/s]\u001b[A\n","Iteration:  96% 1784/1851 [13:07<00:29,  2.27it/s]\u001b[A\n","Iteration:  96% 1785/1851 [13:07<00:29,  2.28it/s]\u001b[A\n","Iteration:  96% 1786/1851 [13:08<00:28,  2.28it/s]\u001b[A\n","Iteration:  97% 1787/1851 [13:08<00:28,  2.28it/s]\u001b[A\n","Iteration:  97% 1788/1851 [13:08<00:27,  2.28it/s]\u001b[A\n","Iteration:  97% 1789/1851 [13:09<00:27,  2.28it/s]\u001b[A\n","Iteration:  97% 1790/1851 [13:09<00:26,  2.28it/s]\u001b[A\n","Iteration:  97% 1791/1851 [13:10<00:26,  2.28it/s]\u001b[A\n","Iteration:  97% 1792/1851 [13:10<00:25,  2.28it/s]\u001b[A\n","Iteration:  97% 1793/1851 [13:11<00:25,  2.28it/s]\u001b[A\n","Iteration:  97% 1794/1851 [13:11<00:24,  2.28it/s]\u001b[A\n","Iteration:  97% 1795/1851 [13:12<00:24,  2.28it/s]\u001b[A\n","Iteration:  97% 1796/1851 [13:12<00:24,  2.28it/s]\u001b[A\n","Iteration:  97% 1797/1851 [13:12<00:23,  2.27it/s]\u001b[A\n","Iteration:  97% 1798/1851 [13:13<00:23,  2.28it/s]\u001b[A\n","Iteration:  97% 1799/1851 [13:13<00:22,  2.28it/s]\u001b[A\n","Iteration:  97% 1800/1851 [13:14<00:22,  2.28it/s]\u001b[A\n","Iteration:  97% 1801/1851 [13:14<00:21,  2.28it/s]\u001b[A\n","Iteration:  97% 1802/1851 [13:15<00:21,  2.28it/s]\u001b[A\n","Iteration:  97% 1803/1851 [13:15<00:21,  2.28it/s]\u001b[A\n","Iteration:  97% 1804/1851 [13:16<00:20,  2.28it/s]\u001b[A\n","Iteration:  98% 1805/1851 [13:16<00:20,  2.28it/s]\u001b[A\n","Iteration:  98% 1806/1851 [13:16<00:19,  2.28it/s]\u001b[A\n","Iteration:  98% 1807/1851 [13:17<00:19,  2.28it/s]\u001b[A\n","Iteration:  98% 1808/1851 [13:17<00:18,  2.28it/s]\u001b[A\n","Iteration:  98% 1809/1851 [13:18<00:18,  2.28it/s]\u001b[A\n","Iteration:  98% 1810/1851 [13:18<00:17,  2.28it/s]\u001b[A\n","Iteration:  98% 1811/1851 [13:19<00:17,  2.28it/s]\u001b[A\n","Iteration:  98% 1812/1851 [13:19<00:17,  2.28it/s]\u001b[A\n","Iteration:  98% 1813/1851 [13:19<00:16,  2.28it/s]\u001b[A\n","Iteration:  98% 1814/1851 [13:20<00:16,  2.28it/s]\u001b[A\n","Iteration:  98% 1815/1851 [13:20<00:15,  2.28it/s]\u001b[A\n","Iteration:  98% 1816/1851 [13:21<00:15,  2.28it/s]\u001b[A\n","Iteration:  98% 1817/1851 [13:21<00:14,  2.28it/s]\u001b[A\n","Iteration:  98% 1818/1851 [13:22<00:14,  2.28it/s]\u001b[A\n","Iteration:  98% 1819/1851 [13:22<00:14,  2.28it/s]\u001b[A\n","Iteration:  98% 1820/1851 [13:23<00:13,  2.28it/s]\u001b[A\n","Iteration:  98% 1821/1851 [13:23<00:13,  2.28it/s]\u001b[A\n","Iteration:  98% 1822/1851 [13:23<00:12,  2.28it/s]\u001b[A\n","Iteration:  98% 1823/1851 [13:24<00:12,  2.28it/s]\u001b[A\n","Iteration:  99% 1824/1851 [13:24<00:11,  2.28it/s]\u001b[A\n","Iteration:  99% 1825/1851 [13:25<00:11,  2.28it/s]\u001b[A\n","Iteration:  99% 1826/1851 [13:25<00:11,  2.27it/s]\u001b[A\n","Iteration:  99% 1827/1851 [13:26<00:10,  2.27it/s]\u001b[A\n","Iteration:  99% 1828/1851 [13:26<00:10,  2.28it/s]\u001b[A\n","Iteration:  99% 1829/1851 [13:26<00:09,  2.28it/s]\u001b[A\n","Iteration:  99% 1830/1851 [13:27<00:09,  2.27it/s]\u001b[A\n","Iteration:  99% 1831/1851 [13:27<00:08,  2.27it/s]\u001b[A\n","Iteration:  99% 1832/1851 [13:28<00:09,  1.99it/s]\u001b[A\n","Iteration:  99% 1833/1851 [13:28<00:08,  2.06it/s]\u001b[A\n","Iteration:  99% 1834/1851 [13:29<00:08,  2.12it/s]\u001b[A\n","Iteration:  99% 1835/1851 [13:29<00:07,  2.16it/s]\u001b[A\n","Iteration:  99% 1836/1851 [13:30<00:06,  2.20it/s]\u001b[A\n","Iteration:  99% 1837/1851 [13:30<00:06,  2.22it/s]\u001b[A\n","Iteration:  99% 1838/1851 [13:31<00:05,  2.24it/s]\u001b[A\n","Iteration:  99% 1839/1851 [13:31<00:05,  2.25it/s]\u001b[A\n","Iteration:  99% 1840/1851 [13:32<00:04,  2.26it/s]\u001b[A\n","Iteration:  99% 1841/1851 [13:32<00:04,  2.26it/s]\u001b[A\n","Iteration: 100% 1842/1851 [13:32<00:03,  2.27it/s]\u001b[A\n","Iteration: 100% 1843/1851 [13:33<00:03,  2.27it/s]\u001b[A\n","Iteration: 100% 1844/1851 [13:33<00:03,  2.27it/s]\u001b[A\n","Iteration: 100% 1845/1851 [13:34<00:02,  2.28it/s]\u001b[A\n","Iteration: 100% 1846/1851 [13:34<00:02,  2.28it/s]\u001b[A\n","Iteration: 100% 1847/1851 [13:35<00:01,  2.28it/s]\u001b[A\n","Iteration: 100% 1848/1851 [13:35<00:01,  2.28it/s]\u001b[A\n","Iteration: 100% 1849/1851 [13:35<00:00,  2.28it/s]\u001b[A\n","Iteration: 100% 1850/1851 [13:36<00:00,  2.28it/s]\u001b[A\n","Iteration: 100% 1851/1851 [13:36<00:00,  2.27it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-14 23:52:02,603][__main__][DEBUG] - epoch is 0\n","[2022-08-14 23:52:02,604][__main__][DEBUG] - validation loss is tensor(0.1148, device='cuda:0')\n","Epoch:   1% 1/100 [16:59<28:02:13, 1019.53s/it]\n","Iteration:   0% 0/1851 [00:00<?, ?it/s]\u001b[AThe current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\n","Iteration:   0% 1/1851 [00:01<40:40,  1.32s/it]\u001b[A\n","Iteration:   0% 2/1851 [00:01<25:27,  1.21it/s]\u001b[A\n","Iteration:   0% 3/1851 [00:02<22:48,  1.35it/s]\u001b[A\n","Iteration:   0% 4/1851 [00:02<19:08,  1.61it/s]\u001b[A\n","Iteration:   0% 5/1851 [00:03<17:06,  1.80it/s]\u001b[A\n","Iteration:   0% 6/1851 [00:03<15:55,  1.93it/s]\u001b[A\n","Iteration:   0% 7/1851 [00:04<15:07,  2.03it/s]\u001b[A\n","Iteration:   0% 8/1851 [00:04<14:36,  2.10it/s]\u001b[A\n","Iteration:   0% 9/1851 [00:05<14:15,  2.15it/s]\u001b[A\n","Iteration:   1% 10/1851 [00:05<14:01,  2.19it/s]\u001b[A\n","Iteration:   1% 11/1851 [00:05<13:50,  2.22it/s]\u001b[A\n","Iteration:   1% 12/1851 [00:06<13:43,  2.23it/s]\u001b[A\n","Iteration:   1% 13/1851 [00:06<13:38,  2.25it/s]\u001b[A\n","Iteration:   1% 14/1851 [00:07<13:35,  2.25it/s]\u001b[A\n","Iteration:   1% 15/1851 [00:07<13:33,  2.26it/s]\u001b[A\n","Iteration:   1% 16/1851 [00:08<13:30,  2.26it/s]\u001b[A\n","Iteration:   1% 17/1851 [00:08<13:29,  2.26it/s]\u001b[A\n","Iteration:   1% 18/1851 [00:09<13:29,  2.26it/s]\u001b[A\n","Iteration:   1% 19/1851 [00:09<13:28,  2.27it/s]\u001b[A\n","Iteration:   1% 20/1851 [00:09<13:28,  2.26it/s]\u001b[A\n","Iteration:   1% 21/1851 [00:10<13:27,  2.27it/s]\u001b[A\n","Iteration:   1% 22/1851 [00:10<13:25,  2.27it/s]\u001b[A\n","Iteration:   1% 23/1851 [00:11<13:24,  2.27it/s]\u001b[A\n","Iteration:   1% 24/1851 [00:11<13:24,  2.27it/s]\u001b[A\n","Iteration:   1% 25/1851 [00:12<13:23,  2.27it/s]\u001b[A\n","Iteration:   1% 26/1851 [00:12<13:23,  2.27it/s]\u001b[A\n","Iteration:   1% 27/1851 [00:13<13:22,  2.27it/s]\u001b[A\n","Iteration:   2% 28/1851 [00:13<13:21,  2.27it/s]\u001b[A\n","Iteration:   2% 29/1851 [00:13<13:21,  2.27it/s]\u001b[A\n","Iteration:   2% 30/1851 [00:14<13:21,  2.27it/s]\u001b[A\n","Iteration:   2% 31/1851 [00:14<13:20,  2.27it/s]\u001b[A\n","Iteration:   2% 32/1851 [00:15<13:20,  2.27it/s]\u001b[A\n","Iteration:   2% 33/1851 [00:15<13:19,  2.27it/s]\u001b[A\n","Iteration:   2% 34/1851 [00:16<13:19,  2.27it/s]\u001b[A\n","Iteration:   2% 35/1851 [00:16<13:20,  2.27it/s]\u001b[A\n","Iteration:   2% 36/1851 [00:16<13:22,  2.26it/s]\u001b[A\n","Iteration:   2% 37/1851 [00:17<13:45,  2.20it/s]\u001b[A\n","Iteration:   2% 38/1851 [00:17<13:36,  2.22it/s]\u001b[A\n","Iteration:   2% 39/1851 [00:18<13:31,  2.23it/s]\u001b[A\n","Iteration:   2% 40/1851 [00:18<13:27,  2.24it/s]\u001b[A\n","Iteration:   2% 41/1851 [00:19<13:23,  2.25it/s]\u001b[A\n","Iteration:   2% 42/1851 [00:19<13:22,  2.26it/s]\u001b[A\n","Iteration:   2% 43/1851 [00:20<13:20,  2.26it/s]\u001b[A\n","Iteration:   2% 44/1851 [00:20<13:19,  2.26it/s]\u001b[A\n","Iteration:   2% 45/1851 [00:20<13:18,  2.26it/s]\u001b[A\n","Iteration:   2% 46/1851 [00:21<13:16,  2.27it/s]\u001b[A\n","Iteration:   3% 47/1851 [00:21<13:15,  2.27it/s]\u001b[A\n","Iteration:   3% 48/1851 [00:22<13:15,  2.27it/s]\u001b[A\n","Iteration:   3% 49/1851 [00:22<13:14,  2.27it/s]\u001b[A\n","Iteration:   3% 50/1851 [00:23<13:13,  2.27it/s]\u001b[A\n","Iteration:   3% 51/1851 [00:23<13:12,  2.27it/s]\u001b[A\n","Iteration:   3% 52/1851 [00:24<13:11,  2.27it/s]\u001b[A\n","Iteration:   3% 53/1851 [00:24<13:10,  2.27it/s]\u001b[A\n","Iteration:   3% 54/1851 [00:24<13:09,  2.28it/s]\u001b[A\n","Iteration:   3% 55/1851 [00:25<13:09,  2.28it/s]\u001b[A\n","Iteration:   3% 56/1851 [00:25<13:08,  2.28it/s]\u001b[A\n","Iteration:   3% 57/1851 [00:26<13:08,  2.28it/s]\u001b[A\n","Iteration:   3% 58/1851 [00:26<13:07,  2.28it/s]\u001b[A\n","Iteration:   3% 59/1851 [00:27<13:07,  2.27it/s]\u001b[A\n","Iteration:   3% 60/1851 [00:27<13:06,  2.28it/s]\u001b[A\n","Iteration:   3% 61/1851 [00:28<13:05,  2.28it/s]\u001b[A\n","Iteration:   3% 62/1851 [00:28<13:04,  2.28it/s]\u001b[A\n","Iteration:   3% 63/1851 [00:28<13:04,  2.28it/s]\u001b[A\n","Iteration:   3% 64/1851 [00:29<13:04,  2.28it/s]\u001b[A\n","Iteration:   4% 65/1851 [00:29<13:03,  2.28it/s]\u001b[A\n","Iteration:   4% 66/1851 [00:30<13:04,  2.28it/s]\u001b[A\n","Iteration:   4% 67/1851 [00:30<13:03,  2.28it/s]\u001b[A\n","Iteration:   4% 68/1851 [00:31<13:02,  2.28it/s]\u001b[A\n","Iteration:   4% 69/1851 [00:31<13:02,  2.28it/s]\u001b[A\n","Iteration:   4% 70/1851 [00:31<13:01,  2.28it/s]\u001b[A\n","Iteration:   4% 71/1851 [00:32<13:01,  2.28it/s]\u001b[A\n","Iteration:   4% 72/1851 [00:32<13:01,  2.28it/s]\u001b[A\n","Iteration:   4% 73/1851 [00:33<13:00,  2.28it/s]\u001b[A\n","Iteration:   4% 74/1851 [00:33<13:00,  2.28it/s]\u001b[A\n","Iteration:   4% 75/1851 [00:34<13:01,  2.27it/s]\u001b[A\n","Iteration:   4% 76/1851 [00:34<13:00,  2.27it/s]\u001b[A\n","Iteration:   4% 77/1851 [00:35<12:59,  2.28it/s]\u001b[A\n","Iteration:   4% 78/1851 [00:35<12:58,  2.28it/s]\u001b[A\n","Iteration:   4% 79/1851 [00:35<12:58,  2.28it/s]\u001b[A\n","Iteration:   4% 80/1851 [00:36<12:58,  2.28it/s]\u001b[A\n","Iteration:   4% 81/1851 [00:36<12:57,  2.28it/s]\u001b[A\n","Iteration:   4% 82/1851 [00:37<12:57,  2.28it/s]\u001b[A\n","Iteration:   4% 83/1851 [00:37<12:56,  2.28it/s]\u001b[A\n","Iteration:   5% 84/1851 [00:38<12:55,  2.28it/s]\u001b[A\n","Iteration:   5% 85/1851 [00:38<12:55,  2.28it/s]\u001b[A\n","Iteration:   5% 86/1851 [00:38<12:54,  2.28it/s]\u001b[A\n","Iteration:   5% 87/1851 [00:39<12:54,  2.28it/s]\u001b[A\n","Iteration:   5% 88/1851 [00:39<12:54,  2.28it/s]\u001b[A\n","Iteration:   5% 89/1851 [00:40<12:54,  2.28it/s]\u001b[A\n","Iteration:   5% 90/1851 [00:40<12:53,  2.28it/s]\u001b[A\n","Iteration:   5% 91/1851 [00:41<12:53,  2.28it/s]\u001b[A\n","Iteration:   5% 92/1851 [00:41<12:52,  2.28it/s]\u001b[A\n","Iteration:   5% 93/1851 [00:42<12:52,  2.28it/s]\u001b[A\n","Iteration:   5% 94/1851 [00:42<12:51,  2.28it/s]\u001b[A\n","Iteration:   5% 95/1851 [00:42<12:50,  2.28it/s]\u001b[A\n","Iteration:   5% 96/1851 [00:43<12:50,  2.28it/s]\u001b[A\n","Iteration:   5% 97/1851 [00:43<12:49,  2.28it/s]\u001b[A\n","Iteration:   5% 98/1851 [00:44<12:49,  2.28it/s]\u001b[A\n","Iteration:   5% 99/1851 [00:44<12:48,  2.28it/s]\u001b[A\n","Iteration:   5% 100/1851 [00:45<12:48,  2.28it/s]\u001b[A\n","Iteration:   5% 101/1851 [00:45<12:47,  2.28it/s]\u001b[A\n","Iteration:   6% 102/1851 [00:46<12:47,  2.28it/s]\u001b[A\n","Iteration:   6% 103/1851 [00:46<12:47,  2.28it/s]\u001b[A\n","Iteration:   6% 104/1851 [00:46<12:46,  2.28it/s]\u001b[A\n","Iteration:   6% 105/1851 [00:47<12:45,  2.28it/s]\u001b[A\n","Iteration:   6% 106/1851 [00:47<12:45,  2.28it/s]\u001b[A\n","Iteration:   6% 107/1851 [00:48<12:45,  2.28it/s]\u001b[A\n","Iteration:   6% 108/1851 [00:48<12:46,  2.28it/s]\u001b[A\n","Iteration:   6% 109/1851 [00:49<12:45,  2.28it/s]\u001b[A\n","Iteration:   6% 110/1851 [00:49<12:45,  2.27it/s]\u001b[A\n","Iteration:   6% 111/1851 [00:49<12:44,  2.28it/s]\u001b[A\n","Iteration:   6% 112/1851 [00:50<12:44,  2.27it/s]\u001b[A\n","Iteration:   6% 113/1851 [00:50<12:43,  2.28it/s]\u001b[A\n","Iteration:   6% 114/1851 [00:51<12:43,  2.28it/s]\u001b[A\n","Iteration:   6% 115/1851 [00:51<12:42,  2.28it/s]\u001b[A\n","Iteration:   6% 116/1851 [00:52<13:07,  2.20it/s]\u001b[A\n","Iteration:   6% 117/1851 [00:52<13:01,  2.22it/s]\u001b[A\n","Iteration:   6% 118/1851 [00:53<12:54,  2.24it/s]\u001b[A\n","Iteration:   6% 119/1851 [00:53<12:50,  2.25it/s]\u001b[A\n","Iteration:   6% 120/1851 [00:53<12:46,  2.26it/s]\u001b[A\n","Iteration:   7% 121/1851 [00:54<12:43,  2.27it/s]\u001b[A\n","Iteration:   7% 122/1851 [00:54<12:41,  2.27it/s]\u001b[A\n","Iteration:   7% 123/1851 [00:55<12:40,  2.27it/s]\u001b[A\n","Iteration:   7% 124/1851 [00:55<12:39,  2.27it/s]\u001b[A\n","Iteration:   7% 125/1851 [00:56<12:37,  2.28it/s]\u001b[A\n","Iteration:   7% 126/1851 [00:56<12:37,  2.28it/s]\u001b[A\n","Iteration:   7% 127/1851 [00:57<12:37,  2.28it/s]\u001b[A\n","Iteration:   7% 128/1851 [00:57<12:36,  2.28it/s]\u001b[A\n","Iteration:   7% 129/1851 [00:57<12:36,  2.28it/s]\u001b[A\n","Iteration:   7% 130/1851 [00:58<12:35,  2.28it/s]\u001b[A\n","Iteration:   7% 131/1851 [00:58<12:35,  2.28it/s]\u001b[A\n","Iteration:   7% 132/1851 [00:59<12:34,  2.28it/s]\u001b[A\n","Iteration:   7% 133/1851 [00:59<12:35,  2.28it/s]\u001b[A\n","Iteration:   7% 134/1851 [01:00<12:41,  2.25it/s]\u001b[A\n","Iteration:   7% 135/1851 [01:00<12:39,  2.26it/s]\u001b[A\n","Iteration:   7% 136/1851 [01:01<13:43,  2.08it/s]\u001b[A\n","Iteration:   7% 137/1851 [01:01<13:21,  2.14it/s]\u001b[A\n","Iteration:   7% 138/1851 [01:02<13:07,  2.18it/s]\u001b[A\n","Iteration:   8% 139/1851 [01:02<12:55,  2.21it/s]\u001b[A\n","Iteration:   8% 140/1851 [01:02<12:49,  2.22it/s]\u001b[A\n","Iteration:   8% 141/1851 [01:03<12:42,  2.24it/s]\u001b[A\n","Iteration:   8% 142/1851 [01:03<12:39,  2.25it/s]\u001b[A\n","Iteration:   8% 143/1851 [01:04<12:35,  2.26it/s]\u001b[A\n","Iteration:   8% 144/1851 [01:04<12:33,  2.27it/s]\u001b[A\n","Iteration:   8% 145/1851 [01:05<12:31,  2.27it/s]\u001b[A\n","Iteration:   8% 146/1851 [01:05<12:29,  2.27it/s]\u001b[A\n","Iteration:   8% 147/1851 [01:05<12:28,  2.28it/s]\u001b[A\n","Iteration:   8% 148/1851 [01:06<12:30,  2.27it/s]\u001b[A\n","Iteration:   8% 149/1851 [01:06<12:30,  2.27it/s]\u001b[A\n","Iteration:   8% 150/1851 [01:07<12:28,  2.27it/s]\u001b[A\n","Iteration:   8% 151/1851 [01:07<12:28,  2.27it/s]\u001b[A\n","Iteration:   8% 152/1851 [01:08<12:27,  2.27it/s]\u001b[A\n","Iteration:   8% 153/1851 [01:08<12:26,  2.27it/s]\u001b[A\n","Iteration:   8% 154/1851 [01:09<12:25,  2.28it/s]\u001b[A\n","Iteration:   8% 155/1851 [01:09<12:25,  2.28it/s]\u001b[A\n","Iteration:   8% 156/1851 [01:09<12:26,  2.27it/s]\u001b[A\n","Iteration:   8% 157/1851 [01:10<12:24,  2.27it/s]\u001b[A\n","Iteration:   9% 158/1851 [01:10<12:23,  2.28it/s]\u001b[A\n","Iteration:   9% 159/1851 [01:11<12:23,  2.28it/s]\u001b[A\n","Iteration:   9% 160/1851 [01:11<12:22,  2.28it/s]\u001b[A\n","Iteration:   9% 161/1851 [01:12<12:22,  2.27it/s]\u001b[A\n","Iteration:   9% 162/1851 [01:12<12:22,  2.27it/s]\u001b[A\n","Iteration:   9% 163/1851 [01:13<12:22,  2.27it/s]\u001b[A\n","Iteration:   9% 164/1851 [01:13<12:21,  2.28it/s]\u001b[A\n","Iteration:   9% 165/1851 [01:13<12:21,  2.28it/s]\u001b[A\n","Iteration:   9% 166/1851 [01:14<12:20,  2.28it/s]\u001b[A\n","Iteration:   9% 167/1851 [01:14<12:19,  2.28it/s]\u001b[A\n","Iteration:   9% 168/1851 [01:15<12:18,  2.28it/s]\u001b[A\n","Iteration:   9% 169/1851 [01:15<12:18,  2.28it/s]\u001b[A\n","Iteration:   9% 170/1851 [01:16<12:18,  2.28it/s]\u001b[A\n","Iteration:   9% 171/1851 [01:16<12:17,  2.28it/s]\u001b[A\n","Iteration:   9% 172/1851 [01:16<12:17,  2.28it/s]\u001b[A\n","Iteration:   9% 173/1851 [01:17<12:17,  2.27it/s]\u001b[A\n","Iteration:   9% 174/1851 [01:17<12:17,  2.27it/s]\u001b[A\n","Iteration:   9% 175/1851 [01:18<12:16,  2.28it/s]\u001b[A\n","Iteration:  10% 176/1851 [01:18<12:15,  2.28it/s]\u001b[A\n","Iteration:  10% 177/1851 [01:19<12:15,  2.27it/s]\u001b[A\n","Iteration:  10% 178/1851 [01:19<12:14,  2.28it/s]\u001b[A\n","Iteration:  10% 179/1851 [01:20<12:14,  2.28it/s]\u001b[A\n","Iteration:  10% 180/1851 [01:20<12:14,  2.28it/s]\u001b[A\n","Iteration:  10% 181/1851 [01:20<12:13,  2.28it/s]\u001b[A\n","Iteration:  10% 182/1851 [01:21<12:13,  2.28it/s]\u001b[A\n","Iteration:  10% 183/1851 [01:21<12:14,  2.27it/s]\u001b[A\n","Iteration:  10% 184/1851 [01:22<12:13,  2.27it/s]\u001b[A\n","Iteration:  10% 185/1851 [01:22<12:13,  2.27it/s]\u001b[A\n","Iteration:  10% 186/1851 [01:23<12:15,  2.26it/s]\u001b[A\n","Iteration:  10% 187/1851 [01:23<12:14,  2.26it/s]\u001b[A\n","Iteration:  10% 188/1851 [01:24<12:16,  2.26it/s]\u001b[A\n","Iteration:  10% 189/1851 [01:24<12:27,  2.22it/s]\u001b[A\n","Iteration:  10% 190/1851 [01:24<12:27,  2.22it/s]\u001b[A\n","Iteration:  10% 191/1851 [01:25<12:20,  2.24it/s]\u001b[A\n","Iteration:  10% 192/1851 [01:25<12:16,  2.25it/s]\u001b[A\n","Iteration:  10% 193/1851 [01:26<12:13,  2.26it/s]\u001b[A\n","Iteration:  10% 194/1851 [01:26<12:11,  2.26it/s]\u001b[A\n","Iteration:  11% 195/1851 [01:27<12:09,  2.27it/s]\u001b[A\n","Iteration:  11% 196/1851 [01:27<12:08,  2.27it/s]\u001b[A\n","Iteration:  11% 197/1851 [01:28<12:07,  2.27it/s]\u001b[A\n","Iteration:  11% 198/1851 [01:28<12:06,  2.27it/s]\u001b[A\n","Iteration:  11% 199/1851 [01:28<12:05,  2.28it/s]\u001b[A\n","Iteration:  11% 200/1851 [01:29<12:04,  2.28it/s]\u001b[A\n","Iteration:  11% 201/1851 [01:29<12:04,  2.28it/s]\u001b[A\n","Iteration:  11% 202/1851 [01:30<12:04,  2.28it/s]\u001b[A\n","Iteration:  11% 203/1851 [01:30<12:03,  2.28it/s]\u001b[A\n","Iteration:  11% 204/1851 [01:31<12:03,  2.28it/s]\u001b[A\n","Iteration:  11% 205/1851 [01:31<12:02,  2.28it/s]\u001b[A\n","Iteration:  11% 206/1851 [01:31<12:01,  2.28it/s]\u001b[A\n","Iteration:  11% 207/1851 [01:32<12:02,  2.28it/s]\u001b[A\n","Iteration:  11% 208/1851 [01:32<12:02,  2.28it/s]\u001b[A\n","Iteration:  11% 209/1851 [01:33<12:01,  2.27it/s]\u001b[A\n","Iteration:  11% 210/1851 [01:33<12:59,  2.11it/s]\u001b[A\n","Iteration:  11% 211/1851 [01:34<12:41,  2.15it/s]\u001b[A\n","Iteration:  11% 212/1851 [01:34<12:28,  2.19it/s]\u001b[A\n","Iteration:  12% 213/1851 [01:35<12:19,  2.22it/s]\u001b[A\n","Iteration:  12% 214/1851 [01:35<12:12,  2.23it/s]\u001b[A\n","Iteration:  12% 215/1851 [01:36<12:07,  2.25it/s]\u001b[A\n","Iteration:  12% 216/1851 [01:36<12:06,  2.25it/s]\u001b[A\n","Iteration:  12% 217/1851 [01:36<12:03,  2.26it/s]\u001b[A\n","Iteration:  12% 218/1851 [01:37<12:01,  2.26it/s]\u001b[A\n","Iteration:  12% 219/1851 [01:37<11:59,  2.27it/s]\u001b[A\n","Iteration:  12% 220/1851 [01:38<11:58,  2.27it/s]\u001b[A\n","Iteration:  12% 221/1851 [01:38<11:56,  2.27it/s]\u001b[A\n","Iteration:  12% 222/1851 [01:39<11:55,  2.28it/s]\u001b[A\n","Iteration:  12% 223/1851 [01:39<11:54,  2.28it/s]\u001b[A\n","Iteration:  12% 224/1851 [01:39<11:54,  2.28it/s]\u001b[A\n","Iteration:  12% 225/1851 [01:40<11:55,  2.27it/s]\u001b[A\n","Iteration:  12% 226/1851 [01:40<11:54,  2.28it/s]\u001b[A\n","Iteration:  12% 227/1851 [01:41<11:53,  2.28it/s]\u001b[A\n","Iteration:  12% 228/1851 [01:41<11:52,  2.28it/s]\u001b[A\n","Iteration:  12% 229/1851 [01:42<11:52,  2.28it/s]\u001b[A\n","Iteration:  12% 230/1851 [01:42<11:51,  2.28it/s]\u001b[A\n","Iteration:  12% 231/1851 [01:43<11:51,  2.28it/s]\u001b[A\n","Iteration:  13% 232/1851 [01:43<11:51,  2.28it/s]\u001b[A\n","Iteration:  13% 233/1851 [01:43<11:51,  2.27it/s]\u001b[A\n","Iteration:  13% 234/1851 [01:44<11:50,  2.28it/s]\u001b[A\n","Iteration:  13% 235/1851 [01:44<11:49,  2.28it/s]\u001b[A\n","Iteration:  13% 236/1851 [01:45<11:49,  2.28it/s]\u001b[A\n","Iteration:  13% 237/1851 [01:45<11:48,  2.28it/s]\u001b[A\n","Iteration:  13% 238/1851 [01:46<11:48,  2.28it/s]\u001b[A\n","Iteration:  13% 239/1851 [01:46<11:47,  2.28it/s]\u001b[A\n","Iteration:  13% 240/1851 [01:47<11:47,  2.28it/s]\u001b[A\n","Iteration:  13% 241/1851 [01:47<11:46,  2.28it/s]\u001b[A\n","Iteration:  13% 242/1851 [01:47<11:46,  2.28it/s]\u001b[A\n","Iteration:  13% 243/1851 [01:48<11:45,  2.28it/s]\u001b[A\n","Iteration:  13% 244/1851 [01:48<11:49,  2.26it/s]\u001b[A\n","Iteration:  13% 245/1851 [01:49<11:52,  2.26it/s]\u001b[A\n","Iteration:  13% 246/1851 [01:49<14:01,  1.91it/s]\u001b[A\n","Iteration:  13% 247/1851 [01:50<13:21,  2.00it/s]\u001b[A\n","Iteration:  13% 248/1851 [01:50<12:52,  2.08it/s]\u001b[A\n","Iteration:  13% 249/1851 [01:51<12:31,  2.13it/s]\u001b[A\n","Iteration:  14% 250/1851 [01:51<12:17,  2.17it/s]\u001b[A\n","Iteration:  14% 251/1851 [01:52<12:06,  2.20it/s]\u001b[A\n","Iteration:  14% 252/1851 [01:52<11:59,  2.22it/s]\u001b[A\n","Iteration:  14% 253/1851 [01:53<11:53,  2.24it/s]\u001b[A\n","Iteration:  14% 254/1851 [01:53<11:49,  2.25it/s]\u001b[A\n","Iteration:  14% 255/1851 [01:53<11:47,  2.25it/s]\u001b[A\n","Iteration:  14% 256/1851 [01:54<11:44,  2.26it/s]\u001b[A\n","Iteration:  14% 257/1851 [01:54<11:43,  2.27it/s]\u001b[A\n","Iteration:  14% 258/1851 [01:55<11:41,  2.27it/s]\u001b[A\n","Iteration:  14% 259/1851 [01:55<11:41,  2.27it/s]\u001b[A\n","Iteration:  14% 260/1851 [01:56<11:39,  2.27it/s]\u001b[A\n","Iteration:  14% 261/1851 [01:56<11:38,  2.28it/s]\u001b[A\n","Iteration:  14% 262/1851 [01:56<11:38,  2.28it/s]\u001b[A\n","Iteration:  14% 263/1851 [01:57<11:37,  2.28it/s]\u001b[A\n","Iteration:  14% 264/1851 [01:57<11:37,  2.28it/s]\u001b[A\n","Iteration:  14% 265/1851 [01:58<11:38,  2.27it/s]\u001b[A\n","Iteration:  14% 266/1851 [01:58<11:37,  2.27it/s]\u001b[A\n","Iteration:  14% 267/1851 [01:59<11:36,  2.27it/s]\u001b[A\n","Iteration:  14% 268/1851 [01:59<11:35,  2.28it/s]\u001b[A\n","Iteration:  15% 269/1851 [02:00<11:35,  2.28it/s]\u001b[A\n","Iteration:  15% 270/1851 [02:00<11:36,  2.27it/s]\u001b[A\n","Iteration:  15% 271/1851 [02:00<11:36,  2.27it/s]\u001b[A\n","Iteration:  15% 272/1851 [02:01<11:35,  2.27it/s]\u001b[A\n","Iteration:  15% 273/1851 [02:01<11:34,  2.27it/s]\u001b[A\n","Iteration:  15% 274/1851 [02:02<11:33,  2.28it/s]\u001b[A\n","Iteration:  15% 275/1851 [02:02<11:32,  2.28it/s]\u001b[A\n","Iteration:  15% 276/1851 [02:03<11:31,  2.28it/s]\u001b[A\n","Iteration:  15% 277/1851 [02:03<11:30,  2.28it/s]\u001b[A\n","Iteration:  15% 278/1851 [02:04<11:31,  2.28it/s]\u001b[A\n","Iteration:  15% 279/1851 [02:04<11:30,  2.28it/s]\u001b[A\n","Iteration:  15% 280/1851 [02:04<11:29,  2.28it/s]\u001b[A\n","Iteration:  15% 281/1851 [02:05<11:29,  2.28it/s]\u001b[A\n","Iteration:  15% 282/1851 [02:05<11:29,  2.28it/s]\u001b[A\n","Iteration:  15% 283/1851 [02:06<11:28,  2.28it/s]\u001b[A\n","Iteration:  15% 284/1851 [02:06<11:28,  2.28it/s]\u001b[A\n","Iteration:  15% 285/1851 [02:07<11:27,  2.28it/s]\u001b[A\n","Iteration:  15% 286/1851 [02:07<11:27,  2.28it/s]\u001b[A\n","Iteration:  16% 287/1851 [02:07<11:26,  2.28it/s]\u001b[A\n","Iteration:  16% 288/1851 [02:08<11:25,  2.28it/s]\u001b[A\n","Iteration:  16% 289/1851 [02:08<11:25,  2.28it/s]\u001b[A\n","Iteration:  16% 290/1851 [02:09<11:24,  2.28it/s]\u001b[A\n","Iteration:  16% 291/1851 [02:09<11:24,  2.28it/s]\u001b[A\n","Iteration:  16% 292/1851 [02:10<11:23,  2.28it/s]\u001b[A\n","Iteration:  16% 293/1851 [02:10<11:23,  2.28it/s]\u001b[A\n","Iteration:  16% 294/1851 [02:11<11:23,  2.28it/s]\u001b[A\n","Iteration:  16% 295/1851 [02:11<11:22,  2.28it/s]\u001b[A\n","Iteration:  16% 296/1851 [02:11<11:22,  2.28it/s]\u001b[A\n","Iteration:  16% 297/1851 [02:12<11:21,  2.28it/s]\u001b[A\n","Iteration:  16% 298/1851 [02:12<11:22,  2.28it/s]\u001b[A\n","Iteration:  16% 299/1851 [02:13<11:21,  2.28it/s]\u001b[A\n","Iteration:  16% 300/1851 [02:13<11:20,  2.28it/s]\u001b[A\n","Iteration:  16% 301/1851 [02:14<11:19,  2.28it/s]\u001b[A\n","Iteration:  16% 302/1851 [02:14<11:19,  2.28it/s]\u001b[A\n","Iteration:  16% 303/1851 [02:14<11:19,  2.28it/s]\u001b[A\n","Iteration:  16% 304/1851 [02:15<11:18,  2.28it/s]\u001b[A\n","Iteration:  16% 305/1851 [02:15<11:18,  2.28it/s]\u001b[A\n","Iteration:  17% 306/1851 [02:16<11:18,  2.28it/s]\u001b[A\n","Iteration:  17% 307/1851 [02:16<11:17,  2.28it/s]\u001b[A\n","Iteration:  17% 308/1851 [02:17<11:17,  2.28it/s]\u001b[A\n","Iteration:  17% 309/1851 [02:17<11:16,  2.28it/s]\u001b[A\n","Iteration:  17% 310/1851 [02:18<11:16,  2.28it/s]\u001b[A\n","Iteration:  17% 311/1851 [02:18<11:15,  2.28it/s]\u001b[A\n","Iteration:  17% 312/1851 [02:18<11:15,  2.28it/s]\u001b[A\n","Iteration:  17% 313/1851 [02:19<11:14,  2.28it/s]\u001b[A\n","Iteration:  17% 314/1851 [02:19<11:14,  2.28it/s]\u001b[A\n","Iteration:  17% 315/1851 [02:20<11:14,  2.28it/s]\u001b[A\n","Iteration:  17% 316/1851 [02:20<11:13,  2.28it/s]\u001b[A\n","Iteration:  17% 317/1851 [02:21<11:13,  2.28it/s]\u001b[A\n","Iteration:  17% 318/1851 [02:21<11:13,  2.28it/s]\u001b[A\n","Iteration:  17% 319/1851 [02:21<11:12,  2.28it/s]\u001b[A\n","Iteration:  17% 320/1851 [02:22<11:11,  2.28it/s]\u001b[A\n","Iteration:  17% 321/1851 [02:22<11:11,  2.28it/s]\u001b[A\n","Iteration:  17% 322/1851 [02:23<11:10,  2.28it/s]\u001b[A\n","Iteration:  17% 323/1851 [02:23<11:10,  2.28it/s]\u001b[A\n","Iteration:  18% 324/1851 [02:24<11:10,  2.28it/s]\u001b[A\n","Iteration:  18% 325/1851 [02:24<11:10,  2.28it/s]\u001b[A\n","Iteration:  18% 326/1851 [02:25<11:09,  2.28it/s]\u001b[A\n","Iteration:  18% 327/1851 [02:25<11:09,  2.28it/s]\u001b[A\n","Iteration:  18% 328/1851 [02:25<11:09,  2.27it/s]\u001b[A\n","Iteration:  18% 329/1851 [02:26<11:08,  2.28it/s]\u001b[A\n","Iteration:  18% 330/1851 [02:26<11:07,  2.28it/s]\u001b[A\n","Iteration:  18% 331/1851 [02:27<11:07,  2.28it/s]\u001b[A\n","Iteration:  18% 332/1851 [02:27<11:06,  2.28it/s]\u001b[A\n","Iteration:  18% 333/1851 [02:28<11:06,  2.28it/s]\u001b[A\n","Iteration:  18% 334/1851 [02:28<11:05,  2.28it/s]\u001b[A\n","Iteration:  18% 335/1851 [02:29<11:05,  2.28it/s]\u001b[A\n","Iteration:  18% 336/1851 [02:29<11:06,  2.27it/s]\u001b[A\n","Iteration:  18% 337/1851 [02:29<11:06,  2.27it/s]\u001b[A\n","Iteration:  18% 338/1851 [02:30<11:05,  2.28it/s]\u001b[A\n","Iteration:  18% 339/1851 [02:30<11:04,  2.28it/s]\u001b[A\n","Iteration:  18% 340/1851 [02:31<11:03,  2.28it/s]\u001b[A\n","Iteration:  18% 341/1851 [02:31<11:03,  2.28it/s]\u001b[A\n","Iteration:  18% 342/1851 [02:32<11:02,  2.28it/s]\u001b[A\n","Iteration:  19% 343/1851 [02:32<11:02,  2.28it/s]\u001b[A\n","Iteration:  19% 344/1851 [02:32<11:01,  2.28it/s]\u001b[A\n","Iteration:  19% 345/1851 [02:33<11:01,  2.28it/s]\u001b[A\n","Iteration:  19% 346/1851 [02:33<11:00,  2.28it/s]\u001b[A\n","Iteration:  19% 347/1851 [02:34<11:01,  2.27it/s]\u001b[A\n","Iteration:  19% 348/1851 [02:34<11:01,  2.27it/s]\u001b[A\n","Iteration:  19% 349/1851 [02:35<11:00,  2.27it/s]\u001b[A\n","Iteration:  19% 350/1851 [02:35<10:59,  2.28it/s]\u001b[A\n","Iteration:  19% 351/1851 [02:36<10:59,  2.28it/s]\u001b[A\n","Iteration:  19% 352/1851 [02:36<10:58,  2.28it/s]\u001b[A\n","Iteration:  19% 353/1851 [02:36<10:58,  2.28it/s]\u001b[A\n","Iteration:  19% 354/1851 [02:37<10:57,  2.28it/s]\u001b[A\n","Iteration:  19% 355/1851 [02:37<10:57,  2.28it/s]\u001b[A\n","Iteration:  19% 356/1851 [02:38<10:56,  2.28it/s]\u001b[A\n","Iteration:  19% 357/1851 [02:38<10:56,  2.28it/s]\u001b[A\n","Iteration:  19% 358/1851 [02:39<10:56,  2.28it/s]\u001b[A\n","Iteration:  19% 359/1851 [02:39<10:55,  2.28it/s]\u001b[A\n","Iteration:  19% 360/1851 [02:40<10:54,  2.28it/s]\u001b[A\n","Iteration:  20% 361/1851 [02:40<10:54,  2.28it/s]\u001b[A\n","Iteration:  20% 362/1851 [02:40<10:54,  2.28it/s]\u001b[A\n","Iteration:  20% 363/1851 [02:41<10:54,  2.27it/s]\u001b[A\n","Iteration:  20% 364/1851 [02:41<10:53,  2.28it/s]\u001b[A\n","Iteration:  20% 365/1851 [02:42<10:52,  2.28it/s]\u001b[A\n","Iteration:  20% 366/1851 [02:42<10:52,  2.28it/s]\u001b[A\n","Iteration:  20% 367/1851 [02:43<10:52,  2.28it/s]\u001b[A\n","Iteration:  20% 368/1851 [02:43<10:52,  2.27it/s]\u001b[A\n","Iteration:  20% 369/1851 [02:43<10:51,  2.28it/s]\u001b[A\n","Iteration:  20% 370/1851 [02:44<10:50,  2.28it/s]\u001b[A\n","Iteration:  20% 371/1851 [02:44<10:49,  2.28it/s]\u001b[A\n","Iteration:  20% 372/1851 [02:45<10:49,  2.28it/s]\u001b[A\n","Iteration:  20% 373/1851 [02:45<10:48,  2.28it/s]\u001b[A\n","Iteration:  20% 374/1851 [02:46<10:48,  2.28it/s]\u001b[A\n","Iteration:  20% 375/1851 [02:46<10:48,  2.28it/s]\u001b[A\n","Iteration:  20% 376/1851 [02:47<10:47,  2.28it/s]\u001b[A\n","Iteration:  20% 377/1851 [02:47<10:47,  2.28it/s]\u001b[A\n","Iteration:  20% 378/1851 [02:47<10:46,  2.28it/s]\u001b[A\n","Iteration:  20% 379/1851 [02:48<10:46,  2.28it/s]\u001b[A\n","Iteration:  21% 380/1851 [02:48<10:45,  2.28it/s]\u001b[A\n","Iteration:  21% 381/1851 [02:49<10:45,  2.28it/s]\u001b[A\n","Iteration:  21% 382/1851 [02:49<10:45,  2.28it/s]\u001b[A\n","Iteration:  21% 383/1851 [02:50<10:45,  2.27it/s]\u001b[A\n","Iteration:  21% 384/1851 [02:50<10:45,  2.27it/s]\u001b[A\n","Iteration:  21% 385/1851 [02:50<10:44,  2.27it/s]\u001b[A\n","Iteration:  21% 386/1851 [02:51<10:43,  2.28it/s]\u001b[A\n","Iteration:  21% 387/1851 [02:51<10:43,  2.27it/s]\u001b[A\n","Iteration:  21% 388/1851 [02:52<10:44,  2.27it/s]\u001b[A\n","Iteration:  21% 389/1851 [02:52<10:41,  2.28it/s]\u001b[A\n","Iteration:  21% 390/1851 [02:53<10:41,  2.28it/s]\u001b[A\n","Iteration:  21% 391/1851 [02:53<10:41,  2.28it/s]\u001b[A\n","Iteration:  21% 392/1851 [02:54<10:41,  2.28it/s]\u001b[A\n","Iteration:  21% 393/1851 [02:54<10:40,  2.28it/s]\u001b[A\n","Iteration:  21% 394/1851 [02:54<10:40,  2.28it/s]\u001b[A\n","Iteration:  21% 395/1851 [02:55<10:39,  2.28it/s]\u001b[A\n","Iteration:  21% 396/1851 [02:55<10:39,  2.27it/s]\u001b[A\n","Iteration:  21% 397/1851 [02:56<10:39,  2.27it/s]\u001b[A\n","Iteration:  22% 398/1851 [02:56<10:43,  2.26it/s]\u001b[A\n","Iteration:  22% 399/1851 [02:57<10:45,  2.25it/s]\u001b[A\n","Iteration:  22% 400/1851 [02:57<10:43,  2.26it/s]\u001b[A\n","Iteration:  22% 401/1851 [02:58<10:42,  2.26it/s]\u001b[A\n","Iteration:  22% 402/1851 [02:58<10:42,  2.25it/s]\u001b[A\n","Iteration:  22% 403/1851 [02:58<10:40,  2.26it/s]\u001b[A\n","Iteration:  22% 404/1851 [02:59<10:38,  2.27it/s]\u001b[A\n","Iteration:  22% 405/1851 [02:59<10:37,  2.27it/s]\u001b[A\n","Iteration:  22% 406/1851 [03:00<10:38,  2.26it/s]\u001b[A\n","Iteration:  22% 407/1851 [03:00<10:38,  2.26it/s]\u001b[A\n","Iteration:  22% 408/1851 [03:01<10:36,  2.27it/s]\u001b[A\n","Iteration:  22% 409/1851 [03:01<10:36,  2.27it/s]\u001b[A\n","Iteration:  22% 410/1851 [03:02<10:34,  2.27it/s]\u001b[A\n","Iteration:  22% 411/1851 [03:02<10:34,  2.27it/s]\u001b[A\n","Iteration:  22% 412/1851 [03:02<10:33,  2.27it/s]\u001b[A\n","Iteration:  22% 413/1851 [03:03<10:32,  2.27it/s]\u001b[A\n","Iteration:  22% 414/1851 [03:03<10:31,  2.27it/s]\u001b[A\n","Iteration:  22% 415/1851 [03:04<10:31,  2.27it/s]\u001b[A\n","Iteration:  22% 416/1851 [03:04<10:30,  2.28it/s]\u001b[A\n","Iteration:  23% 417/1851 [03:05<10:29,  2.28it/s]\u001b[A\n","Iteration:  23% 418/1851 [03:05<10:29,  2.28it/s]\u001b[A\n","Iteration:  23% 419/1851 [03:05<10:29,  2.28it/s]\u001b[A\n","Iteration:  23% 420/1851 [03:06<10:28,  2.28it/s]\u001b[A\n","Iteration:  23% 421/1851 [03:06<10:27,  2.28it/s]\u001b[A\n","Iteration:  23% 422/1851 [03:07<10:27,  2.28it/s]\u001b[A\n","Iteration:  23% 423/1851 [03:07<10:26,  2.28it/s]\u001b[A\n","Iteration:  23% 424/1851 [03:08<10:26,  2.28it/s]\u001b[A\n","Iteration:  23% 425/1851 [03:08<10:25,  2.28it/s]\u001b[A\n","Iteration:  23% 426/1851 [03:09<10:25,  2.28it/s]\u001b[A\n","Iteration:  23% 427/1851 [03:09<10:25,  2.28it/s]\u001b[A\n","Iteration:  23% 428/1851 [03:09<10:24,  2.28it/s]\u001b[A\n","Iteration:  23% 429/1851 [03:10<10:24,  2.28it/s]\u001b[A\n","Iteration:  23% 430/1851 [03:10<10:23,  2.28it/s]\u001b[A\n","Iteration:  23% 431/1851 [03:11<10:29,  2.26it/s]\u001b[A\n","Iteration:  23% 432/1851 [03:11<10:29,  2.25it/s]\u001b[A\n","Iteration:  23% 433/1851 [03:12<10:29,  2.25it/s]\u001b[A\n","Iteration:  23% 434/1851 [03:12<10:23,  2.27it/s]\u001b[A\n","Iteration:  24% 435/1851 [03:13<10:23,  2.27it/s]\u001b[A\n","Iteration:  24% 436/1851 [03:13<11:40,  2.02it/s]\u001b[A\n","Iteration:  24% 437/1851 [03:14<11:18,  2.08it/s]\u001b[A\n","Iteration:  24% 438/1851 [03:14<12:00,  1.96it/s]\u001b[A\n","Iteration:  24% 439/1851 [03:15<11:30,  2.05it/s]\u001b[A\n","Iteration:  24% 440/1851 [03:15<11:08,  2.11it/s]\u001b[A\n","Iteration:  24% 441/1851 [03:15<10:53,  2.16it/s]\u001b[A\n","Iteration:  24% 442/1851 [03:16<10:43,  2.19it/s]\u001b[A\n","Iteration:  24% 443/1851 [03:16<10:35,  2.22it/s]\u001b[A\n","Iteration:  24% 444/1851 [03:17<10:29,  2.23it/s]\u001b[A\n","Iteration:  24% 445/1851 [03:17<10:25,  2.25it/s]\u001b[A\n","Iteration:  24% 446/1851 [03:18<10:23,  2.25it/s]\u001b[A\n","Iteration:  24% 447/1851 [03:18<10:20,  2.26it/s]\u001b[A\n","Iteration:  24% 448/1851 [03:19<10:19,  2.27it/s]\u001b[A\n","Iteration:  24% 449/1851 [03:19<10:18,  2.27it/s]\u001b[A\n","Iteration:  24% 450/1851 [03:19<10:16,  2.27it/s]\u001b[A\n","Iteration:  24% 451/1851 [03:20<10:15,  2.27it/s]\u001b[A\n","Iteration:  24% 452/1851 [03:20<10:14,  2.27it/s]\u001b[A\n","Iteration:  24% 453/1851 [03:21<10:14,  2.28it/s]\u001b[A\n","Iteration:  25% 454/1851 [03:21<10:14,  2.27it/s]\u001b[A\n","Iteration:  25% 455/1851 [03:22<10:13,  2.27it/s]\u001b[A\n","Iteration:  25% 456/1851 [03:22<10:13,  2.28it/s]\u001b[A\n","Iteration:  25% 457/1851 [03:23<10:12,  2.28it/s]\u001b[A\n","Iteration:  25% 458/1851 [03:23<10:12,  2.27it/s]\u001b[A\n","Iteration:  25% 459/1851 [03:23<10:12,  2.27it/s]\u001b[A\n","Iteration:  25% 460/1851 [03:24<10:11,  2.27it/s]\u001b[A\n","Iteration:  25% 461/1851 [03:24<10:10,  2.28it/s]\u001b[A\n","Iteration:  25% 462/1851 [03:25<10:10,  2.28it/s]\u001b[A\n","Iteration:  25% 463/1851 [03:25<10:09,  2.28it/s]\u001b[A\n","Iteration:  25% 464/1851 [03:26<10:09,  2.28it/s]\u001b[A\n","Iteration:  25% 465/1851 [03:26<10:08,  2.28it/s]\u001b[A\n","Iteration:  25% 466/1851 [03:26<10:07,  2.28it/s]\u001b[A\n","Iteration:  25% 467/1851 [03:27<10:07,  2.28it/s]\u001b[A\n","Iteration:  25% 468/1851 [03:27<10:07,  2.28it/s]\u001b[A\n","Iteration:  25% 469/1851 [03:28<10:06,  2.28it/s]\u001b[A\n","Iteration:  25% 470/1851 [03:28<10:08,  2.27it/s]\u001b[A\n","Iteration:  25% 471/1851 [03:29<10:07,  2.27it/s]\u001b[A\n","Iteration:  25% 472/1851 [03:29<10:06,  2.27it/s]\u001b[A\n","Iteration:  26% 473/1851 [03:30<10:05,  2.28it/s]\u001b[A\n","Iteration:  26% 474/1851 [03:30<10:06,  2.27it/s]\u001b[A\n","Iteration:  26% 475/1851 [03:30<10:05,  2.27it/s]\u001b[A\n","Iteration:  26% 476/1851 [03:31<10:04,  2.27it/s]\u001b[A\n","Iteration:  26% 477/1851 [03:31<10:04,  2.27it/s]\u001b[A\n","Iteration:  26% 478/1851 [03:32<10:03,  2.27it/s]\u001b[A\n","Iteration:  26% 479/1851 [03:32<10:02,  2.28it/s]\u001b[A\n","Iteration:  26% 480/1851 [03:33<10:02,  2.28it/s]\u001b[A\n","Iteration:  26% 481/1851 [03:33<10:01,  2.28it/s]\u001b[A\n","Iteration:  26% 482/1851 [03:33<10:01,  2.28it/s]\u001b[A\n","Iteration:  26% 483/1851 [03:34<10:00,  2.28it/s]\u001b[A\n","Iteration:  26% 484/1851 [03:34<10:00,  2.28it/s]\u001b[A\n","Iteration:  26% 485/1851 [03:35<09:59,  2.28it/s]\u001b[A\n","Iteration:  26% 486/1851 [03:35<09:59,  2.28it/s]\u001b[A\n","Iteration:  26% 487/1851 [03:36<09:58,  2.28it/s]\u001b[A\n","Iteration:  26% 488/1851 [03:36<09:58,  2.28it/s]\u001b[A\n","Iteration:  26% 489/1851 [03:37<09:58,  2.28it/s]\u001b[A\n","Iteration:  26% 490/1851 [03:37<09:57,  2.28it/s]\u001b[A\n","Iteration:  27% 491/1851 [03:37<09:57,  2.28it/s]\u001b[A\n","Iteration:  27% 492/1851 [03:38<09:57,  2.27it/s]\u001b[A\n","Iteration:  27% 493/1851 [03:38<09:57,  2.27it/s]\u001b[A\n","Iteration:  27% 494/1851 [03:39<09:56,  2.28it/s]\u001b[A\n","Iteration:  27% 495/1851 [03:39<09:56,  2.27it/s]\u001b[A\n","Iteration:  27% 496/1851 [03:40<09:55,  2.28it/s]\u001b[A\n","Iteration:  27% 497/1851 [03:40<09:54,  2.28it/s]\u001b[A\n","Iteration:  27% 498/1851 [03:41<09:53,  2.28it/s]\u001b[A\n","Iteration:  27% 499/1851 [03:41<09:53,  2.28it/s]\u001b[A\n","Iteration:  27% 500/1851 [03:41<09:52,  2.28it/s]\u001b[A\n","Iteration:  27% 501/1851 [03:42<09:53,  2.28it/s]\u001b[A\n","Iteration:  27% 502/1851 [03:42<09:52,  2.28it/s]\u001b[A\n","Iteration:  27% 503/1851 [03:43<09:52,  2.27it/s]\u001b[A\n","Iteration:  27% 504/1851 [03:43<09:51,  2.28it/s]\u001b[A\n","Iteration:  27% 505/1851 [03:44<09:51,  2.28it/s]\u001b[A\n","Iteration:  27% 506/1851 [03:44<09:52,  2.27it/s]\u001b[A\n","Iteration:  27% 507/1851 [03:44<09:51,  2.27it/s]\u001b[A\n","Iteration:  27% 508/1851 [03:45<09:50,  2.28it/s]\u001b[A\n","Iteration:  27% 509/1851 [03:45<09:49,  2.28it/s]\u001b[A\n","Iteration:  28% 510/1851 [03:46<09:49,  2.28it/s]\u001b[A\n","Iteration:  28% 511/1851 [03:46<09:48,  2.28it/s]\u001b[A\n","Iteration:  28% 512/1851 [03:47<09:47,  2.28it/s]\u001b[A\n","Iteration:  28% 513/1851 [03:47<09:47,  2.28it/s]\u001b[A\n","Iteration:  28% 514/1851 [03:48<09:47,  2.28it/s]\u001b[A\n","Iteration:  28% 515/1851 [03:48<09:46,  2.28it/s]\u001b[A\n","Iteration:  28% 516/1851 [03:48<09:46,  2.28it/s]\u001b[A\n","Iteration:  28% 517/1851 [03:49<09:45,  2.28it/s]\u001b[A\n","Iteration:  28% 518/1851 [03:49<09:45,  2.28it/s]\u001b[A\n","Iteration:  28% 519/1851 [03:50<09:44,  2.28it/s]\u001b[A\n","Iteration:  28% 520/1851 [03:50<09:44,  2.28it/s]\u001b[A\n","Iteration:  28% 521/1851 [03:51<09:43,  2.28it/s]\u001b[A\n","Iteration:  28% 522/1851 [03:51<09:43,  2.28it/s]\u001b[A\n","Iteration:  28% 523/1851 [03:52<09:42,  2.28it/s]\u001b[A\n","Iteration:  28% 524/1851 [03:52<09:42,  2.28it/s]\u001b[A\n","Iteration:  28% 525/1851 [03:52<09:41,  2.28it/s]\u001b[A\n","Iteration:  28% 526/1851 [03:53<09:41,  2.28it/s]\u001b[A\n","Iteration:  28% 527/1851 [03:53<09:41,  2.28it/s]\u001b[A\n","Iteration:  29% 528/1851 [03:54<09:40,  2.28it/s]\u001b[A\n","Iteration:  29% 529/1851 [03:54<09:40,  2.28it/s]\u001b[A\n","Iteration:  29% 530/1851 [03:55<09:39,  2.28it/s]\u001b[A\n","Iteration:  29% 531/1851 [03:55<09:39,  2.28it/s]\u001b[A\n","Iteration:  29% 532/1851 [03:55<09:39,  2.28it/s]\u001b[A\n","Iteration:  29% 533/1851 [03:56<09:38,  2.28it/s]\u001b[A\n","Iteration:  29% 534/1851 [03:56<09:38,  2.28it/s]\u001b[A\n","Iteration:  29% 535/1851 [03:57<09:38,  2.28it/s]\u001b[A\n","Iteration:  29% 536/1851 [03:57<09:37,  2.28it/s]\u001b[A\n","Iteration:  29% 537/1851 [03:58<09:37,  2.28it/s]\u001b[A\n","Iteration:  29% 538/1851 [03:58<09:36,  2.28it/s]\u001b[A\n","Iteration:  29% 539/1851 [03:59<09:36,  2.28it/s]\u001b[A\n","Iteration:  29% 540/1851 [03:59<09:35,  2.28it/s]\u001b[A\n","Iteration:  29% 541/1851 [03:59<09:35,  2.28it/s]\u001b[A\n","Iteration:  29% 542/1851 [04:00<09:34,  2.28it/s]\u001b[A\n","Iteration:  29% 543/1851 [04:00<09:34,  2.28it/s]\u001b[A\n","Iteration:  29% 544/1851 [04:01<09:33,  2.28it/s]\u001b[A\n","Iteration:  29% 545/1851 [04:01<09:33,  2.28it/s]\u001b[A\n","Iteration:  29% 546/1851 [04:02<09:32,  2.28it/s]\u001b[A\n","Iteration:  30% 547/1851 [04:02<09:32,  2.28it/s]\u001b[A\n","Iteration:  30% 548/1851 [04:02<09:31,  2.28it/s]\u001b[A\n","Iteration:  30% 549/1851 [04:03<09:31,  2.28it/s]\u001b[A\n","Iteration:  30% 550/1851 [04:03<09:31,  2.28it/s]\u001b[A\n","Iteration:  30% 551/1851 [04:04<09:30,  2.28it/s]\u001b[A\n","Iteration:  30% 552/1851 [04:04<09:30,  2.28it/s]\u001b[A\n","Iteration:  30% 553/1851 [04:05<09:30,  2.28it/s]\u001b[A\n","Iteration:  30% 554/1851 [04:05<09:29,  2.28it/s]\u001b[A\n","Iteration:  30% 555/1851 [04:06<09:28,  2.28it/s]\u001b[A\n","Iteration:  30% 556/1851 [04:06<09:28,  2.28it/s]\u001b[A\n","Iteration:  30% 557/1851 [04:06<09:28,  2.28it/s]\u001b[A\n","Iteration:  30% 558/1851 [04:07<09:27,  2.28it/s]\u001b[A\n","Iteration:  30% 559/1851 [04:07<09:28,  2.27it/s]\u001b[A\n","Iteration:  30% 560/1851 [04:08<09:27,  2.28it/s]\u001b[A\n","Iteration:  30% 561/1851 [04:08<09:26,  2.28it/s]\u001b[A\n","Iteration:  30% 562/1851 [04:09<09:26,  2.28it/s]\u001b[A\n","Iteration:  30% 563/1851 [04:09<09:25,  2.28it/s]\u001b[A\n","Iteration:  30% 564/1851 [04:10<09:25,  2.28it/s]\u001b[A\n","Iteration:  31% 565/1851 [04:10<09:26,  2.27it/s]\u001b[A\n","Iteration:  31% 566/1851 [04:10<09:25,  2.27it/s]\u001b[A\n","Iteration:  31% 567/1851 [04:11<09:24,  2.27it/s]\u001b[A\n","Iteration:  31% 568/1851 [04:11<09:23,  2.28it/s]\u001b[A\n","Iteration:  31% 569/1851 [04:12<09:23,  2.28it/s]\u001b[A\n","Iteration:  31% 570/1851 [04:12<09:22,  2.28it/s]\u001b[A\n","Iteration:  31% 571/1851 [04:13<09:21,  2.28it/s]\u001b[A\n","Iteration:  31% 572/1851 [04:13<09:21,  2.28it/s]\u001b[A\n","Iteration:  31% 573/1851 [04:13<09:21,  2.27it/s]\u001b[A\n","Iteration:  31% 574/1851 [04:14<09:21,  2.28it/s]\u001b[A\n","Iteration:  31% 575/1851 [04:14<09:20,  2.27it/s]\u001b[A\n","Iteration:  31% 576/1851 [04:15<09:20,  2.28it/s]\u001b[A\n","Iteration:  31% 577/1851 [04:15<09:19,  2.28it/s]\u001b[A\n","Iteration:  31% 578/1851 [04:16<09:18,  2.28it/s]\u001b[A\n","Iteration:  31% 579/1851 [04:16<09:18,  2.28it/s]\u001b[A\n","Iteration:  31% 580/1851 [04:17<09:17,  2.28it/s]\u001b[A\n","Iteration:  31% 581/1851 [04:17<09:17,  2.28it/s]\u001b[A\n","Iteration:  31% 582/1851 [04:17<09:16,  2.28it/s]\u001b[A\n","Iteration:  31% 583/1851 [04:18<09:16,  2.28it/s]\u001b[A\n","Iteration:  32% 584/1851 [04:18<09:15,  2.28it/s]\u001b[A\n","Iteration:  32% 585/1851 [04:19<09:16,  2.28it/s]\u001b[A\n","Iteration:  32% 586/1851 [04:19<09:16,  2.27it/s]\u001b[A\n","Iteration:  32% 587/1851 [04:20<09:15,  2.28it/s]\u001b[A\n","Iteration:  32% 588/1851 [04:20<09:14,  2.28it/s]\u001b[A\n","Iteration:  32% 589/1851 [04:20<09:14,  2.28it/s]\u001b[A\n","Iteration:  32% 590/1851 [04:21<09:13,  2.28it/s]\u001b[A\n","Iteration:  32% 591/1851 [04:21<09:13,  2.28it/s]\u001b[A\n","Iteration:  32% 592/1851 [04:22<09:14,  2.27it/s]\u001b[A\n","Iteration:  32% 593/1851 [04:22<09:13,  2.27it/s]\u001b[A\n","Iteration:  32% 594/1851 [04:23<09:12,  2.27it/s]\u001b[A\n","Iteration:  32% 595/1851 [04:23<09:11,  2.28it/s]\u001b[A\n","Iteration:  32% 596/1851 [04:24<09:11,  2.28it/s]\u001b[A\n","Iteration:  32% 597/1851 [04:24<09:10,  2.28it/s]\u001b[A\n","Iteration:  32% 598/1851 [04:24<09:10,  2.28it/s]\u001b[A\n","Iteration:  32% 599/1851 [04:25<09:09,  2.28it/s]\u001b[A\n","Iteration:  32% 600/1851 [04:25<09:08,  2.28it/s]\u001b[A\n","Iteration:  32% 601/1851 [04:26<09:08,  2.28it/s]\u001b[A\n","Iteration:  33% 602/1851 [04:26<09:08,  2.28it/s]\u001b[A\n","Iteration:  33% 603/1851 [04:27<09:07,  2.28it/s]\u001b[A\n","Iteration:  33% 604/1851 [04:27<09:07,  2.28it/s]\u001b[A\n","Iteration:  33% 605/1851 [04:28<09:06,  2.28it/s]\u001b[A\n","Iteration:  33% 606/1851 [04:28<09:06,  2.28it/s]\u001b[A\n","Iteration:  33% 607/1851 [04:28<09:05,  2.28it/s]\u001b[A\n","Iteration:  33% 608/1851 [04:29<09:05,  2.28it/s]\u001b[A\n","Iteration:  33% 609/1851 [04:29<09:05,  2.28it/s]\u001b[A\n","Iteration:  33% 610/1851 [04:30<09:05,  2.27it/s]\u001b[A\n","Iteration:  33% 611/1851 [04:30<09:05,  2.27it/s]\u001b[A\n","Iteration:  33% 612/1851 [04:31<09:04,  2.28it/s]\u001b[A\n","Iteration:  33% 613/1851 [04:31<09:04,  2.28it/s]\u001b[A\n","Iteration:  33% 614/1851 [04:31<09:04,  2.27it/s]\u001b[A\n","Iteration:  33% 615/1851 [04:32<09:05,  2.26it/s]\u001b[A\n","Iteration:  33% 616/1851 [04:32<09:06,  2.26it/s]\u001b[A\n","Iteration:  33% 617/1851 [04:33<09:05,  2.26it/s]\u001b[A\n","Iteration:  33% 618/1851 [04:33<09:04,  2.27it/s]\u001b[A\n","Iteration:  33% 619/1851 [04:34<09:04,  2.26it/s]\u001b[A\n","Iteration:  33% 620/1851 [04:34<09:03,  2.27it/s]\u001b[A\n","Iteration:  34% 621/1851 [04:35<09:01,  2.27it/s]\u001b[A\n","Iteration:  34% 622/1851 [04:35<09:01,  2.27it/s]\u001b[A\n","Iteration:  34% 623/1851 [04:35<09:00,  2.27it/s]\u001b[A\n","Iteration:  34% 624/1851 [04:36<08:59,  2.27it/s]\u001b[A\n","Iteration:  34% 625/1851 [04:36<08:58,  2.28it/s]\u001b[A\n","Iteration:  34% 626/1851 [04:37<08:58,  2.27it/s]\u001b[A\n","Iteration:  34% 627/1851 [04:37<08:58,  2.27it/s]\u001b[A\n","Iteration:  34% 628/1851 [04:38<08:57,  2.28it/s]\u001b[A\n","Iteration:  34% 629/1851 [04:38<08:56,  2.28it/s]\u001b[A\n","Iteration:  34% 630/1851 [04:39<08:56,  2.28it/s]\u001b[A\n","Iteration:  34% 631/1851 [04:39<08:55,  2.28it/s]\u001b[A\n","Iteration:  34% 632/1851 [04:39<08:55,  2.28it/s]\u001b[A\n","Iteration:  34% 633/1851 [04:40<08:56,  2.27it/s]\u001b[A\n","Iteration:  34% 634/1851 [04:40<08:56,  2.27it/s]\u001b[A\n","Iteration:  34% 635/1851 [04:41<08:54,  2.27it/s]\u001b[A\n","Iteration:  34% 636/1851 [04:41<08:53,  2.28it/s]\u001b[A\n","Iteration:  34% 637/1851 [04:42<08:52,  2.28it/s]\u001b[A\n","Iteration:  34% 638/1851 [04:42<08:52,  2.28it/s]\u001b[A\n","Iteration:  35% 639/1851 [04:42<08:52,  2.28it/s]\u001b[A\n","Iteration:  35% 640/1851 [04:43<08:51,  2.28it/s]\u001b[A\n","Iteration:  35% 641/1851 [04:43<08:51,  2.27it/s]\u001b[A\n","Iteration:  35% 642/1851 [04:44<08:51,  2.27it/s]\u001b[A\n","Iteration:  35% 643/1851 [04:44<08:50,  2.28it/s]\u001b[A\n","Iteration:  35% 644/1851 [04:45<08:50,  2.27it/s]\u001b[A\n","Iteration:  35% 645/1851 [04:45<08:49,  2.28it/s]\u001b[A\n","Iteration:  35% 646/1851 [04:46<08:49,  2.28it/s]\u001b[A\n","Iteration:  35% 647/1851 [04:46<08:48,  2.28it/s]\u001b[A\n","Iteration:  35% 648/1851 [04:46<08:48,  2.28it/s]\u001b[A\n","Iteration:  35% 649/1851 [04:47<08:47,  2.28it/s]\u001b[A\n","Iteration:  35% 650/1851 [04:47<08:47,  2.28it/s]\u001b[A\n","Iteration:  35% 651/1851 [04:48<08:46,  2.28it/s]\u001b[A\n","Iteration:  35% 652/1851 [04:48<08:46,  2.28it/s]\u001b[A\n","Iteration:  35% 653/1851 [04:49<08:46,  2.28it/s]\u001b[A\n","Iteration:  35% 654/1851 [04:49<08:46,  2.27it/s]\u001b[A\n","Iteration:  35% 655/1851 [04:50<08:45,  2.28it/s]\u001b[A\n","Iteration:  35% 656/1851 [04:50<08:45,  2.27it/s]\u001b[A\n","Iteration:  35% 657/1851 [04:50<08:44,  2.28it/s]\u001b[A\n","Iteration:  36% 658/1851 [04:51<08:43,  2.28it/s]\u001b[A\n","Iteration:  36% 659/1851 [04:51<08:43,  2.28it/s]\u001b[A\n","Iteration:  36% 660/1851 [04:52<08:42,  2.28it/s]\u001b[A\n","Iteration:  36% 661/1851 [04:52<08:42,  2.28it/s]\u001b[A\n","Iteration:  36% 662/1851 [04:53<08:41,  2.28it/s]\u001b[A\n","Iteration:  36% 663/1851 [04:53<08:41,  2.28it/s]\u001b[A\n","Iteration:  36% 664/1851 [04:53<08:41,  2.28it/s]\u001b[A\n","Iteration:  36% 665/1851 [04:54<08:40,  2.28it/s]\u001b[A\n","Iteration:  36% 666/1851 [04:54<08:40,  2.28it/s]\u001b[A\n","Iteration:  36% 667/1851 [04:55<08:39,  2.28it/s]\u001b[A\n","Iteration:  36% 668/1851 [04:55<08:39,  2.28it/s]\u001b[A\n","Iteration:  36% 669/1851 [04:56<08:39,  2.28it/s]\u001b[A\n","Iteration:  36% 670/1851 [04:56<08:38,  2.28it/s]\u001b[A\n","Iteration:  36% 671/1851 [04:57<08:38,  2.28it/s]\u001b[A\n","Iteration:  36% 672/1851 [04:57<08:37,  2.28it/s]\u001b[A\n","Iteration:  36% 673/1851 [04:57<08:37,  2.28it/s]\u001b[A\n","Iteration:  36% 674/1851 [04:58<08:37,  2.28it/s]\u001b[A\n","Iteration:  36% 675/1851 [04:58<08:36,  2.28it/s]\u001b[A\n","Iteration:  37% 676/1851 [04:59<08:35,  2.28it/s]\u001b[A\n","Iteration:  37% 677/1851 [04:59<08:35,  2.28it/s]\u001b[A\n","Iteration:  37% 678/1851 [05:00<08:34,  2.28it/s]\u001b[A\n","Iteration:  37% 679/1851 [05:00<08:34,  2.28it/s]\u001b[A\n","Iteration:  37% 680/1851 [05:00<08:34,  2.28it/s]\u001b[A\n","Iteration:  37% 681/1851 [05:01<08:33,  2.28it/s]\u001b[A\n","Iteration:  37% 682/1851 [05:01<08:33,  2.28it/s]\u001b[A\n","Iteration:  37% 683/1851 [05:02<08:32,  2.28it/s]\u001b[A\n","Iteration:  37% 684/1851 [05:02<08:32,  2.28it/s]\u001b[A\n","Iteration:  37% 685/1851 [05:03<08:32,  2.27it/s]\u001b[A\n","Iteration:  37% 686/1851 [05:03<08:31,  2.28it/s]\u001b[A\n","Iteration:  37% 687/1851 [05:04<08:31,  2.28it/s]\u001b[A\n","Iteration:  37% 688/1851 [05:04<08:30,  2.28it/s]\u001b[A\n","Iteration:  37% 689/1851 [05:04<08:30,  2.28it/s]\u001b[A\n","Iteration:  37% 690/1851 [05:05<08:29,  2.28it/s]\u001b[A\n","Iteration:  37% 691/1851 [05:05<08:29,  2.28it/s]\u001b[A\n","Iteration:  37% 692/1851 [05:06<08:29,  2.28it/s]\u001b[A\n","Iteration:  37% 693/1851 [05:06<08:28,  2.28it/s]\u001b[A\n","Iteration:  37% 694/1851 [05:07<08:27,  2.28it/s]\u001b[A\n","Iteration:  38% 695/1851 [05:07<08:27,  2.28it/s]\u001b[A\n","Iteration:  38% 696/1851 [05:08<08:27,  2.28it/s]\u001b[A\n","Iteration:  38% 697/1851 [05:08<08:26,  2.28it/s]\u001b[A\n","Iteration:  38% 698/1851 [05:08<08:26,  2.28it/s]\u001b[A\n","Iteration:  38% 699/1851 [05:09<08:25,  2.28it/s]\u001b[A\n","Iteration:  38% 700/1851 [05:09<08:25,  2.28it/s]\u001b[A\n","Iteration:  38% 701/1851 [05:10<08:24,  2.28it/s]\u001b[A\n","Iteration:  38% 702/1851 [05:10<08:25,  2.27it/s]\u001b[A\n","Iteration:  38% 703/1851 [05:11<08:26,  2.27it/s]\u001b[A\n","Iteration:  38% 704/1851 [05:11<08:30,  2.25it/s]\u001b[A\n","Iteration:  38% 705/1851 [05:11<08:27,  2.26it/s]\u001b[A\n","Iteration:  38% 706/1851 [05:12<08:28,  2.25it/s]\u001b[A\n","Iteration:  38% 707/1851 [05:12<08:27,  2.26it/s]\u001b[A\n","Iteration:  38% 708/1851 [05:13<08:27,  2.25it/s]\u001b[A\n","Iteration:  38% 709/1851 [05:14<10:19,  1.84it/s]\u001b[A\n","Iteration:  38% 710/1851 [05:14<09:43,  1.95it/s]\u001b[A\n","Iteration:  38% 711/1851 [05:14<09:18,  2.04it/s]\u001b[A\n","Iteration:  38% 712/1851 [05:15<09:00,  2.11it/s]\u001b[A\n","Iteration:  39% 713/1851 [05:15<08:48,  2.15it/s]\u001b[A\n","Iteration:  39% 714/1851 [05:16<08:39,  2.19it/s]\u001b[A\n","Iteration:  39% 715/1851 [05:16<08:33,  2.21it/s]\u001b[A\n","Iteration:  39% 716/1851 [05:17<08:28,  2.23it/s]\u001b[A\n","Iteration:  39% 717/1851 [05:17<08:24,  2.25it/s]\u001b[A\n","Iteration:  39% 718/1851 [05:18<08:22,  2.25it/s]\u001b[A\n","Iteration:  39% 719/1851 [05:18<08:20,  2.26it/s]\u001b[A\n","Iteration:  39% 720/1851 [05:18<08:18,  2.27it/s]\u001b[A\n","Iteration:  39% 721/1851 [05:19<08:17,  2.27it/s]\u001b[A\n","Iteration:  39% 722/1851 [05:19<08:16,  2.27it/s]\u001b[A\n","Iteration:  39% 723/1851 [05:20<08:16,  2.27it/s]\u001b[A\n","Iteration:  39% 724/1851 [05:20<08:15,  2.28it/s]\u001b[A\n","Iteration:  39% 725/1851 [05:21<08:14,  2.28it/s]\u001b[A\n","Iteration:  39% 726/1851 [05:21<08:14,  2.28it/s]\u001b[A\n","Iteration:  39% 727/1851 [05:21<08:13,  2.28it/s]\u001b[A\n","Iteration:  39% 728/1851 [05:22<08:13,  2.28it/s]\u001b[A\n","Iteration:  39% 729/1851 [05:22<08:12,  2.28it/s]\u001b[A\n","Iteration:  39% 730/1851 [05:23<08:11,  2.28it/s]\u001b[A\n","Iteration:  39% 731/1851 [05:23<08:11,  2.28it/s]\u001b[A\n","Iteration:  40% 732/1851 [05:24<08:11,  2.28it/s]\u001b[A\n","Iteration:  40% 733/1851 [05:24<08:11,  2.28it/s]\u001b[A\n","Iteration:  40% 734/1851 [05:25<08:10,  2.28it/s]\u001b[A\n","Iteration:  40% 735/1851 [05:25<08:10,  2.28it/s]\u001b[A\n","Iteration:  40% 736/1851 [05:25<08:09,  2.28it/s]\u001b[A\n","Iteration:  40% 737/1851 [05:26<08:09,  2.28it/s]\u001b[A\n","Iteration:  40% 738/1851 [05:26<08:08,  2.28it/s]\u001b[A\n","Iteration:  40% 739/1851 [05:27<08:08,  2.28it/s]\u001b[A\n","Iteration:  40% 740/1851 [05:27<08:07,  2.28it/s]\u001b[A\n","Iteration:  40% 741/1851 [05:28<08:07,  2.28it/s]\u001b[A\n","Iteration:  40% 742/1851 [05:28<08:06,  2.28it/s]\u001b[A\n","Iteration:  40% 743/1851 [05:29<08:06,  2.28it/s]\u001b[A\n","Iteration:  40% 744/1851 [05:29<08:06,  2.28it/s]\u001b[A\n","Iteration:  40% 745/1851 [05:29<08:05,  2.28it/s]\u001b[A\n","Iteration:  40% 746/1851 [05:30<08:05,  2.28it/s]\u001b[A\n","Iteration:  40% 747/1851 [05:30<08:04,  2.28it/s]\u001b[A\n","Iteration:  40% 748/1851 [05:31<08:04,  2.28it/s]\u001b[A\n","Iteration:  40% 749/1851 [05:31<08:04,  2.28it/s]\u001b[A\n","Iteration:  41% 750/1851 [05:32<08:03,  2.28it/s]\u001b[A\n","Iteration:  41% 751/1851 [05:32<08:02,  2.28it/s]\u001b[A\n","Iteration:  41% 752/1851 [05:32<08:02,  2.28it/s]\u001b[A\n","Iteration:  41% 753/1851 [05:33<08:01,  2.28it/s]\u001b[A\n","Iteration:  41% 754/1851 [05:33<08:01,  2.28it/s]\u001b[A\n","Iteration:  41% 755/1851 [05:34<08:01,  2.28it/s]\u001b[A\n","Iteration:  41% 756/1851 [05:34<08:01,  2.28it/s]\u001b[A\n","Iteration:  41% 757/1851 [05:35<08:00,  2.28it/s]\u001b[A\n","Iteration:  41% 758/1851 [05:35<08:00,  2.27it/s]\u001b[A\n","Iteration:  41% 759/1851 [05:36<08:00,  2.27it/s]\u001b[A\n","Iteration:  41% 760/1851 [05:36<07:59,  2.27it/s]\u001b[A\n","Iteration:  41% 761/1851 [05:36<07:58,  2.28it/s]\u001b[A\n","Iteration:  41% 762/1851 [05:37<07:58,  2.28it/s]\u001b[A\n","Iteration:  41% 763/1851 [05:37<07:57,  2.28it/s]\u001b[A\n","Iteration:  41% 764/1851 [05:38<07:57,  2.28it/s]\u001b[A\n","Iteration:  41% 765/1851 [05:38<07:56,  2.28it/s]\u001b[A\n","Iteration:  41% 766/1851 [05:39<07:56,  2.28it/s]\u001b[A\n","Iteration:  41% 767/1851 [05:39<07:56,  2.27it/s]\u001b[A\n","Iteration:  41% 768/1851 [05:40<07:55,  2.28it/s]\u001b[A\n","Iteration:  42% 769/1851 [05:40<07:55,  2.27it/s]\u001b[A\n","Iteration:  42% 770/1851 [05:40<07:55,  2.27it/s]\u001b[A\n","Iteration:  42% 771/1851 [05:41<07:55,  2.27it/s]\u001b[A\n","Iteration:  42% 772/1851 [05:41<07:54,  2.27it/s]\u001b[A\n","Iteration:  42% 773/1851 [05:42<07:53,  2.27it/s]\u001b[A\n","Iteration:  42% 774/1851 [05:42<07:53,  2.28it/s]\u001b[A\n","Iteration:  42% 775/1851 [05:43<07:52,  2.28it/s]\u001b[A\n","Iteration:  42% 776/1851 [05:43<07:52,  2.27it/s]\u001b[A\n","Iteration:  42% 777/1851 [05:43<07:51,  2.28it/s]\u001b[A\n","Iteration:  42% 778/1851 [05:44<07:51,  2.28it/s]\u001b[A\n","Iteration:  42% 779/1851 [05:44<07:50,  2.28it/s]\u001b[A\n","Iteration:  42% 780/1851 [05:45<07:50,  2.27it/s]\u001b[A\n","Iteration:  42% 781/1851 [05:45<07:50,  2.28it/s]\u001b[A\n","Iteration:  42% 782/1851 [05:46<07:49,  2.28it/s]\u001b[A\n","Iteration:  42% 783/1851 [05:46<07:49,  2.28it/s]\u001b[A\n","Iteration:  42% 784/1851 [05:47<07:48,  2.28it/s]\u001b[A\n","Iteration:  42% 785/1851 [05:47<07:48,  2.28it/s]\u001b[A\n","Iteration:  42% 786/1851 [05:47<07:47,  2.28it/s]\u001b[A\n","Iteration:  43% 787/1851 [05:48<07:47,  2.28it/s]\u001b[A\n","Iteration:  43% 788/1851 [05:48<07:48,  2.27it/s]\u001b[A\n","Iteration:  43% 789/1851 [05:49<07:49,  2.26it/s]\u001b[A\n","Iteration:  43% 790/1851 [05:49<07:47,  2.27it/s]\u001b[A\n","Iteration:  43% 791/1851 [05:50<07:47,  2.27it/s]\u001b[A\n","Iteration:  43% 792/1851 [05:50<07:46,  2.27it/s]\u001b[A\n","Iteration:  43% 793/1851 [05:50<07:45,  2.27it/s]\u001b[A\n","Iteration:  43% 794/1851 [05:51<07:44,  2.27it/s]\u001b[A\n","Iteration:  43% 795/1851 [05:51<07:44,  2.27it/s]\u001b[A\n","Iteration:  43% 796/1851 [05:52<07:43,  2.27it/s]\u001b[A\n","Iteration:  43% 797/1851 [05:52<07:43,  2.27it/s]\u001b[A\n","Iteration:  43% 798/1851 [05:53<07:43,  2.27it/s]\u001b[A\n","Iteration:  43% 799/1851 [05:53<07:47,  2.25it/s]\u001b[A\n","Iteration:  43% 800/1851 [05:54<07:43,  2.27it/s]\u001b[A\n","Iteration:  43% 801/1851 [05:54<07:42,  2.27it/s]\u001b[A\n","Iteration:  43% 802/1851 [05:54<07:41,  2.27it/s]\u001b[A\n","Iteration:  43% 803/1851 [05:55<07:41,  2.27it/s]\u001b[A\n","Iteration:  43% 804/1851 [05:55<07:42,  2.27it/s]\u001b[A\n","Iteration:  43% 805/1851 [05:56<07:41,  2.27it/s]\u001b[A\n","Iteration:  44% 806/1851 [05:56<07:40,  2.27it/s]\u001b[A\n","Iteration:  44% 807/1851 [05:57<07:39,  2.27it/s]\u001b[A\n","Iteration:  44% 808/1851 [05:57<07:38,  2.27it/s]\u001b[A\n","Iteration:  44% 809/1851 [05:58<07:38,  2.27it/s]\u001b[A\n","Iteration:  44% 810/1851 [05:58<07:37,  2.27it/s]\u001b[A\n","Iteration:  44% 811/1851 [05:58<07:37,  2.28it/s]\u001b[A\n","Iteration:  44% 812/1851 [05:59<07:36,  2.28it/s]\u001b[A\n","Iteration:  44% 813/1851 [05:59<07:36,  2.28it/s]\u001b[A\n","Iteration:  44% 814/1851 [06:00<07:35,  2.27it/s]\u001b[A\n","Iteration:  44% 815/1851 [06:00<07:35,  2.27it/s]\u001b[A\n","Iteration:  44% 816/1851 [06:01<07:35,  2.27it/s]\u001b[A\n","Iteration:  44% 817/1851 [06:01<07:34,  2.27it/s]\u001b[A\n","Iteration:  44% 818/1851 [06:01<07:33,  2.28it/s]\u001b[A\n","Iteration:  44% 819/1851 [06:02<07:33,  2.28it/s]\u001b[A\n","Iteration:  44% 820/1851 [06:02<07:32,  2.28it/s]\u001b[A\n","Iteration:  44% 821/1851 [06:03<07:32,  2.28it/s]\u001b[A\n","Iteration:  44% 822/1851 [06:03<07:32,  2.28it/s]\u001b[A\n","Iteration:  44% 823/1851 [06:04<07:32,  2.27it/s]\u001b[A\n","Iteration:  45% 824/1851 [06:04<07:31,  2.27it/s]\u001b[A\n","Iteration:  45% 825/1851 [06:05<07:31,  2.27it/s]\u001b[A\n","Iteration:  45% 826/1851 [06:05<07:30,  2.27it/s]\u001b[A\n","Iteration:  45% 827/1851 [06:05<07:31,  2.27it/s]\u001b[A\n","Iteration:  45% 828/1851 [06:06<07:30,  2.27it/s]\u001b[A\n","Iteration:  45% 829/1851 [06:06<07:30,  2.27it/s]\u001b[A\n","Iteration:  45% 830/1851 [06:07<07:31,  2.26it/s]\u001b[A\n","Iteration:  45% 831/1851 [06:07<07:30,  2.27it/s]\u001b[A\n","Iteration:  45% 832/1851 [06:08<07:33,  2.25it/s]\u001b[A\n","Iteration:  45% 833/1851 [06:08<07:30,  2.26it/s]\u001b[A\n","Iteration:  45% 834/1851 [06:09<07:28,  2.27it/s]\u001b[A\n","Iteration:  45% 835/1851 [06:09<07:30,  2.26it/s]\u001b[A\n","Iteration:  45% 836/1851 [06:09<07:39,  2.21it/s]\u001b[A\n","Iteration:  45% 837/1851 [06:10<07:34,  2.23it/s]\u001b[A\n","Iteration:  45% 838/1851 [06:10<07:31,  2.24it/s]\u001b[A\n","Iteration:  45% 839/1851 [06:11<07:28,  2.26it/s]\u001b[A\n","Iteration:  45% 840/1851 [06:11<07:26,  2.26it/s]\u001b[A\n","Iteration:  45% 841/1851 [06:12<07:25,  2.27it/s]\u001b[A\n","Iteration:  45% 842/1851 [06:12<07:24,  2.27it/s]\u001b[A\n","Iteration:  46% 843/1851 [06:13<07:23,  2.27it/s]\u001b[A\n","Iteration:  46% 844/1851 [06:13<07:22,  2.27it/s]\u001b[A\n","Iteration:  46% 845/1851 [06:13<07:22,  2.27it/s]\u001b[A\n","Iteration:  46% 846/1851 [06:14<07:21,  2.27it/s]\u001b[A\n","Iteration:  46% 847/1851 [06:14<07:22,  2.27it/s]\u001b[A\n","Iteration:  46% 848/1851 [06:15<07:21,  2.27it/s]\u001b[A\n","Iteration:  46% 849/1851 [06:15<07:21,  2.27it/s]\u001b[A\n","Iteration:  46% 850/1851 [06:16<07:20,  2.27it/s]\u001b[A\n","Iteration:  46% 851/1851 [06:16<07:19,  2.27it/s]\u001b[A\n","Iteration:  46% 852/1851 [06:17<07:19,  2.27it/s]\u001b[A\n","Iteration:  46% 853/1851 [06:17<07:18,  2.28it/s]\u001b[A\n","Iteration:  46% 854/1851 [06:17<07:18,  2.27it/s]\u001b[A\n","Iteration:  46% 855/1851 [06:18<07:17,  2.28it/s]\u001b[A\n","Iteration:  46% 856/1851 [06:18<07:16,  2.28it/s]\u001b[A\n","Iteration:  46% 857/1851 [06:19<07:16,  2.28it/s]\u001b[A\n","Iteration:  46% 858/1851 [06:19<07:16,  2.28it/s]\u001b[A\n","Iteration:  46% 859/1851 [06:20<07:15,  2.28it/s]\u001b[A\n","Iteration:  46% 860/1851 [06:20<07:14,  2.28it/s]\u001b[A\n","Iteration:  47% 861/1851 [06:20<07:14,  2.28it/s]\u001b[A\n","Iteration:  47% 862/1851 [06:21<07:14,  2.28it/s]\u001b[A\n","Iteration:  47% 863/1851 [06:21<07:13,  2.28it/s]\u001b[A\n","Iteration:  47% 864/1851 [06:22<07:13,  2.28it/s]\u001b[A\n","Iteration:  47% 865/1851 [06:22<07:12,  2.28it/s]\u001b[A\n","Iteration:  47% 866/1851 [06:23<07:12,  2.28it/s]\u001b[A\n","Iteration:  47% 867/1851 [06:23<07:12,  2.28it/s]\u001b[A\n","Iteration:  47% 868/1851 [06:24<07:13,  2.27it/s]\u001b[A\n","Iteration:  47% 869/1851 [06:24<07:12,  2.27it/s]\u001b[A\n","Iteration:  47% 870/1851 [06:24<07:11,  2.27it/s]\u001b[A\n","Iteration:  47% 871/1851 [06:25<07:10,  2.28it/s]\u001b[A\n","Iteration:  47% 872/1851 [06:25<07:10,  2.28it/s]\u001b[A\n","Iteration:  47% 873/1851 [06:26<07:09,  2.28it/s]\u001b[A\n","Iteration:  47% 874/1851 [06:26<07:09,  2.28it/s]\u001b[A\n","Iteration:  47% 875/1851 [06:27<07:08,  2.28it/s]\u001b[A\n","Iteration:  47% 876/1851 [06:27<07:07,  2.28it/s]\u001b[A\n","Iteration:  47% 877/1851 [06:27<07:07,  2.28it/s]\u001b[A\n","Iteration:  47% 878/1851 [06:28<07:06,  2.28it/s]\u001b[A\n","Iteration:  47% 879/1851 [06:28<07:08,  2.27it/s]\u001b[A\n","Iteration:  48% 880/1851 [06:29<07:09,  2.26it/s]\u001b[A\n","Iteration:  48% 881/1851 [06:29<07:08,  2.27it/s]\u001b[A\n","Iteration:  48% 882/1851 [06:30<07:07,  2.27it/s]\u001b[A\n","Iteration:  48% 883/1851 [06:30<07:06,  2.27it/s]\u001b[A\n","Iteration:  48% 884/1851 [06:31<07:05,  2.27it/s]\u001b[A\n","Iteration:  48% 885/1851 [06:31<07:04,  2.27it/s]\u001b[A\n","Iteration:  48% 886/1851 [06:31<07:04,  2.27it/s]\u001b[A\n","Iteration:  48% 887/1851 [06:32<07:03,  2.28it/s]\u001b[A\n","Iteration:  48% 888/1851 [06:32<07:03,  2.28it/s]\u001b[A\n","Iteration:  48% 889/1851 [06:33<07:02,  2.28it/s]\u001b[A\n","Iteration:  48% 890/1851 [06:33<07:02,  2.28it/s]\u001b[A\n","Iteration:  48% 891/1851 [06:34<07:01,  2.28it/s]\u001b[A\n","Iteration:  48% 892/1851 [06:34<07:00,  2.28it/s]\u001b[A\n","Iteration:  48% 893/1851 [06:35<07:00,  2.28it/s]\u001b[A\n","Iteration:  48% 894/1851 [06:35<07:00,  2.28it/s]\u001b[A\n","Iteration:  48% 895/1851 [06:35<06:59,  2.28it/s]\u001b[A\n","Iteration:  48% 896/1851 [06:36<06:59,  2.28it/s]\u001b[A\n","Iteration:  48% 897/1851 [06:36<06:59,  2.27it/s]\u001b[A\n","Iteration:  49% 898/1851 [06:37<06:59,  2.27it/s]\u001b[A\n","Iteration:  49% 899/1851 [06:37<06:58,  2.27it/s]\u001b[A\n","Iteration:  49% 900/1851 [06:38<06:58,  2.27it/s]\u001b[A\n","Iteration:  49% 901/1851 [06:38<06:57,  2.28it/s]\u001b[A\n","Iteration:  49% 902/1851 [06:38<06:57,  2.28it/s]\u001b[A\n","Iteration:  49% 903/1851 [06:39<06:56,  2.28it/s]\u001b[A\n","Iteration:  49% 904/1851 [06:39<06:55,  2.28it/s]\u001b[A\n","Iteration:  49% 905/1851 [06:40<06:55,  2.28it/s]\u001b[A\n","Iteration:  49% 906/1851 [06:40<06:54,  2.28it/s]\u001b[A\n","Iteration:  49% 907/1851 [06:41<06:54,  2.28it/s]\u001b[A\n","Iteration:  49% 908/1851 [06:41<06:55,  2.27it/s]\u001b[A\n","Iteration:  49% 909/1851 [06:42<06:54,  2.27it/s]\u001b[A\n","Iteration:  49% 910/1851 [06:42<06:53,  2.28it/s]\u001b[A\n","Iteration:  49% 911/1851 [06:42<06:52,  2.28it/s]\u001b[A\n","Iteration:  49% 912/1851 [06:43<06:52,  2.28it/s]\u001b[A\n","Iteration:  49% 913/1851 [06:43<06:52,  2.28it/s]\u001b[A\n","Iteration:  49% 914/1851 [06:44<06:51,  2.28it/s]\u001b[A\n","Iteration:  49% 915/1851 [06:44<06:51,  2.28it/s]\u001b[A\n","Iteration:  49% 916/1851 [06:45<06:51,  2.27it/s]\u001b[A\n","Iteration:  50% 917/1851 [06:45<06:50,  2.27it/s]\u001b[A\n","Iteration:  50% 918/1851 [06:46<06:50,  2.27it/s]\u001b[A\n","Iteration:  50% 919/1851 [06:46<06:50,  2.27it/s]\u001b[A\n","Iteration:  50% 920/1851 [06:46<06:49,  2.27it/s]\u001b[A\n","Iteration:  50% 921/1851 [06:47<06:48,  2.28it/s]\u001b[A\n","Iteration:  50% 922/1851 [06:47<06:48,  2.28it/s]\u001b[A\n","Iteration:  50% 923/1851 [06:48<06:47,  2.28it/s]\u001b[A\n","Iteration:  50% 924/1851 [06:48<06:46,  2.28it/s]\u001b[A\n","Iteration:  50% 925/1851 [06:49<06:46,  2.28it/s]\u001b[A\n","Iteration:  50% 926/1851 [06:49<06:46,  2.28it/s]\u001b[A\n","Iteration:  50% 927/1851 [06:49<06:47,  2.27it/s]\u001b[A\n","Iteration:  50% 928/1851 [06:50<06:48,  2.26it/s]\u001b[A\n","Iteration:  50% 929/1851 [06:50<06:47,  2.26it/s]\u001b[A\n","Iteration:  50% 930/1851 [06:51<06:49,  2.25it/s]\u001b[A\n","Iteration:  50% 931/1851 [06:51<06:49,  2.24it/s]\u001b[A\n","Iteration:  50% 932/1851 [06:52<06:49,  2.24it/s]\u001b[A\n","Iteration:  50% 933/1851 [06:52<06:46,  2.26it/s]\u001b[A\n","Iteration:  50% 934/1851 [06:53<06:45,  2.26it/s]\u001b[A\n","Iteration:  51% 935/1851 [06:55<15:07,  1.01it/s]\u001b[A\n","Iteration:  51% 936/1851 [06:55<12:34,  1.21it/s]\u001b[A\n","Iteration:  51% 937/1851 [06:56<10:47,  1.41it/s]\u001b[A\n","Iteration:  51% 938/1851 [06:56<09:33,  1.59it/s]\u001b[A\n","Iteration:  51% 939/1851 [06:57<08:40,  1.75it/s]\u001b[A\n","Iteration:  51% 940/1851 [06:57<08:04,  1.88it/s]\u001b[A\n","Iteration:  51% 941/1851 [06:57<07:40,  1.98it/s]\u001b[A\n","Iteration:  51% 942/1851 [06:58<07:23,  2.05it/s]\u001b[A\n","Iteration:  51% 943/1851 [06:58<07:11,  2.10it/s]\u001b[A\n","Iteration:  51% 944/1851 [06:59<07:40,  1.97it/s]\u001b[A\n","Iteration:  51% 945/1851 [06:59<07:21,  2.05it/s]\u001b[A\n","Iteration:  51% 946/1851 [07:00<07:07,  2.11it/s]\u001b[A\n","Iteration:  51% 947/1851 [07:00<06:58,  2.16it/s]\u001b[A\n","Iteration:  51% 948/1851 [07:01<06:51,  2.20it/s]\u001b[A\n","Iteration:  51% 949/1851 [07:01<06:46,  2.22it/s]\u001b[A\n","Iteration:  51% 950/1851 [07:02<06:42,  2.24it/s]\u001b[A\n","Iteration:  51% 951/1851 [07:02<06:40,  2.25it/s]\u001b[A\n","Iteration:  51% 952/1851 [07:02<06:38,  2.25it/s]\u001b[A\n","Iteration:  51% 953/1851 [07:03<06:36,  2.26it/s]\u001b[A\n","Iteration:  52% 954/1851 [07:03<06:35,  2.27it/s]\u001b[A\n","Iteration:  52% 955/1851 [07:04<06:34,  2.27it/s]\u001b[A\n","Iteration:  52% 956/1851 [07:04<06:33,  2.27it/s]\u001b[A\n","Iteration:  52% 957/1851 [07:05<06:33,  2.27it/s]\u001b[A\n","Iteration:  52% 958/1851 [07:05<06:32,  2.27it/s]\u001b[A\n","Iteration:  52% 959/1851 [07:06<06:32,  2.28it/s]\u001b[A\n","Iteration:  52% 960/1851 [07:06<06:31,  2.28it/s]\u001b[A\n","Iteration:  52% 961/1851 [07:06<06:30,  2.28it/s]\u001b[A\n","Iteration:  52% 962/1851 [07:07<06:30,  2.28it/s]\u001b[A\n","Iteration:  52% 963/1851 [07:07<06:29,  2.28it/s]\u001b[A\n","Iteration:  52% 964/1851 [07:08<06:29,  2.28it/s]\u001b[A\n","Iteration:  52% 965/1851 [07:08<06:28,  2.28it/s]\u001b[A\n","Iteration:  52% 966/1851 [07:09<06:28,  2.28it/s]\u001b[A\n","Iteration:  52% 967/1851 [07:09<06:29,  2.27it/s]\u001b[A\n","Iteration:  52% 968/1851 [07:10<06:28,  2.27it/s]\u001b[A\n","Iteration:  52% 969/1851 [07:10<06:28,  2.27it/s]\u001b[A\n","Iteration:  52% 970/1851 [07:10<06:27,  2.27it/s]\u001b[A\n","Iteration:  52% 971/1851 [07:11<06:26,  2.28it/s]\u001b[A\n","Iteration:  53% 972/1851 [07:11<06:26,  2.27it/s]\u001b[A\n","Iteration:  53% 973/1851 [07:12<06:25,  2.28it/s]\u001b[A\n","Iteration:  53% 974/1851 [07:12<06:25,  2.28it/s]\u001b[A\n","Iteration:  53% 975/1851 [07:13<06:24,  2.28it/s]\u001b[A\n","Iteration:  53% 976/1851 [07:13<06:24,  2.28it/s]\u001b[A\n","Iteration:  53% 977/1851 [07:13<06:23,  2.28it/s]\u001b[A\n","Iteration:  53% 978/1851 [07:14<06:23,  2.28it/s]\u001b[A\n","Iteration:  53% 979/1851 [07:14<06:22,  2.28it/s]\u001b[A\n","Iteration:  53% 980/1851 [07:15<06:22,  2.28it/s]\u001b[A\n","Iteration:  53% 981/1851 [07:15<06:21,  2.28it/s]\u001b[A\n","Iteration:  53% 982/1851 [07:16<06:21,  2.28it/s]\u001b[A\n","Iteration:  53% 983/1851 [07:16<06:21,  2.28it/s]\u001b[A\n","Iteration:  53% 984/1851 [07:17<06:20,  2.28it/s]\u001b[A\n","Iteration:  53% 985/1851 [07:17<06:20,  2.28it/s]\u001b[A\n","Iteration:  53% 986/1851 [07:17<06:20,  2.28it/s]\u001b[A\n","Iteration:  53% 987/1851 [07:18<06:19,  2.28it/s]\u001b[A\n","Iteration:  53% 988/1851 [07:18<06:19,  2.28it/s]\u001b[A\n","Iteration:  53% 989/1851 [07:19<06:19,  2.27it/s]\u001b[A\n","Iteration:  53% 990/1851 [07:19<06:18,  2.27it/s]\u001b[A\n","Iteration:  54% 991/1851 [07:20<06:18,  2.27it/s]\u001b[A\n","Iteration:  54% 992/1851 [07:20<06:17,  2.27it/s]\u001b[A\n","Iteration:  54% 993/1851 [07:20<06:17,  2.27it/s]\u001b[A\n","Iteration:  54% 994/1851 [07:21<06:17,  2.27it/s]\u001b[A\n","Iteration:  54% 995/1851 [07:21<06:16,  2.27it/s]\u001b[A\n","Iteration:  54% 996/1851 [07:22<06:16,  2.27it/s]\u001b[A\n","Iteration:  54% 997/1851 [07:22<06:15,  2.27it/s]\u001b[A\n","Iteration:  54% 998/1851 [07:23<06:15,  2.27it/s]\u001b[A\n","Iteration:  54% 999/1851 [07:23<06:14,  2.28it/s]\u001b[A\n","Iteration:  54% 1000/1851 [07:24<06:13,  2.28it/s]\u001b[A\n","Iteration:  54% 1001/1851 [07:24<06:13,  2.28it/s]\u001b[A\n","Iteration:  54% 1002/1851 [07:24<06:13,  2.27it/s]\u001b[A\n","Iteration:  54% 1003/1851 [07:25<06:12,  2.28it/s]\u001b[A\n","Iteration:  54% 1004/1851 [07:25<06:12,  2.27it/s]\u001b[A\n","Iteration:  54% 1005/1851 [07:26<06:11,  2.28it/s]\u001b[A\n","Iteration:  54% 1006/1851 [07:26<06:11,  2.28it/s]\u001b[A\n","Iteration:  54% 1007/1851 [07:27<06:10,  2.28it/s]\u001b[A\n","Iteration:  54% 1008/1851 [07:27<06:10,  2.28it/s]\u001b[A\n","Iteration:  55% 1009/1851 [07:28<06:09,  2.28it/s]\u001b[A\n","Iteration:  55% 1010/1851 [07:28<06:09,  2.28it/s]\u001b[A\n","Iteration:  55% 1011/1851 [07:28<06:08,  2.28it/s]\u001b[A\n","Iteration:  55% 1012/1851 [07:29<06:08,  2.28it/s]\u001b[A\n","Iteration:  55% 1013/1851 [07:29<06:07,  2.28it/s]\u001b[A\n","Iteration:  55% 1014/1851 [07:30<06:08,  2.27it/s]\u001b[A\n","Iteration:  55% 1015/1851 [07:30<06:08,  2.27it/s]\u001b[A\n","Iteration:  55% 1016/1851 [07:31<06:07,  2.27it/s]\u001b[A\n","Iteration:  55% 1017/1851 [07:31<06:06,  2.28it/s]\u001b[A\n","Iteration:  55% 1018/1851 [07:31<06:05,  2.28it/s]\u001b[A\n","Iteration:  55% 1019/1851 [07:32<06:05,  2.27it/s]\u001b[A\n","Iteration:  55% 1020/1851 [07:32<06:05,  2.28it/s]\u001b[A\n","Iteration:  55% 1021/1851 [07:33<06:04,  2.28it/s]\u001b[A\n","Iteration:  55% 1022/1851 [07:33<06:03,  2.28it/s]\u001b[A\n","Iteration:  55% 1023/1851 [07:34<06:03,  2.28it/s]\u001b[A\n","Iteration:  55% 1024/1851 [07:34<06:03,  2.28it/s]\u001b[A\n","Iteration:  55% 1025/1851 [07:35<06:02,  2.28it/s]\u001b[A\n","Iteration:  55% 1026/1851 [07:35<06:02,  2.28it/s]\u001b[A\n","Iteration:  55% 1027/1851 [07:35<06:01,  2.28it/s]\u001b[A\n","Iteration:  56% 1028/1851 [07:36<06:03,  2.27it/s]\u001b[A\n","Iteration:  56% 1029/1851 [07:36<06:02,  2.27it/s]\u001b[A\n","Iteration:  56% 1030/1851 [07:37<06:01,  2.27it/s]\u001b[A\n","Iteration:  56% 1031/1851 [07:37<06:00,  2.27it/s]\u001b[A\n","Iteration:  56% 1032/1851 [07:38<06:00,  2.27it/s]\u001b[A\n","Iteration:  56% 1033/1851 [07:38<05:59,  2.28it/s]\u001b[A\n","Iteration:  56% 1034/1851 [07:39<05:59,  2.27it/s]\u001b[A\n","Iteration:  56% 1035/1851 [07:39<05:58,  2.27it/s]\u001b[A\n","Iteration:  56% 1036/1851 [07:39<05:58,  2.27it/s]\u001b[A\n","Iteration:  56% 1037/1851 [07:40<06:32,  2.08it/s]\u001b[A\n","Iteration:  56% 1038/1851 [07:40<06:22,  2.13it/s]\u001b[A\n","Iteration:  56% 1039/1851 [07:41<06:15,  2.16it/s]\u001b[A\n","Iteration:  56% 1040/1851 [07:41<06:10,  2.19it/s]\u001b[A\n","Iteration:  56% 1041/1851 [07:42<06:14,  2.17it/s]\u001b[A\n","Iteration:  56% 1042/1851 [07:42<06:08,  2.20it/s]\u001b[A\n","Iteration:  56% 1043/1851 [07:43<06:03,  2.22it/s]\u001b[A\n","Iteration:  56% 1044/1851 [07:43<06:00,  2.24it/s]\u001b[A\n","Iteration:  56% 1045/1851 [07:44<05:58,  2.25it/s]\u001b[A\n","Iteration:  57% 1046/1851 [07:44<05:56,  2.26it/s]\u001b[A\n","Iteration:  57% 1047/1851 [07:44<05:55,  2.26it/s]\u001b[A\n","Iteration:  57% 1048/1851 [07:45<05:54,  2.26it/s]\u001b[A\n","Iteration:  57% 1049/1851 [07:45<05:53,  2.27it/s]\u001b[A\n","Iteration:  57% 1050/1851 [07:46<05:52,  2.27it/s]\u001b[A\n","Iteration:  57% 1051/1851 [07:46<05:51,  2.27it/s]\u001b[A\n","Iteration:  57% 1052/1851 [07:47<05:51,  2.27it/s]\u001b[A\n","Iteration:  57% 1053/1851 [07:47<05:50,  2.27it/s]\u001b[A\n","Iteration:  57% 1054/1851 [07:47<05:50,  2.28it/s]\u001b[A\n","Iteration:  57% 1055/1851 [07:48<05:49,  2.28it/s]\u001b[A\n","Iteration:  57% 1056/1851 [07:48<05:49,  2.28it/s]\u001b[A\n","Iteration:  57% 1057/1851 [07:49<05:48,  2.28it/s]\u001b[A\n","Iteration:  57% 1058/1851 [07:49<05:48,  2.28it/s]\u001b[A\n","Iteration:  57% 1059/1851 [07:50<05:47,  2.28it/s]\u001b[A\n","Iteration:  57% 1060/1851 [07:50<05:47,  2.28it/s]\u001b[A\n","Iteration:  57% 1061/1851 [07:51<05:47,  2.28it/s]\u001b[A\n","Iteration:  57% 1062/1851 [07:51<05:46,  2.28it/s]\u001b[A\n","Iteration:  57% 1063/1851 [07:51<05:46,  2.28it/s]\u001b[A\n","Iteration:  57% 1064/1851 [07:52<05:45,  2.27it/s]\u001b[A\n","Iteration:  58% 1065/1851 [07:52<05:45,  2.28it/s]\u001b[A\n","Iteration:  58% 1066/1851 [07:53<05:44,  2.28it/s]\u001b[A\n","Iteration:  58% 1067/1851 [07:53<05:44,  2.28it/s]\u001b[A\n","Iteration:  58% 1068/1851 [07:54<05:43,  2.28it/s]\u001b[A\n","Iteration:  58% 1069/1851 [07:54<05:43,  2.28it/s]\u001b[A\n","Iteration:  58% 1070/1851 [07:55<05:42,  2.28it/s]\u001b[A\n","Iteration:  58% 1071/1851 [07:55<05:42,  2.28it/s]\u001b[A\n","Iteration:  58% 1072/1851 [07:55<05:41,  2.28it/s]\u001b[A\n","Iteration:  58% 1073/1851 [07:56<05:41,  2.28it/s]\u001b[A\n","Iteration:  58% 1074/1851 [07:56<05:41,  2.28it/s]\u001b[A\n","Iteration:  58% 1075/1851 [07:57<05:40,  2.28it/s]\u001b[A\n","Iteration:  58% 1076/1851 [07:57<05:40,  2.28it/s]\u001b[A\n","Iteration:  58% 1077/1851 [07:58<05:39,  2.28it/s]\u001b[A\n","Iteration:  58% 1078/1851 [07:58<05:39,  2.28it/s]\u001b[A\n","Iteration:  58% 1079/1851 [07:58<05:38,  2.28it/s]\u001b[A\n","Iteration:  58% 1080/1851 [07:59<05:38,  2.28it/s]\u001b[A\n","Iteration:  58% 1081/1851 [07:59<05:38,  2.28it/s]\u001b[A\n","Iteration:  58% 1082/1851 [08:00<05:37,  2.28it/s]\u001b[A\n","Iteration:  59% 1083/1851 [08:00<05:37,  2.27it/s]\u001b[A\n","Iteration:  59% 1084/1851 [08:01<05:37,  2.28it/s]\u001b[A\n","Iteration:  59% 1085/1851 [08:01<05:36,  2.28it/s]\u001b[A\n","Iteration:  59% 1086/1851 [08:02<05:35,  2.28it/s]\u001b[A\n","Iteration:  59% 1087/1851 [08:02<05:35,  2.28it/s]\u001b[A\n","Iteration:  59% 1088/1851 [08:02<05:34,  2.28it/s]\u001b[A\n","Iteration:  59% 1089/1851 [08:03<05:34,  2.28it/s]\u001b[A\n","Iteration:  59% 1090/1851 [08:03<05:33,  2.28it/s]\u001b[A\n","Iteration:  59% 1091/1851 [08:04<05:33,  2.28it/s]\u001b[A\n","Iteration:  59% 1092/1851 [08:04<05:33,  2.28it/s]\u001b[A\n","Iteration:  59% 1093/1851 [08:05<05:33,  2.28it/s]\u001b[A\n","Iteration:  59% 1094/1851 [08:05<05:32,  2.28it/s]\u001b[A\n","Iteration:  59% 1095/1851 [08:05<05:31,  2.28it/s]\u001b[A\n","Iteration:  59% 1096/1851 [08:06<05:31,  2.28it/s]\u001b[A\n","Iteration:  59% 1097/1851 [08:06<05:30,  2.28it/s]\u001b[A\n","Iteration:  59% 1098/1851 [08:07<05:30,  2.28it/s]\u001b[A\n","Iteration:  59% 1099/1851 [08:07<05:29,  2.28it/s]\u001b[A\n","Iteration:  59% 1100/1851 [08:08<05:29,  2.28it/s]\u001b[A\n","Iteration:  59% 1101/1851 [08:08<05:29,  2.28it/s]\u001b[A\n","Iteration:  60% 1102/1851 [08:09<05:28,  2.28it/s]\u001b[A\n","Iteration:  60% 1103/1851 [08:09<05:28,  2.28it/s]\u001b[A\n","Iteration:  60% 1104/1851 [08:09<05:27,  2.28it/s]\u001b[A\n","Iteration:  60% 1105/1851 [08:10<05:27,  2.28it/s]\u001b[A\n","Iteration:  60% 1106/1851 [08:10<05:27,  2.28it/s]\u001b[A\n","Iteration:  60% 1107/1851 [08:11<05:26,  2.28it/s]\u001b[A\n","Iteration:  60% 1108/1851 [08:11<05:26,  2.28it/s]\u001b[A\n","Iteration:  60% 1109/1851 [08:12<05:25,  2.28it/s]\u001b[A\n","Iteration:  60% 1110/1851 [08:12<05:25,  2.28it/s]\u001b[A\n","Iteration:  60% 1111/1851 [08:13<05:24,  2.28it/s]\u001b[A\n","Iteration:  60% 1112/1851 [08:13<05:24,  2.28it/s]\u001b[A\n","Iteration:  60% 1113/1851 [08:13<05:23,  2.28it/s]\u001b[A\n","Iteration:  60% 1114/1851 [08:14<05:23,  2.28it/s]\u001b[A\n","Iteration:  60% 1115/1851 [08:14<05:22,  2.28it/s]\u001b[A\n","Iteration:  60% 1116/1851 [08:15<05:22,  2.28it/s]\u001b[A\n","Iteration:  60% 1117/1851 [08:15<05:22,  2.28it/s]\u001b[A\n","Iteration:  60% 1118/1851 [08:16<05:21,  2.28it/s]\u001b[A\n","Iteration:  60% 1119/1851 [08:16<05:21,  2.28it/s]\u001b[A\n","Iteration:  61% 1120/1851 [08:16<05:21,  2.28it/s]\u001b[A\n","Iteration:  61% 1121/1851 [08:17<05:20,  2.27it/s]\u001b[A\n","Iteration:  61% 1122/1851 [08:17<05:20,  2.27it/s]\u001b[A\n","Iteration:  61% 1123/1851 [08:18<05:20,  2.27it/s]\u001b[A\n","Iteration:  61% 1124/1851 [08:18<05:20,  2.27it/s]\u001b[A\n","Iteration:  61% 1125/1851 [08:19<05:19,  2.27it/s]\u001b[A\n","Iteration:  61% 1126/1851 [08:19<05:18,  2.27it/s]\u001b[A\n","Iteration:  61% 1127/1851 [08:20<05:18,  2.27it/s]\u001b[A\n","Iteration:  61% 1128/1851 [08:20<05:18,  2.27it/s]\u001b[A\n","Iteration:  61% 1129/1851 [08:20<05:17,  2.27it/s]\u001b[A\n","Iteration:  61% 1130/1851 [08:21<05:17,  2.27it/s]\u001b[A\n","Iteration:  61% 1131/1851 [08:21<05:16,  2.28it/s]\u001b[A\n","Iteration:  61% 1132/1851 [08:22<05:15,  2.28it/s]\u001b[A\n","Iteration:  61% 1133/1851 [08:22<05:15,  2.27it/s]\u001b[A\n","Iteration:  61% 1134/1851 [08:23<05:15,  2.27it/s]\u001b[A\n","Iteration:  61% 1135/1851 [08:23<05:14,  2.28it/s]\u001b[A\n","Iteration:  61% 1136/1851 [08:24<05:14,  2.28it/s]\u001b[A\n","Iteration:  61% 1137/1851 [08:24<05:13,  2.28it/s]\u001b[A\n","Iteration:  61% 1138/1851 [08:24<05:13,  2.28it/s]\u001b[A\n","Iteration:  62% 1139/1851 [08:25<05:12,  2.28it/s]\u001b[A\n","Iteration:  62% 1140/1851 [08:25<05:12,  2.28it/s]\u001b[A\n","Iteration:  62% 1141/1851 [08:26<05:11,  2.28it/s]\u001b[A\n","Iteration:  62% 1142/1851 [08:26<05:11,  2.28it/s]\u001b[A\n","Iteration:  62% 1143/1851 [08:27<05:10,  2.28it/s]\u001b[A\n","Iteration:  62% 1144/1851 [08:27<05:10,  2.27it/s]\u001b[A\n","Iteration:  62% 1145/1851 [08:27<05:10,  2.27it/s]\u001b[A\n","Iteration:  62% 1146/1851 [08:28<05:09,  2.27it/s]\u001b[A\n","Iteration:  62% 1147/1851 [08:28<05:09,  2.28it/s]\u001b[A\n","Iteration:  62% 1148/1851 [08:29<05:08,  2.28it/s]\u001b[A\n","Iteration:  62% 1149/1851 [08:29<05:07,  2.28it/s]\u001b[A\n","Iteration:  62% 1150/1851 [08:30<05:07,  2.28it/s]\u001b[A\n","Iteration:  62% 1151/1851 [08:30<05:07,  2.28it/s]\u001b[A\n","Iteration:  62% 1152/1851 [08:31<05:06,  2.28it/s]\u001b[A\n","Iteration:  62% 1153/1851 [08:31<05:06,  2.28it/s]\u001b[A\n","Iteration:  62% 1154/1851 [08:31<05:06,  2.27it/s]\u001b[A\n","Iteration:  62% 1155/1851 [08:32<05:05,  2.28it/s]\u001b[A\n","Iteration:  62% 1156/1851 [08:32<05:05,  2.28it/s]\u001b[A\n","Iteration:  63% 1157/1851 [08:33<05:04,  2.28it/s]\u001b[A\n","Iteration:  63% 1158/1851 [08:33<05:04,  2.28it/s]\u001b[A\n","Iteration:  63% 1159/1851 [08:34<05:03,  2.28it/s]\u001b[A\n","Iteration:  63% 1160/1851 [08:34<05:03,  2.28it/s]\u001b[A\n","Iteration:  63% 1161/1851 [08:34<05:02,  2.28it/s]\u001b[A\n","Iteration:  63% 1162/1851 [08:35<05:02,  2.28it/s]\u001b[A\n","Iteration:  63% 1163/1851 [08:35<05:01,  2.28it/s]\u001b[A\n","Iteration:  63% 1164/1851 [08:36<05:01,  2.28it/s]\u001b[A\n","Iteration:  63% 1165/1851 [08:36<05:00,  2.28it/s]\u001b[A\n","Iteration:  63% 1166/1851 [08:37<05:00,  2.28it/s]\u001b[A\n","Iteration:  63% 1167/1851 [08:37<05:00,  2.28it/s]\u001b[A\n","Iteration:  63% 1168/1851 [08:38<04:59,  2.28it/s]\u001b[A\n","Iteration:  63% 1169/1851 [08:38<04:59,  2.28it/s]\u001b[A\n","Iteration:  63% 1170/1851 [08:38<04:58,  2.28it/s]\u001b[A\n","Iteration:  63% 1171/1851 [08:39<04:58,  2.28it/s]\u001b[A\n","Iteration:  63% 1172/1851 [08:39<04:58,  2.28it/s]\u001b[A\n","Iteration:  63% 1173/1851 [08:40<04:57,  2.28it/s]\u001b[A\n","Iteration:  63% 1174/1851 [08:40<04:57,  2.28it/s]\u001b[A\n","Iteration:  63% 1175/1851 [08:41<04:56,  2.28it/s]\u001b[A\n","Iteration:  64% 1176/1851 [08:41<04:56,  2.28it/s]\u001b[A\n","Iteration:  64% 1177/1851 [08:42<04:55,  2.28it/s]\u001b[A\n","Iteration:  64% 1178/1851 [08:42<04:55,  2.28it/s]\u001b[A\n","Iteration:  64% 1179/1851 [08:42<04:55,  2.28it/s]\u001b[A\n","Iteration:  64% 1180/1851 [08:43<04:55,  2.27it/s]\u001b[A\n","Iteration:  64% 1181/1851 [08:43<04:55,  2.27it/s]\u001b[A\n","Iteration:  64% 1182/1851 [08:44<04:54,  2.27it/s]\u001b[A\n","Iteration:  64% 1183/1851 [08:44<04:54,  2.27it/s]\u001b[A\n","Iteration:  64% 1184/1851 [08:45<04:53,  2.27it/s]\u001b[A\n","Iteration:  64% 1185/1851 [08:45<04:53,  2.27it/s]\u001b[A\n","Iteration:  64% 1186/1851 [08:45<04:52,  2.27it/s]\u001b[A\n","Iteration:  64% 1187/1851 [08:46<04:52,  2.27it/s]\u001b[A\n","Iteration:  64% 1188/1851 [08:46<04:51,  2.27it/s]\u001b[A\n","Iteration:  64% 1189/1851 [08:47<04:50,  2.28it/s]\u001b[A\n","Iteration:  64% 1190/1851 [08:47<04:50,  2.28it/s]\u001b[A\n","Iteration:  64% 1191/1851 [08:48<04:49,  2.28it/s]\u001b[A\n","Iteration:  64% 1192/1851 [08:48<04:49,  2.28it/s]\u001b[A\n","Iteration:  64% 1193/1851 [08:49<04:49,  2.27it/s]\u001b[A\n","Iteration:  65% 1194/1851 [08:49<04:49,  2.27it/s]\u001b[A\n","Iteration:  65% 1195/1851 [08:49<04:48,  2.28it/s]\u001b[A\n","Iteration:  65% 1196/1851 [08:50<04:47,  2.28it/s]\u001b[A\n","Iteration:  65% 1197/1851 [08:50<04:47,  2.28it/s]\u001b[A\n","Iteration:  65% 1198/1851 [08:51<04:46,  2.28it/s]\u001b[A\n","Iteration:  65% 1199/1851 [08:51<04:46,  2.28it/s]\u001b[A\n","Iteration:  65% 1200/1851 [08:52<04:45,  2.28it/s]\u001b[A\n","Iteration:  65% 1201/1851 [08:52<04:45,  2.28it/s]\u001b[A\n","Iteration:  65% 1202/1851 [08:53<04:45,  2.27it/s]\u001b[A\n","Iteration:  65% 1203/1851 [08:53<04:45,  2.27it/s]\u001b[A\n","Iteration:  65% 1204/1851 [08:53<04:44,  2.27it/s]\u001b[A\n","Iteration:  65% 1205/1851 [08:54<04:44,  2.27it/s]\u001b[A\n","Iteration:  65% 1206/1851 [08:54<04:43,  2.27it/s]\u001b[A\n","Iteration:  65% 1207/1851 [08:55<04:43,  2.28it/s]\u001b[A\n","Iteration:  65% 1208/1851 [08:55<04:43,  2.27it/s]\u001b[A\n","Iteration:  65% 1209/1851 [08:56<04:43,  2.27it/s]\u001b[A\n","Iteration:  65% 1210/1851 [08:56<04:42,  2.27it/s]\u001b[A\n","Iteration:  65% 1211/1851 [08:56<04:43,  2.26it/s]\u001b[A\n","Iteration:  65% 1212/1851 [08:57<04:42,  2.27it/s]\u001b[A\n","Iteration:  66% 1213/1851 [08:57<04:41,  2.27it/s]\u001b[A\n","Iteration:  66% 1214/1851 [08:58<04:40,  2.27it/s]\u001b[A\n","Iteration:  66% 1215/1851 [08:58<04:39,  2.27it/s]\u001b[A\n","Iteration:  66% 1216/1851 [08:59<04:39,  2.27it/s]\u001b[A\n","Iteration:  66% 1217/1851 [08:59<04:38,  2.27it/s]\u001b[A\n","Iteration:  66% 1218/1851 [09:00<04:38,  2.27it/s]\u001b[A\n","Iteration:  66% 1219/1851 [09:00<04:39,  2.26it/s]\u001b[A\n","Iteration:  66% 1220/1851 [09:00<04:38,  2.26it/s]\u001b[A\n","Iteration:  66% 1221/1851 [09:01<04:37,  2.27it/s]\u001b[A\n","Iteration:  66% 1222/1851 [09:01<04:36,  2.27it/s]\u001b[A\n","Iteration:  66% 1223/1851 [09:02<04:36,  2.27it/s]\u001b[A\n","Iteration:  66% 1224/1851 [09:02<04:36,  2.27it/s]\u001b[A\n","Iteration:  66% 1225/1851 [09:03<04:35,  2.27it/s]\u001b[A\n","Iteration:  66% 1226/1851 [09:03<04:34,  2.28it/s]\u001b[A\n","Iteration:  66% 1227/1851 [09:04<04:33,  2.28it/s]\u001b[A\n","Iteration:  66% 1228/1851 [09:04<04:33,  2.28it/s]\u001b[A\n","Iteration:  66% 1229/1851 [09:04<04:33,  2.28it/s]\u001b[A\n","Iteration:  66% 1230/1851 [09:05<04:32,  2.28it/s]\u001b[A\n","Iteration:  67% 1231/1851 [09:05<04:32,  2.28it/s]\u001b[A\n","Iteration:  67% 1232/1851 [09:06<04:31,  2.28it/s]\u001b[A\n","Iteration:  67% 1233/1851 [09:06<04:31,  2.28it/s]\u001b[A\n","Iteration:  67% 1234/1851 [09:07<04:30,  2.28it/s]\u001b[A\n","Iteration:  67% 1235/1851 [09:07<04:30,  2.28it/s]\u001b[A\n","Iteration:  67% 1236/1851 [09:07<04:30,  2.28it/s]\u001b[A\n","Iteration:  67% 1237/1851 [09:08<04:29,  2.28it/s]\u001b[A\n","Iteration:  67% 1238/1851 [09:08<04:29,  2.28it/s]\u001b[A\n","Iteration:  67% 1239/1851 [09:09<04:28,  2.28it/s]\u001b[A\n","Iteration:  67% 1240/1851 [09:09<04:28,  2.28it/s]\u001b[A\n","Iteration:  67% 1241/1851 [09:10<04:27,  2.28it/s]\u001b[A\n","Iteration:  67% 1242/1851 [09:10<04:27,  2.28it/s]\u001b[A\n","Iteration:  67% 1243/1851 [09:11<04:26,  2.28it/s]\u001b[A\n","Iteration:  67% 1244/1851 [09:11<04:26,  2.28it/s]\u001b[A\n","Iteration:  67% 1245/1851 [09:11<04:26,  2.28it/s]\u001b[A\n","Iteration:  67% 1246/1851 [09:12<04:25,  2.28it/s]\u001b[A\n","Iteration:  67% 1247/1851 [09:12<04:25,  2.28it/s]\u001b[A\n","Iteration:  67% 1248/1851 [09:13<04:25,  2.27it/s]\u001b[A\n","Iteration:  67% 1249/1851 [09:13<04:26,  2.25it/s]\u001b[A\n","Iteration:  68% 1250/1851 [09:14<04:27,  2.25it/s]\u001b[A\n","Iteration:  68% 1251/1851 [09:14<04:27,  2.25it/s]\u001b[A\n","Iteration:  68% 1252/1851 [09:15<04:25,  2.26it/s]\u001b[A\n","Iteration:  68% 1253/1851 [09:15<04:25,  2.25it/s]\u001b[A\n","Iteration:  68% 1254/1851 [09:15<04:25,  2.25it/s]\u001b[A\n","Iteration:  68% 1255/1851 [09:16<04:24,  2.25it/s]\u001b[A\n","Iteration:  68% 1256/1851 [09:16<04:23,  2.26it/s]\u001b[A\n","Iteration:  68% 1257/1851 [09:17<04:22,  2.26it/s]\u001b[A\n","Iteration:  68% 1258/1851 [09:17<04:21,  2.27it/s]\u001b[A\n","Iteration:  68% 1259/1851 [09:18<04:20,  2.27it/s]\u001b[A\n","Iteration:  68% 1260/1851 [09:18<04:20,  2.27it/s]\u001b[A\n","Iteration:  68% 1261/1851 [09:18<04:19,  2.27it/s]\u001b[A\n","Iteration:  68% 1262/1851 [09:19<04:18,  2.28it/s]\u001b[A\n","Iteration:  68% 1263/1851 [09:19<04:18,  2.28it/s]\u001b[A\n","Iteration:  68% 1264/1851 [09:20<04:17,  2.28it/s]\u001b[A\n","Iteration:  68% 1265/1851 [09:20<04:17,  2.27it/s]\u001b[A\n","Iteration:  68% 1266/1851 [09:21<04:17,  2.27it/s]\u001b[A\n","Iteration:  68% 1267/1851 [09:21<04:16,  2.27it/s]\u001b[A\n","Iteration:  69% 1268/1851 [09:22<04:16,  2.27it/s]\u001b[A\n","Iteration:  69% 1269/1851 [09:22<04:15,  2.27it/s]\u001b[A\n","Iteration:  69% 1270/1851 [09:22<04:15,  2.27it/s]\u001b[A\n","Iteration:  69% 1271/1851 [09:23<04:15,  2.27it/s]\u001b[A\n","Iteration:  69% 1272/1851 [09:23<04:14,  2.28it/s]\u001b[A\n","Iteration:  69% 1273/1851 [09:24<04:13,  2.28it/s]\u001b[A\n","Iteration:  69% 1274/1851 [09:24<04:13,  2.28it/s]\u001b[A\n","Iteration:  69% 1275/1851 [09:25<04:12,  2.28it/s]\u001b[A\n","Iteration:  69% 1276/1851 [09:25<04:12,  2.28it/s]\u001b[A\n","Iteration:  69% 1277/1851 [09:26<04:12,  2.28it/s]\u001b[A\n","Iteration:  69% 1278/1851 [09:26<04:11,  2.28it/s]\u001b[A\n","Iteration:  69% 1279/1851 [09:26<04:11,  2.28it/s]\u001b[A\n","Iteration:  69% 1280/1851 [09:27<04:10,  2.28it/s]\u001b[A\n","Iteration:  69% 1281/1851 [09:27<04:10,  2.28it/s]\u001b[A\n","Iteration:  69% 1282/1851 [09:28<04:09,  2.28it/s]\u001b[A\n","Iteration:  69% 1283/1851 [09:28<04:09,  2.28it/s]\u001b[A\n","Iteration:  69% 1284/1851 [09:29<04:09,  2.28it/s]\u001b[A\n","Iteration:  69% 1285/1851 [09:29<04:08,  2.28it/s]\u001b[A\n","Iteration:  69% 1286/1851 [09:29<04:08,  2.27it/s]\u001b[A\n","Iteration:  70% 1287/1851 [09:30<04:07,  2.28it/s]\u001b[A\n","Iteration:  70% 1288/1851 [09:30<04:07,  2.28it/s]\u001b[A\n","Iteration:  70% 1289/1851 [09:31<04:06,  2.28it/s]\u001b[A\n","Iteration:  70% 1290/1851 [09:31<04:06,  2.28it/s]\u001b[A\n","Iteration:  70% 1291/1851 [09:32<04:06,  2.28it/s]\u001b[A\n","Iteration:  70% 1292/1851 [09:32<04:05,  2.28it/s]\u001b[A\n","Iteration:  70% 1293/1851 [09:33<04:05,  2.28it/s]\u001b[A\n","Iteration:  70% 1294/1851 [09:33<04:04,  2.28it/s]\u001b[A\n","Iteration:  70% 1295/1851 [09:33<04:04,  2.28it/s]\u001b[A\n","Iteration:  70% 1296/1851 [09:34<04:03,  2.28it/s]\u001b[A\n","Iteration:  70% 1297/1851 [09:34<04:03,  2.28it/s]\u001b[A\n","Iteration:  70% 1298/1851 [09:35<04:02,  2.28it/s]\u001b[A\n","Iteration:  70% 1299/1851 [09:35<04:02,  2.28it/s]\u001b[A\n","Iteration:  70% 1300/1851 [09:36<04:01,  2.28it/s]\u001b[A\n","Iteration:  70% 1301/1851 [09:36<04:01,  2.28it/s]\u001b[A\n","Iteration:  70% 1302/1851 [09:36<04:00,  2.28it/s]\u001b[A\n","Iteration:  70% 1303/1851 [09:37<04:00,  2.28it/s]\u001b[A\n","Iteration:  70% 1304/1851 [09:37<04:00,  2.28it/s]\u001b[A\n","Iteration:  71% 1305/1851 [09:38<03:59,  2.28it/s]\u001b[A\n","Iteration:  71% 1306/1851 [09:38<03:59,  2.28it/s]\u001b[A\n","Iteration:  71% 1307/1851 [09:39<03:58,  2.28it/s]\u001b[A\n","Iteration:  71% 1308/1851 [09:39<03:58,  2.28it/s]\u001b[A\n","Iteration:  71% 1309/1851 [09:40<03:58,  2.28it/s]\u001b[A\n","Iteration:  71% 1310/1851 [09:40<03:57,  2.28it/s]\u001b[A\n","Iteration:  71% 1311/1851 [09:40<03:57,  2.28it/s]\u001b[A\n","Iteration:  71% 1312/1851 [09:41<03:56,  2.28it/s]\u001b[A\n","Iteration:  71% 1313/1851 [09:41<03:56,  2.28it/s]\u001b[A\n","Iteration:  71% 1314/1851 [09:42<03:55,  2.28it/s]\u001b[A\n","Iteration:  71% 1315/1851 [09:42<03:55,  2.28it/s]\u001b[A\n","Iteration:  71% 1316/1851 [09:43<03:54,  2.28it/s]\u001b[A\n","Iteration:  71% 1317/1851 [09:43<03:54,  2.28it/s]\u001b[A\n","Iteration:  71% 1318/1851 [09:44<03:53,  2.28it/s]\u001b[A\n","Iteration:  71% 1319/1851 [09:44<03:53,  2.28it/s]\u001b[A\n","Iteration:  71% 1320/1851 [09:44<03:52,  2.28it/s]\u001b[A\n","Iteration:  71% 1321/1851 [09:45<03:52,  2.28it/s]\u001b[A\n","Iteration:  71% 1322/1851 [09:45<03:52,  2.28it/s]\u001b[A\n","Iteration:  71% 1323/1851 [09:46<03:51,  2.28it/s]\u001b[A\n","Iteration:  72% 1324/1851 [09:46<03:51,  2.28it/s]\u001b[A\n","Iteration:  72% 1325/1851 [09:47<03:51,  2.28it/s]\u001b[A\n","Iteration:  72% 1326/1851 [09:47<03:50,  2.28it/s]\u001b[A\n","Iteration:  72% 1327/1851 [09:47<03:50,  2.28it/s]\u001b[A\n","Iteration:  72% 1328/1851 [09:48<03:49,  2.28it/s]\u001b[A\n","Iteration:  72% 1329/1851 [09:48<03:49,  2.28it/s]\u001b[A\n","Iteration:  72% 1330/1851 [09:49<03:49,  2.27it/s]\u001b[A\n","Iteration:  72% 1331/1851 [09:49<03:48,  2.27it/s]\u001b[A\n","Iteration:  72% 1332/1851 [09:50<03:48,  2.28it/s]\u001b[A\n","Iteration:  72% 1333/1851 [09:50<03:47,  2.28it/s]\u001b[A\n","Iteration:  72% 1334/1851 [09:51<03:47,  2.28it/s]\u001b[A\n","Iteration:  72% 1335/1851 [09:51<03:46,  2.27it/s]\u001b[A\n","Iteration:  72% 1336/1851 [09:51<03:46,  2.28it/s]\u001b[A\n","Iteration:  72% 1337/1851 [09:52<03:45,  2.28it/s]\u001b[A\n","Iteration:  72% 1338/1851 [09:52<03:45,  2.28it/s]\u001b[A\n","Iteration:  72% 1339/1851 [09:53<03:44,  2.28it/s]\u001b[A\n","Iteration:  72% 1340/1851 [09:53<03:44,  2.28it/s]\u001b[A\n","Iteration:  72% 1341/1851 [09:54<03:44,  2.28it/s]\u001b[A\n","Iteration:  73% 1342/1851 [09:54<03:43,  2.28it/s]\u001b[A\n","Iteration:  73% 1343/1851 [09:55<03:43,  2.28it/s]\u001b[A\n","Iteration:  73% 1344/1851 [09:55<03:42,  2.28it/s]\u001b[A\n","Iteration:  73% 1345/1851 [09:55<03:42,  2.28it/s]\u001b[A\n","Iteration:  73% 1346/1851 [09:56<03:41,  2.28it/s]\u001b[A\n","Iteration:  73% 1347/1851 [09:56<03:41,  2.28it/s]\u001b[A\n","Iteration:  73% 1348/1851 [09:57<03:40,  2.28it/s]\u001b[A\n","Iteration:  73% 1349/1851 [09:57<03:40,  2.28it/s]\u001b[A\n","Iteration:  73% 1350/1851 [09:58<03:40,  2.28it/s]\u001b[A\n","Iteration:  73% 1351/1851 [09:58<03:39,  2.28it/s]\u001b[A\n","Iteration:  73% 1352/1851 [09:58<03:39,  2.28it/s]\u001b[A\n","Iteration:  73% 1353/1851 [09:59<03:38,  2.28it/s]\u001b[A\n","Iteration:  73% 1354/1851 [09:59<03:38,  2.28it/s]\u001b[A\n","Iteration:  73% 1355/1851 [10:00<03:37,  2.28it/s]\u001b[A\n","Iteration:  73% 1356/1851 [10:00<03:37,  2.28it/s]\u001b[A\n","Iteration:  73% 1357/1851 [10:01<03:36,  2.28it/s]\u001b[A\n","Iteration:  73% 1358/1851 [10:01<03:36,  2.28it/s]\u001b[A\n","Iteration:  73% 1359/1851 [10:02<03:35,  2.28it/s]\u001b[A\n","Iteration:  73% 1360/1851 [10:02<03:35,  2.28it/s]\u001b[A\n","Iteration:  74% 1361/1851 [10:02<03:35,  2.28it/s]\u001b[A\n","Iteration:  74% 1362/1851 [10:03<03:34,  2.28it/s]\u001b[A\n","Iteration:  74% 1363/1851 [10:03<03:34,  2.27it/s]\u001b[A\n","Iteration:  74% 1364/1851 [10:04<03:34,  2.27it/s]\u001b[A\n","Iteration:  74% 1365/1851 [10:04<03:33,  2.27it/s]\u001b[A\n","Iteration:  74% 1366/1851 [10:05<03:33,  2.28it/s]\u001b[A\n","Iteration:  74% 1367/1851 [10:05<03:32,  2.28it/s]\u001b[A\n","Iteration:  74% 1368/1851 [10:05<03:32,  2.28it/s]\u001b[A\n","Iteration:  74% 1369/1851 [10:06<03:31,  2.28it/s]\u001b[A\n","Iteration:  74% 1370/1851 [10:06<03:31,  2.28it/s]\u001b[A\n","Iteration:  74% 1371/1851 [10:07<03:31,  2.27it/s]\u001b[A\n","Iteration:  74% 1372/1851 [10:07<03:30,  2.27it/s]\u001b[A\n","Iteration:  74% 1373/1851 [10:08<03:30,  2.27it/s]\u001b[A\n","Iteration:  74% 1374/1851 [10:08<03:29,  2.28it/s]\u001b[A\n","Iteration:  74% 1375/1851 [10:09<03:29,  2.28it/s]\u001b[A\n","Iteration:  74% 1376/1851 [10:09<03:28,  2.28it/s]\u001b[A\n","Iteration:  74% 1377/1851 [10:09<03:28,  2.28it/s]\u001b[A\n","Iteration:  74% 1378/1851 [10:10<03:27,  2.28it/s]\u001b[A\n","Iteration:  75% 1379/1851 [10:10<03:27,  2.28it/s]\u001b[A\n","Iteration:  75% 1380/1851 [10:11<03:27,  2.27it/s]\u001b[A\n","Iteration:  75% 1381/1851 [10:11<03:26,  2.27it/s]\u001b[A\n","Iteration:  75% 1382/1851 [10:12<03:26,  2.28it/s]\u001b[A\n","Iteration:  75% 1383/1851 [10:12<03:25,  2.28it/s]\u001b[A\n","Iteration:  75% 1384/1851 [10:13<03:25,  2.27it/s]\u001b[A\n","Iteration:  75% 1385/1851 [10:13<03:24,  2.28it/s]\u001b[A\n","Iteration:  75% 1386/1851 [10:13<03:24,  2.27it/s]\u001b[A\n","Iteration:  75% 1387/1851 [10:14<03:23,  2.28it/s]\u001b[A\n","Iteration:  75% 1388/1851 [10:14<03:23,  2.27it/s]\u001b[A\n","Iteration:  75% 1389/1851 [10:15<03:23,  2.28it/s]\u001b[A\n","Iteration:  75% 1390/1851 [10:15<03:22,  2.28it/s]\u001b[A\n","Iteration:  75% 1391/1851 [10:16<03:21,  2.28it/s]\u001b[A\n","Iteration:  75% 1392/1851 [10:16<03:21,  2.28it/s]\u001b[A\n","Iteration:  75% 1393/1851 [10:16<03:21,  2.28it/s]\u001b[A\n","Iteration:  75% 1394/1851 [10:17<03:20,  2.28it/s]\u001b[A\n","Iteration:  75% 1395/1851 [10:17<03:20,  2.28it/s]\u001b[A\n","Iteration:  75% 1396/1851 [10:18<03:19,  2.28it/s]\u001b[A\n","Iteration:  75% 1397/1851 [10:18<03:19,  2.28it/s]\u001b[A\n","Iteration:  76% 1398/1851 [10:19<03:18,  2.28it/s]\u001b[A\n","Iteration:  76% 1399/1851 [10:19<03:18,  2.28it/s]\u001b[A\n","Iteration:  76% 1400/1851 [10:20<03:18,  2.28it/s]\u001b[A\n","Iteration:  76% 1401/1851 [10:20<03:17,  2.28it/s]\u001b[A\n","Iteration:  76% 1402/1851 [10:20<03:16,  2.28it/s]\u001b[A\n","Iteration:  76% 1403/1851 [10:21<03:16,  2.28it/s]\u001b[A\n","Iteration:  76% 1404/1851 [10:21<03:16,  2.28it/s]\u001b[A\n","Iteration:  76% 1405/1851 [10:22<03:15,  2.28it/s]\u001b[A\n","Iteration:  76% 1406/1851 [10:22<03:15,  2.28it/s]\u001b[A\n","Iteration:  76% 1407/1851 [10:23<03:14,  2.28it/s]\u001b[A\n","Iteration:  76% 1408/1851 [10:23<03:14,  2.28it/s]\u001b[A\n","Iteration:  76% 1409/1851 [10:24<03:15,  2.27it/s]\u001b[A\n","Iteration:  76% 1410/1851 [10:24<03:13,  2.28it/s]\u001b[A\n","Iteration:  76% 1411/1851 [10:24<03:13,  2.28it/s]\u001b[A\n","Iteration:  76% 1412/1851 [10:25<03:12,  2.27it/s]\u001b[A\n","Iteration:  76% 1413/1851 [10:25<03:12,  2.28it/s]\u001b[A\n","Iteration:  76% 1414/1851 [10:26<03:12,  2.27it/s]\u001b[A\n","Iteration:  76% 1415/1851 [10:26<03:11,  2.27it/s]\u001b[A\n","Iteration:  76% 1416/1851 [10:27<03:11,  2.28it/s]\u001b[A\n","Iteration:  77% 1417/1851 [10:27<03:10,  2.28it/s]\u001b[A\n","Iteration:  77% 1418/1851 [10:27<03:10,  2.28it/s]\u001b[A\n","Iteration:  77% 1419/1851 [10:28<03:09,  2.28it/s]\u001b[A\n","Iteration:  77% 1420/1851 [10:28<03:09,  2.28it/s]\u001b[A\n","Iteration:  77% 1421/1851 [10:29<03:08,  2.28it/s]\u001b[A\n","Iteration:  77% 1422/1851 [10:29<03:08,  2.28it/s]\u001b[A\n","Iteration:  77% 1423/1851 [10:30<03:07,  2.28it/s]\u001b[A\n","Iteration:  77% 1424/1851 [10:30<03:07,  2.28it/s]\u001b[A\n","Iteration:  77% 1425/1851 [10:31<03:06,  2.28it/s]\u001b[A\n","Iteration:  77% 1426/1851 [10:31<03:06,  2.28it/s]\u001b[A\n","Iteration:  77% 1427/1851 [10:31<03:06,  2.28it/s]\u001b[A\n","Iteration:  77% 1428/1851 [10:32<03:07,  2.25it/s]\u001b[A\n","Iteration:  77% 1429/1851 [10:32<03:06,  2.26it/s]\u001b[A\n","Iteration:  77% 1430/1851 [10:33<03:07,  2.24it/s]\u001b[A\n","Iteration:  77% 1431/1851 [10:33<03:38,  1.92it/s]\u001b[A\n","Iteration:  77% 1432/1851 [10:34<03:28,  2.01it/s]\u001b[A\n","Iteration:  77% 1433/1851 [10:34<03:21,  2.08it/s]\u001b[A\n","Iteration:  77% 1434/1851 [10:35<03:15,  2.13it/s]\u001b[A\n","Iteration:  78% 1435/1851 [10:35<03:11,  2.18it/s]\u001b[A\n","Iteration:  78% 1436/1851 [10:36<03:08,  2.21it/s]\u001b[A\n","Iteration:  78% 1437/1851 [10:36<03:05,  2.23it/s]\u001b[A\n","Iteration:  78% 1438/1851 [10:37<03:04,  2.24it/s]\u001b[A\n","Iteration:  78% 1439/1851 [10:37<03:03,  2.25it/s]\u001b[A\n","Iteration:  78% 1440/1851 [10:37<03:02,  2.25it/s]\u001b[A\n","Iteration:  78% 1441/1851 [10:38<03:01,  2.26it/s]\u001b[A\n","Iteration:  78% 1442/1851 [10:38<03:00,  2.26it/s]\u001b[A\n","Iteration:  78% 1443/1851 [10:39<02:59,  2.27it/s]\u001b[A\n","Iteration:  78% 1444/1851 [10:39<02:59,  2.27it/s]\u001b[A\n","Iteration:  78% 1445/1851 [10:40<02:58,  2.27it/s]\u001b[A\n","Iteration:  78% 1446/1851 [10:40<02:58,  2.27it/s]\u001b[A\n","Iteration:  78% 1447/1851 [10:40<02:57,  2.27it/s]\u001b[A\n","Iteration:  78% 1448/1851 [10:41<02:57,  2.27it/s]\u001b[A\n","Iteration:  78% 1449/1851 [10:41<02:56,  2.28it/s]\u001b[A\n","Iteration:  78% 1450/1851 [10:42<02:56,  2.28it/s]\u001b[A\n","Iteration:  78% 1451/1851 [10:42<02:55,  2.27it/s]\u001b[A\n","Iteration:  78% 1452/1851 [10:43<02:55,  2.28it/s]\u001b[A\n","Iteration:  78% 1453/1851 [10:43<02:54,  2.28it/s]\u001b[A\n","Iteration:  79% 1454/1851 [10:44<02:54,  2.28it/s]\u001b[A\n","Iteration:  79% 1455/1851 [10:44<02:53,  2.28it/s]\u001b[A\n","Iteration:  79% 1456/1851 [10:44<02:53,  2.28it/s]\u001b[A\n","Iteration:  79% 1457/1851 [10:45<02:52,  2.28it/s]\u001b[A\n","Iteration:  79% 1458/1851 [10:45<02:52,  2.28it/s]\u001b[A\n","Iteration:  79% 1459/1851 [10:46<02:52,  2.28it/s]\u001b[A\n","Iteration:  79% 1460/1851 [10:46<02:51,  2.28it/s]\u001b[A\n","Iteration:  79% 1461/1851 [10:47<02:51,  2.27it/s]\u001b[A\n","Iteration:  79% 1462/1851 [10:47<02:50,  2.28it/s]\u001b[A\n","Iteration:  79% 1463/1851 [10:48<02:50,  2.28it/s]\u001b[A\n","Iteration:  79% 1464/1851 [10:48<02:50,  2.27it/s]\u001b[A\n","Iteration:  79% 1465/1851 [10:48<02:50,  2.26it/s]\u001b[A\n","Iteration:  79% 1466/1851 [10:49<02:51,  2.24it/s]\u001b[A\n","Iteration:  79% 1467/1851 [10:49<03:00,  2.13it/s]\u001b[A\n","Iteration:  79% 1468/1851 [10:50<02:56,  2.17it/s]\u001b[A\n","Iteration:  79% 1469/1851 [10:50<02:54,  2.19it/s]\u001b[A\n","Iteration:  79% 1470/1851 [10:51<02:51,  2.22it/s]\u001b[A\n","Iteration:  79% 1471/1851 [10:51<02:50,  2.24it/s]\u001b[A\n","Iteration:  80% 1472/1851 [10:52<02:48,  2.25it/s]\u001b[A\n","Iteration:  80% 1473/1851 [10:52<02:47,  2.26it/s]\u001b[A\n","Iteration:  80% 1474/1851 [10:52<02:46,  2.26it/s]\u001b[A\n","Iteration:  80% 1475/1851 [10:53<02:45,  2.27it/s]\u001b[A\n","Iteration:  80% 1476/1851 [10:53<02:45,  2.27it/s]\u001b[A\n","Iteration:  80% 1477/1851 [10:54<02:44,  2.27it/s]\u001b[A\n","Iteration:  80% 1478/1851 [10:54<02:44,  2.27it/s]\u001b[A\n","Iteration:  80% 1479/1851 [10:55<02:43,  2.27it/s]\u001b[A\n","Iteration:  80% 1480/1851 [10:55<02:43,  2.27it/s]\u001b[A\n","Iteration:  80% 1481/1851 [10:56<02:42,  2.28it/s]\u001b[A\n","Iteration:  80% 1482/1851 [10:56<02:42,  2.28it/s]\u001b[A\n","Iteration:  80% 1483/1851 [10:56<02:41,  2.28it/s]\u001b[A\n","Iteration:  80% 1484/1851 [10:57<02:41,  2.27it/s]\u001b[A\n","Iteration:  80% 1485/1851 [10:57<02:41,  2.27it/s]\u001b[A\n","Iteration:  80% 1486/1851 [10:58<02:40,  2.27it/s]\u001b[A\n","Iteration:  80% 1487/1851 [10:58<02:40,  2.27it/s]\u001b[A\n","Iteration:  80% 1488/1851 [10:59<02:39,  2.27it/s]\u001b[A\n","Iteration:  80% 1489/1851 [10:59<02:39,  2.27it/s]\u001b[A\n","Iteration:  80% 1490/1851 [11:00<02:38,  2.27it/s]\u001b[A\n","Iteration:  81% 1491/1851 [11:00<02:38,  2.27it/s]\u001b[A\n","Iteration:  81% 1492/1851 [11:00<02:37,  2.27it/s]\u001b[A\n","Iteration:  81% 1493/1851 [11:01<02:37,  2.27it/s]\u001b[A\n","Iteration:  81% 1494/1851 [11:01<02:36,  2.28it/s]\u001b[A\n","Iteration:  81% 1495/1851 [11:02<02:36,  2.28it/s]\u001b[A\n","Iteration:  81% 1496/1851 [11:02<02:35,  2.28it/s]\u001b[A\n","Iteration:  81% 1497/1851 [11:03<02:35,  2.28it/s]\u001b[A\n","Iteration:  81% 1498/1851 [11:03<02:34,  2.28it/s]\u001b[A\n","Iteration:  81% 1499/1851 [11:03<02:34,  2.28it/s]\u001b[A\n","Iteration:  81% 1500/1851 [11:04<02:34,  2.28it/s]\u001b[A\n","Iteration:  81% 1501/1851 [11:04<02:33,  2.28it/s]\u001b[A\n","Iteration:  81% 1502/1851 [11:05<02:33,  2.28it/s]\u001b[A\n","Iteration:  81% 1503/1851 [11:05<02:32,  2.28it/s]\u001b[A\n","Iteration:  81% 1504/1851 [11:06<02:32,  2.28it/s]\u001b[A\n","Iteration:  81% 1505/1851 [11:06<02:31,  2.28it/s]\u001b[A\n","Iteration:  81% 1506/1851 [11:07<02:31,  2.28it/s]\u001b[A\n","Iteration:  81% 1507/1851 [11:07<02:30,  2.28it/s]\u001b[A\n","Iteration:  81% 1508/1851 [11:07<02:30,  2.28it/s]\u001b[A\n","Iteration:  82% 1509/1851 [11:08<02:30,  2.28it/s]\u001b[A\n","Iteration:  82% 1510/1851 [11:08<02:29,  2.28it/s]\u001b[A\n","Iteration:  82% 1511/1851 [11:09<02:29,  2.28it/s]\u001b[A\n","Iteration:  82% 1512/1851 [11:09<02:28,  2.28it/s]\u001b[A\n","Iteration:  82% 1513/1851 [11:10<02:28,  2.28it/s]\u001b[A\n","Iteration:  82% 1514/1851 [11:10<02:28,  2.28it/s]\u001b[A\n","Iteration:  82% 1515/1851 [11:10<02:27,  2.27it/s]\u001b[A\n","Iteration:  82% 1516/1851 [11:11<02:27,  2.28it/s]\u001b[A\n","Iteration:  82% 1517/1851 [11:11<02:26,  2.28it/s]\u001b[A\n","Iteration:  82% 1518/1851 [11:12<02:26,  2.28it/s]\u001b[A\n","Iteration:  82% 1519/1851 [11:12<02:25,  2.28it/s]\u001b[A\n","Iteration:  82% 1520/1851 [11:13<02:25,  2.28it/s]\u001b[A\n","Iteration:  82% 1521/1851 [11:13<02:24,  2.28it/s]\u001b[A\n","Iteration:  82% 1522/1851 [11:14<02:24,  2.28it/s]\u001b[A\n","Iteration:  82% 1523/1851 [11:14<02:24,  2.28it/s]\u001b[A\n","Iteration:  82% 1524/1851 [11:14<02:23,  2.28it/s]\u001b[A\n","Iteration:  82% 1525/1851 [11:15<02:23,  2.28it/s]\u001b[A\n","Iteration:  82% 1526/1851 [11:15<02:22,  2.28it/s]\u001b[A\n","Iteration:  82% 1527/1851 [11:16<02:22,  2.28it/s]\u001b[A\n","Iteration:  83% 1528/1851 [11:16<02:22,  2.27it/s]\u001b[A\n","Iteration:  83% 1529/1851 [11:17<02:22,  2.27it/s]\u001b[A\n","Iteration:  83% 1530/1851 [11:17<02:21,  2.26it/s]\u001b[A\n","Iteration:  83% 1531/1851 [11:18<02:21,  2.27it/s]\u001b[A\n","Iteration:  83% 1532/1851 [11:18<02:20,  2.27it/s]\u001b[A\n","Iteration:  83% 1533/1851 [11:18<02:20,  2.27it/s]\u001b[A\n","Iteration:  83% 1534/1851 [11:19<02:19,  2.27it/s]\u001b[A\n","Iteration:  83% 1535/1851 [11:19<02:18,  2.28it/s]\u001b[A\n","Iteration:  83% 1536/1851 [11:20<02:18,  2.28it/s]\u001b[A\n","Iteration:  83% 1537/1851 [11:20<02:17,  2.28it/s]\u001b[A\n","Iteration:  83% 1538/1851 [11:21<02:17,  2.28it/s]\u001b[A\n","Iteration:  83% 1539/1851 [11:21<02:16,  2.28it/s]\u001b[A\n","Iteration:  83% 1540/1851 [11:21<02:16,  2.28it/s]\u001b[A\n","Iteration:  83% 1541/1851 [11:22<02:16,  2.28it/s]\u001b[A\n","Iteration:  83% 1542/1851 [11:22<02:15,  2.28it/s]\u001b[A\n","Iteration:  83% 1543/1851 [11:23<02:15,  2.28it/s]\u001b[A\n","Iteration:  83% 1544/1851 [11:23<02:14,  2.28it/s]\u001b[A\n","Iteration:  83% 1545/1851 [11:24<02:14,  2.28it/s]\u001b[A\n","Iteration:  84% 1546/1851 [11:24<02:14,  2.27it/s]\u001b[A\n","Iteration:  84% 1547/1851 [11:25<02:14,  2.26it/s]\u001b[A\n","Iteration:  84% 1548/1851 [11:25<02:13,  2.27it/s]\u001b[A\n","Iteration:  84% 1549/1851 [11:25<02:13,  2.27it/s]\u001b[A\n","Iteration:  84% 1550/1851 [11:26<02:12,  2.27it/s]\u001b[A\n","Iteration:  84% 1551/1851 [11:26<02:11,  2.27it/s]\u001b[A\n","Iteration:  84% 1552/1851 [11:27<02:11,  2.27it/s]\u001b[A\n","Iteration:  84% 1553/1851 [11:27<02:11,  2.27it/s]\u001b[A\n","Iteration:  84% 1554/1851 [11:28<02:10,  2.27it/s]\u001b[A\n","Iteration:  84% 1555/1851 [11:28<02:10,  2.27it/s]\u001b[A\n","Iteration:  84% 1556/1851 [11:29<02:09,  2.28it/s]\u001b[A\n","Iteration:  84% 1557/1851 [11:29<02:09,  2.27it/s]\u001b[A\n","Iteration:  84% 1558/1851 [11:29<02:08,  2.28it/s]\u001b[A\n","Iteration:  84% 1559/1851 [11:30<02:08,  2.28it/s]\u001b[A\n","Iteration:  84% 1560/1851 [11:30<02:07,  2.28it/s]\u001b[A\n","Iteration:  84% 1561/1851 [11:31<02:07,  2.28it/s]\u001b[A\n","Iteration:  84% 1562/1851 [11:31<02:06,  2.28it/s]\u001b[A\n","Iteration:  84% 1563/1851 [11:32<02:06,  2.28it/s]\u001b[A\n","Iteration:  84% 1564/1851 [11:32<02:05,  2.28it/s]\u001b[A\n","Iteration:  85% 1565/1851 [11:32<02:05,  2.28it/s]\u001b[A\n","Iteration:  85% 1566/1851 [11:33<02:05,  2.28it/s]\u001b[A\n","Iteration:  85% 1567/1851 [11:33<02:04,  2.28it/s]\u001b[A\n","Iteration:  85% 1568/1851 [11:34<02:04,  2.28it/s]\u001b[A\n","Iteration:  85% 1569/1851 [11:34<02:03,  2.28it/s]\u001b[A\n","Iteration:  85% 1570/1851 [11:35<02:03,  2.28it/s]\u001b[A\n","Iteration:  85% 1571/1851 [11:35<02:02,  2.28it/s]\u001b[A\n","Iteration:  85% 1572/1851 [11:36<02:02,  2.28it/s]\u001b[A\n","Iteration:  85% 1573/1851 [11:36<02:02,  2.28it/s]\u001b[A\n","Iteration:  85% 1574/1851 [11:36<02:01,  2.28it/s]\u001b[A\n","Iteration:  85% 1575/1851 [11:37<02:01,  2.28it/s]\u001b[A\n","Iteration:  85% 1576/1851 [11:37<02:00,  2.28it/s]\u001b[A\n","Iteration:  85% 1577/1851 [11:38<02:00,  2.28it/s]\u001b[A\n","Iteration:  85% 1578/1851 [11:38<01:59,  2.28it/s]\u001b[A\n","Iteration:  85% 1579/1851 [11:39<01:59,  2.28it/s]\u001b[A\n","Iteration:  85% 1580/1851 [11:39<01:58,  2.28it/s]\u001b[A\n","Iteration:  85% 1581/1851 [11:39<01:58,  2.28it/s]\u001b[A\n","Iteration:  85% 1582/1851 [11:40<01:58,  2.27it/s]\u001b[A\n","Iteration:  86% 1583/1851 [11:40<01:57,  2.27it/s]\u001b[A\n","Iteration:  86% 1584/1851 [11:41<01:57,  2.28it/s]\u001b[A\n","Iteration:  86% 1585/1851 [11:41<01:56,  2.28it/s]\u001b[A\n","Iteration:  86% 1586/1851 [11:42<01:56,  2.28it/s]\u001b[A\n","Iteration:  86% 1587/1851 [11:42<01:55,  2.28it/s]\u001b[A\n","Iteration:  86% 1588/1851 [11:43<01:55,  2.28it/s]\u001b[A\n","Iteration:  86% 1589/1851 [11:43<01:54,  2.28it/s]\u001b[A\n","Iteration:  86% 1590/1851 [11:43<01:54,  2.28it/s]\u001b[A\n","Iteration:  86% 1591/1851 [11:44<01:54,  2.28it/s]\u001b[A\n","Iteration:  86% 1592/1851 [11:44<01:53,  2.28it/s]\u001b[A\n","Iteration:  86% 1593/1851 [11:45<01:53,  2.28it/s]\u001b[A\n","Iteration:  86% 1594/1851 [11:45<01:52,  2.28it/s]\u001b[A\n","Iteration:  86% 1595/1851 [11:46<01:52,  2.28it/s]\u001b[A\n","Iteration:  86% 1596/1851 [11:46<01:52,  2.27it/s]\u001b[A\n","Iteration:  86% 1597/1851 [11:47<01:51,  2.28it/s]\u001b[A\n","Iteration:  86% 1598/1851 [11:47<01:51,  2.28it/s]\u001b[A\n","Iteration:  86% 1599/1851 [11:47<01:50,  2.28it/s]\u001b[A\n","Iteration:  86% 1600/1851 [11:48<01:50,  2.28it/s]\u001b[A\n","Iteration:  86% 1601/1851 [11:48<01:49,  2.28it/s]\u001b[A\n","Iteration:  87% 1602/1851 [11:49<01:49,  2.28it/s]\u001b[A\n","Iteration:  87% 1603/1851 [11:49<01:48,  2.28it/s]\u001b[A\n","Iteration:  87% 1604/1851 [11:50<01:48,  2.28it/s]\u001b[A\n","Iteration:  87% 1605/1851 [11:50<01:48,  2.28it/s]\u001b[A\n","Iteration:  87% 1606/1851 [11:50<01:47,  2.28it/s]\u001b[A\n","Iteration:  87% 1607/1851 [11:51<01:47,  2.27it/s]\u001b[A\n","Iteration:  87% 1608/1851 [11:51<01:46,  2.28it/s]\u001b[A\n","Iteration:  87% 1609/1851 [11:52<01:46,  2.27it/s]\u001b[A\n","Iteration:  87% 1610/1851 [11:52<01:46,  2.27it/s]\u001b[A\n","Iteration:  87% 1611/1851 [11:53<01:45,  2.27it/s]\u001b[A\n","Iteration:  87% 1612/1851 [11:53<01:45,  2.27it/s]\u001b[A\n","Iteration:  87% 1613/1851 [11:54<01:44,  2.28it/s]\u001b[A\n","Iteration:  87% 1614/1851 [11:54<01:44,  2.28it/s]\u001b[A\n","Iteration:  87% 1615/1851 [11:54<01:43,  2.28it/s]\u001b[A\n","Iteration:  87% 1616/1851 [11:55<01:43,  2.28it/s]\u001b[A\n","Iteration:  87% 1617/1851 [11:55<01:42,  2.28it/s]\u001b[A\n","Iteration:  87% 1618/1851 [11:56<01:42,  2.28it/s]\u001b[A\n","Iteration:  87% 1619/1851 [11:56<01:41,  2.28it/s]\u001b[A\n","Iteration:  88% 1620/1851 [11:57<01:41,  2.28it/s]\u001b[A\n","Iteration:  88% 1621/1851 [11:57<01:40,  2.28it/s]\u001b[A\n","Iteration:  88% 1622/1851 [11:58<01:40,  2.28it/s]\u001b[A\n","Iteration:  88% 1623/1851 [11:58<01:40,  2.28it/s]\u001b[A\n","Iteration:  88% 1624/1851 [11:58<01:39,  2.28it/s]\u001b[A\n","Iteration:  88% 1625/1851 [11:59<01:39,  2.28it/s]\u001b[A\n","Iteration:  88% 1626/1851 [11:59<01:38,  2.28it/s]\u001b[A\n","Iteration:  88% 1627/1851 [12:00<01:38,  2.28it/s]\u001b[A\n","Iteration:  88% 1628/1851 [12:00<01:37,  2.28it/s]\u001b[A\n","Iteration:  88% 1629/1851 [12:01<01:37,  2.28it/s]\u001b[A\n","Iteration:  88% 1630/1851 [12:01<01:37,  2.28it/s]\u001b[A\n","Iteration:  88% 1631/1851 [12:01<01:36,  2.28it/s]\u001b[A\n","Iteration:  88% 1632/1851 [12:02<01:36,  2.27it/s]\u001b[A\n","Iteration:  88% 1633/1851 [12:02<01:35,  2.27it/s]\u001b[A\n","Iteration:  88% 1634/1851 [12:03<01:50,  1.97it/s]\u001b[A\n","Iteration:  88% 1635/1851 [12:03<01:45,  2.05it/s]\u001b[A\n","Iteration:  88% 1636/1851 [12:04<01:41,  2.11it/s]\u001b[A\n","Iteration:  88% 1637/1851 [12:04<01:39,  2.16it/s]\u001b[A\n","Iteration:  88% 1638/1851 [12:05<01:37,  2.19it/s]\u001b[A\n","Iteration:  89% 1639/1851 [12:05<01:35,  2.22it/s]\u001b[A\n","Iteration:  89% 1640/1851 [12:06<01:34,  2.23it/s]\u001b[A\n","Iteration:  89% 1641/1851 [12:06<01:33,  2.25it/s]\u001b[A\n","Iteration:  89% 1642/1851 [12:07<01:32,  2.26it/s]\u001b[A\n","Iteration:  89% 1643/1851 [12:07<01:31,  2.26it/s]\u001b[A\n","Iteration:  89% 1644/1851 [12:07<01:31,  2.27it/s]\u001b[A\n","Iteration:  89% 1645/1851 [12:08<01:30,  2.27it/s]\u001b[A\n","Iteration:  89% 1646/1851 [12:08<01:30,  2.27it/s]\u001b[A\n","Iteration:  89% 1647/1851 [12:09<01:29,  2.27it/s]\u001b[A\n","Iteration:  89% 1648/1851 [12:09<01:29,  2.27it/s]\u001b[A\n","Iteration:  89% 1649/1851 [12:10<01:28,  2.27it/s]\u001b[A\n","Iteration:  89% 1650/1851 [12:10<01:28,  2.27it/s]\u001b[A\n","Iteration:  89% 1651/1851 [12:10<01:27,  2.28it/s]\u001b[A\n","Iteration:  89% 1652/1851 [12:11<01:27,  2.28it/s]\u001b[A\n","Iteration:  89% 1653/1851 [12:11<01:26,  2.28it/s]\u001b[A\n","Iteration:  89% 1654/1851 [12:12<01:26,  2.28it/s]\u001b[A\n","Iteration:  89% 1655/1851 [12:12<01:26,  2.28it/s]\u001b[A\n","Iteration:  89% 1656/1851 [12:13<01:25,  2.28it/s]\u001b[A\n","Iteration:  90% 1657/1851 [12:13<01:25,  2.28it/s]\u001b[A\n","Iteration:  90% 1658/1851 [12:14<01:24,  2.28it/s]\u001b[A\n","Iteration:  90% 1659/1851 [12:14<01:24,  2.28it/s]\u001b[A\n","Iteration:  90% 1660/1851 [12:14<01:23,  2.28it/s]\u001b[A\n","Iteration:  90% 1661/1851 [12:15<01:23,  2.28it/s]\u001b[A\n","Iteration:  90% 1662/1851 [12:15<01:22,  2.28it/s]\u001b[A\n","Iteration:  90% 1663/1851 [12:16<01:22,  2.28it/s]\u001b[A\n","Iteration:  90% 1664/1851 [12:16<01:22,  2.28it/s]\u001b[A\n","Iteration:  90% 1665/1851 [12:17<01:21,  2.28it/s]\u001b[A\n","Iteration:  90% 1666/1851 [12:17<01:21,  2.28it/s]\u001b[A\n","Iteration:  90% 1667/1851 [12:17<01:20,  2.28it/s]\u001b[A\n","Iteration:  90% 1668/1851 [12:18<01:20,  2.28it/s]\u001b[A\n","Iteration:  90% 1669/1851 [12:18<01:19,  2.28it/s]\u001b[A\n","Iteration:  90% 1670/1851 [12:19<01:19,  2.28it/s]\u001b[A\n","Iteration:  90% 1671/1851 [12:19<01:19,  2.28it/s]\u001b[A\n","Iteration:  90% 1672/1851 [12:20<01:18,  2.28it/s]\u001b[A\n","Iteration:  90% 1673/1851 [12:20<01:18,  2.28it/s]\u001b[A\n","Iteration:  90% 1674/1851 [12:21<01:17,  2.28it/s]\u001b[A\n","Iteration:  90% 1675/1851 [12:21<01:17,  2.28it/s]\u001b[A\n","Iteration:  91% 1676/1851 [12:21<01:16,  2.28it/s]\u001b[A\n","Iteration:  91% 1677/1851 [12:22<01:17,  2.25it/s]\u001b[A\n","Iteration:  91% 1678/1851 [12:22<01:17,  2.23it/s]\u001b[A\n","Iteration:  91% 1679/1851 [12:23<01:16,  2.25it/s]\u001b[A\n","Iteration:  91% 1680/1851 [12:23<01:15,  2.25it/s]\u001b[A\n","Iteration:  91% 1681/1851 [12:24<01:15,  2.26it/s]\u001b[A\n","Iteration:  91% 1682/1851 [12:24<01:14,  2.26it/s]\u001b[A\n","Iteration:  91% 1683/1851 [12:25<01:14,  2.26it/s]\u001b[A\n","Iteration:  91% 1684/1851 [12:25<01:13,  2.27it/s]\u001b[A\n","Iteration:  91% 1685/1851 [12:25<01:13,  2.27it/s]\u001b[A\n","Iteration:  91% 1686/1851 [12:26<01:12,  2.27it/s]\u001b[A\n","Iteration:  91% 1687/1851 [12:26<01:12,  2.27it/s]\u001b[A\n","Iteration:  91% 1688/1851 [12:27<01:11,  2.27it/s]\u001b[A\n","Iteration:  91% 1689/1851 [12:27<01:11,  2.27it/s]\u001b[A\n","Iteration:  91% 1690/1851 [12:28<01:10,  2.27it/s]\u001b[A\n","Iteration:  91% 1691/1851 [12:28<01:10,  2.27it/s]\u001b[A\n","Iteration:  91% 1692/1851 [12:29<01:09,  2.28it/s]\u001b[A\n","Iteration:  91% 1693/1851 [12:29<01:09,  2.28it/s]\u001b[A\n","Iteration:  92% 1694/1851 [12:29<01:08,  2.28it/s]\u001b[A\n","Iteration:  92% 1695/1851 [12:30<01:08,  2.28it/s]\u001b[A\n","Iteration:  92% 1696/1851 [12:30<01:08,  2.27it/s]\u001b[A\n","Iteration:  92% 1697/1851 [12:31<01:07,  2.28it/s]\u001b[A\n","Iteration:  92% 1698/1851 [12:31<01:07,  2.28it/s]\u001b[A\n","Iteration:  92% 1699/1851 [12:32<01:06,  2.28it/s]\u001b[A\n","Iteration:  92% 1700/1851 [12:32<01:06,  2.28it/s]\u001b[A\n","Iteration:  92% 1701/1851 [12:32<01:05,  2.28it/s]\u001b[A\n","Iteration:  92% 1702/1851 [12:33<01:05,  2.28it/s]\u001b[A\n","Iteration:  92% 1703/1851 [12:33<01:04,  2.28it/s]\u001b[A\n","Iteration:  92% 1704/1851 [12:34<01:04,  2.28it/s]\u001b[A\n","Iteration:  92% 1705/1851 [12:34<01:04,  2.28it/s]\u001b[A\n","Iteration:  92% 1706/1851 [12:35<01:03,  2.28it/s]\u001b[A\n","Iteration:  92% 1707/1851 [12:35<01:03,  2.28it/s]\u001b[A\n","Iteration:  92% 1708/1851 [12:36<01:02,  2.28it/s]\u001b[A\n","Iteration:  92% 1709/1851 [12:36<01:02,  2.28it/s]\u001b[A\n","Iteration:  92% 1710/1851 [12:36<01:01,  2.28it/s]\u001b[A\n","Iteration:  92% 1711/1851 [12:37<01:01,  2.27it/s]\u001b[A\n","Iteration:  92% 1712/1851 [12:37<01:01,  2.27it/s]\u001b[A\n","Iteration:  93% 1713/1851 [12:38<01:00,  2.28it/s]\u001b[A\n","Iteration:  93% 1714/1851 [12:38<01:00,  2.28it/s]\u001b[A\n","Iteration:  93% 1715/1851 [12:39<00:59,  2.28it/s]\u001b[A\n","Iteration:  93% 1716/1851 [12:39<00:59,  2.28it/s]\u001b[A\n","Iteration:  93% 1717/1851 [12:40<00:58,  2.28it/s]\u001b[A\n","Iteration:  93% 1718/1851 [12:40<00:58,  2.28it/s]\u001b[A\n","Iteration:  93% 1719/1851 [12:40<00:57,  2.28it/s]\u001b[A\n","Iteration:  93% 1720/1851 [12:41<00:57,  2.28it/s]\u001b[A\n","Iteration:  93% 1721/1851 [12:41<00:57,  2.28it/s]\u001b[A\n","Iteration:  93% 1722/1851 [12:42<00:56,  2.27it/s]\u001b[A\n","Iteration:  93% 1723/1851 [12:42<00:56,  2.28it/s]\u001b[A\n","Iteration:  93% 1724/1851 [12:43<00:55,  2.28it/s]\u001b[A\n","Iteration:  93% 1725/1851 [12:43<00:55,  2.28it/s]\u001b[A\n","Iteration:  93% 1726/1851 [12:43<00:54,  2.28it/s]\u001b[A\n","Iteration:  93% 1727/1851 [12:44<00:54,  2.26it/s]\u001b[A\n","Iteration:  93% 1728/1851 [12:44<00:54,  2.27it/s]\u001b[A\n","Iteration:  93% 1729/1851 [12:45<00:53,  2.27it/s]\u001b[A\n","Iteration:  93% 1730/1851 [12:45<00:53,  2.27it/s]\u001b[A\n","Iteration:  94% 1731/1851 [12:46<00:52,  2.27it/s]\u001b[A\n","Iteration:  94% 1732/1851 [12:46<00:52,  2.27it/s]\u001b[A\n","Iteration:  94% 1733/1851 [12:47<00:51,  2.28it/s]\u001b[A\n","Iteration:  94% 1734/1851 [12:47<00:51,  2.28it/s]\u001b[A\n","Iteration:  94% 1735/1851 [12:47<00:50,  2.28it/s]\u001b[A\n","Iteration:  94% 1736/1851 [12:48<00:50,  2.28it/s]\u001b[A\n","Iteration:  94% 1737/1851 [12:48<00:50,  2.28it/s]\u001b[A\n","Iteration:  94% 1738/1851 [12:49<00:49,  2.28it/s]\u001b[A\n","Iteration:  94% 1739/1851 [12:49<00:49,  2.28it/s]\u001b[A\n","Iteration:  94% 1740/1851 [12:50<00:48,  2.28it/s]\u001b[A\n","Iteration:  94% 1741/1851 [12:50<00:48,  2.27it/s]\u001b[A\n","Iteration:  94% 1742/1851 [12:50<00:48,  2.27it/s]\u001b[A\n","Iteration:  94% 1743/1851 [12:51<00:47,  2.27it/s]\u001b[A\n","Iteration:  94% 1744/1851 [12:52<00:54,  1.98it/s]\u001b[A\n","Iteration:  94% 1745/1851 [12:52<00:51,  2.06it/s]\u001b[A\n","Iteration:  94% 1746/1851 [12:52<00:49,  2.12it/s]\u001b[A\n","Iteration:  94% 1747/1851 [12:53<00:48,  2.16it/s]\u001b[A\n","Iteration:  94% 1748/1851 [12:53<00:46,  2.20it/s]\u001b[A\n","Iteration:  94% 1749/1851 [12:54<00:45,  2.22it/s]\u001b[A\n","Iteration:  95% 1750/1851 [12:54<00:45,  2.24it/s]\u001b[A\n","Iteration:  95% 1751/1851 [12:55<00:44,  2.25it/s]\u001b[A\n","Iteration:  95% 1752/1851 [12:55<00:43,  2.26it/s]\u001b[A\n","Iteration:  95% 1753/1851 [12:56<00:43,  2.26it/s]\u001b[A\n","Iteration:  95% 1754/1851 [12:56<00:42,  2.27it/s]\u001b[A\n","Iteration:  95% 1755/1851 [12:56<00:42,  2.27it/s]\u001b[A\n","Iteration:  95% 1756/1851 [12:57<00:41,  2.27it/s]\u001b[A\n","Iteration:  95% 1757/1851 [12:57<00:41,  2.27it/s]\u001b[A\n","Iteration:  95% 1758/1851 [12:58<00:40,  2.27it/s]\u001b[A\n","Iteration:  95% 1759/1851 [12:58<00:40,  2.27it/s]\u001b[A\n","Iteration:  95% 1760/1851 [12:59<00:39,  2.28it/s]\u001b[A\n","Iteration:  95% 1761/1851 [12:59<00:39,  2.28it/s]\u001b[A\n","Iteration:  95% 1762/1851 [13:00<00:39,  2.28it/s]\u001b[A\n","Iteration:  95% 1763/1851 [13:00<00:38,  2.28it/s]\u001b[A\n","Iteration:  95% 1764/1851 [13:00<00:38,  2.28it/s]\u001b[A\n","Iteration:  95% 1765/1851 [13:01<00:37,  2.28it/s]\u001b[A\n","Iteration:  95% 1766/1851 [13:01<00:37,  2.28it/s]\u001b[A\n","Iteration:  95% 1767/1851 [13:02<00:36,  2.28it/s]\u001b[A\n","Iteration:  96% 1768/1851 [13:02<00:36,  2.27it/s]\u001b[A\n","Iteration:  96% 1769/1851 [13:03<00:36,  2.28it/s]\u001b[A\n","Iteration:  96% 1770/1851 [13:03<00:35,  2.28it/s]\u001b[A\n","Iteration:  96% 1771/1851 [13:03<00:35,  2.28it/s]\u001b[A\n","Iteration:  96% 1772/1851 [13:04<00:34,  2.28it/s]\u001b[A\n","Iteration:  96% 1773/1851 [13:04<00:34,  2.28it/s]\u001b[A\n","Iteration:  96% 1774/1851 [13:05<00:33,  2.28it/s]\u001b[A\n","Iteration:  96% 1775/1851 [13:05<00:33,  2.28it/s]\u001b[A\n","Iteration:  96% 1776/1851 [13:06<00:33,  2.27it/s]\u001b[A\n","Iteration:  96% 1777/1851 [13:06<00:32,  2.26it/s]\u001b[A\n","Iteration:  96% 1778/1851 [13:07<00:45,  1.61it/s]\u001b[A\n","Iteration:  96% 1779/1851 [13:08<00:40,  1.76it/s]\u001b[A\n","Iteration:  96% 1780/1851 [13:08<00:37,  1.89it/s]\u001b[A\n","Iteration:  96% 1781/1851 [13:08<00:35,  1.99it/s]\u001b[A\n","Iteration:  96% 1782/1851 [13:09<00:33,  2.07it/s]\u001b[A\n","Iteration:  96% 1783/1851 [13:09<00:31,  2.13it/s]\u001b[A\n","Iteration:  96% 1784/1851 [13:10<00:30,  2.17it/s]\u001b[A\n","Iteration:  96% 1785/1851 [13:10<00:29,  2.20it/s]\u001b[A\n","Iteration:  96% 1786/1851 [13:11<00:29,  2.22it/s]\u001b[A\n","Iteration:  97% 1787/1851 [13:11<00:28,  2.24it/s]\u001b[A\n","Iteration:  97% 1788/1851 [13:12<00:27,  2.25it/s]\u001b[A\n","Iteration:  97% 1789/1851 [13:12<00:27,  2.25it/s]\u001b[A\n","Iteration:  97% 1790/1851 [13:12<00:26,  2.26it/s]\u001b[A\n","Iteration:  97% 1791/1851 [13:13<00:26,  2.27it/s]\u001b[A\n","Iteration:  97% 1792/1851 [13:13<00:25,  2.27it/s]\u001b[A\n","Iteration:  97% 1793/1851 [13:14<00:25,  2.27it/s]\u001b[A\n","Iteration:  97% 1794/1851 [13:14<00:25,  2.27it/s]\u001b[A\n","Iteration:  97% 1795/1851 [13:15<00:24,  2.28it/s]\u001b[A\n","Iteration:  97% 1796/1851 [13:15<00:24,  2.28it/s]\u001b[A\n","Iteration:  97% 1797/1851 [13:15<00:23,  2.28it/s]\u001b[A\n","Iteration:  97% 1798/1851 [13:16<00:23,  2.28it/s]\u001b[A\n","Iteration:  97% 1799/1851 [13:16<00:22,  2.28it/s]\u001b[A\n","Iteration:  97% 1800/1851 [13:17<00:22,  2.28it/s]\u001b[A\n","Iteration:  97% 1801/1851 [13:17<00:21,  2.28it/s]\u001b[A\n","Iteration:  97% 1802/1851 [13:18<00:21,  2.28it/s]\u001b[A\n","Iteration:  97% 1803/1851 [13:18<00:21,  2.28it/s]\u001b[A\n","Iteration:  97% 1804/1851 [13:19<00:20,  2.28it/s]\u001b[A\n","Iteration:  98% 1805/1851 [13:19<00:20,  2.28it/s]\u001b[A\n","Iteration:  98% 1806/1851 [13:19<00:19,  2.28it/s]\u001b[A\n","Iteration:  98% 1807/1851 [13:20<00:19,  2.28it/s]\u001b[A\n","Iteration:  98% 1808/1851 [13:20<00:18,  2.28it/s]\u001b[A\n","Iteration:  98% 1809/1851 [13:21<00:18,  2.28it/s]\u001b[A\n","Iteration:  98% 1810/1851 [13:21<00:17,  2.28it/s]\u001b[A\n","Iteration:  98% 1811/1851 [13:22<00:17,  2.28it/s]\u001b[A\n","Iteration:  98% 1812/1851 [13:22<00:17,  2.28it/s]\u001b[A\n","Iteration:  98% 1813/1851 [13:23<00:16,  2.28it/s]\u001b[A\n","Iteration:  98% 1814/1851 [13:23<00:16,  2.28it/s]\u001b[A\n","Iteration:  98% 1815/1851 [13:23<00:15,  2.28it/s]\u001b[A\n","Iteration:  98% 1816/1851 [13:24<00:15,  2.28it/s]\u001b[A\n","Iteration:  98% 1817/1851 [13:24<00:14,  2.28it/s]\u001b[A\n","Iteration:  98% 1818/1851 [13:25<00:14,  2.28it/s]\u001b[A\n","Iteration:  98% 1819/1851 [13:25<00:14,  2.28it/s]\u001b[A\n","Iteration:  98% 1820/1851 [13:26<00:13,  2.28it/s]\u001b[A\n","Iteration:  98% 1821/1851 [13:26<00:13,  2.28it/s]\u001b[A\n","Iteration:  98% 1822/1851 [13:26<00:12,  2.28it/s]\u001b[A\n","Iteration:  98% 1823/1851 [13:27<00:12,  2.28it/s]\u001b[A\n","Iteration:  99% 1824/1851 [13:27<00:11,  2.28it/s]\u001b[A\n","Iteration:  99% 1825/1851 [13:28<00:11,  2.28it/s]\u001b[A\n","Iteration:  99% 1826/1851 [13:28<00:10,  2.28it/s]\u001b[A\n","Iteration:  99% 1827/1851 [13:29<00:10,  2.28it/s]\u001b[A\n","Iteration:  99% 1828/1851 [13:29<00:10,  2.28it/s]\u001b[A\n","Iteration:  99% 1829/1851 [13:30<00:09,  2.28it/s]\u001b[A\n","Iteration:  99% 1830/1851 [13:30<00:09,  2.28it/s]\u001b[A\n","Iteration:  99% 1831/1851 [13:30<00:08,  2.28it/s]\u001b[A\n","Iteration:  99% 1832/1851 [13:31<00:08,  2.28it/s]\u001b[A\n","Iteration:  99% 1833/1851 [13:31<00:07,  2.28it/s]\u001b[A\n","Iteration:  99% 1834/1851 [13:32<00:07,  2.28it/s]\u001b[A\n","Iteration:  99% 1835/1851 [13:32<00:07,  2.28it/s]\u001b[A\n","Iteration:  99% 1836/1851 [13:33<00:06,  2.28it/s]\u001b[A\n","Iteration:  99% 1837/1851 [13:33<00:06,  2.28it/s]\u001b[A\n","Iteration:  99% 1838/1851 [13:33<00:05,  2.28it/s]\u001b[A\n","Iteration:  99% 1839/1851 [13:34<00:05,  2.28it/s]\u001b[A\n","Iteration:  99% 1840/1851 [13:34<00:04,  2.28it/s]\u001b[A\n","Iteration:  99% 1841/1851 [13:35<00:04,  2.28it/s]\u001b[A\n","Iteration: 100% 1842/1851 [13:35<00:03,  2.28it/s]\u001b[A\n","Iteration: 100% 1843/1851 [13:36<00:03,  2.28it/s]\u001b[A\n","Iteration: 100% 1844/1851 [13:36<00:03,  2.28it/s]\u001b[A\n","Iteration: 100% 1845/1851 [13:37<00:02,  2.28it/s]\u001b[A\n","Iteration: 100% 1846/1851 [13:37<00:02,  2.28it/s]\u001b[A\n","Iteration: 100% 1847/1851 [13:37<00:01,  2.28it/s]\u001b[A\n","Iteration: 100% 1848/1851 [13:38<00:01,  2.28it/s]\u001b[A\n","Iteration: 100% 1849/1851 [13:38<00:00,  2.28it/s]\u001b[A\n","Iteration: 100% 1850/1851 [13:39<00:00,  2.28it/s]\u001b[A\n","Iteration: 100% 1851/1851 [13:39<00:00,  2.26it/s]\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","[2022-08-15 00:09:04,951][__main__][DEBUG] - early stop\n","Epoch:   1% 1/100 [33:42<55:37:56, 2022.99s/it]\n"]}],"source":["!HYDRA_FULL_ERROR=1 python run.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"w7sdHHb0uFV-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660525197552,"user_tz":-540,"elapsed":2913407,"user":{"displayName":"Kosuke Aigo","userId":"01303562836135023230"}},"outputId":"0b95e135-416c-4427-d73e-1da3fe3f872c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using backend: pytorch\n","eval.py:21: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"config\", config_name='config')\n","/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","[2022-08-15 00:09:13,244][HYDRA] Hydra 1.2.0\n","[2022-08-15 00:09:13,244][HYDRA] ===========\n","[2022-08-15 00:09:13,244][HYDRA] Installed Hydra Plugins\n","[2022-08-15 00:09:13,244][HYDRA] ***********************\n","[2022-08-15 00:09:13,244][HYDRA] \tConfigSource:\n","[2022-08-15 00:09:13,244][HYDRA] \t-------------\n","[2022-08-15 00:09:13,244][HYDRA] \t\tFileConfigSource\n","[2022-08-15 00:09:13,244][HYDRA] \t\tImportlibResourcesConfigSource\n","[2022-08-15 00:09:13,244][HYDRA] \t\tStructuredConfigSource\n","[2022-08-15 00:09:13,244][HYDRA] \tCompletionPlugin:\n","[2022-08-15 00:09:13,244][HYDRA] \t-----------------\n","[2022-08-15 00:09:13,244][HYDRA] \t\tBashCompletion\n","[2022-08-15 00:09:13,244][HYDRA] \t\tFishCompletion\n","[2022-08-15 00:09:13,244][HYDRA] \t\tZshCompletion\n","[2022-08-15 00:09:13,244][HYDRA] \tLauncher:\n","[2022-08-15 00:09:13,244][HYDRA] \t---------\n","[2022-08-15 00:09:13,244][HYDRA] \t\tBasicLauncher\n","[2022-08-15 00:09:13,244][HYDRA] \tSweeper:\n","[2022-08-15 00:09:13,244][HYDRA] \t--------\n","[2022-08-15 00:09:13,244][HYDRA] \t\tBasicSweeper\n","[2022-08-15 00:09:13,244][HYDRA] \n","[2022-08-15 00:09:13,244][HYDRA] Config search path\n","[2022-08-15 00:09:13,244][HYDRA] ******************\n","[2022-08-15 00:09:13,519][HYDRA] | Provider | Search path                                                           |\n","[2022-08-15 00:09:13,519][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-15 00:09:13,519][HYDRA] | hydra    | pkg://hydra.conf                                                      |\n","[2022-08-15 00:09:13,519][HYDRA] | main     | file:///content/drive/MyDrive/ColabNotebooks/Research/GBTI-Exp/config |\n","[2022-08-15 00:09:13,519][HYDRA] | schema   | structured://                                                         |\n","[2022-08-15 00:09:13,519][HYDRA] ------------------------------------------------------------------------------------\n","[2022-08-15 00:09:13,589][HYDRA] \n","[2022-08-15 00:09:13,589][HYDRA] Defaults Tree\n","[2022-08-15 00:09:13,589][HYDRA] *************\n","[2022-08-15 00:09:13,589][HYDRA] <root>:\n","[2022-08-15 00:09:13,589][HYDRA]   hydra/config:\n","[2022-08-15 00:09:13,589][HYDRA]     hydra/output: default\n","[2022-08-15 00:09:13,589][HYDRA]     hydra/launcher: basic\n","[2022-08-15 00:09:13,589][HYDRA]     hydra/sweeper: basic\n","[2022-08-15 00:09:13,590][HYDRA]     hydra/help: default\n","[2022-08-15 00:09:13,590][HYDRA]     hydra/hydra_help: default\n","[2022-08-15 00:09:13,590][HYDRA]     hydra/hydra_logging: default\n","[2022-08-15 00:09:13,590][HYDRA]     hydra/job_logging: default\n","[2022-08-15 00:09:13,590][HYDRA]     hydra/callbacks: null\n","[2022-08-15 00:09:13,590][HYDRA]     hydra/env: default\n","[2022-08-15 00:09:13,590][HYDRA]     _self_\n","[2022-08-15 00:09:13,590][HYDRA]   config:\n","[2022-08-15 00:09:13,590][HYDRA]     data/FB15kET\n","[2022-08-15 00:09:13,590][HYDRA]     model/T5\n","[2022-08-15 00:09:13,590][HYDRA]     _self_\n","[2022-08-15 00:09:13,655][HYDRA] \n","[2022-08-15 00:09:13,655][HYDRA] Defaults List\n","[2022-08-15 00:09:13,655][HYDRA] *************\n","[2022-08-15 00:09:13,655][HYDRA] | Config path                 | Package             | _self_ | Parent       | \n","[2022-08-15 00:09:13,655][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-15 00:09:13,655][HYDRA] | hydra/output/default        | hydra               | False  | hydra/config |\n","[2022-08-15 00:09:13,655][HYDRA] | hydra/launcher/basic        | hydra.launcher      | False  | hydra/config |\n","[2022-08-15 00:09:13,655][HYDRA] | hydra/sweeper/basic         | hydra.sweeper       | False  | hydra/config |\n","[2022-08-15 00:09:13,655][HYDRA] | hydra/help/default          | hydra.help          | False  | hydra/config |\n","[2022-08-15 00:09:13,655][HYDRA] | hydra/hydra_help/default    | hydra.hydra_help    | False  | hydra/config |\n","[2022-08-15 00:09:13,655][HYDRA] | hydra/hydra_logging/default | hydra.hydra_logging | False  | hydra/config |\n","[2022-08-15 00:09:13,656][HYDRA] | hydra/job_logging/default   | hydra.job_logging   | False  | hydra/config |\n","[2022-08-15 00:09:13,656][HYDRA] | hydra/env/default           | hydra.env           | False  | hydra/config |\n","[2022-08-15 00:09:13,656][HYDRA] | hydra/config                | hydra               | True   | <root>       |\n","[2022-08-15 00:09:13,656][HYDRA] | data/FB15kET                | data                | False  | config       |\n","[2022-08-15 00:09:13,656][HYDRA] | model/T5                    | model               | False  | config       |\n","[2022-08-15 00:09:13,656][HYDRA] | config                      |                     | True   | <root>       |\n","[2022-08-15 00:09:13,656][HYDRA] ------------------------------------------------------------------------------\n","[2022-08-15 00:09:13,777][HYDRA] Config\n","[2022-08-15 00:09:13,777][HYDRA] ******\n","[2022-08-15 00:09:13,781][HYDRA] data:\n","  name: FB15kET\n","  data_dir: data\n","  overwrite: false\n","  is_unigraph: false\n","  change_mid_to_name: true\n","  lowest_level: true\n","  remove_under_score: true\n","model:\n","  cuda: true\n","  debug: false\n","  save_dir: save\n","  name: T5\n","  train_dataset: ET_train.txt\n","  pretrained_model: t5-base\n","  append_another_bos: false\n","  append_sep_token: false\n","  is_in_edge: true\n","  is_out_edge: true\n","  max_epoch: 100\n","  train_batch_size: 8\n","  valid_batch_size: 8\n","  test_batch_size: 8\n","  num_workers: 4\n","  temperature: 0.5\n","  repetition_penalty: 1.5\n","  n_gpus: 1\n","  max_input_length: 256\n","  max_output_length: 128\n","  gradient_accumulation_steps: 1\n","  max_grad_norm: 1.0\n","  early_stopping: true\n","  optimizer:\n","    algorithm: Adam\n","    learning_rate: 0.0001\n","  valid:\n","    valid_dataset: ET_valid.txt\n","    valid_epoch: 1\n","    num_beams: 5\n","    length_penalty: 1.0\n","    max_output_length: 128\n","    clean_up_spaces: true\n","    save_outputs: true\n","    save_one_batch: true\n","  test:\n","    test_dataset: ET_test.txt\n","    save_outputs: true\n","    get_from_file: false\n","    get_from_model: true\n","    file_path: Exp/Exp19/save/ET_1_1_test\n","preprocess:\n","  load_ET: false\n","  load_KG: true\n","  neighbor_sampling: true\n","  neighbor_num: 10\n","  num_layers: 1\n","\n","[2022-08-15 00:09:13,846][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-15 00:09:13,846 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-15 00:09:14,655][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 0\n","2022-08-15 00:09:14,655 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-spiece.model HTTP/1.1\" 200 0\n","[2022-08-15 00:09:14,657][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","2022-08-15 00:09:14,657 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","[2022-08-15 00:09:22,514][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-15 00:09:22,514 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-15 00:09:23,287][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 0\n","2022-08-15 00:09:23,287 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/t5-base-config.json HTTP/1.1\" 200 0\n","[2022-08-15 00:09:23,289][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","2022-08-15 00:09:23,289 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n","[2022-08-15 00:09:23,289][transformers.configuration_utils][INFO] - Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","2022-08-15 00:09:23,289 INFO     Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","[2022-08-15 00:09:23,291][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-15 00:09:23,291 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-15 00:09:23,375][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /t5-base-pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-15 00:09:23,375 DEBUG    https://cdn.huggingface.co:443 \"HEAD /t5-base-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-15 00:09:23,377][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","2022-08-15 00:09:23,377 INFO     loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n","[2022-08-15 00:09:28,950][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","2022-08-15 00:09:28,950 INFO     All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","[2022-08-15 00:09:28,950][transformers.modeling_utils][WARNING] - Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2022-08-15 00:09:28,950 WARNING  Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[2022-08-15 00:09:32,705][root][DEBUG] - Parameter model.shared.weight: torch.Size([32128, 768]), require_grad=True\n","2022-08-15 00:09:32,705 DEBUG    Parameter model.shared.weight: torch.Size([32128, 768]), require_grad=True\n","[2022-08-15 00:09:32,706][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,706 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,706][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,706 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,706][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,706 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,706][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,706 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,706][root][DEBUG] - Parameter model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","2022-08-15 00:09:32,706 DEBUG    Parameter model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-15 00:09:32,707][root][DEBUG] - Parameter model.encoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,707 DEBUG    Parameter model.encoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,707][root][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,707 DEBUG    Parameter model.encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,707][root][DEBUG] - Parameter model.encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,707 DEBUG    Parameter model.encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,707][root][DEBUG] - Parameter model.encoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,707 DEBUG    Parameter model.encoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,707][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,707 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,707][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,707 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,707][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,707 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,708][root][DEBUG] - Parameter model.encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,708 DEBUG    Parameter model.encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,708][root][DEBUG] - Parameter model.encoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,708 DEBUG    Parameter model.encoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,708][root][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,708 DEBUG    Parameter model.encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,708][root][DEBUG] - Parameter model.encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,708 DEBUG    Parameter model.encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,708][root][DEBUG] - Parameter model.encoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,708 DEBUG    Parameter model.encoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,708][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,708 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,708][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,708 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,709][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,709 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,709][root][DEBUG] - Parameter model.encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,709 DEBUG    Parameter model.encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,709][root][DEBUG] - Parameter model.encoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,709 DEBUG    Parameter model.encoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,709][root][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,709 DEBUG    Parameter model.encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,709][root][DEBUG] - Parameter model.encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,709 DEBUG    Parameter model.encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,709][root][DEBUG] - Parameter model.encoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,709 DEBUG    Parameter model.encoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,709][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,709 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,710][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,710 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,710][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,710 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,710][root][DEBUG] - Parameter model.encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,710 DEBUG    Parameter model.encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,710][root][DEBUG] - Parameter model.encoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,710 DEBUG    Parameter model.encoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,710][root][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,710 DEBUG    Parameter model.encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,710][root][DEBUG] - Parameter model.encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,710 DEBUG    Parameter model.encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,711][root][DEBUG] - Parameter model.encoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,711 DEBUG    Parameter model.encoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,711][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,711 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,711][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,711 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,711][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,711 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,711][root][DEBUG] - Parameter model.encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,711 DEBUG    Parameter model.encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,711][root][DEBUG] - Parameter model.encoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,711 DEBUG    Parameter model.encoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,711][root][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,711 DEBUG    Parameter model.encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,711][root][DEBUG] - Parameter model.encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,711 DEBUG    Parameter model.encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,712][root][DEBUG] - Parameter model.encoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,712 DEBUG    Parameter model.encoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,712][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,712 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,712][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,712 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,712][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,712 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,712][root][DEBUG] - Parameter model.encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,712 DEBUG    Parameter model.encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,712][root][DEBUG] - Parameter model.encoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,712 DEBUG    Parameter model.encoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,713][root][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,713 DEBUG    Parameter model.encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,713][root][DEBUG] - Parameter model.encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,713 DEBUG    Parameter model.encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,713][root][DEBUG] - Parameter model.encoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,713 DEBUG    Parameter model.encoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,713][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,713 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,713][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,713 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,713][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,713 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,713][root][DEBUG] - Parameter model.encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,713 DEBUG    Parameter model.encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,713][root][DEBUG] - Parameter model.encoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,713 DEBUG    Parameter model.encoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,714][root][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,714 DEBUG    Parameter model.encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,714][root][DEBUG] - Parameter model.encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,714 DEBUG    Parameter model.encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,714][root][DEBUG] - Parameter model.encoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,714 DEBUG    Parameter model.encoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,714][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,714 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,714][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,714 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,714][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,714 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,715][root][DEBUG] - Parameter model.encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,715 DEBUG    Parameter model.encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,753][root][DEBUG] - Parameter model.encoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,753 DEBUG    Parameter model.encoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,753][root][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,753 DEBUG    Parameter model.encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,753][root][DEBUG] - Parameter model.encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,753 DEBUG    Parameter model.encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,754][root][DEBUG] - Parameter model.encoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,754 DEBUG    Parameter model.encoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,754][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,754 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,754][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,754 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,754][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,754 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,755][root][DEBUG] - Parameter model.encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,755 DEBUG    Parameter model.encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,755][root][DEBUG] - Parameter model.encoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,755 DEBUG    Parameter model.encoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,755][root][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,755 DEBUG    Parameter model.encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,755][root][DEBUG] - Parameter model.encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,755 DEBUG    Parameter model.encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,755][root][DEBUG] - Parameter model.encoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,755 DEBUG    Parameter model.encoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,756][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,756 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,756][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,756 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,756][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,756 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,756][root][DEBUG] - Parameter model.encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,756 DEBUG    Parameter model.encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,756][root][DEBUG] - Parameter model.encoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,756 DEBUG    Parameter model.encoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,757][root][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,757 DEBUG    Parameter model.encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,757][root][DEBUG] - Parameter model.encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,757 DEBUG    Parameter model.encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,757][root][DEBUG] - Parameter model.encoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,757 DEBUG    Parameter model.encoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,757][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,757 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,757][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,757 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,758][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,758 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,758][root][DEBUG] - Parameter model.encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,758 DEBUG    Parameter model.encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,758][root][DEBUG] - Parameter model.encoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,758 DEBUG    Parameter model.encoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,758][root][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,758 DEBUG    Parameter model.encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,758][root][DEBUG] - Parameter model.encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,758 DEBUG    Parameter model.encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,759][root][DEBUG] - Parameter model.encoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,759 DEBUG    Parameter model.encoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,759][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,759 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,759][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,759 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,759][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,759 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,759][root][DEBUG] - Parameter model.encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,759 DEBUG    Parameter model.encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,760][root][DEBUG] - Parameter model.encoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,760 DEBUG    Parameter model.encoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,760][root][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,760 DEBUG    Parameter model.encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,760][root][DEBUG] - Parameter model.encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,760 DEBUG    Parameter model.encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,760][root][DEBUG] - Parameter model.encoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,760 DEBUG    Parameter model.encoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,760][root][DEBUG] - Parameter model.encoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,760 DEBUG    Parameter model.encoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,761][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,761 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,761][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,761 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,761][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,761 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,761][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,761 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,761][root][DEBUG] - Parameter model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","2022-08-15 00:09:32,761 DEBUG    Parameter model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-15 00:09:32,762][root][DEBUG] - Parameter model.decoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,762 DEBUG    Parameter model.decoder.block.0.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,762][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,762 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,762][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,762 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,762][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,762 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,762][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,762 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,763][root][DEBUG] - Parameter model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","2022-08-15 00:09:32,763 DEBUG    Parameter model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight: torch.Size([32, 12]), require_grad=True\n","[2022-08-15 00:09:32,763][root][DEBUG] - Parameter model.decoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,763 DEBUG    Parameter model.decoder.block.0.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,763][root][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,763 DEBUG    Parameter model.decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,763][root][DEBUG] - Parameter model.decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,763 DEBUG    Parameter model.decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,763][root][DEBUG] - Parameter model.decoder.block.0.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,763 DEBUG    Parameter model.decoder.block.0.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,763][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,763 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,764][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,764 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,764][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,764 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,764][root][DEBUG] - Parameter model.decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,764 DEBUG    Parameter model.decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,764][root][DEBUG] - Parameter model.decoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,764 DEBUG    Parameter model.decoder.block.1.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,764][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,764 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,765][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,765 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,765][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,765 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,765][root][DEBUG] - Parameter model.decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,765 DEBUG    Parameter model.decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,765][root][DEBUG] - Parameter model.decoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,765 DEBUG    Parameter model.decoder.block.1.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,765][root][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,765 DEBUG    Parameter model.decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,765][root][DEBUG] - Parameter model.decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,765 DEBUG    Parameter model.decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,766][root][DEBUG] - Parameter model.decoder.block.1.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,766 DEBUG    Parameter model.decoder.block.1.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,766][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,766 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,766][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,766 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,766][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,766 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,766][root][DEBUG] - Parameter model.decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,766 DEBUG    Parameter model.decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,767][root][DEBUG] - Parameter model.decoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,767 DEBUG    Parameter model.decoder.block.2.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,767][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,767 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,767][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,767 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,767][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,767 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,767][root][DEBUG] - Parameter model.decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,767 DEBUG    Parameter model.decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,768][root][DEBUG] - Parameter model.decoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,768 DEBUG    Parameter model.decoder.block.2.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,768][root][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,768 DEBUG    Parameter model.decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,768][root][DEBUG] - Parameter model.decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,768 DEBUG    Parameter model.decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,768][root][DEBUG] - Parameter model.decoder.block.2.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,768 DEBUG    Parameter model.decoder.block.2.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,768][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,768 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,768][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,768 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,769][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,769 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,769][root][DEBUG] - Parameter model.decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,769 DEBUG    Parameter model.decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,769][root][DEBUG] - Parameter model.decoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,769 DEBUG    Parameter model.decoder.block.3.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,769][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,769 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,769][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,769 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,770][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,770 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,770][root][DEBUG] - Parameter model.decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,770 DEBUG    Parameter model.decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,770][root][DEBUG] - Parameter model.decoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,770 DEBUG    Parameter model.decoder.block.3.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,770][root][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,770 DEBUG    Parameter model.decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,770][root][DEBUG] - Parameter model.decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,770 DEBUG    Parameter model.decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,770][root][DEBUG] - Parameter model.decoder.block.3.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,770 DEBUG    Parameter model.decoder.block.3.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,771][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,771 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,771][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,771 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,771][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,771 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,771][root][DEBUG] - Parameter model.decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,771 DEBUG    Parameter model.decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,771][root][DEBUG] - Parameter model.decoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,771 DEBUG    Parameter model.decoder.block.4.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,772][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,772 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,772][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,772 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,772][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,772 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,772][root][DEBUG] - Parameter model.decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,772 DEBUG    Parameter model.decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,772][root][DEBUG] - Parameter model.decoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,772 DEBUG    Parameter model.decoder.block.4.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,772][root][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,772 DEBUG    Parameter model.decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,773][root][DEBUG] - Parameter model.decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,773 DEBUG    Parameter model.decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,773][root][DEBUG] - Parameter model.decoder.block.4.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,773 DEBUG    Parameter model.decoder.block.4.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,773][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,773 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,773][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,773 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,773][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,773 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,774][root][DEBUG] - Parameter model.decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,774 DEBUG    Parameter model.decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,774][root][DEBUG] - Parameter model.decoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,774 DEBUG    Parameter model.decoder.block.5.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,774][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,774 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,774][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,774 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,774][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,774 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,774][root][DEBUG] - Parameter model.decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,774 DEBUG    Parameter model.decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,775][root][DEBUG] - Parameter model.decoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,775 DEBUG    Parameter model.decoder.block.5.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,775][root][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,775 DEBUG    Parameter model.decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,775][root][DEBUG] - Parameter model.decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,775 DEBUG    Parameter model.decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,775][root][DEBUG] - Parameter model.decoder.block.5.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,775 DEBUG    Parameter model.decoder.block.5.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,775][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,775 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,776][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,776 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,776][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,776 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,776][root][DEBUG] - Parameter model.decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,776 DEBUG    Parameter model.decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,776][root][DEBUG] - Parameter model.decoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,776 DEBUG    Parameter model.decoder.block.6.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,776][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,776 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,776][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,776 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,777][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,777 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,777][root][DEBUG] - Parameter model.decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,777 DEBUG    Parameter model.decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,777][root][DEBUG] - Parameter model.decoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,777 DEBUG    Parameter model.decoder.block.6.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,777][root][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,777 DEBUG    Parameter model.decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,777][root][DEBUG] - Parameter model.decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,777 DEBUG    Parameter model.decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,778][root][DEBUG] - Parameter model.decoder.block.6.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,778 DEBUG    Parameter model.decoder.block.6.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,778][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,778 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,778][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,778 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,778][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,778 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,778][root][DEBUG] - Parameter model.decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,778 DEBUG    Parameter model.decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,778][root][DEBUG] - Parameter model.decoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,778 DEBUG    Parameter model.decoder.block.7.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,779][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,779 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,779][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,779 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,779][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,779 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,779][root][DEBUG] - Parameter model.decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,779 DEBUG    Parameter model.decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,779][root][DEBUG] - Parameter model.decoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,779 DEBUG    Parameter model.decoder.block.7.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,780][root][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,780 DEBUG    Parameter model.decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,780][root][DEBUG] - Parameter model.decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,780 DEBUG    Parameter model.decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,780][root][DEBUG] - Parameter model.decoder.block.7.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,780 DEBUG    Parameter model.decoder.block.7.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,780][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,780 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,780][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,780 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,781][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,781 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,781][root][DEBUG] - Parameter model.decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,781 DEBUG    Parameter model.decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,781][root][DEBUG] - Parameter model.decoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,781 DEBUG    Parameter model.decoder.block.8.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,781][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,781 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,781][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,781 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,782][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,782 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,782][root][DEBUG] - Parameter model.decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,782 DEBUG    Parameter model.decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,782][root][DEBUG] - Parameter model.decoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,782 DEBUG    Parameter model.decoder.block.8.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,782][root][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,782 DEBUG    Parameter model.decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,782][root][DEBUG] - Parameter model.decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,782 DEBUG    Parameter model.decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,782][root][DEBUG] - Parameter model.decoder.block.8.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,782 DEBUG    Parameter model.decoder.block.8.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,783][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,783 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,783][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,783 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,783][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,783 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,783][root][DEBUG] - Parameter model.decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,783 DEBUG    Parameter model.decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,783][root][DEBUG] - Parameter model.decoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,783 DEBUG    Parameter model.decoder.block.9.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,784][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,784 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,784][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,784 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,784][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,784 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,784][root][DEBUG] - Parameter model.decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,784 DEBUG    Parameter model.decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,784][root][DEBUG] - Parameter model.decoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,784 DEBUG    Parameter model.decoder.block.9.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,784][root][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,784 DEBUG    Parameter model.decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,785][root][DEBUG] - Parameter model.decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,785 DEBUG    Parameter model.decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,785][root][DEBUG] - Parameter model.decoder.block.9.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,785 DEBUG    Parameter model.decoder.block.9.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,785][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,785 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,786][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,786 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,786][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,786 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,786][root][DEBUG] - Parameter model.decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,786 DEBUG    Parameter model.decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,786][root][DEBUG] - Parameter model.decoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,786 DEBUG    Parameter model.decoder.block.10.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,787][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,787 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,787][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,787 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,787][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,787 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,787][root][DEBUG] - Parameter model.decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,787 DEBUG    Parameter model.decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,788][root][DEBUG] - Parameter model.decoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,788 DEBUG    Parameter model.decoder.block.10.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,788][root][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,788 DEBUG    Parameter model.decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,788][root][DEBUG] - Parameter model.decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,788 DEBUG    Parameter model.decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,788][root][DEBUG] - Parameter model.decoder.block.10.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,788 DEBUG    Parameter model.decoder.block.10.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,788][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,788 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,789][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,789 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,789][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,789 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,789][root][DEBUG] - Parameter model.decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,789 DEBUG    Parameter model.decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,789][root][DEBUG] - Parameter model.decoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,789 DEBUG    Parameter model.decoder.block.11.layer.0.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,789][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,789 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,790][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,790 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,790][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,790 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,790][root][DEBUG] - Parameter model.decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","2022-08-15 00:09:32,790 DEBUG    Parameter model.decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768]), require_grad=True\n","[2022-08-15 00:09:32,790][root][DEBUG] - Parameter model.decoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,790 DEBUG    Parameter model.decoder.block.11.layer.1.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,790][root][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","2022-08-15 00:09:32,790 DEBUG    Parameter model.decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768]), require_grad=True\n","[2022-08-15 00:09:32,791][root][DEBUG] - Parameter model.decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","2022-08-15 00:09:32,791 DEBUG    Parameter model.decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072]), require_grad=True\n","[2022-08-15 00:09:32,791][root][DEBUG] - Parameter model.decoder.block.11.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,791 DEBUG    Parameter model.decoder.block.11.layer.2.layer_norm.weight: torch.Size([768]), require_grad=True\n","[2022-08-15 00:09:32,791][root][DEBUG] - Parameter model.decoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","2022-08-15 00:09:32,791 DEBUG    Parameter model.decoder.final_layer_norm.weight: torch.Size([768]), require_grad=True\n","Iteration:   0% 0/1082 [00:00<?, ?it/s]The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","Iteration: 100% 1082/1082 [46:16<00:00,  2.57s/it]\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","[2022-08-15 00:55:54,968][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-15 00:55:54,968 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-15 00:55:55,741][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-15 00:55:55,741 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-15 00:55:55,742][filelock][DEBUG] - Attempting to acquire lock 140577106419088 on /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748.lock\n","2022-08-15 00:55:55,742 DEBUG    Attempting to acquire lock 140577106419088 on /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748.lock\n","[2022-08-15 00:55:55,743][filelock][DEBUG] - Lock 140577106419088 acquired on /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748.lock\n","2022-08-15 00:55:55,743 DEBUG    Lock 140577106419088 acquired on /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748.lock\n","[2022-08-15 00:55:55,743][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpghsgavpc\n","2022-08-15 00:55:55,743 INFO     https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpghsgavpc\n","[2022-08-15 00:55:55,745][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-15 00:55:55,745 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-15 00:55:56,547][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 482\n","2022-08-15 00:55:56,547 DEBUG    https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 482\n","Downloading: 100% 482/482 [00:00<00:00, 454kB/s]\n","[2022-08-15 00:55:56,550][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json in cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-15 00:55:56,550 INFO     storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json in cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-15 00:55:56,550][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-15 00:55:56,550 INFO     creating metadata file for /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-15 00:55:56,550][filelock][DEBUG] - Attempting to release lock 140577106419088 on /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748.lock\n","2022-08-15 00:55:56,550 DEBUG    Attempting to release lock 140577106419088 on /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748.lock\n","[2022-08-15 00:55:56,550][filelock][DEBUG] - Lock 140577106419088 released on /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748.lock\n","2022-08-15 00:55:56,550 DEBUG    Lock 140577106419088 released on /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748.lock\n","[2022-08-15 00:55:56,551][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-15 00:55:56,551 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-15 00:55:56,551][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-15 00:55:56,551 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-15 00:55:56,553][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-15 00:55:56,553 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-15 00:55:57,327][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","2022-08-15 00:55:57,327 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 0\n","[2022-08-15 00:55:57,329][filelock][DEBUG] - Attempting to acquire lock 140577106419088 on /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n","2022-08-15 00:55:57,329 DEBUG    Attempting to acquire lock 140577106419088 on /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n","[2022-08-15 00:55:57,329][filelock][DEBUG] - Lock 140577106419088 acquired on /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n","2022-08-15 00:55:57,329 DEBUG    Lock 140577106419088 acquired on /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n","[2022-08-15 00:55:57,330][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp2v72764x\n","2022-08-15 00:55:57,330 INFO     https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp2v72764x\n","[2022-08-15 00:55:57,331][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-15 00:55:57,331 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-15 00:55:58,109][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 898823\n","2022-08-15 00:55:58,109 DEBUG    https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/roberta-large-vocab.json HTTP/1.1\" 200 898823\n","Downloading: 100% 899k/899k [00:00<00:00, 973kB/s]\n","[2022-08-15 00:55:59,033][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json in cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-15 00:55:59,033 INFO     storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json in cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-15 00:55:59,034][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-15 00:55:59,034 INFO     creating metadata file for /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-15 00:55:59,034][filelock][DEBUG] - Attempting to release lock 140577106419088 on /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n","2022-08-15 00:55:59,034 DEBUG    Attempting to release lock 140577106419088 on /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n","[2022-08-15 00:55:59,034][filelock][DEBUG] - Lock 140577106419088 released on /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n","2022-08-15 00:55:59,034 DEBUG    Lock 140577106419088 released on /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n","[2022-08-15 00:55:59,036][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-15 00:55:59,036 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-15 00:55:59,807][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","2022-08-15 00:55:59,807 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 0\n","[2022-08-15 00:55:59,809][filelock][DEBUG] - Attempting to acquire lock 140580438364240 on /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","2022-08-15 00:55:59,809 DEBUG    Attempting to acquire lock 140580438364240 on /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","[2022-08-15 00:55:59,809][filelock][DEBUG] - Lock 140580438364240 acquired on /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","2022-08-15 00:55:59,809 DEBUG    Lock 140580438364240 acquired on /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","[2022-08-15 00:55:59,809][transformers.file_utils][INFO] - https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpn4rrhw94\n","2022-08-15 00:55:59,809 INFO     https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpn4rrhw94\n","[2022-08-15 00:55:59,811][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-15 00:55:59,811 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-15 00:56:00,582][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 456318\n","2022-08-15 00:56:00,582 DEBUG    https://s3.amazonaws.com:443 \"GET /models.huggingface.co/bert/roberta-large-merges.txt HTTP/1.1\" 200 456318\n","Downloading: 100% 456k/456k [00:00<00:00, 618kB/s]\n","[2022-08-15 00:56:01,322][transformers.file_utils][INFO] - storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt in cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-15 00:56:01,322 INFO     storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt in cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-15 00:56:01,322][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-15 00:56:01,322 INFO     creating metadata file for /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-15 00:56:01,322][filelock][DEBUG] - Attempting to release lock 140580438364240 on /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","2022-08-15 00:56:01,322 DEBUG    Attempting to release lock 140580438364240 on /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","[2022-08-15 00:56:01,323][filelock][DEBUG] - Lock 140580438364240 released on /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","2022-08-15 00:56:01,323 DEBUG    Lock 140580438364240 released on /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","[2022-08-15 00:56:01,323][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","2022-08-15 00:56:01,323 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","[2022-08-15 00:56:01,323][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","2022-08-15 00:56:01,323 INFO     loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","[2022-08-15 00:56:01,406][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): s3.amazonaws.com:443\n","2022-08-15 00:56:01,406 DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n","[2022-08-15 00:56:02,174][urllib3.connectionpool][DEBUG] - https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","2022-08-15 00:56:02,174 DEBUG    https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/roberta-large-config.json HTTP/1.1\" 200 0\n","[2022-08-15 00:56:02,176][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","2022-08-15 00:56:02,176 INFO     loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n","[2022-08-15 00:56:02,176][transformers.configuration_utils][INFO] - Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","2022-08-15 00:56:02,176 INFO     Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","[2022-08-15 00:56:02,178][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-15 00:56:02,178 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-15 00:56:03,099][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","2022-08-15 00:56:03,099 DEBUG    https://cdn.huggingface.co:443 \"HEAD /roberta-large-pytorch_model.bin HTTP/1.1\" 200 0\n","[2022-08-15 00:56:03,101][filelock][DEBUG] - Attempting to acquire lock 140580449094736 on /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536.lock\n","2022-08-15 00:56:03,101 DEBUG    Attempting to acquire lock 140580449094736 on /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536.lock\n","[2022-08-15 00:56:03,102][filelock][DEBUG] - Lock 140580449094736 acquired on /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536.lock\n","2022-08-15 00:56:03,102 DEBUG    Lock 140580449094736 acquired on /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536.lock\n","[2022-08-15 00:56:03,102][transformers.file_utils][INFO] - https://cdn.huggingface.co/roberta-large-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmptfgq1795\n","2022-08-15 00:56:03,102 INFO     https://cdn.huggingface.co/roberta-large-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmptfgq1795\n","[2022-08-15 00:56:03,105][urllib3.connectionpool][DEBUG] - Starting new HTTPS connection (1): cdn.huggingface.co:443\n","2022-08-15 00:56:03,105 DEBUG    Starting new HTTPS connection (1): cdn.huggingface.co:443\n","[2022-08-15 00:56:03,500][urllib3.connectionpool][DEBUG] - https://cdn.huggingface.co:443 \"GET /roberta-large-pytorch_model.bin HTTP/1.1\" 200 1425941629\n","2022-08-15 00:56:03,500 DEBUG    https://cdn.huggingface.co:443 \"GET /roberta-large-pytorch_model.bin HTTP/1.1\" 200 1425941629\n","Downloading: 100% 1.43G/1.43G [01:16<00:00, 18.7MB/s]\n","[2022-08-15 00:57:19,654][transformers.file_utils][INFO] - storing https://cdn.huggingface.co/roberta-large-pytorch_model.bin in cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","2022-08-15 00:57:19,654 INFO     storing https://cdn.huggingface.co/roberta-large-pytorch_model.bin in cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","[2022-08-15 00:57:19,655][transformers.file_utils][INFO] - creating metadata file for /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","2022-08-15 00:57:19,655 INFO     creating metadata file for /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","[2022-08-15 00:57:19,655][filelock][DEBUG] - Attempting to release lock 140580449094736 on /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536.lock\n","2022-08-15 00:57:19,655 DEBUG    Attempting to release lock 140580449094736 on /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536.lock\n","[2022-08-15 00:57:19,655][filelock][DEBUG] - Lock 140580449094736 released on /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536.lock\n","2022-08-15 00:57:19,655 DEBUG    Lock 140580449094736 released on /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536.lock\n","[2022-08-15 00:57:19,656][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","2022-08-15 00:57:19,656 INFO     loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n","[2022-08-15 00:57:28,361][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing RobertaModel.\n","\n","2022-08-15 00:57:28,361 INFO     All model checkpoint weights were used when initializing RobertaModel.\n","\n","[2022-08-15 00:57:28,362][transformers.modeling_utils][INFO] - All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","2022-08-15 00:57:28,362 INFO     All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.\n","calculating scores...\n","computing bert embedding.\n","100% 89/89 [00:09<00:00,  8.96it/s]\n","computing greedy matching.\n","100% 136/136 [00:01<00:00, 102.55it/s]\n","done in 11.29 seconds, 766.99 sentences/sec\n","[2022-08-15 00:57:40,033][root][INFO] - test data set : ET_test.txt\n","2022-08-15 00:57:40,033 INFO     test data set : ET_test.txt\n","[2022-08-15 00:57:40,033][root][INFO] - N-grams: 1-0.13736968594122478, 2-0.06360221572724412, 3-0.01867504622065322, 4-0.007282852234759778\n","2022-08-15 00:57:40,033 INFO     N-grams: 1-0.13736968594122478, 2-0.06360221572724412, 3-0.01867504622065322, 4-0.007282852234759778\n","[2022-08-15 00:57:40,033][root][INFO] - BERT-P:0.795515, BERT-R:0.867382, BERT-F1:0.829264\n","2022-08-15 00:57:40,033 INFO     BERT-P:0.795515, BERT-R:0.867382, BERT-F1:0.829264\n"]}],"source":["!HYDRA_FULL_ERROR=1 python eval.py hydra.job.chdir=False hydra.verbose=True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiRHm4nruPw9"},"outputs":[],"source":["!kill $(ps aux | awk '{print $2}')"]},{"cell_type":"code","source":[""],"metadata":{"id":"WPTZiAzwc_WZ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"cmd_train.ipynb","provenance":[],"mount_file_id":"1Mrwlgkjv2G7LOLpOtCehzWxaTRu9sXPA","authorship_tag":"ABX9TyM2dd7XQjK7MtzbhdCWkdas"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}