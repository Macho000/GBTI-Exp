cuda: True
debug: False
save_dir: save
name: JointGT
tokenizer_path: pretrain_model/jointgt_bart # pretrain_model/jointgt_bart or  pretrain_model/jointgt_t5
model_path: pretrain_model/jointgt_bart # pretrain_model/jointgt_bart or  pretrain_model/jointgt_t5
train_dataset: ET_1_1_train.txt # ET_train.txt or ET_1_1_train.txt or ET_1_n_train.txt
pretrained_model: Bart # Bart or T5
append_another_bos: False
append_sep_token: False
is_in_edge: True
is_out_edge: True
max_node_length: 50
max_edge_length: 60
max_epoch: 100 # default: 100
train_batch_size: 8
valid_batch_size: 8
test_batch_size: 8
num_workers: 4 # debug 0
temperature: 0.5
n_gpus: 1
max_input_length: 256
max_output_length: 128
gradient_accumulation_steps: 1
max_grad_norm: 1.0
early_stopping: True
optimizer:
  algorithm: Adam
  learning_rate: 1.0e-04
valid:
  valid_dataset: ET_1_1_valid.txt # ET_valid.txt or ET_1_1_valid.txt or ET_1_n_valid.txt or ET_unobserved_vaild.txt
  valid_epoch: 1
  num_beams: 5
  length_penalty: 1.0
  max_output_length: 128
  clean_up_spaces: True
  save_outputs: True
  save_one_batch: True
test:
  test_dataset: ET_1_1_test.txt # ET_test.txt or ET_1_1_test.txt or ET_1_n_test.txt or ET_unobserved_test.txt
  save_outputs: True